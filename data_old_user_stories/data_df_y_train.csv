As a developer Id want to document the limitations of HSQL DB when using composed jobs,1
As a user I would like to have an option to write data into Hive sink so that I can query and manage large datasets in distributed storage,5
As a stream definer when defining a stream ending with a file sink I would like to have more flexibility for naming the file Add an alternative --nameExpression option allowing complete control over the finename-generator-expression attribute See httpstackoverflowcomquestions28466477issue-with-file-sink-and-filename-expression2846706928467069,1
As a developer Id like to upgrade to SI 422GA release so I can leverage the latest improvements,1
As a s-c-d user Id like to create a new banner so I can embed and display the banner when the shell server boots-up Perhaps use this banner generatorhttppatorjkcomsoftwaretaagpdisplayfStandardtSpring20Cloud0AData20Flow20203E3E3E3E3E20,1
As a user Id like to use Boot-based ModuleRunner for use in container-managed environments so I can run XD without xd-containers Scope,5
As a developer Id like to update all the module docs to also include shortDescription so that its available for users to learn more about the module,2
As a user Id like to add the Hadoop namenode specifics in a config file so that I dont have to incur the hassle of pointing to the namenode location every time I open a new DSL session but it is automatically configured,3
As a user Id like to use SFTP source module so I can create streaming pipeline with it However I cannot see SFTP as OOTB module listed on module list and as well as the module bits are not available in maven repohttprepospringiolibs-snapshotorgspringframeworkcloudstreammodule,1
As a developer Id like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD Challenge Detailshttpwwwdebs2015orgcall-grand-challengehtml,8
As a developer Id like to have the option of CoAP source module so I can consume data using bandwidth efficient protocol that fits in constrained embedded environment,3
As a Spring XD developer Id like to move tcp-client module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a user Id like to have API and Documentation links in the Abouthttpsgithubcomspring-projectsspring-xdblobmasterspring-xd-uiappscriptssharedviewsabouthtml section within admin-ui It would be ideal to have the version dynamically replaced for every release,1
As a Spring XD user Id like to create streaming pipelines so I can take advantage of latest specs from both XD and SparkSpark Streaming,3
As a developer Id like to replace all Jobs references with Tasks,2
As a user Id like to have the option of reliable HDFS writes for stream pipelines so I can get acknowledgement of actual HDFS commits as opposed to just from the message bus,5
As a user Id like to use the GF source along with native GF authentication enabled so I can consume data from GF in a secured way Id like to refer to documentation on where the GF specific native and security properties needs configured See this SC posthttpsgopivotal-comsocialcastcommessages24377202 for more details,1
As a developer Id like to update to Spring Hadoop 220 GA release so I can leverage the latest improvements,1
As a CF user Id like to have the ability to override the YARN config location so that I can change where the custom module uber-jar can be stored and retrieved,3
As a s-c-d developer Id like to collaborate with Boot engineering team and derive a strategy for module metadata via ConfigurationProperties so I can implement the functionality to support shell autocompletion flo and ascii documentation in spring-cloud-data Erics gap analysishttpsdocsgooglecomdocumentd1A-9RpgSNL6SXD61q9eW2YRkrkn3tXk09rdkx7eCKlxYedit document captures all the specifics in detail,8
As a PM Id like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds,8
As a QA Id like to include acceptance test coverage for router sink module so that I can validate the functionality as part of every CI build,3
As a Flo user Id like to have timeout and pollInterval as global options at the DSL level so I can override the defaults at will,1
As a developer Id like override the partition function within my source or processor module so I can send the data to a specific partition,5
As a developer Id like to handle the non-default ConfigurableConversionService tuples in an uniform manner so theyre not reset after deserialization,5
As a user Id like to have Spring Core upgraded to 411 milestone so that I can benefit from performance improvements associated with compiled SpEL and other enhancements,3
As a s-c-s developer Id like to setup CI builds for s-c-s builds so I can incrementally build and test code commits automatically,3
As a user Im trying to setup HA cluster using Ambari installed Spring XD however Im running into issues with the overrides More details herehttpsgithubcomspring-projectsspring-xd-ambariissues6,5
As a QA Id like to include acceptance test coverage for reactor-syslog source module so that I can validate the functionality as part of every CI build,3
As a developer Id like to create a end-to-end Kafka use-case so I can study demonstrate and verify kafka xd play thats built for scale and performance,3
As a s-c-s developer Id like to setup CI infrastructure for spring-cloud-stream-modules s-c-s-m repo so I can build the project continuously on every commits,3
As a user Id like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios,3
As a QA Id like to include acceptance test coverage for aggregator processor module so that I can validate the functionality as part of every CI build,3
As a user Id like to have the option to version the custom modules so I can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly,5
As a developer Id like to upgrade to 060 release of Lattice so I can demonstrate data flow on the latest Lattice improvements,5
As a developer Id like to port field-value-counter module from XD to s-c-s repo so I can use it as sink module to build streaming pipeline,2
As a developer Id like to port gauge module from XD to s-c-s repo so I can use it as sink module to build streaming pipeline,2
As a Spring XD developer Id like to move mongo module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline,2
As a developer Id like to build Spark Streaming as data processors in XD so that we can demonstrate some of the capabilities Implement using Java Java Lambdas Scala,8
As a XD developer Id like to upgrade to SI 42 Spring 421 and AMQP 15 dependencies so I can take advantage of the latest improvements,3
As a s-c-s developer Id like to adapt redis counter from XD to s-c-s so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards,3
As a developer Id like to add undeployed status for Lattice SPI so I can represent the correct status instead of the current unknown state,3
As a user Id like to have the option to specify system properties that will be passed in to the Sqoop job which runs in its own Java process This is needed for defining memory usage and also for defining some options for various connector implementations,5
As a user Id like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository metadata persistence The scope of this task is to have the configuration specifics documented in the wiki,2
As a user Id like to have the option to write into File Roll sink so that I can store events on the local file system,8
As a s-c-s developer Id like to move spring-cloud-stream-modules from s-c-s to s-c repo so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s,3
As a user Id like to have the option to read the file line by line so I get the optional OOTB optimum file reading experience,8
As a user Id like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed metadata options,1
As a developer Id like to upgrade to 221 GA release so I can leverage the latest improvements without breaking backwards compatibility SHDP 230 uses Boot 13 and HDP and CDH versions that drop older Hive support To avoid breaking changes we should instead use SHDP 221 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones,1
As a user Im trying to use counter sink with SpEL expression but Im not able to use them in combination It throwshttpsgithubcomspring-cloudspring-cloud-stream-modulesblobmastercounter-sinksrcmainjavaorgspringframeworkcloudstreammodulemetricsCounterSinkPropertiesjavaL77 exactly one of name and nameExpression must be set as error message,1
As a user Id like to have the option to enable HTTPS so that I can access XDs Admin server endpointshttpsgithubcomspring-projectsspring-xdwikiREST-APIxd-resources over secured communication Technical Implementation This functionality is available in Spring Boot 120 M1 and has been backported into the 11x branch to be released under Spring 117 We can test against 117 SNAPSHOT Working through the way to update the build file to pick up a new version of boot is a bit tricky,1
As a Spring XD user Id like to have IPython Notebook integration so I can perform interactive data computations in real-time,8
As a user I would like to connect the Sqoop batch job to Teradata for import jobs I have tried the Teradata JDBC driver directly using codejob create tdTest --definition sqoop --commandimport --args--table FrequentFlyers --connect jdbcteradatatdexpressDATABASEtransportation --driver comteradatajdbcTeraDriver --username dbc --password dbc --target-dirxdteradata --num-mappers 1 code but that results in an NPE The only way so far is to use the Hortonworks Connector for Teradata - httppublic-repo-1hortonworkscomHDPtools2242hdp-connector-for-teradata-1342242-2-distrotargz That one allows me to use the following codejob create tdTest --definition sqoop --commandimport --args--table FrequentFlyers --connect jdbcteradatatdexpressDATABASEtransportation --connection-manager orgapachesqoopteradataTeradataConnManager --username dbc --password dbc --target-dirxdteradata --num-mappers 1 code,3
As a user Id like to have a config parameter preferably in serversyml file so that I can enabledisable message rates in the cluster view,2
As a user Id like to have the option of SOLR sink so that I can perform full-text indexing and search through SOLR backend server,5
As a user Id like to have the option to gracefully shutdown the stream so when it is undeployed while in the middle of its operation we would want to complete its journey to the sink before XD stops the stream Use case One of the streams has a custom module that performs archive extraction When this stream is undeployed while in the middle of extraction It looks like the message goes to the DLQ However we would like the message to complete its journey to the sink of the queue before xd stops the stream Is this possible,8
As a user I want to be able to provide the partitioning logic for a named destination so that I can control the ordering of outbound messages,1
As a developer Id like to define pluggable runtime SPI so I have the option to choose the implementation based on deployment targets such as CF on-prem Mesos etc,5
As a Spring XD developer Id like to move cassandra module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,5
As a field engineer Id like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint,8
As a developer Id like to upgrade to SHDP 212 GA so that I can sync-up with latest features,1
As a user Id like to see the version and SPI type in the about section so I can confirm which build of admin-ui Im currently using,1
As a performance tester Id like to investigate why theres high CPU startup time for both admin and container servers Perhaps profiling would assist isolating the bottlenecks Scope Identify the bottlenecks Document reasons List proscons,8
As a spring-cloud-data developer Id like to use an in-memory stream definition repository so I dont have to spin up a store obviously this will not persist between application executions but it will be useful for a simplified development experience,5
As a developer Id like to bench test cases around TupleBuilder so I can identify the bottlenecks and tune for performance optimizations,8
As a user Im trying to delete the custom module using the module delete command via shell though the command is successfully Im still seeing the associated artifact jar file present in the custommodules folder Refer to SO threadhttpstackoverflowcomquestions30984922springxd-module-delete-command-does-not-delete-the-uploaded-jar-file for more details,5
As a developer Id like to upgrade to 203 release of Reactor so I can inherit the latest optimizations to further improve XD performance characteristics,3
As a developer I want to have a BinderFactory abstraction so that I can support multiple binder types in the future,5
As a user Id like to have concurrency and compression support for Kafka so that I can increase performance throughput andor increase responsiveness Things to consider make global configuration options be defaults and allow per-deployment overrides add options for concurrency compression support,3
As a developer Id like to add support for undeployed status consistently across all the deployers so I can present the correct status instead of the current unknown This is applicable for existing streams without any deployment context associated with it,1
As a user Id like to upgrade to Spring Boot 123 release do I can leverage the latest improvements and bug fixes We should also sync-up the following dependency updates to synchronize with Boothttpsgithubcomspring-projectsspring-bootblobmasterspring-boot-dependenciespomxml code logbackversion113logbackversion jacksonversion251jacksonversion gemfireversion800gemfireversion h2version14185h2version javax-mailversion153javax-mailversion undertowversion123Finalundertowversion joda-timeversion27joda-timeversion nekohtmlversion1921nekohtmlversion activemqversion5111activemqversion antlr2version277antlr2version commons-dbcp2version201commons-dbcp2version tomcatversion8021tomcatversion aspectjversion185aspectjversion groovyversion243groovyversion crashubversion131crashubversion jettyversion929v20150224jettyversion elasticsearchversion144elasticsearchversion flywayversion321flywayversion freemarkerversion2322freemarkerversion jdom2version206jdom2version liquibaseversion332liquibaseversion mockitoversion11019mockitoversion mongodbversion2130mongodbversion slf4jversion1711slf4jversion spring-cloud-connectorsversion111RELEASEspring-cloud-connectorsversion spring-securityversion401RELEASEspring-securityversion jedisversion262jedisversion spring-wsversion221RELEASEspring-wsversion code,1
As a QA Id like to benchmark Sqoop vs jdbchdfs batch job so that I can compare and contrast performance stats,5
As a s-c-s user Id like to use kinesis module so I can use it as source module to build streaming pipeline,2
As a developer Id like to revisit performance benchmarks with new improvements so I can verify the optimizations around jdbchdfs,1
As a developer Id like to upgrade to SI milestoneGA release so I can synchronize with JMX improvements This is dependent on SI Milestone and GA release timelines,1
As a user Id like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner Ideally all the listed endpoints httplocalhost9393 needs to be encapsulated within LDAP based security layer Reference Authentication using LDAPhttpsspringioguidesgsauthenticating-ldap,8
As a QA Id like to include acceptance test coverage for aggregate-counter sink module so that I can validate the functionality as part of every CI build,3
As a s-c-d developer Id like to enhance integration test coverage for YARN SPI so I can continuously evaluate functionalities via CI pipeline,5
As a developer Id like to split up spring-xd dependencies to more fine-grained so I can get the ones below the line down to spring-bus- instead of spring-xd- bundle,8
As a QA Id like to include acceptance test coverage for richgauge sink module so that I can validate the functionality as part of every CI build,3
As a developer Id like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience,3
As a developer Id like to create a example to demonstrate JDBC to HDFS data movement,8
As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment Best way for now would be to add an info command to the xd-yarn script With the latest changes the admin server runs on a random port when we deploy to YARN In order for the user to connect they would have to query Zookeeper This is inconvenient,5
As a user Id like to implement the core interface contract so that I can create a processor module that uses RxJava API,1
As a developer Id like to add undeployed status for CF SPI so I can represent the correct status instead of the current unknown state,3
As a user I want Spring XDs message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesnt happen when a container crashes andor its redeployed,8
As a s-c-s user Id like to investigate the possibility of s-c-s modules self-registering themselves to service discovery so I could use Spring XD runtime running on CF to discover and orchestrate such modules through streams,8
As a continuation we would like to further investigate Spark develop POC and identify the best appropriate design and implementation for XD,8
As a user I want to know my configuration options are for enabling SSLHTTPS and Basic authentication for administration endpoints so that I can secure my application,1
As a Flo developer Id like to add improvements to existing Flo parser endpoints so I can streamline the error reporting strategy,3
As a CF user Id like to have the ability to override the HDFS location so that I can change where the custom module uber-jar can be stored and retrieved,3
As a user Id like to have the option of editing the deployedundeployed stream so that I dont have to destroy to just change any deployment property,8
As a s-c-d user Id like to deploy data flow on YARN so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines,2
As a user Id like to use the latest release of gemfire sink so I can create a streaming pipeline to land data in gemfire,2
As a s-c-d developer Id like to move kafka module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a Spring XD developer Id like to move jdbc module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a user Id like to have a generator source module so that I can create a number of messages of a specified size similar to Rabbits PerfTest utility Example generator --numMsgs 10000 --msgSize 1024 --numThreads 1,8
As a s-c-d developer Id like to have module info module list module register and module unregister commands so I can interact with ModuleRegistry,8
As a user Im trying to connect to xd-admin server with basic security enabled however Im unable to successfully connect to the server and I get the following error message codejava server-unknownadmin config server --uri httplocalhost9393 --username bob --password bobspwd Unable to contact XD Admin Server at httplocalhost9393 code,5
As a follow-up to Kafka message bus support we would like to rerun the failing tests after upgrading to new consumerhttpscwikiapacheorgconfluencedisplayKAFKAKafka09ConsumerRewriteDesign rewrite Response from Kafka supporthttpmail-archivesapacheorgmodmboxkafka-users201410mbox3CCAHwHRrWZmLr94eHX1z5i36BYz2B3DCisx7GcbW1Nn7ooNJcShMw40mailgmailcom3E,3
As a user Id like to use the Mail source to connect to secured IMAP andor SMTP mail servers Mail source config file requires a utilproperties bean with ssltls properties provided to the adapter via the java-mail-properties attribute Ref Examplehttpdocsspringiospring-integrationdocslatest-gareferencehtmlmailhtml codexml beansbeans profiledefault utilproperties idjavaMailProperties beansprop keymailimapsocketFactoryclassjavaxnetsslSSLSocketFactorybeansprop beansprop keymailimapsocketFactoryfallbackfalsebeansprop beansprop keymailstoreprotocolimapsbeansprop beansprop keymaildebugfalsebeansprop utilproperties beansbeans code List of all java-mail propertieshttpsjavamailjavanetnonavdocsapicomsunmailsmtppackage-summaryhtml,1
As a developer Id like to get rid off XDRuntimeException from XD,1
As a user Id like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended,1
As a user Id like to have a R processor so I can efficiently perform data computations and statistical analysis in the context of streaming pipeline Investigate the right approach that fits Spring XD model R Java Libraries rJavahttprforgenetrJava Renjinhttpwwwrenjinorg,8
As a XD developer Id like to move header-enricher from modules repo to XD proper,1
As a user Id like to parameterize all Import Options so I can eliminate the need for args option since it gets confusing,2
As a user Id like to be able to understand the root cause of an error on the http shell command When an exception occurs on an http shell command the user gets Failed to access http endpoint s target No information from the exception is conveyed to the user nor is it logged by the admin,1
As a scala developer someone could easily deploy the spark streaming module developed using scala,8
As a developer Id like to move serialization codec from Spring XD repo into spring-bus so I can update Spring XD to inherit the featuresfunctionalities via maven dependency,8
As a s-c-d developer Id like to add support to add external libraries so I can consume such dependencies for modules in an uniform way,2
As a user Id like to retain the data partitioning state so that when I restart the containers I continue to write based on the original partitioning strategy Currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different hashCode Design consideration Mine through the container info to derive the partition index instead of relying on hashCode,5
As a developer Id like to have acceptance test coverage for XD YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle,8
As a developer Id like to move serialization codec from Spring XD repo into SI so I can update Spring XD to inherit the featuresfunctionalities via maven dependency,2
As a developer Id like to upgrade to Reactor 204 release so I could leverage the latest improvements and bug-fixes,1
As a developer Id like to study the state management requirements so I can brainstorm and identify the design to natively add stateful stream processing support in XD,8
As a developer Id like to have an OOTB MVC-aware HTTP module with embedded tomcat so I can use this module to leverage spring-mvc and spring-security features instead of rewriting them within the existing HTTP source module Adds richer support for content-type in the HTTP Source module See jbrisbin comments httpsgithubcomspring-projectsspring-xdpull879 Adds full header mapping in the source see comments See SO request httpstackoverflowcomquestions29353471spring-xd-as-a-rest-endpoint,8
As a developer I want that the Spring XD partitioning process targets Kafka bus partitions directly so that the design of my stream processing application is easier to understand and the order of messages is not altered Current situation - Spring XD partitioning logic that builds on top of Kafka partitioning - The number of Spring XD partitions is not explicitly configured its inferred from the number of consumer modules - If the concurrency of the consumer modules is 1 then Spring XD partitions are matched 11 with Kafka partitions - If the concurrency of the consumer modules is n then a Spring XD partition uses n Kafka partitions and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions - this could be confusing to the end user especially if they are used to the Kafka partitioning process - this can also lead to changes of ordering between messages as messages within the same Spring XD partitions will be sent to different Kafka partitions this only happens if the concurrency of the receiving module is higher than 1 Improvement - For the Kafka message bus the number of Spring XD partitions does not need to be equal to the number of modules must be higher or equal though so that consumers can be created and should be configured explicitly - using the partitionCount property - as an option the module count concurrency can be used as a default - as a result in the case of Kafka there will always be a 11 match between Kafka partitions and Spring XD partitions optionally processed by fewer modules than the partition count,5
As a user Id like to see the date in logs so that I can troubleshoot issues that had occurred on a specific day and time Property that needs adjusted httpsgithubcomspring-projectsspring-xdblobmasterconfigxd-container-loggerpropertiesL11,1
As a user Id like to leverage propertieis-location parameter while using Filter or Transform modules so that I can load the user-defined properties included in the external properties file Attempting to include the propertieis-location attribute errors out - refer to the attachment It could also be beneficial to load user-defined properties through stream definition similar to deployment properties Example --scriptmyscriptgroovy --variablesfoobargoogaz,5
As a s-c-d user Id like to have runtime info as shell command so I can use this to list the details about the module such as host port and the like,5
As a user Id like to have a flexible RxJava module so that it can as a processor,8
As a user Id like to type the username and password to gain access to Admin server so that I dont have to add it in some file hence I dont have to worry about having the password getting logged somewhere,5
As a s-c-d user Id like to have the option of Gemfire as module registry so I can build data pipelines that are entirely orchestrated within Gemfire,8
As a user Id like to have a common shared location so that I can place the dependent jars that are required by 2 or more custom modules Current Recommendation Place the dependent jar under xdlib folder if it necessary to support different versions of jars then bundle it in custom module to get around the classloader problem if a oldernewer version exist in xdlib,5
As a user Id like to define security definitions so that I can configure entity REST API specific grouprole access policies,8
As a developer Id like to certify Spring XD against PHD 30 so I can synchronize with the latest ODP based bits,3
As a Spring XD developer Id like to port analytic-pmml module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,5
As a user Id like to have the ability to configure ACLs so that I can restrict access to resources accessed via Admin UI Examples Who can create streams Who can destroy the streams Who can view the streams defaults to all,8
As a Spring XD developer Id like to port http-client module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,2
As a user Id like to enable HA on namenode without having to enable custom configuration More details herehttpsgithubcomspring-projectsspring-xd-ambariissues6,3
As a developer Id like to add support for dynamic partition subscription for the Kafka source module so I can consume the payload from dynamic partitions,5
As a Spring XD developer Id like to have a permanent location of SPI implementations so I could use the common repo every time I contribute or enhance the test coverage,3
As a Spring XD developer Id like to move syslog module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a user I should be able to leverage native ElasticSearch sink so that I can aggregate search and analyze data insights in real-time,8
As a developer Id like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized,5
As a s-c-d user Id like to have the option to support passing definition parameters into YARN container so I can effectively use those params within the module running inside the container,3
As a Spring XD developer Id like to move jms module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline,2
As a user Id like to have the ability to configure ACLs so that I can restrict access to resources accessed via DSL Shell Examples Who can create streams Who can destroy the streams Who can view the streams defaults to all,8
As a developer Id like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors This fix needs to be formally applied in Spring Batch itself XD will upgrade to Batch release in order to inherit this functionality hence the current workaround with XD-2486 needs reafctored,5
As a QA Id like to include acceptance test coverage for spark-app batch job so that I can validate the functionality as part of every CI build,5
As a developer Id like to add support to flush state intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer,8
As a user Id like to override the default commit-interval so that I can configure commit interval depending on data volume Note This would apply for all OOTB jobs that has partition support The property could be part of serversyml file,3
As a user Id like to have the option of WebSocket source module so that I can create a interactive communication channel between users browser session and the runtime to ingest browser based events and activities Reference Spring Integration WebSocket Supporthttpsgithubcomspring-projectsspring-integrationtreemasterspring-integration-websocketsrc,3
As a Spring XD developer Id like to move twittersearch module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline,2
As a developer Id like to review and refactor JobLaunchingTasklet so I can improve performance characteristics,3
As a developer Id like to rerun baseline Tuple and Serialized payloads so I can compare the differences in performance between 081 and 082 Kafka releases Note 111 Benched against 081 12 Benched against 082,8
As a developer I in the new development of component sourceprocessorsink how to get the module id and container id Because components need to generate log log information must include the unique identifier xdruntime modules,1
As a developer Id like to resolve remaining gaps wrt CI pipelines for Data Flow and the family so I can continuously evaluate functionalities on every commit,8
As a user Id like to have an option to track history so that I get the visibility of stream name module name etc added as part of the message header,3
As a developer I want to have to run Kafka tests on an external broker so that I reduce the footprint of the build process,2
As a user Id like to refer to the documentation to configure the properties file so I can use it as recommended to represent the deployment manifest,1
As a user Id like to have the option to use the SFTP source module so that I can access transfer and mange files over any reliable data streams Reference Spring Integration SFTP Adapterhttpdocsspringiospring-integrationreferencehtmlsftphtml Need to consider the infrastructure for testing,2
As a developer Id like to build isolated Boot-based ModuleRunner for use in container-managed environments so I can run XD without the hard requirement for running xd-containers,8
As a user Id like to have guidance to create custom modules so that I can align the development practices with recommended approach 1120 Update Scope of this task is to create an example to demonstrate and document the capability,1
As a user Id like to have the ability to access the random port generated by tomcat of the admin server via xd-shell so that I can point to the server and continue my interactions Spike Details Research whether connecting xd-shell directly to ZK is a good approach or have a LB in-charge for the interaction How about something other than a pointer to a ZK directory in the shell for folks to experiment a bit before getting a LB involved Note On some hadoophdfs setups access to zk is mandatory from hdfs client libs There are some HA and federation setups which would anyway require xd shell to get access to zk if fs shell commands are used,8
As a s-c-d developer Id like to enhance unit test coverage for Lattice SPI so I can continuously evaluate functionalities via CI pipeline,3
As a Spring XD user I want to have the ability to customize the encoders and decoders used by the Kafka source sink and bus so that I can customize data formats and choose the most appropriate strategy,5
As a Spring XD developer Id like to port tcp module from XD to s-c-s repo so I can use it as source module to build streaming pipeline,2
As a developer Id like to complete the remaining work with DEBS challenge so I can submit by the deadline,2
As a user Id like to migrate from 10 to 11 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features,2
As a user I want to know how to enable and configure LDAP as an authentication provider for the administration server so that I can set up my security configuration accordingly,1
As a Spring XD developer Id like to move gpfdist module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a user Id like to have an option to specify timeout so I can expect the job to not run forever if it is in hung state,3
As a user Id like to have the custom module built as uber-jar hosted in HDFS so that I can deploy the module to newly arriving containers,8
As a developer Id like to update to SI Kafka extension 120 so I can leverage the latest performance improvements,1
As a Spring XD user Id like to make SPI implementation profile aware so I can run java -jar admin or cf push admin or ltc create admin and the corresponding implementation gets wired-in automatically,3
As a developer Id like to add support to flush offsets intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer,8
As a s-c-d developer Id like to produce ref documentation for s-c-d architecture so I could define 1x and 2x deployment differences,8
As a developer Id like to document performance benchmark results along with the infrastructure specifics so I can publish the blog for customersusers to use it as a reference while setting up Spring XD cluster,8
As a developer Id like to create separate repo for CF SPI so I dont have to bundle all SPI variants under one admin project,3
As a QA Id like to include acceptance test coverage for null sink module so that I can validate the functionality as part of every CI build,3
As a developer Id like revisit the design to determine the necessity for ID and TimeStamp attributes in Tuple so I can refactor in order to improve performance throughput,1
As a user Id like to have the option to ACK messages so that I can guarantee that the messagerequest sent is successful,3
As a user Id like to run the sqoop jobs against secured hdfs cluster so I can restrict access to only authorized users,3
As a s-c-d developer Id like to document the use of BOM templates so the general audience can use it as a reference to include external libraries dynamically,1
As a developer Id like to add undeployed status for k8s SPI so I can represent the correct status instead of the current unknown state,1
As a user Id like to have the option to setup batching so that I can ingest data in batches as opposed to payload-at-a-time,8
As a user Id like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism,5
As a user Id like to refer to documentation while migrating to 13 release,3
As a user Id like to consume multiple topic-partitions so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue,3
As a developer Id like to migrate module deployment from the repository abstraction used for streamjob definitions so I can create it as a pluggable runtime SPI,8
As a developer Id like to build data pipeline using Kafka as as message bus in XD so that we can demonstrate some of the capabilities Use case to consider Log aggregation and analysis Lambda architecture how to avoid code duplication how to eliminate tight coupling of business logic how Kafka can be used for reliable reprocessing,8
As a user Id like to have an OOTB jdbcgpfdist batch job so I can read from JDBC and write to HAWQGPDB using gpfdist protocol The scope is to reuse the existing gpfdist sink code and adapt it to fit the batch model gpfdist writer,8
As a s-c-d developer Id like to create foundation to support processor as OOTB modules so I can use the processor modules from s-c-s-m repo to build streaming pipeline,5
As a user Id like to have an option to have the hdfs sink not use a temporary inUseSuffix like tmp Instead we should write using the filename specified directly This could be useful if we use Syncable writes and the sink fails while the file is open Without this new option the user would have to explicitly rename the file,5
As a developer Id like to update to the 415 SI release so I can pickup the latest improvements to message channels,1
As a developer Id like to split admin artifact packaged with hadoop distro specific libraries so I could avoid adding all variations of hadoop libraries under one project,5
As a user Id like to have the option to change the default Sqoop metastore so I can implement a DB of my choice and not tied to default specifications Refer to this threadhttpstackoverflowcomquestions24078668how-to-change-sqoop-metastore for more details,1
As a consequence of not fixing XD-1289 we should document keys of the form xdstreamname that are available to users xdstreamjobname and xdcontainer come to mind there may be others,4
As a user I should be able to leverage native WebSocket sink so that I can take the advantage of full-duplex communications channels over a single TCP connection,8
As a Spring XD developer Id like to refactor current controller with SPI calls so I can invoke the respective Admin SPI implementation based on the deployment Controllers to Refactor ContainersController StreamsController ModulesController JobsController,5
As a user Id like to have the option to stop an existing Sqoop job so that I can clean-up resources at the time of completion,8
As a Spring XD developer Id like to move tcp module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a QA Id like to include acceptance test coverage for json-tuple processor module so that I can validate the functionality as part of every CI build,3
As a s-c-s developer Id like to setup a CI workflow to build bundle and upload the module-launcher image to DockerHub so I dont have to worry about having a local-private docker registry for developmenttesting It could be nice to have the image uploaded to existing spring-cloudhttpsregistryhubdockercomreposspringcloud DockerHub location,5
As a user Id like to also have the capability to upload the custom module through mavengradle targets so I can automate the installation of custom module fragments,2
As a s-c-d developer Id like to support multiple app instances This is simply to make controlling app instances more clever Potentially we could use deployment properties to define different yarn app instances like code cloud-datastream deploy --name ticktock --properties moduleyarnappnameapp cloud-datastream deploy --name ticktock --properties moduletimeyarnappnameapp code Motivation to this is that different yarn apps can have different queues and priorities Yarn administrator can define that some app queues have higher priority to reserve resources from Using deployment properties like this allows to customize runtime parameters like how much we try to reserve memcpu for modules etc,2
As a Spring XD user Id like to use redissentinel cluster as the message bus so I could create streams and batch pipelines,8
As a Spring XD developer Id like to move stdout module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a user Id like to have the option to explicitly defineconfigure error channel so that I can stage and route the errorsexceptions through the dedicated channel and continue ingestion Scenario http source ingest failure at either source processor or sink module regardless of whether it is a custom module or not traverse through the exception to propagate the actual Caused by stage the error as payload and route it to the error channel Example Configuration error channel definition similar to topicerrorsstreammodule configure custom exception similar to catchException exception hierarchy GlobalException DefaultException ModuleSpecificException,8
As a developer Id like to have a simplified UX around parameters for GPDB so I dont have to escape each parameter The scope is also to test the Sqoop job with SQLServer and GPDB to identify the UX differences,8
As a user Id like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queuestopics,3
As a user Id like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I dont have to manually move and set it up Scope of this spike Assess customer requirement brainstorm and document options Socialize with the team to collect feedback Identify phases Create new stories,8
As a user Id like to upgrade Spring XD from 12 RC to 12 GA using the Ambari plugin so I can work on the latest release bits Id like to refer to the documentation to do so,1
As a user Id like to have the configuration option to use an alternative DLQ so I can publish the message this time with additional headers including one that contains the exception and stack trace,3
As a developer Id like to create separate repo for YARN SPI so I dont have to bundle all SPI variants under one admin project,5
As a developer Id like to create a new load-generator so I can use it to measure highly optimized kryo serialized payload to measure the performance differences,3
As a user Id like to have the option to delete the queuestopics so that we can include an optional attribute as part of the stream destroy command to also clean-up the associated queuestopics Notes Spring-AMQP RabbitAdmin now has a getQueueProperties method which returns the number of consumers so it may be possible to use it for this purpose Consider the possibility of producers andor queues still containing data Consider the scenario even after the topicsqueues are cleaned-up what to do with fanout exchange Some Further Thoughts Consider using the upcoming Spring AMQP REST API RabbitManagementTemplate if the timing is not right we could temporarily invoke the rabbit REST API directly Should be optional perhaps via stream destroy foo --clean Should this be done by the admin Or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queuebindingexchange since we undeploy left-right everything can be cleaned up on the consumer side Third option would be new methods on the bus cleanConsumer etc invoked by the StreamPlugin Down side of doing it on the admin is that he wouldnt necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so wed need the admin urls for the cluster,5
As a user Id like to refer to a Pig scriptjob sample so that I can use that as a reference to integrate Pig jobs in XD,5
As a user Id like to have a Redis based aggregation over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data Scope Port specs from previous implementationhttpsgithubcomspring-projectsspring-xdwikiOLD---Aggregate-Field-Value-Counters Identify gaps Update reference documentation,3
As a Spring XD developer Id like to port json-to-tuple module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,2
As a QA Id like to include acceptance test coverage for mail sink module so that I can validate the functionality as part of every CI build,3
As a s-c-d developer Id like to pass any overrides via external config file so I can influence and override the default module configurations ex module resolution from a different maven coordinate,3
As a minimum we need some common polling strategy on the client side to detect status changes of job streams etc Eg during deployment of streamsjobs Ideally I would like to have this addressed on the server-side as well It would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system We could then use those to notify connected UI clients,3
As a developer Id like to use spring-cloud-config server for spring-bus modules so I can centrally manage external properties,8
As a user Id like to have a sample app GitHub project so that I can use it as a reference while provisioning Spring XD cluster with Kafka Consider Kafka as message bus Kafka as source,8
As a developer Id like to add undeployed status for YARN SPI so I can represent the correct status instead of the current unknown state,3
As a developer Id like to move k8s SPI to its own repo,5
As a developer Id like to migrate the current MASTER branch CI builds to EC2 instances so I can manage them all in one-place reliably,8
As a s-c-s developer Id like to enable offline mode for AetherModuleResolver so I can pull the module artifacts from local instead of remote maven repo,3
As a Spring XD user Id like to use CloudController based implementation of XD Admin SPI based on ModuleLauncher so I can run data pipeline use-cases running on CF Relevant repos spring-cloud-datahttpsgithubcomspring-cloudspring-cloud-datatreemasterspring-cloud-data-module-deployers spring-cloud-streamhttpsgithubcomspring-cloudspring-cloud-stream Please refer to XD-3194 or XD-3229 as sample spike-deliverables google doc that were completed in the last sprint,8
As a user I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth Technical implementation Add ---password and --username to the admin config command,5
As a user Id like to have the option to provide security configurations so that I can access REST endpoints in a secured manner Ideally all the listed RESThttpsgithubcomspring-projectsspring-xdwikiREST-APIxd-resources endpoints needs to be wrapped within a security layer Scope of this spike Research Spring Security and Spring Boot and the OOTB features Design considerations and approach for XD Developer experience How users will be configuring security credentials How DSL shell will be handled How Admin UI will be handled,8
As a user I would like to use fsUri file to use Hadoop LocalFileSystem instead of a running cluster In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job The quickest way to solve this was to change the fsUri to file and it should have just worked This will work alright for singlenode setups for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing,1
As a s-c-d developer Id like to add support for hadoop commands in shell so I can use it to query the hadoop file system,3
As a developer Id like to add load generator source module so that I could use it for performance testing use-cases,3
As a s-c-d user Id like to have the option to choose Hadoop distribution of choice so I can load the right Hadoop libraries in the CP,5
As a s-c-d developer Id like to add test coverage to test shell commands in isolation so I dont have to run end-to-end full stream deployment based functional tests More details herehttpsdocsgooglecomdocumentd18uNqRAgVGO0BHdvDsVg3X78gDBeqXALNC6jJ0YpKwedit,5
As a Spring XD developer Id like to move rabbit module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a s-c-s developer Id like to investigate the right approach to include external library as dependency ex MySQL so I can decide better handling of libraries which needs loaded and available in root CP at the runtime,8
As a user Id like to parameterize Merge Options so I can incrementally consume the delta with the help of megastore,5
As a developer Id like to port aggregate-counter module from XD to s-c-s repo so I can use it as sink module to build streaming pipeline,2
As a developer Id like to be able to clean Rabbit binder broker artifacts using the REST API When the Rabbit Bus was ported from XD the bus cleaner was ported as RabbitBindingCleaner but the REST API to invoke it was not ported over,2
As a user Id like to have the option to compress messages so that I can influence the performance throughput Itd be beneficial to have support for gzip zip compression and decompression,3
As a s-c-d developer Id like to move rabbit module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a s-c-d developer Id like to move the external library to its own project so we have a clear separation of functionalities in s-c-d repo,3
As a s-c-d developer Id like to make the deployer work asynchronously so I can use the shell to return quickly and also queue deploy operations within YARN as tasks,2
As a s-c-d developer Id like to add support to deploy YARN App into HDFS automatically so I can have the xd-admin orchestrate overall deployment by leveraging the manifest to deploy where and with what assets,3
As a user Id like to have shell to automatically configure itself against an environment I have setup This really came up with ambari work where shell can be anywhere in a cluster Best I was able to do for now is to build an init file for commandsambari xd-shell deploy already knows locationsaddresses for xd admin and namenode code cat etcspringxdconfxd-shellinit admin config server httpambari-2localdomain9393 hadoop config fs --namenode hdfsambari-2localdomain8020 code and then run those after starting xd-shell code server-unknownscript --file etcspringxdconfxd-shellinit admin config server httpambari-2localdomain9393 Successfully targeted httpambari-2localdomain9393 hadoop config fs --namenode hdfsambari-2localdomain8020 Script required 0662 seconds to execute xd code,1
As a s-c-d developer Id like to add support for having different binder types for modules channels so I can plug rabbit redis or kafka as the source or sink to read and write respectively,8
As a user I would like to be able to configure the logging directory to be outside of what is defined as xdhome The logging directory is currently hard coded as codexdhomelogscode This would be useful for RPM installations where the logs really should be going to varlogsspring-xd instead of the current optpivotalspring-xdxdlogs location,3
As a s-c-d developer Id like to upgrade receptor-client to comply with latest Receptor API changes so I can sync-up and take advantage of the recent improvements,3
As a performance tester Id like to rerun baseline benchmarks with batching enabled on Rabbit so that I can compare the results with previous performance snapshots Note - batchingEnabled true - batchingSize 100 default We could also vary default size to compute and record at granular level,3
As a developer I would like to connect to the broker that hosts the Rabbit queue so I can connect to a Rabbit cluster thats setup for HAFT Perhaps consider having this feature natively supported in spring amqp itself,3
As a tester Id like to add test coverage for complex objects such protocol buffers any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics,8
As a QA Id like to include acceptance test coverage for gauge sink module so that I can validate the functionality as part of every CI build,3
As a XD Admin Id like to upgrade to Spring Boot 120 RELEASE and the associated dependencies so that we can catch up with the latest features bug-fixes and enhancements Following XD dependencies needs upgraded to sync-up with Boot 120 RELEASE activemqversion5100activemqversion aspectjversion184aspectjversion commons-dbcp2version201commons-dbcp2version h2version14182h2version hibernateversiondd437Finalhibernateversion hibernate-validatorversion513Finalhibernate-validatorversion hikaricpversion225hikaricpversion hornetqversion245Finalhornetqversion httpasyncclientversion402httpasyncclientversion httpclientversion436httpclientversion jacksonversion244jacksonversion janinoversion261janinoversion jettyversion924v20141103jettyversion jetty-jspversion220v201112011158jetty-jspversion joda-timeversion25joda-timeversion jolokiaversion123jolokiaversion junitversion412junitversion liquibaseversion330liquibaseversion log4jversion1217log4jversion log4j2version21log4j2version mockitoversion1108mockitoversion mongodbversion2124mongodbversion mysqlversion5134mysqlversion reactorversion115RELEASEreactorversion reactor-springversion113RELEASEreactor-springversion servlet-apiversion310servlet-apiversion springversion413RELEASEspringversion spring-batchversion302RELEASEspring-batchversion spring-data-releasetrainversionEvans-SR1spring-data-releasetrainversion spring-hateoasversion0160RELEASEspring-hateoasversion spring-mobileversion113RELEASEspring-mobileversion spring-securityversion325RELEASEspring-securityversion tomcatversion8015tomcatversion undertowversion111Finalundertowversion,5
As a developer Id like to add a new CI build to include install target so I can verify the target expectations as it is often time consuming to verify it in the development environment,2
As a user Id like to have an option of AWS source module so that I can ingest data from Amazon S3 or use the Simple Email Service SES Reference Spring Integration AWS Extensionhttpsgithubcomspring-projectsspring-integration-extensionstreemasterspring-integration-aws,5
As a user Id like to refer to job orchestration documentation so I can use it as guideline for building batch workflows,3
As a QA Id like to include acceptance test coverage for bridge processor module so that I can validate the functionality as part of every CI build,3
As a developer Id like to synchronize with the latest Gemfire version 81 so I can leverage the latest Gemfire features and as well support updated BDS stack This effort in XD depends on Spring Data Gosling GA release which in turn depends on Gemfire 81 release timelines,2
As a user Id like to have paging support so that I can scroll through the list of streams jobs and containers Currently the following error is thrown when we cross 20 rows httplocalhost9393jobsdefinitionsjson JSON Response codexml links logref IllegalStateException message Not all instances were looked at code Stack trace code 155121931 ERROR http-nio-9393-exec-9 restRestControllerAdvice - Caught exception while handling a request javalangIllegalStateException Not all instances were looked at orgspringframeworkutilAssertstateAssertjava385 code,5
As a QA Id like to include acceptance test coverage for analytic-pmml processor module so that I can validate the functionality as part of every CI build,3
As a Spring XD developer Id like to port router module from XD to s-c-s repo so I can use it as sink module to build streaming pipeline,2
As a spring-bus lead Id like to review the current spring-bus architecture and the design specs so I can address any foundation level gaps,5
As a user Id like to parameterize CodeGen Options so I can generate code on the fly as needed,5
As a s-c-d developer Id like to provide optional key-value pairs as deployment properties so I could leverage them at the runtime to instruct how the modules will be deployed The scope of this story is to specifically support count to represent N instances of modules that share the same environment variables,8
As a Spring XD user Im trying to use a custom MongoDB Batch job however Im getting an error running it against 120121 release while the same works with older releases of Spring XD More details in this SO threadhttpstackoverflowcomquestions31838720mongodb-batch-job-broken-in-spring-xd-1-2-0,3
As a developer Id like to brainstorm and investigate various techniques around installation of XD modules from a maven repo so I could define the module artifactId from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime,8
As a developer Id like to setup a performance testing infrastructure rackspace so I can start benching Kafka baselines and continue with XD use-cases,8
As a user Id like to start multiple instances of xd-containers through the RPM scripts so I can easily spin-up instances on the same nodevm,2
As a s-c-s developer Id like to investigate the right approach to port PHD as the provider to support HDFS module from XD so I can decide better handling of HDFS dependencies which needs loaded and available in root CP at the runtime,5
As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations,2
As a developer Id like to have a maintenance branch so that I can commit MINOR release ex 102 code changes instead of committing to MASTER,5
As a QA Id like to include acceptance test coverage for splitter processor module so that I can validate the functionality as part of every CI build,3
As a s-c-d developer Id like to document Running on Cloud Foundryhttpsgithubcomspring-cloudspring-cloud-dataflowrunning-on-cloud-foundry section in README so it can be publicly available as deployment guideline,2
As a user Id like to use Boot-based ModuleRunner for use in container-managed environments so I can run XD without xd-containers Scope Complete the remaining deployment properties work,8
As a module author I want to be able to test my code in next to real world conditions ie Integration Testing but not really - I want all my module wiring to be testable - I want all my module configuration ConfigurationProperties to be in effect and I want to be able to test various combination of props - I want to be able to send data to my module and assert what is coming at the other end - I want an idiomatic way of asserting the above eg integration with Hamcrest etc - I DONT want to have to send data to an actual bus redis rabbit etc,5
As a user Id like to refer to the documentation so I can configure HDFS backed module registry XD-2287 as recommended,1
As a user I should not be allowed to create a custom module with a reserved keywords so that I it will avoid confusions from seeing duplicate strings in deployment manifest Example We would like to avoid a custom module name of producer to eliminate the confusion below code xdstream deploy --name test1 --properties moduleproducerproducerdeliveryMode PERSISTENTmodulelogcriteriagroupscontainsgroup1 code List of available reserved keywordshttpsgithubcomspring-projectsspring-xdwikiDeploymentdeployment-properties,5
As a Spring XD developer Id like to move mongo module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a user Id like to have the option of HAWQ sink so that I can write data directly into HAWQ via PXF extensions through AvroParquet format,3
As a user I would like to specify the default output channel when the channel name resolution doesnt occur In cases where I wont prefer to lose the data and like to investigate the messages from errorChannel or that sort,2
As a developer Id like to measure performance numbers for a simple stream so that I can characterize the overall throughput,8
As a developer Id like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster,8
As a developer Id like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests,2
As a developer Id like to bench Kafka as message bus using in-built perf-testing producerconsumer utilities so that I can use that as a foundation to build XD use-cases and measure performance Id like to reproduce baseline performance metrics as identified by the Kafka engineering teamhttpsengineeringlinkedincomkafkabenchmarking-apache-kafka-2-million-writes-second-three-cheap-machines,8
As a user Id like to have the option to configure permissions so that Ill have the flexibility to bind permissions REST endpoint to a specific role Default Roles Admin CRUD Viewer R,2
As a developer Id like to develop a singlenode in a single JVM implementation of XD Admin SPI based on Module Launcher so I can run data pipeline use-cases locally,8
As a developer Id like to complete the remaining Kryo optimization changes so I can polish and get the guidelines documented appropriately,1
As a s-c-d developer Id like to add support for profiles to the core Admin application so I can back the stream repository with respective backend strategy For example local profile would use in-memory strategy to store the metadata,3
As a user I need a sandbox Docker Image so that I can get started to experiment XD deployment with the following setup Ubuntu OS Full XD Jar Java 7x Redis RabbitMQ,5
As a s-c-d developer Id like to move kafka module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a user Id like to have microbatching capability so that I can ingest based on batch intervals for enhanced performance throughput Example http --batchInterval10 log,5
As a XD developer Id like to reproduce and fix anomalies as listed herehttpsgithubcomspring-projectsspring-xd-admin-ui-clientissues9,1
As a s-c-d user Id like to have the option of Gemfire SPI so I can use Gemfire and the infrastructure to orchestrate s-c-d data microservices,8
As a user Id like to have the moduleapp specific metrics consumed directly from Boot actuator exporthttpsgithubcomspring-projectsspring-bootblobmasterspring-boot-actuatorsrcmainjavaorgspringframeworkbootactuateautoconfigureMetricRepositoryAutoConfigurationjava API so I can have insight on how it is performing being used and that it works etc,8
As a Spring XD developer Id like to move redis module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a s-c-s user Id like to have my modules addupdate its current state to Eureka so I can use the repository to discover the current sate of the module as needed,2
As a developer Id like to move the project reactor based gpfdisthttpsgithubcomspring-projectsspring-xd-modulestreemastergpfdist from spring-xd-module repo to the core so I can natively use this sink to write to GPDBHAWQ,2
As a s-c-s developer Id like to create a public screencast of firehose counter pipe so I can demonstrate s-c-s and the development experience,3
As a developer Id like to have the option of extending the Trigger abstraction so that I can implement my own trigger,8
As a user Id like to have a separate YML file to list the deployment manifest properties so that I dont have to include as part of the stream definition,8
As a s-c-d developer Id like to publish the s-c-d image to DockerHub so I can incrementally push the latest commits to the remote location,1
As a s-c-d developer Id like to setup ghpages branch for s-c-d and s-c-s-m repos so I can start pushing documentation with PR commits,5
As a developer Id like to create a java clienthttpsgithubcommarkfisherreceptor-client for Receptor so I can interact with Diego runtime via Receptor API calls from XD,8
As a developer Id like to upgrade to SHDP GA release so that I can sync -up with the latest bits,1
As a user Id like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion,3
As a follow-up from XD-3613httpsjiraspringiobrowseXD-3629 we would want to fix this experience for Kafka message bus,5
As a QA Id like to include acceptance test coverage for SFTP source module so that I can validate the functionality as part of every CI build,3
As a developer Id like to remove ID and TimeStamp attributes from the Tuple class so I can improve performance characteristics by not having them go through serde instead we could leverage message headers to collect such information,3
As a user Id like to have the option of HDFS source module so that I can ingest data directly from HDFS file system,3
As a user Id like to have the option of AWS sink so that I can write data into S3 directly Reference Spring Integration AWS Extensionhttpsgithubcomspring-projectsspring-integration-extensionstreemasterspring-integration-aws,5
As a developer Id like to publish performance benchmarks along with the infrastructure specifics so the users can use it as a reference while setting up Spring XD cluster,8
As a developer Id like to revisit the existing design and identify known limitations andor the gaps,5
As a developer Id like to have a central place to manage external properties for applications across all the environments so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers,8
As a user Id like to have an option to have the hdfs sink use Syncable writes to provide better resiliency in the case of sinkcontainer failures Im willing to accept the performance penalty if I choose this option,3
As a consequence change gradle script regarding generation of documentation remove pushGeneratedDocs task etc remove link rewriting that is no longer needed,8
As a developer Id like to document the Kryo optimization guidelines so the end-users can refer to it while tuning to improve performance,3
As a user Id like to have a Shell command so that I can point to the custom-built module archive and push it to the runtime for immediate usage,3
As a developer Id like to upgrade to Kafka 082 so I can leverage the latest features in order to test the performance characteristics,8
As a spring-cloud-stream user Id like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON,3
As a s-c-s developer Id like to create auto configuration for singlenode binder configurationproperties so I can automatically configure the Spring application based on the dependencies,1
As a users I would to be able to execute SQL StatementScript via a Processor or Job statement,3
As a developer I want to be able to override Kafka bus defaults for module consumers and producers so that I can finely tune performance and behaviour Such properties should include - autoCommitEnabledqueueSizemaxWaitfetchSize for consumers - batchSizebatchTimeout for producers,3
As a s-c-d developer Id like to complete documentation and test-cases on resolving and adding JARs to Boot loader so we could use this as a reference while porting modules with external dependencies,3
As a s-c-s user Id like to have the modules self-register itself with Eureka whenever theyre installed so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines,5
As a developer Id like to add documentation on escape quotes so when someone using Sqoop job can double escape N instead of sending quotes N to successfully submit the job,1
As a user I need a production-ready Docker Image so that I can use that as a baseline to deploy XD with the following setup Ubuntu OS Full XD Jar Java 7x,8
As a developer Id like to enhance test coverage to capture DSL and XML generation variants,5
As a Spring XD developer Id like to move mail module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a user Id like to use SpEL expressions inline at the stream definition level so I can operate on the payload consistently while using any OOTB including the custom modules,8
As a Spring XD on CF user Id like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics Possible APIs code ModuleStatus getStatusModuleDescriptor descriptor CollectionModuleDescriptor listModules MapModuleDescriptorKey ModuleStatus code,5
As a developer Id like to create persistent repository for streams so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions,5
As a developer Id like to research and Identify the EC2 infrastructure required so that I can run performance tests on Kafka,3
As a user Id like to have the option to extend compression support so that I can override the defaults and customize as needed Follow-up from this PR httpsgithubcomspring-projectsspring-xdpull1346,3
As a s-c-s-m developer Id like to move jdbc module from XD to s-c-s repo so I can use it as sink to build streaming pipeline See also XD-2250,5
As a XD developer Id like to explore repository options for composed jobs so I have the leverage to readwrite composed job definitions,5
As a developer Id like to create a custom job module using Java Config so that I dont have to deal with XML configurations While deployinglaunching the following job I get the error attached below codexml job create --name CDKGlobal --definition customBatchJob --deploy module upload --type job --name customBatchJob --file UsersmminellaDocumentsIntelliJWorkspaceCustomBatchModulebuildlibsCustomBatchModule-110RELEASEjar job launch --name CDKGlobal code Error Im getting an exception that the job doesnt exist asking if its deployed,5
As a s-c-d developer Id like to study Concourse CIhttpconcourseci so I can understand how to use it for s-c-d going forward,3
As a developer Id like to build Spark batch job sample so that we can demonstrate some of the distributed data computation capabilities,8
As a s-c-d developer Id like to invoke REST APIs via shell so I can validate StreamController operations,8
As a s-c-d developer Id like to enhance integration test coverage for Lattice SPI so I can continuously evaluate functionalities via CI pipeline,3
As a developer Id like to hostread Python script file from HDFS so I can use the shell processor in XD on CF to delegate data science functionality to Py runtime and receive the feedback back in XD,8
As a user Id like to have a perf-meter sink that will collect and push metrics to the standard container log file Example perf-meter --numMsgs 1000 Will write to the container log a timestamp message count and message rate every 1000 messages The message rate is the value since the last log event Default values are those specified above,8
As a XD user Id like to orchestrate composed jobs so I can bring multiple jobs into single workflow and operationalize,5
As a developer Id like to move 12x branch to EC2 infrastructure so I can reliably run CI test suites,2
As a performance tester Id like to re-run baseline benchmarks with compression enabled on Rabbit so that I can compare the results with previous performance snapshots,3
As a user I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed so that I can colocate with other data sources,8
As a user Id like to have the option to define access control list ACLs so that I can define access controls to the resource by each user and what the privileges are for that resource Spike Scope Review customer use cases and come up with design specs Identify the best approach that fits XD runtime Identify scope for DSL and UI Document next steps and phases,8
As a PM Id like to have XD and XD Ambari RPM scripts into a single public repo so that users can go to a single location to use the respective build scripts,3
As a s-c-d user Id like to add REST support for stream commands so I can maneuver streaming pipeline backed by StreamController,5
As a Spring XD developer Id like to port transform module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,2
As a Spring XD developer Id like to port FTPSFTP module from XD to s-c-s repo so I can use it as sink modules to build streaming pipeline,2
As a developer Id like to upgrade Spring XDs ambari plugin to 13 release,3
As a user Id like to have the ability to use expressions so I can dynamically name directoriesfiles based on the timestamp or other intermediate data point,5
As a user Id like to use the admin-ui and flo with consistent look and feel,1
As a s-c-d user Id like to have the option of Gemfire as stream repository so I can build data pipelines that are entirely orchestrated within Gemfire,8
As a developer Id like to port file module from XD to s-c-s repo so I can use it as source module to build streaming pipeline,3
As a user Id like Flo Graphs as screenshots while referring to the batch DSL so it will be easy for me to relate to concepts,1
As a Spring XD developer Id like to move hdfs-dataset module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,5
As a user Id like to clean-up stale queuestopics associated with the stream so when the stream gets destroyed I can clean-up resources,3
As a developer Id like to create a Tuple load-generator so I can use it to measure Tuple based payload performance,3
As a Spring XD user Id like to use the latest releases of HDPPHD distros so I can leverage the latest features to create pipelines involving HDFS,8
As a Spring XD user Id like to use Diego based Receptor implementation of XD Admin SPI based on ModuleLauncher so I can run data pipeline use-cases running on CF LatticeDiego,8
As a user Id like to have the option to write into Kafka sink so that I can publish mass data into Kafka broker,8
As a user I cannot use admin-ui on the master build It wont come up,2
As a user Id like to create a stream such as generator perf-meter so that I can ingest 1M messages of 1000 bytes and one thread using XDs singlenode container and measure performance characteristics,8
As a user Id like to have a REST-API to get all the counters gauges and rich-gauges in a single request so I dont have to issue multiple request to fetch each one of the metrics by nameid for custom dashboards Example code metricscountersall fetches all available counters metricsgaugesall fetches all available gauges metricsrich-gaugesall fetches all available rich-gauges code,5
As a developer Id like to add support for explicit partition count configuration so I can use this option to cleverly route the payload to the intended consumer module,5
As a developer Id like to move message-bus from Spring XD repo into spring-bus so I can update Spring XD to inherit the featuresfunctionalities via maven dependency,8
As a user I logged in with ROLECREATE and I get an error while trying job creation from adminui I can create job from the shell successfully Trying the same workflow with ROLEADMIN results with the same error as well I dont see anything in the admincontainer logs about the error itself,1
As a field engineer Id like to have reference architectures built on Spring XD so that I can use that as reference building POCs The scope is to get the raw domain specific ideas captured as first step,8
As a user I would like to have shell interface to the spring-cloud-data rest API The scope for this JIRA could be limited to stream commands,5
As a Spring XD developer Id like to move reactor-ip module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a Spring XD developer Id like to port FTPSFTP modules from XD to s-c-s repo so I can use them as source modules to build streaming pipeline,2
As a s-c-s user Id like to store module metadata in Eureka so I can use the repository to determine the current state,2
As a developer Id like to create separate repo for Mesos SPI so I dont have to bundle all SPI variants under one admin project,3
As a user Id like to use the Mail sink to connect to secured IMAP andor SMTP mail servers Currently the sink doesnt support TLS Mail sink config file requires a utilproperties bean with ssltls properties provided to the adapter via the java-mail-properties attribute Ref Examplehttpdocsspringiospring-integrationdocslatest-gareferencehtmlmailhtml codexml utilproperties idjavaMailProperties prop keymailimapsocketFactoryclassjavaxnetsslSSLSocketFactoryprop prop keymailimapsocketFactoryfallbackfalseprop prop keymailstoreprotocolimapsprop prop keymaildebugfalseprop utilproperties code List of all java-mail propertieshttpsjavamailjavanetnonavdocsapicomsunmailsmtppackage-summaryhtml,1
As a QA Id like to include acceptance test coverage for timestampfile batch job so that I can validate the functionality as part of every CI build,3
As a developer Id like to handle module options via pure boot property source management so I can leverage Boots module METADATAhttpdocsspringiospring-bootdocscurrent-SNAPSHOTreferencehtmlsingleconfiguration-metadata option to inject module options as opposed to maintaining them in core Spring XD runtime CP,8
As a s-c-s user Id like to have the option to use more than one binder connection factory so I can mix and match where I consume and publish data More details herehttpsgithubcomspring-cloudspring-cloud-streamissues140,5
As a Spring XD developer Id like to move mqtt module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a user Id like to have the data partition strategy state preserved so that when I adddelete modules they are able to dynamically adapt to the strategy This is already included as part of the GA release This story is to account for the testing effort,1
As a developer Id like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers so it is setup for HA,5
As a s-c-d user Im unable to push admin app to CF due to SSL certification errors while bootstrapping Consider adding CF trusted certificatehttpsgithubcompivotal-cfcloudfoundry-certificate-truster as a CF SPI dependency Adding CF trusted certificate as dependency doesnt help either code Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR Caused by sunsecurityvalidatorValidatorException PKIX path building failed sunsecurityprovidercertpathSunCertPathBuilderException unable to find valid certification path to requested target Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR at sunsecurityvalidatorPKIXValidatordoBuildPKIXValidatorjava387 Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR at sunsecurityvalidatorPKIXValidatorengineValidatePKIXValidatorjava292 Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR at sunsecurityvalidatorValidatorvalidateValidatorjava260 Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR at sunsecuritysslX509TrustManagerImplvalidateX509TrustManagerImpljava324 Fri Sep 25 2015 125532 GMT-0400 EDT App0 ERR at sunsecuritysslX509TrustManagerImplcheckTrustedX509TrustManagerImpljava229 Fri Sep 25 2015 125532 GMT- code,3
As a Flo for Spring XD user I would like to be able to create a new stream using the graphicat UI This flow should be shown in a graphical way also in definition tab httpexamplecomimagepng Right now it doesnt happen due to a javascript error code TypeError thisnodegetTransformToElement is not a function at ObjectVElementbbox httplocalhost9393admin-uilibjointsrcvectorizerjs32336 at jointdiaElementViewjointdiaCellViewextendpositionRelative httplocalhost9393admin-uilibjointdistjointallcleanjs274051 at nullanonymous httplocalhost9393admin-uilibjointdistjointallcleanjs271018 at httplocalhost9393admin-uiliblodashlodashcompatjs117723 at eval eval at createIterator httplocalhost9393admin-uiliblodashlodashcompatjs10 anonymous109 at FunctionforEach httplocalhost9393admin-uiliblodashlodashcompatjs36459 at jointdiaElementViewjointdiaCellViewextendupdate httplocalhost9393admin-uilibjointdistjointallcleanjs270011 at bound as update httplocalhost9393admin-uiliblodashlodashcompatjs100521 at jointdiaElementViewjointdiaCellViewextendrender httplocalhost9393admin-uilibjointdistjointallcleanjs290314 at jointdiaPaperBackboneViewextendaddCell httplocalhost9393admin-uilibjointdistjointallcleanjs500414anonymous function 9393admin-uilibangularangularjs11500 9393attachment-namejpgthumbnail code,1
As a user Id like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios,3
As a user Id like to have the flexibility to change the namespace so that I can isolate ZK metadata based on each tenant profile,5
As a s-c-d developer Id like to add support for dependency resolution so when two or more modules use different version of jars ex direct binding of two modules that include different versions of spring data I have the capability to resolve and include the right bits at runtime,2
As a s-c-d developer Id like to enhance unit test coverage for YARN SPI so I can continuously evaluate functionalities via CI pipeline,3
As a developer Id like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing,3
As a s-c-d developer Id like to have module unregister shell command so I can unregister an existing module from the ModuleRegistry,2
As a user Im trying to get all job definitions but the first 20 alone are returned Job samples code job create aaa --definition hello --deploy job create bbb --definition hello --deploy job create ccc --definition hello --deploy job create ddd --definition hello --deploy job create eee --definition hello --deploy job create fff --definition hello --deploy job create ggg --definition hello --deploy job create hhh --definition hello --deploy job create iii --definition hello --deploy job create jjj --definition hello --deploy job create kkk --definition hello --deploy job create lll --definition hello --deploy job create mmm --definition hello --deploy job create nnn --definition hello --deploy job create ooo --definition hello --deploy job create ppp --definition hello --deploy job create qqq --definition hello --deploy job create rrr --definition hello --deploy job create sss --definition hello --deploy job create ttt --definition hello --deploy job create uuu --definition hello --deploy job create vvv --definition hello --deploy job create www --definition hello --deploy job create xxx --definition hello --deploy job create yyy --definition hello --deploy job create zzz --definition hello --deploy job create aaa1 --definition hello --deploy job create bbb1 --definition hello --deploy job create ccc1 --definition hello --deploy job create ddd1 --definition hello --deploy job create eee1 --definition hello --deploy code Request httplocalhost9393jobsdefinitionsjson - returns top 20 the other experiments with page size of either 0 or -1 still brings the top 20,1
As a data scientist Id like to have the option to process data using flink processor so I can take advantage of the streaming machine learning abstractions implemented on top of Flink,5
As a Spring XD user Id like to have IPython Notebookhttpipythonorgnotebookhtml integration so I can perform interactive data computations in real-time,8
As a user Im trying to load Job - Modules page in admin-ui but Im seeing exceptions in console and the page wouldnt load code Failed to convert value of type javalangString to required type orgspringframeworkclouddataflowcoreArtifactType nested exception is orgspringframeworkcoreconvertConversionFailedException Failed to convert from type javalangString to type orgspringframeworkwebbindannotationRequestParam orgspringframeworkclouddataflowcoreArtifactType for value job nested exception is javalangIllegalArgumentException No enum constant orgspringframeworkclouddataflowcoreArtifactTypejob code,2
As a developer Id like to upgrade to SI Kafka release so I can synchronize with latest improvements and bug fixes,1
As a developer Id like to document how to nest batch jobs and workflows in XD so it will be easy for end-users to use it as reference,1
As a user Id like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended,2
As a s-c-d developer Id like to enhance integration test coverage for CC SPI so I can continuously evaluate functionalities via CI pipeline,3
As a s-c-s developer Id like to bootify ModuleLauncher so I can use Spring Boots support for property setting as well as adding options and new functionality in the future such as CP augmentation,5
As a developer Id like to configure HADOOPUSERNAME environment variable to implement and run-as-user for kerberos secured clusters This would need some additional work in SHDP,5
As a user Id like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via serversyml to control the default message size Notes The adapter currently has that hard-coded 1MB limit in the HttpChunkAggregator We will have to expose this property for overrides Related PRhttpsgithubcomspring-projectsspring-xdpull1367,3
As a s-c-d developer Id like to add hdfs sink to module registry so I can use this module to build streaming pipeline and write to Hadoop,1
As a XD developer Id like to refactor and replace codec code from XD with SI library so I dont have to maintain duplicate code,3
As a user Id like to refer to the wiki so that I can create a job with partitions that in turn expects tableName and columns be explicitly included in the job definition It is also beneficial to call-out sql and tableName metadata options are mutually exclusive Following logic in JdbcHdfsOptionsMetadata needs documented codejava AssertTruemessage Use tableName AND columns when using partition column boolean isPartitionedWithTableName if StringUtilshasTextpartitionColumn return StringUtilshasTexttableName StringUtilshasTextsql else return true code,1
As a user Id like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features,1
As a Spring XD developer Id like to move mqtt module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a developer Id like to add load receiving sink module so that I can measure received throughput,3
As a developer Id like to include the following improvements as part of the EC2 CI infrastructure so that we can reliably run the CI builds and also assert over feature functionalities Scope Enable distributed jvm test Change from using artifactory gradle task to a command task that calls gradlew Test w embedded hadoop off Turn on maxParallelForks,5
As a developer Id like to use Ambari plugin so that I can provision manage and monitor Spring XD cluster using the same tool I use for Hadoop clusters,5
As a user Id like to have the ability to mass-ingest data from various database systems so that Im not restricted with the current approach jdbchdfs that is dependent on JDBC drivers Spike Scope Identify integration options Collaborate to determine the design Document outcome design specs,5
As a Spring XD user I need to listen on a JMS Topic and ingest the messages so I can process the messages Currently the module only allows for Queues,2
As a XD build master Id like to fix local gradlew dist and distZip targets the outstanding build issues so I can evaluate that publish builds works as expected,3
As a developer Id like to benchmark a stream with and without JMX enabled so I can test in isolation and document the differences in performance,3
As a user Id like to refer to the analytics tab docs so I can understand how to use various widgets from streaming pipeline,2
As a Spring XD developer Id like to move twitterstream module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline,2
As a developer I want to be able to connect to multiple external systems for the same binding type so that I can read data from a system and write it to another,5
As a developer Id like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo,5
As a s-c-d developer Id like to create ModuleRegistry stubs so I can create mock streams by interacting with the registry APIs,3
As a user Id like to use a jdbchdfs batch job as a passthrough without chunk processing so that I dont have to incur the batch readwrite overhead,2
As a user Id like to have Googles Protocol Bufferhttpscodegooglecompprotobuf codec option so that I can serializedeserialize objects based on its native specifications,5
As a user Id like to use partitionResultsTimeout attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki Note The property should be available for all the jobs that import 3 OOTB jobs have it imported ref attachment,1
As a s-c-s developer Id like to refactor the current ModuleLauncher contract with Boots JarLauncher API so we dont have to maintain duplicate functionality,1
As a user I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework,8
As a user Id like to either use sql or tableName options so that I can build a partitioned job with where clause and strict table-column combo respectively,5
As a Spring XD developer Id like to port script module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,2
As a user Id like to have an option to disable DB requirement so that I can setup to use DIRT runtime when stream processing is the only requirement,8
As a s-c-d developer Id like to enforce external libraries from overriding any existing library in the uber-jar,2
As a developer Id like to build batch sample using Sqoop so that we can demonstrate some of the capabilities Use cases to consider JDBC to HDFS HDFS to JDBC,8
As a s-c-d developer Id like to add as many jars via a bom eg hadoop distro deps so I dont have to explicitly worry about individual but related libraries,2
As a developer Id like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options 0 or via other properties such as including the dependencies from a specific location 1 0 code libjarlibdistrojar code 1 code xdhomelibhadoopdistrojar code Example code http hdfs --distroPHD22 http myCustomModule --classpathmyfunkydir http jpa --providereclipse jpa config libsomething-that-is-commonjar eclipseeclipse-link-32jar hibernatehibernate-core-50jar moduleclasspath libjarlibproviderjar code,5
As a module developer I would like the JsonStringToTupleConverter in the Spring Cloud Streams project to maintain the types provided in the JSON string and not convert everything to a String representation,1
As a s-c-d developer Id like to setup CI infrastructure for s-c-d repohttpsgithubcomspring-cloudspring-cloud-data so I can build the project continuously on every commits,5
As a Spring XD developer Id like to self-register xd-admin server with Eureka so I could have admin server exposed as discoverable endpoint,3
As a developer Id like to rerun baseline Tuple and Serialized payloads so I can compare the differences in performance between 081 and 082 Kafka releases Sinks to be included in test In-Memory Transport Hdfs sink Direct Binding Transport Hdfs Sink Kafka Hdfs Sink,8
As a user Id like to incremental-data-load so that I can retrieve only rows newer than some previously-imported,5
As a user Id like to have the option of JMX source module so that I can publishsubscribe to JMX notifications Reference Sprint Integration JMX Supporthttpdocsspringiospring-integrationreferencehtmlsystem-management-chapterhtmljmx,3
As a s-c-d developer Id like to have module info shell command so I can query each of the module specifics such as description and support options,2
As a developer Id like the publish-mavengradle script to use values for dependencies eg Spring Boot and hadoop-common from our central dependency list in this case dependenciesproperties so that I dont have to update them manually anymore,2
As a user Id like to mass ingest data from databases and others into HDFSHAWQGPDB so that I dont have to write custom code and as well as be able to ingest in an efficient way,5
As a user Id like to have a reactor-stream processor module so that I can ingest data using XD source modules and process them as time-window operations Example 1 http reactor-stream --timeWindow10s --fieldpayloadsensorData --expressionsminavg This would give you 10 second time window of the min and avg values Example 2 Reactor as a module Example 3 Integration with Spark streaming and reactor,8
As a Azure user Id like to readwrite data from Azure Event Hubs so I can leverage the pub-sub service to process and analyze large volumes of data,8
As a QA Id like to include acceptance test coverage for splunk sink module so that I can validate the functionality as part of every CI build,3
As a user Im trying to load Task Task Deployment and Task Executions page but Im seeing an error Error fetching data Is the XD server running instead,1
As a user Id like to have the ability to visually explore XDs cluster view so that Im aware where the components are deployed and how they are connected within the topology,2
As a developer Id like to create separate repo for Lattice SPI so I dont have to bundle all SPI variants under one admin project,3
As a user Im trying to compose a job just with one definition however Im getting the following error message which could be misinterpreted code xdjob create salsa --definition timestampfile Successfully created job salsa xdjob create foo --definition salsa salsa Successfully created job foo xdjob create foo222 --definition salsa Command failed orgspringframeworkxdrestclientimplSpringXDException Could not find module with name salsa and type job code,1
As a QA Id like to include acceptance test coverage for hdfs-dataset sink module so that I can validate the functionality as part of every CI build,3
As a user Im trying to create a composed job with 20 stepstransitions using Rabbit as the message bus and it doesnt complete successfully,3
As a user Id like to use the Java receptor client so I can interact with Diego runtime using the Java receptor REST APIs,8
As a developer Id like to port Log module from XD to s-c-s repo so I can use it as sink modules to build streaming pipeline,2
As a s-c-d developer Id like to create a new project to contain all the rules associated RedisRule contract so it is isolated from core functionalities and reusable by test coverage as needed Consider moving this coverage to SI commons or equivalent,5
As a user Id like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features,1
As a s-c-s user Id like to have the option to direct bind modules so I dont have to use messaging middleware and I can eliminate latency between them This is important for high throughput and low latency use cases,8
As a developer Id like to upgrade reactor-ip and syslog modules to Reactor 20 so that we can sync up with the latest release,1
As a developer Id like to create an annotation EnableModule driven programming model for modules so instead of explicitly defining IO channels as beans on the module for classes annotated with EnableModule the application would be responsible for creating the actual channel beans and channel adapters vs the developer creating concrete channel instance types The Input and Output annotations will be used to indicate the input and output channels of the module,8
As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated The documentation also needs some more information on Reliable receiver,1
As a developer Id like to clean-up compiler and javadoc warnings from the build so we dont see the warnings in build sysout,2
As a s-c-d developer Id like to break the build lifecycle to bundle SPI deployers individually so I dont have to build admin with all the deployer variations as one whole thing,8
As a user Id like to have the option to implement bindRequestor and bindReplier so that I can bind a producer that expects async replies and bind a consumer that handles requests from a requestor and asynchronously sends replies respectively,3
As a user Id like to stream ingest audio and video data so that I can apply predictive analytics algorithms for facial detection Spike scope Research the feasibility of implementing Motion-JPEGhttpenwikipediaorgwikiMotionJPEG Design specs on Motion-JPEG format Note opencvhttpdocsopencvorgtrunkdocpytutorialspyobjdetectpyfacedetectionpyfacedetectionhtml although having OOTB support it is not platform compatible,8
As a Spring XD developer Id like to move tcp module from XD to s-c-s repo so I can use it as sink to build streaming pipeline,2
As a developer Id like to use an efficient approach to read files so I dont have to read line-by-line and keep it in-memory in order to consumewrite the file content Would the tasklet approach be better as opposed to transmitting data via message bus as streams,5
As a user Id like to build XD in Windows machine so that I can develop test and contributed to OSS,5
As a Spring XD developer Id like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective SPI receptor or cloudcontroller implementations,5
As a developer Id like to measure the baseline serialization characteristics in XD so I can determine the areas of performance improvements,5
As a developer Id like to optimize YARN deployer so I can deploy stream and the modules part of the definition rapidly,5
As a developer Id like to upgrade Boot and Spring Cloud Build revisions so I can leverage the latest updates,5
As a developer Id like to refer to wiki so that I can configure machines with recommended ulimit setting for XDs distributed setup Note Recommended ulimit setting is 10K under Troubleshooting new section Exception reason to increase ulimit 82552266 110SNAP ERROR DeploymentsPathChildrenCache-0 serverDeploymentListener - Exception deploying module javalangIllegalStateException javaioFileNotFoundException varvcapdatapackagesspringxdee02bd3482eeb620a65862fb54e1f23fcece80221-bd a341640a5de2f922fd3db906ce504b85819c1espring-xd-110BUILD-SNAPSHOTxdconfigmodulesmodulesyml Too many open files,1
As a QA Id like to include acceptance test coverage for http-client processor module so that I can validate the functionality as part of every CI build,3
As a QA Id like to include acceptance test coverage for throughput-sampler sink module so that I can validate the functionality as part of every CI build,3
As a Spring XD developer Id like to port shell module from XD to s-c-s repo so I can use it as processor module to build streaming pipeline,2
As a user Id like to have the option of kerberized HDFS sink so that I can leverage Kerberos open source distributed authentication system for secured data writes into Hadoop,3
As a developer I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module so that I can take advantage of the native Kafka partitioning and message ordering support,3
As a system administrator I need to connect to SonicMQ as jms provider When setting up the correct spring xml file and added the correct jar files to the lib directory I received the following exception--- Question is there a spot I should be defining the conversion strategy code Spring Boot v050M6 150436092 ERROR http-bio-9393-exec-1 restRestControllerAdvice157 - Caught exception while handling a request orgspringframeworkintegrationMessageHandlingException error occurred in message handler moduleDeployer orgspringframeworkintegrationhandlerAbstractMessageHandlerhandleMessageAbstractMessageHandlerjava79 orgspringframeworkintegrationconfigServiceActivatorFactoryBean1handleRequestMessageServiceActivatorFactoryBeanjava83 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlerhandleMessageInternalAbstractReplyProducingMessageHandlerjava142 orgspringframeworkintegrationhandlerAbstractMessageHandlerhandleMessageAbstractMessageHandlerjava73 orgspringframeworkintegrationdispatcherUnicastingDispatcherdoDispatchUnicastingDispatcherjava115 orgspringframeworkintegrationdispatcherUnicastingDispatcherdispatchUnicastingDispatcherjava102 orgspringframeworkintegrationchannelAbstractSubscribableChanneldoSendAbstractSubscribableChanneljava77 orgspringframeworkintegrationchannelAbstractMessageChannelsendAbstractMessageChanneljava178 orgspringframeworkintegrationchannelAbstractMessageChannelsendAbstractMessageChanneljava149 orgspringframeworkmessagingcoreGenericMessagingTemplatedoSendGenericMessagingTemplatejava94 orgspringframeworkmessagingcoreGenericMessagingTemplatedoSendGenericMessagingTemplatejava42 orgspringframeworkmessagingcoreAbstractMessageSendingTemplatesendAbstractMessageSendingTemplatejava86 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlersendMessageAbstractReplyProducingMessageHandlerjava228 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlersendReplyMessageAbstractReplyProducingMessageHandlerjava212 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlerproduceReplyAbstractReplyProducingMessageHandlerjava177 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlerhandleResultAbstractReplyProducingMessageHandlerjava171 orgspringframeworkintegrationhandlerAbstractReplyProducingMessageHandlerhandleMessageInternalAbstractReplyProducingMessageHandlerjava149 orgspringframeworkintegrationhandlerAbstractMessageHandlerhandleMessageAbstractMessageHandlerjava73 orgspringframeworkintegrationdispatcherUnicastingDispatcherdoDispatchUnicastingDispatcherjava115 orgspringframeworkintegrationdispatcherUnicastingDispatcherdispatchUnicastingDispatcherjava102 orgspringframeworkintegrationchannelAbstractSubscribableChanneldoSendAbstractSubscribableChanneljava77 orgspringframeworkintegrationchannelAbstractMessageChannelsendAbstractMessageChanneljava178 orgspringframeworkintegrationchannelAbstractMessageChannelsendAbstractMessageChanneljava149 orgspringframeworkxddirtstreamDeploymentMessageSendersendDeploymentRequestsDeploymentMessageSenderjava57 orgspringframeworkxddirtstreamAbstractDeployersendDeploymentRequestsAbstractDeployerjava137 orgspringframeworkxddirtstreamAbstractDeployerbasicDeployAbstractDeployerjava157 orgspringframeworkxddirtstreamAbstractInstancePersistingDeployerdeployAbstractInstancePersistingDeployerjava78 orgspringframeworkxddirtrestXDControllersaveXDControllerjava242 sunreflectNativeMethodAccessorImplinvoke0Native Method sunreflectNativeMethodAccessorImplinvokeNativeMethodAccessorImpljava57 sunreflectDelegatingMethodAccessorImplinvokeDelegatingMethodAccessorImpljava43 javalangreflectMethodinvokeMethodjava606 orgspringframeworkwebmethodsupportInvocableHandlerMethodinvokeInvocableHandlerMethodjava214 orgspringframeworkwebmethodsupportInvocableHandlerMethodinvokeForRequestInvocableHandlerMethodjava132 orgspringframeworkwebservletmvcmethodannotationServletInvocableHandlerMethodinvokeAndHandleServletInvocableHandlerMethodjava104 orgspringframeworkwebservletmvcmethodannotationRequestMappingHandlerAdapterinvokeHandleMethodRequestMappingHandlerAdapterjava748 orgspringframeworkwebservletmvcmethodannotationRequestMappingHandlerAdapterhandleInternalRequestMappingHandlerAdapterjava689 orgspringframeworkwebservletmvcmethodAbstractHandlerMethodAdapterhandleAbstractHandlerMethodAdapterjava83 orgspringframeworkwebservletDispatcherServletdoDispatchDispatcherServletjava947 orgspringframeworkwebservletDispatcherServletdoServiceDispatcherServletjava878 orgspringframeworkwebservletFrameworkServletprocessRequestFrameworkServletjava946 orgspringframeworkwebservletFrameworkServletdoPostFrameworkServletjava848 javaxservlethttpHttpServletserviceHttpServletjava647 orgspringframeworkwebservletFrameworkServletserviceFrameworkServletjava822 javaxservlethttpHttpServletserviceHttpServletjava728 orgapachecatalinacoreApplicationFilterChaininternalDoFilterApplicationFilterChainjava305 orgapachecatalinacoreApplicationFilterChaindoFilterApplicationFilterChainjava210 orgspringframeworkwebfilterHttpPutFormContentFilterdoFilterInternalHttpPutFormContentFilterjava88 orgspringframeworkwebfilterOncePerRequestFilterdoFilterOncePerRequestFilterjava108 orgapachecatalinacoreApplicationFilterChaininternalDoFilterApplicationFilterChainjava243 orgapachecatalinacoreApplicationFilterChaindoFilterApplicationFilterChainjava210 orgapachecatalinacoreStandardWrapperValveinvokeStandardWrapperValvejava222 orgapachecatalinacoreStandardContextValveinvokeStandardContextValvejava123 orgapachecatalinaauthenticatorAuthenticatorBaseinvokeAuthenticatorBasejava472 orgapachecatalinacoreStandardHostValveinvokeStandardHostValvejava171 orgapachecatalinavalvesErrorReportValveinvokeErrorReportValvejava99 orgapachecatalinacoreStandardEngineValveinvokeStandardEngineValvejava118 orgapachecatalinaconnectorCoyoteAdapterserviceCoyoteAdapterjava407 orgapachecoyotehttp11AbstractHttp11ProcessorprocessAbstractHttp11Processorjava1004 orgapachecoyoteAbstractProtocolAbstractConnectionHandlerprocessAbstractProtocoljava589 orgapachetomcatutilnetJIoEndpointSocketProcessorrunJIoEndpointjava310 javautilconcurrentThreadPoolExecutorrunWorkerThreadPoolExecutorjava1145 javautilconcurrentThreadPoolExecutorWorkerrunThreadPoolExecutorjava615 javalangThreadrunThreadjava744 Caused by orgspringframeworkbeansfactoryBeanCreationException Error creating bean with name connectionFactory defined in file Usersdmarleysandboxspring-xdbuilddistspring-xdxdmodulessourcejmsconfigcommonjms-sonic-infrastructure-contextxml Initialization of bean failed nested exception is orgspringframeworkbeansConversionNotSupportedException Failed to convert property value of type progressmessagejclientConnectionFactory to required type javaxjmsConnectionFactory for property targetConnectionFactory nested exception is javalangIllegalStateException Cannot convert value of type progressmessagejclientConnectionFactory to required type javaxjmsConnectionFactory for property targetConnectionFactory no matching editors or conversion strategy found orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactorydoCreateBeanAbstractAutowireCapableBeanFactoryjava547 orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactorycreateBeanAbstractAutowireCapableBeanFactoryjava475 orgspringframeworkbeansfactorysupportAbstractBeanFactory1getObjectAbstractBeanFactoryjava300 orgspringframeworkbeansfactorysupportDefaultSingletonBeanRegistrygetSingletonDefaultSingletonBeanRegistryjava228 orgspringframeworkbeansfactorysupportAbstractBeanFactorydoGetBeanAbstractBeanFactoryjava296 orgspringframeworkbeansfactorysupportAbstractBeanFactorygetBeanAbstractBeanFactoryjava195 orgspringframeworkbeansfactorysupportDefaultListableBeanFactorypreInstantiateSingletonsDefaultListableBeanFactoryjava660 orgspringframeworkcontextsupportAbstractApplicationContextfinishBeanFactoryInitializationAbstractApplicationContextjava760 orgspringframeworkcontextsupportAbstractApplicationContextrefreshAbstractApplicationContextjava482 orgspringframeworkbootSpringApplicationrefreshSpringApplicationjava552 orgspringframeworkbootSpringApplicationrunSpringApplicationjava293 orgspringframeworkbootbuilderSpringApplicationBuilderrunSpringApplicationBuilderjava130 orgspringframeworkxdmoduleSimpleModuleinitializeSimpleModulejava135 orgspringframeworkxddirtmoduleModuleDeployerdeployModuleDeployerjava239 orgspringframeworkxddirtmoduleModuleDeployerdeployModuleModuleDeployerjava229 orgspringframeworkxddirtmoduleModuleDeployerhandleDeployModuleDeployerjava214 orgspringframeworkxddirtmoduleModuleDeployerhandleDeploymentRequestModuleDeployerjava196 orgspringframeworkxddirtmoduleModuleDeployerhandleMessageInternalModuleDeployerjava137 orgspringframeworkintegrationhandlerAbstractMessageHandlerhandleMessageAbstractMessageHandlerjava73 63 more Caused by orgspringframeworkbeansConversionNotSupportedException Failed to convert property value of type progressmessagejclientConnectionFactory to required type javaxjmsConnectionFactory for property targetConnectionFactory nested exception is javalangIllegalStateException Cannot convert value of type progressmessagejclientConnectionFactory to required type javaxjmsConnectionFactory for property targetConnectionFactory no matching editors or conversion strategy found orgspringframeworkbeansBeanWrapperImplconvertIfNecessaryBeanWrapperImpljava474 orgspringframeworkbeansBeanWrapperImplconvertForPropertyBeanWrapperImpljava505 orgspringframeworkbeansBeanWrapperImplconvertForPropertyBeanWrapperImpljava499 orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactoryconvertForPropertyAbstractAutowireCapableBeanFactoryjava1497 orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactoryapplyPropertyValuesAbstractAutowireCapableBeanFactoryjava1456 orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactorypopulateBeanAbstractAutowireCapableBeanFactoryjava1192 orgspringframeworkbeansfactorysupportAbstractAutowireCapableBeanFactorydoCreateBeanAbstractAutowireCapableBeanFactoryjava537 81 more Caused by javalangIllegalStateException Cannot convert value of type progressmessagejclientConnectionFactory to required type javaxjmsConnectionFactory for property targetConnectionFactory no matching editors or conversion strategy found orgspringframeworkbeansTypeConverterDelegateconvertIfNecessaryTypeConverterDelegatejava267 orgspringframeworkbeansBeanWrapperImplconvertIfNecessaryBeanWrapperImpljava459 87 more code,4
As a Spring XD developer Id like to port http module from XD to s-c-s repo so I can use it as source module in streaming pipeline,2
As a user Im not able to shutdown container from Admin UI with the following stream definition deployed code stream create swagataTestIssue --definition jdbc --queryselect employeeid employeename employer from EMPLOYEE --urljdbcoraclethinlocalhost1521orcl --usernamespringxd --passwordxdpwd --driverClassNameoraclejdbcOracleDriver --testOnBorrowfalse hdfs --inputTypeapplicationjson --deploy code More details herehttpsissuetrackerspringsourcecombrowseVESC-504,2
As a s-c-d developer Id like to add support to expose counter metrics endpoints so I can consume to feed the dashboards to demonstrate firehose counter pipe,3
As a developer Id like to investigate channel performance issues in SI 42 so I can determine the bottlenecks and take corrective actions to improve overall channel performance,8
As a developer Id like to isolate the Hadoop tests in a different project so that the DIRT project doesnt have to depend upon thus eliminating the incorrect CP file generation in eclipse,3
As a Spring XD developer Id like to move trigger module from XD to s-c-s repo so I can use it as source to build streaming pipeline,2
As a developer Id like to create a gpload tasklet so I can ingest data from various sources into GPDB in an efficient manner,5
As a developer Id like to move inputoutput type conversion from Spring XD repo into spring-bus so I can update Spring XD to inherit the featuresfunctionalities via maven dependency,8
As a developer Id like to troubleshoot and fix root level access over CF SPI REST calls theyre broke at the moment Access for following calls fail code href httpss-c-dataflow-admincfappspezpivotalio80streams href httpss-c-dataflow-admincfappspezpivotalio80tasks href httpss-c-dataflow-admincfappspezpivotalio80metricscounters href httpss-c-dataflow-admincfappspezpivotalio80metricscountersname href httpss-c-dataflow-admincfappspezpivotalio80modules href httpss-c-dataflow-admincfappspezpivotalio80completionsstreamstartdetailLevel code,1
As a developer Id like to troubleshoot the performance issues with Rabbit as message bus implementation so I can isolate the bottleneck and fix as appropriate,8
As a s-c-d developer Id like to investigate how to includeexclude msg busbinding jars so I can decide the binding selection and fallback mechanism when there is none setup,5
As a user I want to be able to provide my own RowMapperTuple implementation to enrich the jdbc data My use case requires me to add timestamp field and a delete flag field to records before they get written to HDFS To do it I have to implement a ItemReaderFactory and perhaps extend NameColumnJdbcItemReader This is to override the afterPropertySet method to change the default implementation Otherwise I have to write my own Processor that can add these fields to Tuples and since tuples are immutable I would have to recreate the tuples with additional fields in the processor For large load this could be big overhead I would love to know any other technique to implement such a use case,1
As a build manager Id like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds Scope Use the environment where Bamboo is running Gain access to powershell Setup services redis rabbit etc Kick-off CI task,5
As a user I want to have a documentation that shows how to configure multiple topics with Kafka source module,1
As a user I need to have the ability to create docker images via CI build so that I can build all the componentsconfigurations I need into a Docker image test it and deploy the image to various environments,8
As a user I would like the ability to undeploy or suspend a module without losing the deployment properties Currently when temporarily suspending a module an undeploy and redeploy is executed During the redeploy the deployment properties need to be added again Instead it would be nice if the properties are persisted so they automatically included with the deployment,5
As a field engineer Id like to have a comparison of Spark Streaming examples in Spring XD so that it is easy to relate from implementation standpoint,8
As a user Id like to have the option of Cassandra sink so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity,3
As a developer Id like to separate mocks vs real repository coupling from the test infrastructure so it is easy to test against thin layer of dependencies,8
As a SCDF user I want to be able to register artifacts as libraries so that I can reference them in include and exclude statements,2
As a user Id like to have the flexibility to specify config options for IP and Hostname so that I can list the correct configuration for XD Admin and XD Container servers in the Admin-UI and Shell,1
As a developer Id like to rebalance partitions as we scale the containers so I dont have to bring down the running streamjob to reestablish dynamic partitions,8
