id,x_test,y_train,y_test,meaningfulness,explanation_accuracy_scores,explanation_accuracy_decisions,okd,sim_threshold,sim_dist_threshold,adherence_to_knowledge_limits
0,as a user i'd like to have a redis based aggregation over field-value counters so that i can continuously write the aggregation in redis as we ingest more data. *scope:* * port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/old---aggregate-field-value-counters]. * identify gaps * update reference documentation,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
1,provide an --override option to the module upload command when uploading a new version of a module the admin container if there is already an existing module the behavior should be to delete the existing contents of the module directory and replace it with that of the new upload jar. this would be an optional parameter.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
2,provide a way to access currently deployed modules for testing it would be useful to access the deployed module instances to connect sources and or sinks to a module's input and output channels etc. this could be a simple as exposing the deployedmodulemap on moduledeployer or possibly something more elaborate if this level of granularity is generally useful for runtime administration.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
3,standardize date/time/timezone handling we should we centrally standardize on date/time formats so that we don't create inconsistencies and follow iso 8601 internally. internally we should only work with utc (or make that the default config option). ultimately whatever the user sees is just a formatting concern.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
4,as a qa i'd like to include acceptance test coverage for _gauge_ sink module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
5,spike: store dsl definition in zk as an xd developer i'd like to explore options to save composed job definition in zk metadata so i can use the repository to recreate jobs to recover from failure scenarios.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
6,create shell integration test for named chanels expected usage (atm) would be // sink channel called foo http | transform --expression=payload.touppercase() > :foo // source channel called foo :foo > count | file,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
7,ensure dsm matrix is diagonal,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
8,as a s-c-d developer i'd like to refactor cc spi deployer with cf java-client so i can improve the overall design and performance.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
9,"make doc generation part of the standard build following the recent move of the doco to the main repo it makes sense to have the doc generation be part of the ""main"" build at an early stage as an incentive for developers to push doc changes as soon as they change the code.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
10,"as a user i'd like to use the _mail_ source to connect to secured imap and/or smtp mail servers. _mail_ source config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [ref. example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html]. {code:xml} <beans:beans profile=""default""> <util:properties id=""javamailproperties""> <beans:prop key=""mail.imap.socketfactory.class"">javax.net.ssl.sslsocketfactory</beans:prop> <beans:prop key=""mail.imap.socketfactory.fallback"">false</beans:prop> <beans:prop key=""mail.store.protocol"">imaps</beans:prop> <beans:prop key=""mail.debug"">false</beans:prop> </util:properties> </beans:beans> {code} [list of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
11,add redisconnectionfactory with connection pool we need to add a connection pool to the redis connection factory used for the transport otherwise we'll see exceptions like these: 12:57:54842 error inbound.tictoc.0-redis:queue-inbound-channel-adapter1 inbound.redisqueuemessagedrivenendpoint:183 - failed to execute listening task. will attempt to resubmit in 5000 milliseconds. org.springframework.data.redis.redissystemexception: redis exception nested exception is com.lambdaworks.redis.redisexception: unable to connect at org.springframework.data.redis.connection.lettuce.lettuceexceptionconverter.convert(lettuceexceptionconverter.java:46) at org.springframework.data.redis.connection.lettuce.lettuceexceptionconverter.convert(lettuceexceptionconverter.java:36) at org.springframework.data.redis.connection.lettuce.lettuceconverters.todataaccessexception(lettuceconverters.java:159) at org.springframework.data.redis.connection.lettuce.lettuceconnection.convertlettuceaccessexception(lettuceconnection.java:253) at org.springframework.data.redis.connection.lettuce.lettuceconnection.brpop(lettuceconnection.java:1508) at org.springframework.data.redis.core.defaultlistoperations$12.inredis(defaultlistoperations.java:163) at org.springframework.data.redis.core.abstractoperations$valuedeserializingrediscallback.doinredis(abstractoperations.java:51) at org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:185) at org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:153) at org.springframework.data.redis.core.abstractoperations.execute(abstractoperations.java:86) at org.springframework.data.redis.core.defaultlistoperations.rightpop(defaultlistoperations.java:160) at org.springframework.data.redis.core.defaultboundlistoperations.rightpop(defaultboundlistoperations.java:105) at org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.popmessageandsend(redisqueuemessagedrivenendpoint.java:178) at org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.access$300(redisqueuemessagedrivenendpoint.java:51) at org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint$listenertask.run(redisqueuemessagedrivenendpoint.java:291) at java.lang.thread.run(thread.java:724) caused by: com.lambdaworks.redis.redisexception: unable to connect at com.lambdaworks.redis.redisclient.connect(redisclient.java:176) at com.lambdaworks.redis.redisclient.connectasync(redisclient.java:139) at org.springframework.data.redis.connection.lettuce.lettuceconnection.getasyncdedicatedconnection(lettuceconnection.java:2924) at org.springframework.data.redis.connection.lettuce.lettuceconnection.getdedicatedconnection(lettuceconnection.java:2932) at org.springframework.data.redis.connection.lettuce.lettuceconnection.brpop(lettuceconnection.java:1506) ... 11 more caused by: java.net.bindexception: cannot assign requested address at sun.nio.ch.net.connect0(native method) at sun.nio.ch.net.connect(net.java:465) at sun.nio.ch.net.connect(net.java:457) at sun.nio.ch.socketchannelimpl.connect(socketchannelimpl.java:639) at org.jboss.netty.channel.socket.nio.nioclientsocketpipelinesink.connect(nioclientsocketpipelinesink.java:108) at org.jboss.netty.channel.socket.nio.nioclientsocketpipelinesink.eventsunk(nioclientsocketpipelinesink.java:70) at org.jboss.netty.channel.channels.connect(channels.java:634) at org.jboss.netty.channel.abstractchannel.connect(abstractchannel.java:207) at com.lambdaworks.redis.redisclient.connect(redisclient.java:165) ... 15 more,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
12,spike for advanced job orchestration features,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
13,add support for xd_config environment variable in windows shell scripts this was added in bash scripts as part of xd-1186.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
14,"creating a base class for plugins it might be worth creating a base class for plugins that combines common concerns across plugins. e.g. that would allow us to hide the commonapplicationcontext and beandefinitionaddingpostprocessor for common cases instead exposing a simple addbeandefinition method to sub-classes.""",0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
15,"tuple unable to serialize objects with nested arrays of objects serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. the error is: {noformat} caused by: com.fasterxml.jackson.databind.jsonmappingexception: no serializer found for class org.springframework.xd.tuple.defaulttupleconversionservice and no properties discovered to create beanserializer (to avoid exception disable serializationfeature.fail_on_empty_beans) ) (through reference chain: java.util.arraylist[0]->org.springframework.xd.tuple.defaulttuple[""values""]->java.util.unmodifiablerandomaccesslist[0]->org.springframework.xd.tuple.defaulttuple[""conversionservice""]) com.fasterxml.jackson.databind.ser.impl.unknownserializer.failforempty(unknownserializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.impl.unknownserializer.serialize(unknownserializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.beanpropertywriter.serializeasfield(beanpropertywriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.asarrayserializerbase.serialize(asarrayserializerbase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.beanpropertywriter.serializeasfield(beanpropertywriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.asarrayserializerbase.serialize(asarrayserializerbase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.defaultserializerprovider.serializevalue(defaultserializerprovider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper.writevalue(objectmapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.core.base.generatorbase.writeobject(generatorbase.java:280) ~[jackson-core-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.pojonode.serialize(pojonode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.defaultserializerprovider.serializevalue(defaultserializerprovider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper.writevalue(objectmapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.core.base.generatorbase.writeobject(generatorbase.java:280) ~[jackson-core-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.pojonode.serialize(pojonode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.objectnode.serialize(objectnode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.defaultserializerprovider.serializevalue(defaultserializerprovider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper.writevalue(objectmapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.core.base.generatorbase.writeobject(generatorbase.java:280) ~[jackson-core-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.pojonode.serialize(pojonode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.objectnode.serialize(objectnode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.defaultserializerprovider.serializevalue(defaultserializerprovider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper.writevalue(objectmapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.core.base.generatorbase.writeobject(generatorbase.java:280) ~[jackson-core-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.pojonode.serialize(pojonode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.node.objectnode.serialize(objectnode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.std.serializableserializer.serialize(serializableserializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.ser.defaultserializerprovider.serializevalue(defaultserializerprovider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper._configandwritevalue(objectmapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5] com.fasterxml.jackson.databind.objectmapper.writevalueasstring(objectmapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5] org.springframework.xd.tuple.tupletojsonstringconverter.convert(tupletojsonstringconverter.java:37) ~[spring-xd-tuple-1.3.0.m1.jar:1.3.0.m1] {noformat} when the input string (read from a kafka topic in my case) looks something like: {noformat} { ""body"": [ { ""datatype"": ""har"" ""har"": { ""log"": { ""browser"": { ""name"": ""google chrome"" ""version"": ""44.0.2403.155"" } ""creator"": { ""name"": ""my extension"" ""version"": ""0.23.6"" } ""pages"": [ { ""_requesttimings"": { ""blocked"": -1 ""connect"": -1 ""dns"": -1 ""receive"": 11 ""send"": -1 ""ssl"": -1 ""wait"": 244 } ""_requesturl"": ""https://google.com"" } { ""_requesttimings"": { ""blocked"": -1 ""connect"": -1 ""dns"": -1 ""receive"": 11 ""send"": -1 ""ssl"": -1 ""wait"": 244 } ""_requesturl"": ""https://google.com"" } ] ""version"": ""1.2"" } } ""testid"": 1 } ] ""bodytype"": ""models.multimessage"" ""headers"": { ""appinstance"": ""localhost/127.0.0.1:8080"" ""clientip"": ""0:0:0:0:0:0:0:1"" ""host"": ""localhost:8080"" ""requestid"": ""27acf948-33ff-491c-8be7-1beb4b8c95d9"" ""requestmethod"": ""post"" ""requesturl"": ""http://localhost:8080/har"" ""timestamp"": 1445914510549 ""userprincipal"": ""235"" } } {noformat} if the inner array (the pages array) is just an object it works when it is an array it fails. the stream used: kafka --topic=agent_mixed --outputtype=application/x-xd-tuple | splitter --expression=payload.body | log",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
16,ui: visual representation of stream/job with deployed modules for a given stream/job we need a visual representation of the stream/job with any deployed modules.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
17,"improve job launch functionality with distributed nodes when sending a launch request the message is not targeted to the container node that hosts the deployed job. with rabbitmq the message is not ack'd so it will get picked up eventually by the container that hosts the deployed job. this should change to a targeted message. ----- original description from thomas below tried deploying some batch jobs and they all seem to fail when running admin and one container using redis as transport xd:>job create mongojob --definition ""hdfsmongodb --resources=/data/*.log --names=col1col2col3 --idfield=col1 --collectionname=test"" fails with this: {quote} 18:19:01612 warn redisinboundadapter-redis:queue-inbound-channel-adapter6 boot.springapplication:635 - error handling failed (error creating bean with name 'integrationrequestmappinghandlermapping': initialization of bean failed nested exception is java.lang.illegalstateexception: org.springframework.context.annotation.annotationconfigapplicationcontext@25e7506f has not been refreshed yet) 18:19:01614 error redisinboundadapter-redis:queue-inbound-channel-adapter6 handler.logginghandler:145 - org.springframework.messaging.messagehandlingexception: error occurred in message handler [moduledeployer] org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:84) org.springframework.integration.config.serviceactivatorfactorybean$1.handlerequestmessage(serviceactivatorfactorybean.java:83) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:170) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:128) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:114) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:92) org.springframework.integration.endpoint.messageproducersupport.sendmessage(messageproducersupport.java:98) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.popmessageandsend(redisqueuemessagedrivenendpoint.java:211) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.access$300(redisqueuemessagedrivenendpoint.java:50) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint$listenertask.run(redisqueuemessagedrivenendpoint.java:290) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) java.lang.thread.run(thread.java:724) caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'readresourcesstep': cannot create inner bean '(inner bean)' of type [org.springframework.batch.core.listener.steplistenerfactorybean] while setting bean property 'listeners' with key [0] nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name '(inner bean)#4': factorybean threw exception on object creation nested exception is java.lang.illegalargumentexception: interface org.springframework.batch.core.steplistener is not visible from class loader org.springframework.beans.factory.support.beandefinitionvalueresolver.resolveinnerbean(beandefinitionvalueresolver.java:282) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvevalueifnecessary(beandefinitionvalueresolver.java:126) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvemanagedlist(beandefinitionvalueresolver.java:351) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvevalueifnecessary(beandefinitionvalueresolver.java:154) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.applypropertyvalues(abstractautowirecapablebeanfactory.java:1456) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.populatebean(abstractautowirecapablebeanfactory.java:1197) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:537) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:475) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:304) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:228) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:300) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:195) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:681) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:760) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:482) org.springframework.boot.springapplication.refresh(springapplication.java:616) org.springframework.boot.springapplication.run(springapplication.java:306) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:130) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:225) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:270) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:260) org.springframework.xd.dirt.module.moduledeployer.handledeploy(moduledeployer.java:201) org.springframework.xd.dirt.module.moduledeployer.handlemessageinternal(moduledeployer.java:172) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) ... 18 more caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name '(inner bean)#4': factorybean threw exception on object creation nested exception is java.lang.illegalargumentexception: interface org.springframework.batch.core.steplistener is not visible from class loader org.springframework.beans.factory.support.factorybeanregistrysupport.dogetobjectfromfactorybean(factorybeanregistrysupport.java:151) org.springframework.beans.factory.support.factorybeanregistrysupport.getobjectfromfactorybean(factorybeanregistrysupport.java:110) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolveinnerbean(beandefinitionvalueresolver.java:272) ... 41 more caused by: java.lang.illegalargumentexception: interface org.springframework.batch.core.steplistener is not visible from class loader java.lang.reflect.proxy.getproxyclass0(proxy.java:487) java.lang.reflect.proxy.newproxyinstance(proxy.java:722) org.springframework.aop.framework.jdkdynamicaopproxy.getproxy(jdkdynamicaopproxy.java:121) org.springframework.aop.framework.jdkdynamicaopproxy.getproxy(jdkdynamicaopproxy.java:111) org.springframework.aop.framework.proxyfactory.getproxy(proxyfactory.java:98) org.springframework.batch.core.listener.abstractlistenerfactorybean.getobject(abstractlistenerfactorybean.java:163) org.springframework.beans.factory.support.factorybeanregistrysupport.dogetobjectfromfactorybean(factorybeanregistrysupport.java:144) ... 43 more {quote} i'll post more errors as i collect them",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
18,investigate long running tests the goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. investigate the long running tests. look for long timeout window declarations.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
19,change accepted-media-types to accpted-content-types,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
20,add integration tests for spel and groovy based routing,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
21,user wants a task status command to retrieve all task & job info for the running or completed job,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
22,add support for bson this has been encountered in a poc. could take the form of a processor (bson -> json) or better yet if possible be added at the automatic type conversion level,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
23,create required infrastructure to easily perform integration testing of shell commands,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
24,move cassandra sink to xd proper,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
25,as a spring xd developer i'd like to port {{aggregator}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline.,2,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
26,batch job's step execution count is always '0' the batch job's step execution count is retrieved from org.springframework.batch.admin.web.jobexecutioninfo in batch job repository. but the jobexecutioninfo always have the stepexecutioncount set to '0'.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
27,error when removing hdfs files in shell i get this: {code} xd:>hadoop fs rm /xd/test/time-3.log error: run hdfs shell failed. message is: org.apache.hadoop.fs.filestatus.isdirectory()z {code} so far i have seen this with --hadoopdistro hdp13 and hadoop12 same command works fine using shell from m5 release,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
28,create a standard way to configure spring cloud data and stream projects,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
29,document the log sink,0,0,0.0025889062881469726,8.333333333333332,1,1,0,1,0
30,as a developer i'd like to remove _id_ and _timestamp_ attributes from the {{tuple}} class so i can improve performance characteristics by not having them go through _serde_ instead we could leverage message headers to collect such information.,3,4,0.0027609235048294068,1.6666666666666672,0,1,0,1,0
31,as a developer i'd like to measure performance numbers for a simple stream so that i can characterize the overall throughput.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
32,upgrade to spring 4.0.2.release,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
33,as a module developer i would like the jsonstringtotupleconverter in the spring cloud streams project to maintain the types provided in the json string and not convert everything to a string representation.,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
34,update docs for new tap syntax now that taps are just channels we need to update the docs. the preceding colon is no longer needed (and will be removed altogether) so all examples should be like this: {code} tap:foo > bar {code},0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
35,"could not override rabbit sink module's rabbit connection factory properties currently rabbitmq sink module's connection properties could not be overridden by ""${xd.config.home}/${configproperties:rabbit}.properties"" even if ""local-override"" is set to true. it looks like the amqptemplate used by the amqp outbound channel adapter doesn't use the connection factory defined in the sink module.",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
36,make runtime modules listing by containerid pageable the runtimecontainerscontroller (from pr#340) returns the list of runtime modules. instead we need make it pageable.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
37,as a user i'd like to see the 'date' in logs so that i can troubleshoot issues that had occurred on a specific day and time. property that needs adjusted: https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#l11,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
38,as a developer i'd like to synchronize with the latest gemfire version (8.1?) so i can leverage the latest gemfire features and as well support updated bds stack. this effort in xd depends on spring data gosling ga release which in turn depends on gemfire 8.1 release timelines.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
39,"fix in-memory analytics most of the infrastructure and code cleanup has been done for in-memory analytics. the only remaining issue is that by including memory-analytics.xml from common.xml we're actually creating e.g. a new inmemorycounterrepository that is different from the one present in the admin process space. this story involves fixing that. it may actually be done as part of xd-353 handling the ""local"" transport as a special case (context inheritance) rather than import based on xd.transport",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
40,tab completion for existing entities provide shell tab completion when referencing an existing entity,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
41,"enable profile selection from module options this came up when working on email source. there is <int-mail:imap-idle-channel-adapter> and <int-mail:inbound-channel-adapter> it would be nice to be able to put those in two profiles and have one of the profile being activated from module options (e.g. email --polling=true|false) don't know the runtime cost of activating profiles but we could blindly activate profiles from all options passed explicitly : <beans profile=""profile-[optionname]-[optionvalue]""> not sure if this is the same as xd-132",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
42,investigate if we should use requrejs with angular,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
43,topic in mqtt source was marked as topics changed field back to topic,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
44,as a user i would like the ability to undeploy or suspend a module without losing the deployment properties. currently when temporarily suspending a module an undeploy and redeploy is executed. during the redeploy the deployment properties need to be added again. instead it would be nice if the properties are persisted so they automatically included with the deployment.,4,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
45,"add new sink modules as an user i'd like to have ootb sink modules to integrate with various data sources to egest data using spring xd. note: the ootb support however is limited to currently available spring integration adapters. acceptance criteria: - user should be able to list the 'new sink' through dsl commands - user should be able to optionally choose the ""new sink"" adapters for stream creation using xd shell - user should see appropriate error messages if the required attributes are missing while creating a stream with the 'new sink' module - after successful stream creation with the 'new sink' module the definition should be included in stream listing - rest endpoints should include 'new sink' definitions - data ingested into 'new sink' should be validated for accurateness - appropriate error/exception message needs logged if there's any problem ingesting data into 'new sink' module",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
46,"kafka source must set autostartup=false on kafkamessagedrivenchanneladapter if the value is not set the source may start before being bound to the bus throwing a ""dispatcher has no subscribers"" error",0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
47,add information that is updated in real-time for use in container matching information related to an xd-container process and/or machine that is not static such as 'group' e.g. free memory number of deployed streams should be available for use as variables in the evaluation context of the criteria spel expression in the admin's container matcher. a good candidate for the source of this information are system mbeans. see http://docs.oracle.com/javase/7/docs/api/java/lang/management/package-summary.html,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
48,as a spring xd developer i'd like to port {{splitter}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline.,2,2,0.0026111719012260437,1.6666666666666672,0,1,0,0,0
49,increase exit description text field on job execution process step page the step execution process (http://localhost:9393/admin-ui/#/jobs/executions/38/52) page should list more lines of text for 'exit description' field to make sense of error messages. *scope:* investigate how much information can be collected directly from the executioncontext. it may be dependent on the error types. let's have the observation documented to decide next steps.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
50,nonodeexception for job creation the following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398 {noformat} error leaderselector-0 leader.leaderselector - the leader threw an exception org.apache.zookeeper.keeperexception$nonodeexception: keepererrorcode = nonode for /xd/deployments/jobs/nnnn/modules org.apache.zookeeper.keeperexception.create(keeperexception.java:111) org.apache.zookeeper.keeperexception.create(keeperexception.java:51) org.apache.zookeeper.zookeeper.getchildren(zookeeper.java:1586) org.apache.curator.framework.imps.getchildrenbuilderimpl$3.call(getchildrenbuilderimpl.java:214) org.apache.curator.framework.imps.getchildrenbuilderimpl$3.call(getchildrenbuilderimpl.java:203) org.apache.curator.retryloop.callwithretry(retryloop.java:107) org.apache.curator.framework.imps.getchildrenbuilderimpl.pathinforeground(getchildrenbuilderimpl.java:199) org.apache.curator.framework.imps.getchildrenbuilderimpl.forpath(getchildrenbuilderimpl.java:191) org.apache.curator.framework.imps.getchildrenbuilderimpl.forpath(getchildrenbuilderimpl.java:38) org.springframework.xd.dirt.server.jobdeploymentlistener.recalculatejobstates(jobdeploymentlistener.java:197) org.springframework.xd.dirt.server.deploymentsupervisor$leaderlistener.takeleadership(deploymentsupervisor.java:389) org.apache.curator.framework.recipes.leader.leaderselector$wrappedlistener.takeleadership(leaderselector.java:536) org.apache.curator.framework.recipes.leader.leaderselector.dowork(leaderselector.java:398) org.apache.curator.framework.recipes.leader.leaderselector.doworkloop(leaderselector.java:443) org.apache.curator.framework.recipes.leader.leaderselector.access$100(leaderselector.java:63) org.apache.curator.framework.recipes.leader.leaderselector$2.call(leaderselector.java:244) org.apache.curator.framework.recipes.leader.leaderselector$2.call(leaderselector.java:238) java.util.concurrent.futuretask.run(futuretask.java:266) java.util.concurrent.executors$runnableadapter.call(executors.java:511) java.util.concurrent.futuretask.run(futuretask.java:266) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) java.lang.thread.run(thread.java:745) {noformat} no specific details on reproducing yet although the socialcast thread indicates: {quote} i only hit this when i have tried to deploy a job that fails deployment the first time {quote},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
51,spike: introduce xolpoc-admin to xd admin the poc for xd on lattice uses the following interface for module deployment: https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/moduledeployer.java {code} public interface moduledeployer { void deploy(moduledescriptor descriptor) void undeploy(moduledescriptor descriptor) modulestatus getstatus(moduledescriptor descriptor) } {code} this spike is to introduce this interface and the lattice implementation in the xd admin. the goals are to: * demo a poc showing simple stream deployment with the existing shell/admin to lattice * learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{abstractdeployer}} and related classes). note that this work will not necessarily be merged into xd itself although some of the concepts may be included in a future pr.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
52,composed of composed fails at stream deployment time although composition of a module out of an already composed module seems to work at the 'module compose' level trying to deploy a stream with that more complex module fails with org.apache.coyote.abstractprotocol$abstractconnectionhandler.process(abstractprotocol.java:589) org.apache.tomcat.util.net.jioendpoint$socketprocessor.run(jioendpoint.java:312) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:724) caused by: java.lang.illegalargumentexception: each module before the last must provide 'output' org.springframework.util.assert.notnull(assert.java:112) org.springframework.xd.module.compositemodule.initialize(compositemodule.java:132) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:234) org.springframework.xd.dirt.module.moduledeployer.deploymodule(moduledeployer.java:224) org.springframework.xd.dirt.module.moduledeployer.handlecompositemoduledeployment(moduledeployer.java:180) org.springframework.xd.dirt.module.moduledeployer.handlemessageinternal(moduledeployer.java:129) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) ... 63 more,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
53,"convert hadoop module to isolated classloader scheme * rename spring-xd-extension-hdfs to something else as it seems it is all spring ""data"" stuff and is not coupled to xd. but leave it in extensions/ for now * rename and move spring-xd-hadoop inside extensions (maybe to spring-xd-extension-hadoop (or hdfs)) * make hadoop related modules depend on the latter (which itself will depend on the former)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
54,update shell to support tasks h2. narrative as a user i need to be able to deploy a task (boot jar) via the cli. h2. back story since the concept of jobs as an explicit primitive within spring xd is going away in spring-cloud-data the shell needs to be updated to reflect that.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
55,investigate how to provide a means to share bean defintions across module instances in some cases it maybe useful to share a specific bean instance contributed by a user across multiple module instances. this story is a placeholder to collect requirements and discuss.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
56,close parent contexts when shutting down,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
57,create a broadcastermessagehandler that uses a 'serialized' broadcaster this is a parallel implementation to the rxjava https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/subjectmessagehandler.java that will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
58,jms source on ec2 only uses localhost for activemq broker [problem] on a ec2 container jms-activemq.properties was configured to use a activemq broker on a different host it still referred to localhost. on my local mac i was able to updated the jms-activemq.properties with an activemq on a different host and it worked. [work-around] while not recommended you can set the amq.url in the jms-activemq-infrastructure-context.xml. [steps to reproduce] 1) deploy a single admin/container using xd-ec2. 2) create a jms-activemq.properties file in the spring-xd-1.0.0.build-snapshot/xd/ where it refers to a broker on another machine (ec2-54-221-32-82.compute-1.amazonaws.com). 3) create a stream with jms as its source.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
59,refactor container to remove shared module context as a separate context the main container context becomes the shared context for modules.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
60,"source:file module read file line by line i have a stream that watch output of multi file in a directory process data and put it to hdfs. here is my stream creat command: stream create --name filehdfs --definition ""file --dir=/var/log/supervisor/ --pattern=tracker.out-*.log --outputtype=text/plain | loghdfstransformer | hdfs --fsuri=hdfs://192.168.1.115:8020 --directory=/data/log/appsync --filename=log --partitionpath=path(dateformat('yyyy/mm/dd'))"" --deploy problem is source:file module send all data read from file to log processing module instead of one line each turn becase of that payload string have millions of char i can't process it. ex: --- payload length---- 9511284 please tell me how to read line by line when use source:file module thanks !!!",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
61,command to create a tap to store it's definition and optionally deploy with --autostart flag,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
62,update the ec2 deployer ec2 deployer needs to change its configuration behavior to use environment variables vs. the property files * remove configuresystem class since we will use environment variables instead * allow users to set environment variables via the xd-ec2 properties. * if properties are not present use those that are available in the application.yml * utilize jclouds environment variable setup features to implement this behavior.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
63,handle xd admin server shutdown cleanly there are couple of issues here: 1) the admin server destroy() - close event's onapplicationevent(contextclosedevent) listener has stop() to stop the admin server's tomcat instance. the stop() also calls the applicationcontext's destroy() which loops again to stop. 2) with hsqlserver or any batch db server(in future) the admin server stop() also needs to handle the batch db server shutdown.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
64,as a user i'd like to push the custom module (built as uber-jar) via a rest api so that i can install the custom module in cluster.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
65,as a s-c-s developer i'd like to fix the {{kafka}} binder so i can create messaging microservices apps and successfully bind them to an operational kafka broker.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
66,"modify file sink to avoid dot with empty suffix the expression currently appends ""."" + ${suffix} (where the default suffix is 'out'). if the suffix value were an empty string this would lead to the file name ending with a dot. we should update the expression so that it only appends the dot if the suffix is not empty. this might be possible with a ternary expression.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
67,investigate typeconvertingstreamtests.testbasictypeconversionwithtap test failure in ci builds typeconvertingstreamtests.testbasictypeconversionwithtap() is failing intermittently. why?,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
68,as a user i want to be able to control the starting offset of the kafka source when a stream is deployed so that i can replay a topic if necessary. note: - starting offset is only considered when the stream is deployed - progress made by modules must survive their crash for a running stream - undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start tbd: what happens when streams are undeployed/redeployed - where do they resume from?,5,1,0.0026434442400932313,1.6666666666666672,0,1,0,1,0
69,vary queue number (b-7) based on the the results from b-6 select the number of consumer/producers that give a distinct >5% increase in message rate. below 5% change in message rate prefer lower consumer/producer count. vary the number of perftest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus. note the cpu performance using ‘top’ for the broker and perftest processes. test 1 (2 queues) * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500 test 2 (3 queues) * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500 test 3 (4 queues) * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500 test 4 (5 queues) * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500 * -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500 etc...,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
70,add aggregate counter monthly resolution query support,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
71,as a developer i'd like to build _spark streaming_ as data processors in xd so that we can demonstrate some of the capabilities. *implement using:* * java / java lambdas * scala,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
72,create documentation for the core analytical model abstractions and use of jpmml processor,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
73,re-add spark job acceptance test with spark standalone cluster the spark app test on spark standalone cluster is currently commented out: https://github.com/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/sparkapptests.java#l74 we need to add it back once the cluster is setup on acceptance test environment.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
74,as a developer i'd like to add support to _flush_ offsets intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
75,"allow tapping a stream prior to stream creation without specifying module name currently this works: stream create foo --definition ""tap:baz.time > log"" stream create baz --definition ""time | file"" but this doesn't: stream create foo --definition ""tap:baz > log"" stream create baz --definition ""time | file"" this is because the parser translates references to ""tap:baz"" to named channel ""tap:baz.time"" (the name of the stream's first module). if the stream is not yet created the parser cannot perform this translation. a fix for this will likely be related to the fix needed for xd-812.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
76,"ambari plugin doesn't work with security_enabled it seems like springxd_shell will pull jhs principal and keytab from mapred-site.xml. when springxd_shell is installed in edge node amabri returns ""can't find jhs keytab"" and failed. details [here|https://github.com/spring-projects/spring-xd-ambari/issues/8].",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
77,as a s-c-d developer i'd like to create {{moduleregistry}} implementation so i can use this infrastructure to lookup module coordinates by name.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
78,create small documentation section on jmx/monitoring functionalty should mention jolokia how to turn on/off boot/jolokia http metric/monitoring and jmx. mention the naming strategy to identify modules running in a stream.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
79,"module option validation not happening anymore it seems that no option validation (being spring or jsr 303) is happening anymore at stream creation time. eg {noformat} stream create foo --definition ""http --port=bar | log"" {noformat}",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
80,job undeploy operation throws exception job `undeploy` operation throws the following stacktrace: ``` http-nio-9393-exec-5 zookeeper.zookeeperjobrepository - exception while transitioning job 'j' state to undeploying org.apache.zookeeper.keeperexception$nonodeexception: keepererrorcode = nonode for /xd/deployments/jobs/j/status org.apache.zookeeper.keeperexception.create(keeperexception.java:111) org.apache.zookeeper.keeperexception.create(keeperexception.java:51) org.apache.zookeeper.zookeeper.setdata(zookeeper.java:1266) org.apache.curator.framework.imps.setdatabuilderimpl$4.call(setdatabuilderimpl.java:260) org.apache.curator.framework.imps.setdatabuilderimpl$4.call(setdatabuilderimpl.java:256) org.apache.curator.retryloop.callwithretry(retryloop.java:107) org.apache.curator.framework.imps.setdatabuilderimpl.pathinforeground(setdatabuilderimpl.java:252) org.apache.curator.framework.imps.setdatabuilderimpl.forpath(setdatabuilderimpl.java:239) org.apache.curator.framework.imps.setdatabuilderimpl.forpath(setdatabuilderimpl.java:39) org.springframework.xd.dirt.stream.zookeeper.zookeeperjobrepository.delete(zookeeperjobrepository.java:177) org.springframework.xd.dirt.stream.zookeeper.zookeeperjobrepository.delete(zookeeperjobrepository.java:199) org.springframework.xd.dirt.stream.zookeeper.zookeeperjobrepository.delete(zookeeperjobrepository.java:1) org.springframework.xd.dirt.stream.abstractinstancepersistingdeployer.undeploy(abstractinstancepersistingdeployer.java:68) org.springframework.xd.dirt.rest.xdcontroller.undeploy(xdcontroller.java:125) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) ```,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
81,as a user i need to use xd sqoop module to support the merge command. currently the sqooprunner createfinalarguments method forces the requirement for connect username and password options which are not valid for the merge option. a check of the module type to not force these options being assigned to sqoop arg list would be preferred,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
82,container server does not log a message that it has started or stopped successfully $ ./xd-container processing module 'module [name=file type=sink]' from group 'tailtest' with index: 1 processing module 'module [name=tail type=source]' from group 'tailtest' with index: 0 logging of 'processing module' should have log level time..,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
83,ui: the user should be able to view the log file for a specific job execution will require additional server-side jiras,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
84,"hsql always started even when using other database i set the config/xd-config.yml properties to use mysql including this profiles: active: defaultmysql when xd admin starts i still see hsql server started and localhost:9393/env shows: ""profiles"": [ ""adminserver"" ""hsqldb"" ""default"" ]",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
85,user wants a list of currently executing jobs,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
86,redis based repositories should use a namingstrategy class to calculate the name of the key to use for persistence rediscounterrepository and redisgaugerepository have duplicated code that needs to be factored out into a one place. one such duplication is the determination of the key name to use for persistence. this should be abstracted out into a strategy helper class.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
87,as a developer i'd like to upgrade boot and spring cloud build revisions so i can leverage the latest updates.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
88,users need the ability to provision an xd cluster on ec2 via command line tool. we need the ability to run an xd cluster to get a handle on general issues and missing features based on running the system in a 'true' clustered environment. we don’t need to make this an end-user facing feature in the short term e.g. set a few keys in the shell and then install via a shell command.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
89,support --ref=true/false for sftp source the file and ftp sources allow working with either the java.io.file or its contents. for consistency the sftp source should support the same mechanism.,0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
90,expose bean settings as configuration options to the kafka source and bus,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
91,batch job is marked as undeployed once computer comes back from hibernation i have a deployed batch job (single node server running inside sts). my machine goes to sleep. once i bring it back up i see the following log: {code} 12:57:35854 error leaderselector-5 leader.leaderselector - the leader threw an exception java.lang.illegalargumentexception: label is required org.springframework.util.assert.hastext(assert.java:162) org.springframework.xd.module.moduledescriptor$key.<init>(moduledescriptor.java:616) org.springframework.xd.dirt.server.jobdeploymentlistener.recalculatejobstates(jobdeploymentlistener.java:218) org.springframework.xd.dirt.server.deploymentsupervisor$leaderlistener.takeleadership(deploymentsupervisor.java:354) org.apache.curator.framework.recipes.leader.leaderselector$wrappedlistener.takeleadership(leaderselector.java:536) org.apache.curator.framework.recipes.leader.leaderselector.dowork(leaderselector.java:398) org.apache.curator.framework.recipes.leader.leaderselector.doworkloop(leaderselector.java:443) org.apache.curator.framework.recipes.leader.leaderselector.access$100(leaderselector.java:63) org.apache.curator.framework.recipes.leader.leaderselector$2.call(leaderselector.java:244) org.apache.curator.framework.recipes.leader.leaderselector$2.call(leaderselector.java:238) java.util.concurrent.futuretask.run(futuretask.java:266) java.util.concurrent.executors$runnableadapter.call(executors.java:511) java.util.concurrent.futuretask.run(futuretask.java:266) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) java.lang.thread.run(thread.java:744) {code} in the ui the job is marked as *undeployed* - however when i click *deploy* i get an error: *the job named 'bbb' is already deployed*.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
92,as a user i'd like to have the option to version the custom modules so i can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.,4,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
93,remove redisstreamdeploymentintegrationtests and rabbitstreamdeploymentintegrationtests these are duplicates of *singlenodedeploymentintegrationtests,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
94,incremental jdbcfile process for loading data into isilon cluster users should have the ability to load data from a jdbc source to a file sink pointing to a file location (nfs mount to an isilon cluster) in a particular directory structure. isilon support multiple protocols including nfs and hdfs. by storing data directly into an nfs mount we would eliminate the hdfs overhead. this functionality should be similar to the jdbchdfs job that is currently available in springxd. see jira issue 'xd-2309' for more details.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
95,"update hdfs sink to accept a partition strategy add configuration for the partition strategy to hdfs sink to support writing files into subdirectories based on a partition key provided in the header or field in the message of the stream data. the writing using hdfs store datawriter should pass in the partition key value to be used for the write operation. partition configuration could be made available to the sink using a --format parameter: that could then be used in xml config like: {code} expression=""new java.text.simpledateformat('${format}').format(${timestamp}) {code} similar to the time source.",0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
96,refactor module to encapsulate group and index currently many methods take module group index - defining a module instance group and index can be encapsulated in {{module}} so one arg can be passed around.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
97,update si dependency to 4.0.0.build-snapshot,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
98,create scripts for batch db creation we need to create a shell script that calls the batch db creation sql files for the jdbc option selected.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
99,as a developer i in the new development of component (source/processor/sink) how to get the module id and container id because components need to generate log log information must include the unique identifier xd:>runtime modules,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
100,"jmx shouldn't register taps or streams if the creation fails there's a lifecycle problem when a tap creation fails (e.g. because the dsl syntax is wrong). subsequent attempts to create the tap will fail with an error: [{""links"":[]""logref"":""messagehandlingexception""""message"":""org.springframework.context.applicationcontextexception: failed to start bean 'org.springframework.integration.monitor.integrationmbeanexporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2' nested exception is org.springframework.jmx.export.unabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=nullchannel sends=0 receives=0]] with key 'xd.tap1:type=messagechannelname=nullchannelindex=1module=log' nested exception is javax.management.instancealreadyexistsexception: xd.tap1:type=messagechannelname=nullchannelindex=1module=log""}] disabling jmx solves the issue. reproduce create a bad stream definition name 'bad' try to recreate with the same name but correct stream definitions. the system will report that the stream already exists.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
101,illegalstateexception when shutting down container {noformat} 13:23:57643 info main-eventthread server.containerregistrar - undeploying module [moduledescriptor@1c736092 modulename = 'log' modulelabel = 'log' group = 'paymenttap' sourcechannelname = 'tap:job:payment' sinkchannelname = [null] sinkchannelname = [null] index = 0 type = sink parameters = map[[empty]] children = list[[empty]]] 13:23:57643 error main-eventthread imps.curatorframeworkimpl - watcher exception java.lang.illegalstateexception: instance must be started before calling this method at com.google.common.base.preconditions.checkstate(preconditions.java:176) at org.apache.curator.framework.imps.curatorframeworkimpl.delete(curatorframeworkimpl.java:344) at org.springframework.xd.dirt.server.containerregistrar.unregistertap(containerregistrar.java:292) at org.springframework.xd.dirt.server.containerregistrar.undeploymodule(containerregistrar.java:257) at org.springframework.xd.dirt.server.containerregistrar$streammodulewatcher.process(containerregistrar.java:711) at org.apache.curator.framework.imps.namespacewatcher.process(namespacewatcher.java:67) at org.apache.zookeeper.clientcnxn$eventthread.processevent(clientcnxn.java:522) at org.apache.zookeeper.clientcnxn$eventthread.run(clientcnxn.java:498) {noformat} sequence of events: * stream module zk path is removed * event is raised * zk connection is closed * event handler causes module undeployment which includes unregistration of tap * since connection is closed exception is thrown,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
102,"create java client lib over rest api so that clients (e.g. shell or custom user program) are insulated from rest details (ala cloud foundry). may go even further if we want a java dsl for stream definitions (that may reuse batch command pojos btw): difference between: xdclient.createstream(""mystream"" ""http --port=9000 | file"") and import static stuff.* streamdef stream = http().port(9000).pipe(file()) xdclient.createstream(""mystream"" stream)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
103,research adding support for 'spring-cloud-config' to configure modules please refer to the gh issue reported here: https://github.com/spring-projects/spring-xd/issues/1218,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
104,as a spring xd developer i'd like to port {{tcp}} module from xd to s-c-s repo so i can use it as {{source}} module to build streaming pipeline.,2,2,0.0026111719012260437,1.6666666666666672,0,1,0,0,0
105,cors support xd instances will not accept xhr requests from browsers whose page origin does not match the xd instance. as an example the kodiak ui is served from a different process (and url) than the xd instance. when users open the kodiak ui in a browser requests from the browser to the xd instance but these requests will fail due to cross-site scripting limitations. cors (cross-origin resource sharing) is a way to get around this. we can configure the server to accept requests from browsers whose origins are not the xd instance. i have this working in a local branch and will submit a pull request. more information: cors spec: http://www.w3.org/tr/cors/ spr-9278 cors support for springframework,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
106,job failed to deploy (sporadic) commit: 433d18f03fd7f3bf7d9aeee80ab292f9c92af5a4 transport: rabbit 1 admin 2 containers admin log is attached. (exception is at line 52) during acceptance tests for testjobcreateduplicatewithdeployfalse failed with the following error reported from the admin. {noformat} org.springframework.xd.rest.client.impl.springxdexception(keepererrorcode = nonode for /xd/jobs/jobfalsedeploy ) org.junit.runners.model.multiplefailureexception.assertempty(multiplefailureexception.java:67) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:39) org.springframework.test.context.junit4.statements.runaftertestmethodcallbacks.evaluate(runaftertestmethodcallbacks.java:82) org.junit.rules.expectedexception$expectedexceptionstatement.evaluate(expectedexception.java:239) org.junit.rules.runrules.evaluate(runrules.java:20) org.springframework.test.context.junit4.statements.springrepeat.evaluate(springrepeat.java:73) org.junit.runners.parentrunner.runleaf(parentrunner.java:325) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:217) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:83) org.junit.runners.parentrunner$3.run(parentrunner.java:290) org.junit.runners.parentrunner$1.schedule(parentrunner.java:71) org.junit.runners.parentrunner.runchildren(parentrunner.java:288) org.junit.runners.parentrunner.access$000(parentrunner.java:58) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268) org.springframework.test.context.junit4.statements.runbeforetestclasscallbacks.evaluate(runbeforetestclasscallbacks.java:61) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.springframework.test.context.junit4.statements.runaftertestclasscallbacks.evaluate(runaftertestclasscallbacks.java:68) org.junit.runners.parentrunner.run(parentrunner.java:363) org.springframework.test.context.junit4.springjunit4classrunner.run(springjunit4classrunner.java:163) org.gradle.api.internal.tasks.testing.junit.junittestclassexecuter.runtestclass(junittestclassexecuter.java:86) org.gradle.api.internal.tasks.testing.junit.junittestclassexecuter.execute(junittestclassexecuter.java:49) org.gradle.api.internal.tasks.testing.junit.junittestclassprocessor.processtestclass(junittestclassprocessor.java:69) org.gradle.api.internal.tasks.testing.suitetestclassprocessor.processtestclass(suitetestclassprocessor.java:48) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:35) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:24) org.gradle.messaging.dispatch.contextclassloaderdispatch.dispatch(contextclassloaderdispatch.java:32) org.gradle.messaging.dispatch.proxydispatchadapter$dispatchinginvocationhandler.invoke(proxydispatchadapter.java:93) com.sun.proxy.$proxy2.processtestclass(unknown source) org.gradle.api.internal.tasks.testing.worker.testworker.processtestclass(testworker.java:105) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:35) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:24) org.gradle.messaging.remote.internal.hub.messagehub$handler.run(messagehub.java:355) org.gradle.internal.concurrent.defaultexecutorfactory$stoppableexecutorimpl$1.run(defaultexecutorfactory.java:64) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
107,as a cf user i'd like to have the ability to override the hdfs location so that i can change where the custom module _uber-jar_ can be stored and retrieved.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
108,"eliminate stack trace on xd-container shutdown when active module running after deploying stream (such as ""time | log"") the xd-container emits the following stacktrace(s) if the stream is in a deployed state when that xd-container process is halted via ctrl-c: {code} 20:15:31415 info main-eventthread module.moduledeployer:215 - removed simplemodule [name=log type=sink group=s index=1 @128936ff] 20:15:31417 error main-eventthread imps.curatorframeworkimpl:512 - watcher exception java.lang.illegalstateexception: org.springframework.context.annotation.annotationconfigapplicationcontext@7bf4bc83 has been closed already org.springframework.context.support.abstractapplicationcontext.assertbeanfactoryactive(abstractapplicationcontext.java:956) org.springframework.context.support.abstractapplicationcontext.getbean(abstractapplicationcontext.java:978) org.springframework.xd.module.core.simplemodule.getcomponent(simplemodule.java:214) org.springframework.xd.dirt.plugins.abstractmessagebusbinderplugin.unbindconsumerandproducers(abstractmessagebusbinderplugin.java:140) org.springframework.xd.dirt.plugins.stream.streamplugin.beforeshutdown(streamplugin.java:74) org.springframework.xd.dirt.module.moduledeployer.beforeshutdown(moduledeployer.java:267) org.springframework.xd.dirt.module.moduledeployer.destroymodule(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.handleundeploy(moduledeployer.java:197) org.springframework.xd.dirt.module.moduledeployer.undeploy(moduledeployer.java:169) org.springframework.xd.dirt.server.containerregistrar.undeploymodule(containerregistrar.java:252) org.springframework.xd.dirt.server.containerregistrar$streammodulewatcher.process(containerregistrar.java:580) org.apache.curator.framework.imps.namespacewatcher.process(namespacewatcher.java:56) org.apache.zookeeper.clientcnxn$eventthread.processevent(clientcnxn.java:522) org.apache.zookeeper.clientcnxn$eventthread.run(clientcnxn.java:498) 20:15:31420 info main-eventthread server.containerregistrar:250 - undeploying module time-0: time type=source deploymentproperties={count=1} 20:15:31420 info main-eventthread module.moduledeployer:215 - removed simplemodule [name=time type=source group=s index=0 @51a42578] 20:15:31420 error main-eventthread imps.curatorframeworkimpl:512 - watcher exception java.lang.illegalstateexception: org.springframework.context.annotation.annotationconfigapplicationcontext@6d223732 has been closed already org.springframework.context.support.abstractapplicationcontext.assertbeanfactoryactive(abstractapplicationcontext.java:956) org.springframework.context.support.abstractapplicationcontext.getbean(abstractapplicationcontext.java:978) org.springframework.xd.module.core.simplemodule.getcomponent(simplemodule.java:214) org.springframework.xd.dirt.plugins.abstractmessagebusbinderplugin.unbindconsumerandproducers(abstractmessagebusbinderplugin.java:144) org.springframework.xd.dirt.plugins.stream.streamplugin.beforeshutdown(streamplugin.java:74) org.springframework.xd.dirt.module.moduledeployer.beforeshutdown(moduledeployer.java:267) org.springframework.xd.dirt.module.moduledeployer.destroymodule(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.handleundeploy(moduledeployer.java:197) org.springframework.xd.dirt.module.moduledeployer.undeploy(moduledeployer.java:169) org.springframework.xd.dirt.server.containerregistrar.undeploymodule(containerregistrar.java:252) org.springframework.xd.dirt.server.containerregistrar$streammodulewatcher.process(containerregistrar.java:580) org.apache.curator.framework.imps.namespacewatcher.process(namespacewatcher.java:56) org.apache.zookeeper.clientcnxn$eventthread.processevent(clientcnxn.java:522) org.apache.zookeeper.clientcnxn$eventthread.run(clientcnxn.java:498) {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
109,rabbit bus: expose channelcachesize on cachingconnectionfactory http://stackoverflow.com/questions/35563064/processing-messages-through-namedchannels-with-prefetch-1/35584333#35584333,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
110,"add ""how to build spring-xd"" instructions to the documentation we need to determine where this information could fit in. it can be either in ""readme"" at the project home page or ""getting started"" wiki page.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
111,as a developer i'd like to use ambari plugin so that i can provision manage and monitor spring xd cluster using the same tool i use for hadoop clusters.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
112,xd-admin silently fails if servers.yml is invalid for example: {code} xd: transport: rabbit messagebus: # local: # queuesize: 2147483647 # polling: 1000 # executor: # corepoolsize: 0 # maxpoolsize: 200 # queuesize: 2147483647 # keepaliveseconds: 60 rabbit: # compressionlevel: 1 # bus-level property applies only when 'compress=true' for a stream module # see java.util.zip.deflater 1=best_speed 9=best_compression ... default: # ackmode: auto # valid: auto (container acks) none (broker acks) manual (consumer acks). # upper case only. # note: manual requires specialized code in the consuming module and is unlikely to be # used in an xd application. for more information see # http://docs.spring.io/spring-integration/reference/html/amqp.html#amqp-inbound-ack # autobinddlq: false # backoffinitialinterval: 1000 # backoffmaxinterval: 10000 # backoffmultiplier: 2.0 # batchbufferlimit: 10000 batchingenabled: true # batchsize: 100 # batchtimeout: 5000 # compress: false # concurrency: 1 # deliverymode: persistent # maxattempts: 3 # maxconcurrency: 1 # prefix: xdbus. # prefix for queue/exchange names so policies (ha dle etc.) can be applied # prefetch: 1 # replyheaderpatterns: standard_reply_headers* # requestheaderpatterns: standard_request_headers* # requeue: true # transacted: false # txsize: 1 # redis: # headers: # comman-delimited list of additional (string-valued) header names to transport # default: # default bus properties if not specified at the module level # backoffinitialinterval: 1000 # backoffmaxinterval: 10000 # backoffmultiplier: 2.0 # concurrency: 1 # maxattempts: 3 # kafka: # brokers: localhost:9092 # zkaddress: localhost:2181 # numofkafkapartitionsforcountequalszero: 10 # socketbuffersize: 2097152 # offsetstoretopic: springxdoffsets # offsetstoresegmentsize: 25000000 # offsetstoreretentiontime: 60000 # offsetstorerequiredacks: 1 # offsetstoremaxfetchsize: 1048576 # offsetstorebatchsize: 200 # offsetstorebatchenabled: false # offsetstorebatchtime: 1000 # offsetupdatetimewindow: 10000 # offsetupdatecount: 0 # offsetupdateshutdowntimeout: 2000 default: batchingenabled: true {code},0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
113,create a loadgenerator source module create a load-generator source module that will generate messages and dispatch messages to a xd stream.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
114,fix existing karma unit tests + migrate e2e tests to protractor the grunt build for karma unit tests is currently broken with requirejs support on the xd admin app.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
115,fix package tangle fix package tangle issue reported here: https://build.spring.io/browse/xd-sonar-490,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
116,disable auto-formatting of javadoc,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
117,"refactor streamparser to return a streamdefinition {code} streamdefinition sd = streamparser.parse(name dsltext) {code} we should also consider explicit methods such as parsestream (so that parsejob and parsecomposedmodule are at least separate methods if not separate parser classes that share the common parser support class that is the core of today's parser). the parsing for ""completion providers"" should probably be spun off to its own class as well. in the end there should be no need for a parsingcontext enum but rather more explicitly named methods and dedicated classes if that seems like the right approach. the streamdefinition should be composed of ""moduledescriptors"" (that name is not set in stone) and other stream-level metadata like source/sink channels consider merging some of streamfactory code there and the rest into streamdeployer merge moduledescriptor and moduledeploymentrequest as part of this effort (again a new name could be considered but moduledescriptor should take precedence over moduledeploymentrequest) and note in the process that moduledescriptor was originally designed to be immutable (taking constructor args) but as we migrated the prototype code into xd itself this was violated. we may want to consider a builder approach and we likely want to avoid the need for a moduledefinition within the moduledescriptor.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
118,filepollhdfs --deletefiles=true has no effect files are not deleted setting --deletefiles=true has no effect any longer. this also causes the script integration tests to fail. suspect this is related to the change here https://github.com/spring-projects/spring-xd/commit/6dbac167758ce23b9a4dbf07169b2d26d1eddef1,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
119,as a user i'd like to use the latest release of {{gemfire}} sink so i can create a streaming pipeline to land data in gemfire.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
120,add tap support for rabbit binder as an s-c-d user i'd like to {{tap}} the primary pipeline so i can fork the same data and do some ad-hoc analysis without impacting the original stream.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
121,as a qa i'd like to include acceptance test coverage for _splitter_ processor module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.77251607550301,0,1,0,0,0
122,test processor module in isolation register the module under test and have access to a source channel that drives messages into the processor and a output channel where output messages are sent. examples built-in message conversion: send json to a processor module that accepts tuples.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
123,the shell processor module cannot be stopped while blocked in receive() both lifecycle and send/receive methods are synchronized so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script the stop() method can't acquire the object lock and proceed stopping the instance and therefore the module.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
124,modify acceptance tests to give a pause time for deployment different than default kafka deployments take nearly 4 times as long as other transports because of the creation of the topic an partitions. currently all test use the same wait time whether it is for waiting for connections or file writes. so to get a ci build for kafka build would take a long period of time. the goal of the story is to allow deployments to have a different pause_time to give kafka bus the extra time it needs but not affect the timeout for other stages of the tests.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
125,deployed modules mbeans are not accessible via jolokia when a module is deployed it doesn't use jolokia auto configuration (which requires an embedded servlet container configuration). but the module context isn't using a servlet context. from simplemodule: application = new springapplicationbuilder().sources(propertyplaceholderautoconfiguration.class).web(false) and hence the mbeans that are exposed by the deployed modules aren't accessible via jolokia. we definitely don't want simplemodule to use web application context but we need to figure out if we can use the container's management port to expose the deployed modules mbeans via jolokia.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
126,pluralize test classes in package org.springframework.xd.shell.command the classes under test are pluralized. therefore the test classes themselves should reflect that. e.g. rename *jobcommandtests* to *jobcommandstests* as it tests class *jobcommands*. please check all tests in that package for correct naming.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
127,update java version to 7,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
128,handle npe while deploying stream module at the container when trying to deploy a stream module the containerregistrar throws npe if the deployment loader couldn't load a non-null stream based on the stream name. 07:10:29902 error deploymentspathchildrencache-0 server.containerregistrar:450 - exception deploying module java.lang.nullpointerexception org.springframework.xd.dirt.server.containerregistrar.deploystreammodule(containerregistrar.java:549) org.springframework.xd.dirt.server.containerregistrar.onchildadded(containerregistrar.java:436) org.springframework.xd.dirt.server.containerregistrar.access$800(containerregistrar.java:96) org.springframework.xd.dirt.server.containerregistrar$deploymentlistener.childevent(containerregistrar.java:803) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:494) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:488) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:293) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:485) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$11.run(pathchildrencache.java:755) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:744),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
129,"file to hdfs batch job fails due to ""/data"" directory not available in hdfs the batch job for file to hdfs will try to check for the default '/data/' directory even if the target directory in hdfs is something else. if the /data directory isn't there the job will fail. this should be fixed so there isn't a check on the directory that isn't the final hdfs target directory and the target directory should be created if it doesn't exist.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
130,as a user i'd like to have a gradle build option so that i can support module projects that will declare the spring xd dependencies as provided configure the boot plugin for 'module' layout and other boilerplate build configuration. this is dependent on boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
131,create script-based batch itemprocessor this would be included in the ootb batch jobs to optionally process the loaded tuple with a configured script.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
132,implement a dirt plugin for spark streaming support,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
133,create plugin module for reactor based processors as an developer i'd like to have a similar approach to creating reactor based stream processor as with spark and rxjava. a plugin should allow a reactor processor module to specify the bare minimum to work e.g. the processor class. explore how additional configuration can be achieved with well known module option commands.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
134,scs - verify/fix abstractkryomultitypecodec implementation this apparently is not tested or used internally but i expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. this method does not always work due to type erasure http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime. we need to verify if this is working if not fix it. the api may require it so possibly unsupportedoperationexception... {code} /** * infers the type from this class's generic type argument * @param kryo * @param input * @return */ protected t dodeserialize(kryo kryo input input) { class<t> type = (class<t>) ( (parameterizedtype) this.getclass().getgenericsuperclass()).getactualtypearguments()[0] return dodeserialize(kryo input type) } {code},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
135,reactor environment improvements use a profile or similar to only include the {{environment}} conditionally (currently in module-common.xml. also jon brisbin one thing to keep in mind: we talked about having a properties file for xd that configured the ringbuffer et al in a non-default way jon brisbin e.g. no event loop dispatchers…a threadpooldispatcher with a large thread pool size (50 threads? 100?)…and maybe even two ringbufferdispatchers: input and output jon brisbin so we might want to change from strictly a default environment bean to an environmentfactorybean with a specific configuration…thinking about it now i maybe should add a namespace element for the environment,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
136,as a scala developer someone could easily deploy the spark streaming module developed using scala.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
137,add support to restart job composition as an xd user i'd like have support restart an existing composed job so i could re-launch it at will.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
138,unable to deploy job in ui this only happens when creating jobs via the cli and deploying using the ui on the job page: http://localhost:9393/admin-ui/#/jobs/definitions i click [deploy] for a job and get a screen asking for container match criteria and job module count - clicking on the [deploy] button on that screen does nothing - i see this error reported: deploying job definition undefined angular.js:9778 typeerror: cannot read property 'jobdefinition' of undefined at scope.$scope.deploydefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78) at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21 at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17 at scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28) at scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23) at htmlbuttonelement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21) at htmlbuttonelement.jquery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9) at htmlbuttonelement.elemdata.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
139,user should be able to specify rabbit virtual host need to support rabbit virtual host property in properties file and as args to rabbit source and sink,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
140,as a qa i'd like to include acceptance test coverage for _sftp_ source module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
141,"cannot destroy tap if tapped stream is already destroyed xd:>tap destroy mytap 16:44:41850 warn spring shell client.resttemplate:524 - delete request for ""http://localhost:8080/taps/mytap"" resulted in 400 (bad request) invoking error handler command failed org.springframework.xd.rest.client.impl.springxdexception: xd116e:(pos 4): unrecognized stream reference 'foo' tap foo.http | log tap is then still listed when i do a ""tap list""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
142,"not able to connect a pubsub channel to spark streaming module if a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel) then it doesn't bind to it. for instance if i have a stream ""ingest"" with a definition ""http | log"" and want to create another stream as ""tap:stream:ingest > spark-processor | count"" then this stream doesn't work.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
143,temp files for stream create not being cleaned during testing for spring xd for pivotalcf we create deploy use undeploy and destroy many streams. each stream generates {{tmp}} directories (i think 2 one for source one for sink) in the xd-admin vm's {{/tmp}} directory e.g. {noformat} dummy-module4635787551932601017sinkredis dummy-module252960009195893204sourcehttp {noformat} these {{tmp}} directories are not being cleared up so our system has hit the inode limit of 32768 files for a volume: {noformat} filesystem inodes iused ifree iuse% mounted on /dev/loop0 32768 32768 0 100% /tmp {noformat} this causes a java {{ioexception}} the immediately relevant part of which appears to be: {noformat} [caught] exception while handling a request feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0: [java.lang.runtimeexception] java.io.ioexception: no space left on device feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0: [] at org.springframework.xd.module.moduledefinitions.dummy(moduledefinitions.java:81) {noformat} this causes the test system to fail entirely.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
144,as a s-c-d developer i'd like to break the build lifecycle to bundle spi deployers individually so i don't have to build {{admin}} with all the deployer variations as one whole thing.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
145,support partitioning properties using these as a starting point support the standard binder partitioning properties: https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/binderproperties.java#l69 https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/messagechannelbindersupport.java#l663,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
146,upgrade to spring integration 4.0.0.m4 currently on snapshots which is oddly pulling in groovy 2.1.0,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
147,as a user i'd like to have the ootb _gpfdist_ sink module so i can use this module to do ultra fast data movement from various sources into gpdb/hawq.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
148,only ship relevant modules files the current build ships everything that is found in the modules directory including build artifacts such as build/ or idea *.iml files. restrict the build to only include config/ lib/ at the moment.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
149,as a developer i'd like to clean-up compiler and javadoc warnings from the build so we don't see the warnings in build sysout.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
150,as a user i'd like to have the option to supply data partitioning strategy so that i can parallelize ingest of data from rdbms to hdfs.,5,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
151,change default date formats to be 'yyyy-mm-dd' we have some places where we us a default data format specified as 'yyyy/mm/dd'. in spring for apache hadoop we use 'yyyy-mm-dd' for partitioning path expressions. this seems more in line with iso standard date format. for consistency we should have both shdp and xd use the same default format.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
152,"refactor message conversion in channelregistrysupport after an initial attempt which was not ready for m2 we are rethinking our strategy. one of the fundamental things we have come to realize is that its important to treat serialization and type conversion as separate concerns. serialization: a core principle is the consumer should by default receive exactly what the producer sent: - if the producer sends a byte[] payload then no serialization is required. - a string payload can use simple byte conversion taking the charset into account - transporting an object uses whatever serialization is configured (json xml avro protocol buffer java.io msgpack etc.). the actual serialization performed for each message must be shared with the producer and consumer. i.e. the consumer needs to know which case above applies to each payload. currently we are using the messageheaders.content_type defining custom mime types for this (the designated header is subject to change) conversion: - the consumer optionally defines one or more content-types (read mimetype) it can accept in order of preference. if no conversion succeeds we can either give them the byte[] payload or throw an exception (configurable?). examples: - consumer accepts a java object (application/x-java-objecttype=example.foo). assume for simplicity the consumer may send a json string or a foo. on the receiving end we need to distinguish a string payload containing a json representation of foo from a serialized foo payload. if the payload is a string we need to know that its original content is application/json. we are currently using a 2nd ""original-content-type"" message header to supply this information. so in the first case we have (conceptually) content-type: ""xd plain text"" original-content-type ""application/json"". in the second case we have content-type: ""xd serialized json"" original-content-type not used in this case since the serialized json includes type information (using jackson conventions which are a bit brittle). -if the producer type is different from the accepted type we use the conversion service and the consumer must register appropriate converters. a twist for xd that may be generally relevant is that some optimization is possible when we know the bytes represent json: - tuple conversion: since we serialize using json and we know how to transform json <->tuple we can convert any object payload or any json string to a tuple. we can avoid the two step deserialization+conversion e.g. 1) foo->json->foo 2) foo->tuple.",0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
153,as a user i logged in with role_create and i get an error while trying job creation from admin_ui. i can create job from the shell successfully. trying the same workflow with role_admin results with the same error as well. i don't see anything in the admin/container logs about the error itself.,1,1,0.0026434442400932313,1.6666666666666672,0,1,0,1,0
154,all controllers to return xyzresource objects not the raw domain objects. resource objects should be returned from all controller methods. mvc tests should be added to check returned values.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
155,use guava 15.0 for spring-xd-integration-test jclouds is not compatible with versions of guava higher than 15.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
156,enabling of jmx support is broken however this is triggered (depending on whether https://github.com/spring-projects/spring-xd/pull/477/files is merged yet or not) jmx seems to be broken because of duplicate beans / mbeans names,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
157,as a developer i'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that i can use this module to ingest data from mongo.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
158,display the ui from xd-admin container when doing development in eclipse the ui code will be sitting in one or more top level directories in the repository this story will address the need to 1) copy over the ui code into a location so that it can be picked up by the embedded servlet container when running inside eclipse,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
159,the container's deploymentlistener should watch /xd/deployments/modules currently it watches /xd/deployments/[containerid] but due to the reuse of that top level node for xd-1483 and xd-1484 we should instead use /xd/deployments/modules/[containerid],0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
160,as a user i'd like to evaluate spring boot dependency upgrades so that i can make sure there aren't any side effects or impacts to existing functionalities.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
161,as a s-c-s user i'd like to search the modules by it's name aside from the default {{spring.application.name}} offered by boot so i can also fetch modules by it's name.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
162,update to spring-data-hadoop 2.0.0.m5 update to spring-data-hadoop 2.0.0.m5 when it is released and remove the temporary datasettemplateallowingnulls in spring-xd-hadoop we should also review the supported hadoop distros - think we should support anything that is current/stable: - hadoop12 - hadoop22 - phd1 (phd 1.1) - hdp13 - hdp20 - cdh4,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
163,defaultmoduleoptionsresolver to use parent classloader to load options metadata classes there are cases where it would be required to load the options metadata classes from the parent classloader *first* than the module's parentlasturlclassloader. it would be nice to have a configuration option in defaultmoduleoptionsresolver to set which classloader to use.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
164,as a developer i'd like to create separate repo for k8s spi so i don't have to bundle all spi variants under one admin project.,3,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
165,xd scripts lib path needs to be dynamic we currently have the manually created xd scripts. this makes it difficult to maintain as the lib path is error prone with the changes. we need to make sure that the properties such as lib path etc. are dynamically updated.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
166,documentation for counter taps put on the guide as a section in an 'input-stream' wiki page.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
167,"better ux when admin is not running current behavior is to just have a prompt of ""unknown:>"" i think any return value of a @clicommand method is not shown b/c the whole infrastructure is not up at that time",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
168,"shell: remove ""taps list"" command we should only allow ""tap list"" - currently ""tap list"" and ""taps list"" are allowed but ""tap list"" does not show up under help.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
169,fix minor bug with gemfire sources https://github.com/spring-projects/spring-xd/blob/master/modules/common/gemfire-connection.groovy#l8 is syntactically incorrect. it looks like the intention was to pass this a property but it appears it is treated as a literal value which groovy coerces to true. thus subscription-enabled is always true. it should be configurable although some modules require subscription-enabled to be true.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
170,as a developer i'd like to revisit performance benchmarks with new improvements so i can verify the optimizations around _jdbchdfs_.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
171,configuration for rabbitmq message bus concurrent consumers by having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
172,as a developer i want to be able to set a partitioning key for the kafka bus even when there is a single downstream module so that i can take advantage of the native kafka partitioning and message ordering support.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
173,"use descriptive texts for some module options defaults need a way to tell the user that this option will be determined at runtimelate bindings. in the module info command references to ${xd.stream.name} could read ""<use stream name>"" for example)",0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
174,enhance hadoopfilesystemtestsupport to obtain resource for a specific hadoop distro it looks like the hadoopfilesystemtestsupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro. currently if the test is run against a version other than 1.2 the rule says: 15:47:34469 error main hadoop.hadoopfilesystemtestsupport:95 - hadoop_fs is not available skipping tests org.apache.hadoop.ipc.remoteexception: server ipc version 9 cannot communicate with client version 4 org.apache.hadoop.ipc.client.call(client.java:1113) org.apache.hadoop.ipc.rpc$invoker.invoke(rpc.java:229) com.sun.proxy.$proxy8.getprotocolversion(unknown source) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:601) org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:85) org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:62) com.sun.proxy.$proxy8.getprotocolversion(unknown source) org.apache.hadoop.ipc.rpc.checkversion(rpc.java:422) org.apache.hadoop.hdfs.dfsclient.createnamenode(dfsclient.java:183) org.apache.hadoop.hdfs.dfsclient.<init>(dfsclient.java:281) org.apache.hadoop.hdfs.dfsclient.<init>(dfsclient.java:245) org.apache.hadoop.hdfs.distributedfilesystem.initialize(distributedfilesystem.java:100) org.apache.hadoop.fs.filesystem.createfilesystem(filesystem.java:1446) org.apache.hadoop.fs.filesystem.access$200(filesystem.java:67) org.apache.hadoop.fs.filesystem$cache.get(filesystem.java:1464) org.apache.hadoop.fs.filesystem.get(filesystem.java:263) org.apache.hadoop.fs.filesystem.get(filesystem.java:124) org.springframework.xd.test.hadoop.hadoopfilesystemtestsupport.obtainresource(hadoopfilesystemtestsupport.java:49) org.springframework.xd.test.abstractexternalresourcetestsupport.apply(abstractexternalresourcetestsupport.java:58) org.junit.rules.runrules.applyall(runrules.java:26) org.junit.rules.runrules.<init>(runrules.java:15) org.junit.runners.blockjunit4classrunner.withtestrules(blockjunit4classrunner.java:379) org.junit.runners.blockjunit4classrunner.withrules(blockjunit4classrunner.java:340) org.junit.runners.blockjunit4classrunner.methodblock(blockjunit4classrunner.java:256) org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:70) org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:50) org.junit.runners.parentrunner$3.run(parentrunner.java:238) org.junit.runners.parentrunner$1.schedule(parentrunner.java:63) org.junit.runners.parentrunner.runchildren(parentrunner.java:236) org.junit.runners.parentrunner.access$000(parentrunner.java:53) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:229) org.junit.runners.parentrunner.run(parentrunner.java:309) org.eclipse.jdt.internal.junit4.runner.junit4testreference.run(junit4testreference.java:50) org.eclipse.jdt.internal.junit.runner.testexecution.run(testexecution.java:38) org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:467) org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:683) org.eclipse.jdt.internal.junit.runner.remotetestrunner.run(remotetestrunner.java:390) org.eclipse.jdt.internal.junit.runner.remotetestrunner.main(remotetestrunner.java:197),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
175,"broken ""deployment"" link in docs please see ""deployment"" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.release/reference/html/#_module_deployment page. !broken-link-deployment.png! the link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.release/reference/html/deployment which is a 404.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
176,the hdfs sink should support a number of rollover options a strategy to roll over files that allows the user to choose between 1) the size of the file 2) the number of events/items in the file 3) an idle timeout value that if exceeded will close the file,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
177,provide xd module build plugins to upload a module provide maven and gradle plugins to execute module upload via rest to upload and install a module to spring xd. e.g. mvn xd:upload-module ...,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
178,return full moduleinstancestatus information currently there is no moduleinstancestatus returned. this issue will fill in the details.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
179,avoid using jquery inside admin ui there are couple of places where jquery is being used in the admin ui and those are for some dom manipulations. i believe these can certainly be replaced with the use of angular directive or custom functions and thereby we can remove jquery dependency in the app.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
180,as a user i'd like to create a stream such as _generator | perf-meter_ so that i can ingest 1m messages of 1000 bytes and one thread using xd's 'singlenode' container and measure performance characteristics.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,1,0
181,allow arbitrary headers to be set in http-client processor see http://stackoverflow.com/questions/26880903/using-mappedrequestheaders-in-spring-xd,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
182,"add named channel api we need an abstraction in place to retrieve messages from a ""named channel"" programmatically. right now there is no implementation agnostic way of doing this (such as receivemessage() queuesize()). this could be quite useful for integration tests of streams. e.g. to do more focussed tests without resorting to ""temp-files"" and non-essential sinks or sources etc. - e.g. {code} :routeit > router --expression=payload.contains('a')?':foo':':bar' {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
183,log hadoop distro and zk client connect info on container startup it would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
184,upgrade asciidoctor toolchain this will in turn allow us to get rid of the custom logic for handling crossref links between documents,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
185,create module options metadata for ootb jobs,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
186,create unit tests for countersinkproperties in s-c-s-m,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
187,taps introduction section should show use of shell to create a real stream and a real tap using the shell see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#taps the existing docs should be made to show a real stream being created with filter and/or transformer and then a tap that goes to logging. the shell syntax to also stop/undeploy a tap should be shown here as well since the lifecycle is discussed.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
188,re-deployment of stream/job modules upon container departure doesn't choose appropriate container candidates upon container departure the containerlistener's onchildleft() event triggers redeployment of stream/job modules that were deployed into the leaving container. during the redeployment it happens that the container candidates from the defaultcontainermatcher *sometimes* (based on the subset from distributeforrequestedcount(list<container> candidates int count)) includes the container which already have the module of the *same* stream/job definition deployed. this causes the re-deployment silently swallowing the nodeexistsexception and the module being re-deployed doesn't actually get deployed.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
189,as a developer i'd like to create a new _load-generator_ so i can use it to measure highly optimized (kryo serialized) payload to measure the performance differences.,3,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
190,add spring cloud config to spi module parent enable spring cloud config for all modules * add spring cloud config client to pom dependencies. * add bootstrap.yml to scs project,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
191,enable/disable boot and integration mbeans when jmx is enabled/disabled spring integration mbeans are enabled by default even though xd_jmx_enabled is set to false. we need to disable jmx on these mbeans as well as spring boot mbeans.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
192,"shell completion crashes the xd shell completion crashes on: job launch --name <tab> gives {noformat} xd:>job launch --name exception in thread ""spring shell"" java.lang.illegalstateexception: could not determine kind: tab-completion-count-1 existing-job disable-string-converter org.springframework.xd.shell.converter.completionconverter.determinekind(completionconverter.java:109) org.springframework.xd.shell.converter.completionconverter.getallpossiblevalues(completionconverter.java:69) org.springframework.shell.core.simpleparser.completeadvanced(simpleparser.java:857) org.springframework.shell.core.parsercompleter.complete(parsercompleter.java:47) jline.console.consolereader.complete(consolereader.java:3077) jline.console.consolereader.readline(consolereader.java:2501) jline.console.consolereader.readline(consolereader.java:2162) jline.console.consolereader.readline(consolereader.java:2150) org.springframework.shell.core.jlineshell.promptloop(jlineshell.java:522) org.springframework.shell.core.jlineshell.run(jlineshell.java:179) java.lang.thread.run(thread.java:744) {noformat} moreover seems completion generally crashes when the server is not up (which was taken care of previously if i'm not mistaken): xd:>job destroy --name <tab> {noformat} exception in thread ""spring shell"" org.springframework.web.client.resourceaccessexception: i/o error on get request for ""http://localhost:9393/jobs/definitions?size=10000&deployments=true"":connection refused nested exception is java.net.connectexception: connection refused org.springframework.web.client.resttemplate.doexecute(resttemplate.java:561) org.springframework.web.client.resttemplate.execute(resttemplate.java:506) org.springframework.web.client.resttemplate.getforobject(resttemplate.java:243) org.springframework.xd.rest.client.impl.jobtemplate.list(jobtemplate.java:121) org.springframework.xd.rest.client.impl.jobtemplate.list(jobtemplate.java:40) org.springframework.xd.shell.converter.existingxdentityconverter.getallpossiblevalues(existingxdentityconverter.java:72) org.springframework.shell.core.simpleparser.completeadvanced(simpleparser.java:857) org.springframework.shell.core.parsercompleter.complete(parsercompleter.java:47) jline.console.consolereader.complete(consolereader.java:3077) jline.console.consolereader.readline(consolereader.java:2501) jline.console.consolereader.readline(consolereader.java:2162) jline.console.consolereader.readline(consolereader.java:2150) org.springframework.shell.core.jlineshell.promptloop(jlineshell.java:522) org.springframework.shell.core.jlineshell.run(jlineshell.java:179) java.lang.thread.run(thread.java:744) caused by: java.net.connectexception: connection refused java.net.plainsocketimpl.socketconnect(native method) java.net.abstractplainsocketimpl.doconnect(abstractplainsocketimpl.java:339) java.net.abstractplainsocketimpl.connecttoaddress(abstractplainsocketimpl.java:200) java.net.abstractplainsocketimpl.connect(abstractplainsocketimpl.java:182) java.net.sockssocketimpl.connect(sockssocketimpl.java:392) java.net.socket.connect(socket.java:579) java.net.socket.connect(socket.java:528) sun.net.networkclient.doconnect(networkclient.java:180) sun.net.www.http.httpclient.openserver(httpclient.java:432) sun.net.www.http.httpclient.openserver(httpclient.java:527) sun.net.www.http.httpclient.<init>(httpclient.java:211) sun.net.www.http.httpclient.new(httpclient.java:308) sun.net.www.http.httpclient.new(httpclient.java:326) sun.net.www.protocol.http.httpurlconnection.getnewhttpclient(httpurlconnection.java:996) sun.net.www.protocol.http.httpurlconnection.plainconnect(httpurlconnection.java:932) sun.net.www.protocol.http.httpurlconnection.connect(httpurlconnection.java:850) org.springframework.http.client.simplebufferingclienthttprequest.executeinternal(simplebufferingclienthttprequest.java:78) org.springframework.http.client.abstractbufferingclienthttprequest.executeinternal(abstractbufferingclienthttprequest.java:48) org.springframework.http.client.abstractclienthttprequest.execute(abstractclienthttprequest.java:52) {noformat}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
193,as a qa i'd like to include acceptance test coverage for _kafka_ as a message bus so that i can validate the functionality as part of every ci build.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
194,x-xd-* transport content-type leakage the {{abstractreplyproducingmessagehandler}} in the rabbit transport exposes the internal transport content-type if none existed on the original transported message.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
195,create config support for redis we would like to have redis driven from a config property file under xd_home.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
196,create ec2 ami for single-node install of hortonworks data platform 1.3,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
197,as a developer i'd like to upgrade to si milestone/ga release so i can synchronize with jmx improvements. this is dependent on si milestone and ga release timelines.,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
198,vary queue number on 32 core machine (ecb-8) rerun test xd-2278 on a ec2 32 core machine and see when we max out.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
199,investigate classloading leakage using the gemfire module as an example there is currently at least two sources of leakage retaining classes that are loaded by the module classloader (and hence everything from there). one of them is because of jmx monitoring. another one i'm not sure about but here is a screenshot,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
200,"failed to create a stream with script processor i attempted to create a stream with a script processor using spring xd shell: {code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --location=print-stacktrace.groovy | null"" command failed org.springframework.xd.rest.client.impl.springxdexception: error with option(s) for module script of type processor: location: option named 'location' is not supported {code} i've corrected the syntax as described in docs by replacing --location with --script: {code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --script=print-stacktrace.groovy | null"" created new stream 'test1'{code} my stream was created but the deployment failed with exception: {code} 20:04:45105 1.0.3.release info deployer server.streamdeploymentlistener - deployment status for stream 'test1': deploymentstatus{state=failederror(s)=org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name 'org.springframework.integration.config.serviceactivatorfactorybean#0' defined in null: could not resolve placeholder 'location' in string value ""${location}"" nested exception is java.lang.illegalargumentexception: could not resolve placeholder 'location' in string value ""${location}"" org.springframework.beans.factory.config.placeholderconfigurersupport.doprocessproperties(placeholderconfigurersupport.java:211) org.springframework.context.support.propertysourcesplaceholderconfigurer.processproperties(propertysourcesplaceholderconfigurer.java:180) org.springframework.context.support.propertysourcesplaceholderconfigurer.postprocessbeanfactory(propertysourcesplaceholderconfigurer.java:155) org.springframework.context.support.postprocessorregistrationdelegate.invokebeanfactorypostprocessors(postprocessorregistrationdelegate.java:265) org.springframework.context.support.postprocessorregistrationdelegate.invokebeanfactorypostprocessors(postprocessorregistrationdelegate.java:162) org.springframework.context.support.abstractapplicationcontext.invokebeanfactorypostprocessors(abstractapplicationcontext.java:609) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:464) org.springframework.boot.springapplication.refresh(springapplication.java:691) org.springframework.boot.springapplication.run(springapplication.java:320) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:142) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:201) org.springframework.xd.dirt.module.moduledeployer.dodeploy(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:200) org.springframework.xd.dirt.server.deploymentlistener.deploymodule(deploymentlistener.java:363) org.springframework.xd.dirt.server.deploymentlistener.deploystreammodule(deploymentlistener.java:332) org.springframework.xd.dirt.server.deploymentlistener.onchildadded(deploymentlistener.java:179) org.springframework.xd.dirt.server.deploymentlistener.childevent(deploymentlistener.java:147) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) caused by: java.lang.illegalargumentexception: could not resolve placeholder 'location' in string value ""${location}"" org.springframework.util.propertyplaceholderhelper.parsestringvalue(propertyplaceholderhelper.java:174) org.springframework.util.propertyplaceholderhelper.replaceplaceholders(propertyplaceholderhelper.java:126) org.springframework.core.env.abstractpropertyresolver.doresolveplaceholders(abstractpropertyresolver.java:194) org.springframework.core.env.abstractpropertyresolver.resolverequiredplaceholders(abstractpropertyresolver.java:158) org.springframework.context.support.propertysourcesplaceholderconfigurer$2.resolvestringvalue(propertysourcesplaceholderconfigurer.java:175) org.springframework.beans.factory.config.beandefinitionvisitor.resolvestringvalue(beandefinitionvisitor.java:282) org.springframework.beans.factory.config.beandefinitionvisitor.resolvevalue(beandefinitionvisitor.java:209) org.springframework.beans.factory.config.beandefinitionvisitor.visitindexedargumentvalues(beandefinitionvisitor.java:150) org.springframework.beans.factory.config.beandefinitionvisitor.visitbeandefinition(beandefinitionvisitor.java:84) org.springframework.beans.factory.config.beandefinitionvisitor.resolvevalue(beandefinitionvisitor.java:169) org.springframework.beans.factory.config.beandefinitionvisitor.visitindexedargumentvalues(beandefinitionvisitor.java:150) org.springframework.beans.factory.config.beandefinitionvisitor.visitbeandefinition(beandefinitionvisitor.java:84) org.springframework.beans.factory.config.beandefinitionvisitor.resolvevalue(beandefinitionvisitor.java:169) org.springframework.beans.factory.config.beandefinitionvisitor.visitpropertyvalues(beandefinitionvisitor.java:141) org.springframework.beans.factory.config.beandefinitionvisitor.visitbeandefinition(beandefinitionvisitor.java:82) org.springframework.beans.factory.config.placeholderconfigurersupport.doprocessproperties(placeholderconfigurersupport.java:208) ... 31 more {code} # [script.xml in 1.0.3 tag|https://github.com/spring-projects/spring-xd/blob/v1.0.3/modules/processor/script/config/script.xml] uses {code}<int-groovy:script location=""${location}"" ...{code} # the [script 1.0.3 processor docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.3.release/reference/html/#script] have issues with properties naming e.g. example is using --location while later --script is used. same with --propertieslocation and --properties-location.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
201,as a developer i'd like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1). (0): {code} /lib/*.jar:lib/${distro}/*.jar {code} (1): {code} ${xd.home}/lib/hadoop/${distro}/*.jar {code} *example:* {code} http | hdfs --distro=phd22 http | mycustommodule --classpath=/my/funky/dir http | jpa --provider=eclipse jpa: /config/ /lib/something-that-is-common.jar /eclipse/eclipse-link-3.2.jar /hibernate/hibernate-core-5.0.jar module.classpath = /lib/*.jar:/lib/${provider}/*.jar {code},4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
202,redis and in-memory offset storage profiles for the kafka source have wrong definitions,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
203,saving a metric (counter gauge..) with an existing name should throw an exception the difference between saving a new metric and updating an existing one needs to be defined. suggest that if we try to save when an existing counter is already in the database to throw exception such as dataintegrityviolationexception.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
204,change springsource references in pom.xml to spring/spring.io this is currently in the m6 pom: <organization> <name>springsource</name> <url>http://springsource.org</url> </organization>,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
205,"creating streams sporadically using kafka as a message bus throws topicnotfound exception xd version spring xd 1.1.1.release 1 admin on own (on-metal) rackspace machine 2 containers each having own (on-metal) rackspace machine 1 zookeeper node collocated with admin while executing xd performance testing on rackspace using kafka as a transport we occasionally get the following exception: {noformat} 2015-03-26 18:36:30677 1.1.1.release info deploymentspathchildrencache-0 server.deploymentlistener - path cache event: path=/deployments/modules/allocated/4c3c9ccf-44db-4772-87c2-70c63b82c3aa/foo3.sink.throughput.1 type=child_added 2015-03-26 18:36:30685 1.1.1.release info deploymentspathchildrencache-0 server.deploymentlistener - deploying module 'throughput' for stream 'foo3' 2015-03-26 18:36:30820 1.1.1.release info deploymentspathchildrencache-0 server.deploymentlistener - deploying module [moduledescriptor@19f0b0a6 modulename = 'throughput' modulelabel = 'throughput' group = 'foo3' sourcechannelname = [null] sinkchannelname = [null] index = 1 type = sink parameters = map[[empty]] children = list[[empty]]] 2015-03-26 18:36:31372 1.1.1.release error deploymentspathchildrencache-0 server.deploymentlistener - exception deploying module org.springframework.integration.kafka.core.topicnotfoundexception: no topic named 'foo3.0' found org.springframework.integration.kafka.core.defaultconnectionfactory.getpartitions(defaultconnectionfactory.java:209) org.springframework.xd.dirt.integration.kafka.kafkamessagebus.createkafkaconsumer(kafkamessagebus.java:640) org.springframework.xd.dirt.integration.kafka.kafkamessagebus.bindconsumer(kafkamessagebus.java:454) org.springframework.xd.dirt.plugins.abstractmessagebusbinderplugin.bindmessageconsumer(abstractmessagebusbinderplugin.java:275) org.springframework.xd.dirt.plugins.abstractmessagebusbinderplugin.bindconsumerandproducers(abstractmessagebusbinderplugin.java:158) org.springframework.xd.dirt.plugins.stream.streamplugin.postprocessmodule(streamplugin.java:73) org.springframework.xd.dirt.module.moduledeployer.postprocessmodule(moduledeployer.java:238) org.springframework.xd.dirt.module.moduledeployer.dodeploy(moduledeployer.java:218) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:200) org.springframework.xd.dirt.server.deploymentlistener.deploymodule(deploymentlistener.java:363) org.springframework.xd.dirt.server.deploymentlistener.deploystreammodule(deploymentlistener.java:332) org.springframework.xd.dirt.server.deploymentlistener.onchildadded(deploymentlistener.java:179) org.springframework.xd.dirt.server.deploymentlistener.childevent(deploymentlistener.java:147) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) {noformat} stream used to create the exception: stream create foo4 --definition ""load-generator --messagesize=1000 --messagecount=10000000 | throughput"" --deploy after failed deployment. i destroy the stream and recreate it and it works fine.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
206,"move $xd_home/modules/processor/scripts out of the way since the refactoring of the module registry that does not ""look inside"" a module it can't know that the scripts directory is not a module. everything that is a direct child of source processor sink job should be a module archive. everything else supporting that should be moved out e.g. in modules/common",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
207,improve implementation of null sink the null sink uses a bridge and in perf testing it seemed to introduce overhead. verify with throughput source and a hand-crafted 'no-op' messageprocessor impl.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
208,documentation for starting spring xd servers,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
209,as a developer i'd like to upgrade to kafka's si ga release so that i can sync -up with the latest bits. the scope is to backport kafka xd changes to si kafka and then upgrade to the ga release.,4,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
210,as a user i want to be able to control the partition allocation for the kafka source modules when a stream is deployed so that i can colocate with other data sources.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
211,as a build manager i'd like to setup ci infrastructure so that i can run integration tests in windows os automatically as we commit-trigger new builds. *scope:* * use the environment where bamboo is running * gain access to powershell * setup services (redis rabbit etc.) * kick-off ci task,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
212,"changing externalized module config properties at runtime once the container starts up and the module is deployed the externalized module configuration properties could not be changed for the subsequent modules of same type. here is the scenario for a stream ""http | transform | log"" with xd_module_config_location and xd_module_config_name using their default values. in ${xd.config.home}/modules/modules.yml i have: processor: transform: expression: ""'inside modules.yml'"" and in ${xd.config.home}/modules/processor/transform/transform.properties i have: expression: ""'first module: inside transform.properties'"" now i deploy this stream: ""http | transform | log"". lets say i have another stream that uses the transform module but this time i want to change the expression in ${xd.config.home}/modules/processor/transform/transform.properties to expression: ""'second module'"" now when the stream containing this transform module gets deployed it uses the same transform.properties that is used by the previously deployed transform module. what i understand from this behavior is that the environmentawaremoduleoptionsmetadataresolver caches the module environments for a given module type and name. when the same module is deployed from a given stream again it uses the stored module environment and doesn't refresh/load the property sources from the module config locations mentioned above. though this is good in one way that same module environment is re-used changing the externalized module config properties would have no affect after the first module of same type/name is deployed. though the environmentawaremoduleoptionsmetadataresolver is used by both admin and container this jira focuses more on the container side. there is one valid point with the current behavior where the module environment is cached and won't change. but is this by design?",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
213,filepollhdfs sporadically fails need to add a retry to the mkdir command in the case that it fails.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
214,"let modules define a default value for --inputtype option if a module e.g. always expects the payload of the message to be of a certain java type if would be good for documentation and convenience reasons in order to specify a default value for the --inputtype option. documentation = output for module info convenience = we could e.g. support to always accept a json payload (or automatic message payload conversion once it is extensible) currently adding options.inputtype.default to the module's property file has no effect i've also tried to ""redefine"" it using options.inputtype.description this leads to the following exception: command failed org.springframework.xd.rest.client.impl.springxdexception: module option named 'outputtype' is present in several delegates: [org.springframework.xd.module.options.simplemoduleoptionsmetadata@3c1d635a flattenedcompositemoduleoptionsmetadata [outputtype] => pojomoduleoptionsmetadata backed by class org.springframework.xd.dirt.plugins.stream.moduletypeconversionpluginmetadataresolver$outputoptionsmetadata defining options [[moduleoption [name=outputtype type=class org.springframework.util.mimetype defaultvalue=null description=how this module should emit messages it produces]]] [inputtype] => pojomoduleoptionsmetadata backed by class org.springframework.xd.dirt.plugins.stream.moduletypeconversionpluginmetadataresolver$inputoptionsmetadata defining options [[moduleoption [name=inputtype type=class org.springframework.util.mimetype defaultvalue=null description=how this module should interpret messages it consumes]]]]",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
215,as a spring xd developer i'd like to move {{gpfdist}} module from xd to s-c-s repo so i can use it as sink to build streaming pipeline.,2,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
216,using a newer version of a spring-xd dependency is ignored in packaging when creating a new module with a dependeny which has a newer version than the one spring-xd uses (in my example i use jedis 2.6.1 and spring-xd uses jedis 2.5.2) the packaging ignores the dependency. using the solution of spring-boot-maven-plugin doesn't help because it will only include what you explicitly add to the include section (transitive dependencies are not included),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
217,update management context path to <root>/management,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
218,support additional aggregate counter query options,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
219,implement undeploy operation for cc spi currently undeploy is a no-op.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
220,allow registering default spel functions to simplify expressions often one has to perform some basic conversion / parsings in stream definitions. it would be helpful if one could provide some helper functions to simplify spel expressions. e.g. instead of: {code} transform --expression=t(java.lang.long).parselong(payload.value.tostring()) {code} it would be nice to be able to write: {code} transform --expression=parselong(payload.value) {code} i'm thinking of support for: * parsebyte * parseint * parseshort * parselong * parsefloat * parsedouble * parseboolean * parsetuple (i don't think we'd need support for parsecharacter) this issue is about: 1) providing the centralised infrastructure for defining the spel expressions 2) add support for the above listed predefined spel expressions those functions should be able to work with string based as well as {{jsontostringfriendlynode}} as input.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
221,provide python module to handle i/o for implementing a python shell processor,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
222,add command for listing of taps,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
223,as a spring xd developer i'd like to port {{ftp/sftp}} module from xd to s-c-s repo so i can use it as {{sink}} modules to build streaming pipeline.,2,4,0.0027609235048294068,8.333333333333332,1,1,0,0,0
224,upgrade to reactor 2.0 m2,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
225,build failure on ubuntu build fails: gradle clean build ... :spring-xd-dirt:test org.springframework.xd.dirt.stream.filesourcemoduletests > classmethod failed java.io.ioexception at filesourcemoduletests.java:53 org.springframework.xd.dirt.stream.filesourcemoduletests > classmethod failed java.lang.illegalargumentexception at filesourcemoduletests.java:130 328 tests completed 2 failed 11 skipped :spring-xd-dirt:test failed failure: build failed with an exception. looks like it is trying to create a directory under the local filesystem / java.io.ioexception: unable to create directory /tmpfilesourcetests org.apache.commons.io.fileutils.forcemkdir(fileutils.java:2024) org.springframework.xd.dirt.stream.filesourcemoduletests.createtempdir(filesourcemoduletests.java:53) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:44) org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:24) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.junit.runners.parentrunner.run(parentrunner.java:309) org.gradle.api.internal.tasks.testing.junit.junittestclassexecuter.runtestclass(junittestclassexecuter.java:80) org.gradle.api.internal.tasks.testing.junit.junittestclassexecuter.execute(junittestclassexecuter.java:47) org.gradle.api.internal.tasks.testing.junit.junittestclassprocessor.processtestclass(junittestclassprocessor.java:69) org.gradle.api.internal.tasks.testing.suitetestclassprocessor.processtestclass(suitetestclassprocessor.java:49) sun.reflect.generatedmethodaccessor23.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:35) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:24) org.gradle.messaging.dispatch.contextclassloaderdispatch.dispatch(contextclassloaderdispatch.java:32) org.gradle.messaging.dispatch.proxydispatchadapter$dispatchinginvocationhandler.invoke(proxydispatchadapter.java:93) com.sun.proxy.$proxy2.processtestclass(unknown source) org.gradle.api.internal.tasks.testing.worker.testworker.processtestclass(testworker.java:103) sun.reflect.generatedmethodaccessor22.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:35) org.gradle.messaging.dispatch.reflectiondispatch.dispatch(reflectiondispatch.java:24) org.gradle.messaging.remote.internal.hub.messagehub$handler.run(messagehub.java:355) org.gradle.internal.concurrent.defaultexecutorfactory$stoppableexecutorimpl$1.run(defaultexecutorfactory.java:66) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:724),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
226,stream-lib - analytics operators we would like to experiment with “stream-lib” a stream summarizer and cardinality (counting distinct elements) estimator to further enrich spring xd's analytics feature-set. github -> https://github.com/addthis/stream-lib,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
227,"all parameters for modules need to use ""hump case"" formerly camel hump",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
228,add documentation for using ftp->hdfs partitioned jobs,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
229,as a developer i'd like to add support for dynamic partition subscription for the kafka source module so i can consume the payload from dynamic partitions.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
230,review existing reactor syslog codec implementation,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
231,documentation: hovering over some of the examples corrupts the text if you mouse over any of the examples in the documentation the grey boxes containing code shell commands etc. typically in the upper right hand corner a label for the type of code/example will appear. e.g. 'ruby' 'javascript' etc. 1) the labels that appear seem to be random and incorrect. shell scripts show as 'ruby' and 'javascript'. 2) more importantly on some of the examples the label appears in front of and part of the example corrupting the example. to see this hover your mouse over the two examples grey boxes here: http://docs.spring.io/spring-xd/docs/1.0.0.m6/reference/html/#_xd_shell_in_distributed_mode there may be more but this is the ones i noticed. -derek,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
232,rabbitmq server.yml options ignored {{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. these values are not being retrieved and hence have to be manually added to each stream definition. * {{addresses}} * {{username}} * {{password}} * {{virtual_host}} (cf xd-2675 xd-2741),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
233,create spring-xd-test-fixtures project acceptance tests has a direct library reference to spring-xd-shell. this causes problems with eclipse. it needs a intermediate main project to resolve the dependencies. this is based on the conversation i had with mark fisher. you cant depend on another projects' src/test what is needed is an intermediate project… some test support project that project would depend on spring-xd-shell (and others) … but then the spring-xd-integration-test project would depend on the intermediate one lib dependencies should only be under src/main src/test is intended to be scoped to the project it sits in… tests for that project - not reusable base classes etc,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
234,mongo sink acceptance tests,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
235,fail sonar ci build if there are any package tangles violated. similar to what would show up on structure101 reports.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
236,as a user i'm trying to setup ha cluster using ambari installed spring xd however i'm running into issues with the overrides. more details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
237,"conversion enhancements content-type during transport transit is not the same as the content-type within modules. ""real"" transports always use byte[] which may contain raw byte[] from a source a byte[] converted from a string (which may or may not already contain json) or a byte[] containing json converted by the transport on the outbound side. the transport needs to convey which of these was applied on the outbound side so it can properly reconstruct the message. retain any content-type header that already exists in the message and restore it. for rabbit use normal si/rabbit headers to convey this information. for redis add the information to the byte[].",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
238,create shell integration test fixture for jdbc related sink would be nice to have some kind of regression testing on the jdbc sink as it becomes more prominent in xd. use of an in memory db where we expose eg a jdbctemplate to assert state,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
239,find and eliminate package-level cycles across xd projects,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
240,harmonize rest features between deployment profiles as an s-c-d user i'd like to take advantage of admin running on variety of platforms such as lattice yarn or cf. i'd like to access rest apis consistently across these platforms.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
241,cannot chain json-field-value-filter & json-field-extractor because stringtojsonnodetransformer expects a string as input one cannot chain json related processors. a simple solution would be to also accept jackson in and forward it directly in that case.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
242,remove unnecessary less files from xd ui styles currently the bootstrap.less file has all the styles that the bootstrap supports. but we should only add/compile the less that are needed by xd ui.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
243,as a qa i'd like to include acceptance test coverage for _reactor-ip_ source module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
244,add service activator processor would be nice to have a serviceactivator processor available so that if one had an existing spring bean they could simply describe the bean id and method name - without going through the full complexity of creating a processing module.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
245,error handling on streams have proper exceptions for common error cases on stream creation/deployment and propagate those to clients correctly.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
246,remove hadoop distro enum options please see the discussion here: https://github.com/spring-projects/spring-xd/pull/655/files#r10892925,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
247,"file source name and duplicates options not working as documented the doc says the name option is ""the absolute path to the directory to monitor for files"" but it actually seems to be the name of a dir in /tmp/xd/input. not sure which is the correct behavior. also ""name"" as an option name seems a little vague. maybe something like ""--directory""? also if i set --duplicates=true it actually prevents duplicates (setting prevents-duplicates to true)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
248,change grunt build - checkin bower artifacts in order to decrease ci build issues we should checkin bower dependencies. see: http://addyosmani.com/blog/checking-in-front-end-dependencies/,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
249,add batchmbeanexporter for batch modules,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
250,metrics - measure based alerts we would like to experiment with “metrics” a java library to extract insights of production code. this will help understand the behavior of critical components to eventually orchestrate workflows to proactively monitor and notify important contacts/groups as needed. website -> http://metrics.codahale.com/ github -> https://github.com/dropwizard/metrics,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
251,add angularjs directive to format stream definition strings it would be neat if streams could be easily formatted. e.g: * make the definition name bold * use different colors for parameter names and values,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
252,as a qa i'd like to include acceptance test coverage for _http-client_ processor module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
253,"processor modules should support scripts in languages other than groovy filter transform and script modules all assume the provided script is written in groovy. this is partly due to the fact that the ""lang"" attribute of <int-script:script> can't be set to a property value (i.e. lang=""${lang:groovy}"") which would allow users to pass in the expected language. or perhaps we could use a spel expression or script to pick the language based on the file extension?",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
254,add @xmlrootelement to all rest resources some rest resources lack an @xmlrootelement annotation. this causes a jaxb marshalling error when trying to access the api with an accept header of xml (which is the default in most browsers) this is a preliminary to xd-1800 (which is much more involved) only to fix ugly exception,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
255,update com.jayway.jsonpath to latest version use latest version might need to exclude version from other dependencies e.g. si in build-common.gradle.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
256,as a developer i'd like to upgrade spring xd's ambari plugin to 1.3 release.,3,4,0.0027609235048294068,1.6666666666666672,0,1,0,0,0
257,admin ui login page failing to load due to require.js timeout - fe when i use the admin-ui web portal which runs on port 9393 there is a load timeout issue by require.js failing to load the login screen. could the team please look into this issue asap or give me some other alternative !sping-ui-issue.png|thumbnail!,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
258,version info not available when security enabled when security is enabled the versioncontroller rest endpoint isn't visible.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
259,as a user i'd like to have the ootb module to consume database changes as event streams so i can incrementally synchronize with real-time db updates with various destinations such as brokers hadoop db etc.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,1,0
260,installer needs to launch a single node xd instance * create a deployer class has methods ** runninginstance deploysinglenode *** takes into account machine size as specified in properties file ** void destroyallinstances() *** or whatever jclouds returns from the destroy call ** ctor gets passed in the root boostrapping credentials. * install script steps ** setup xd_home variable ** make sure privileges are set to ubuntu not root. ** start up redis and rabbit using ports as specified in xd-ec2.properties ** use port watch to make sure they started ** start singlenode after configuration. ** display hostname of singlenode server ** report successful and failed startup ** hit root of xd-admin to see if there is a response on 9393 * integration testing ** verify that config files have been setup ** verify xd has been started ** verify xd can process a basic http post,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
261,update sources tcp section to use shell commands instead of curl see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#tcp,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
262,hadoop distro log message shows wrong version when set via env var if we export hadoop_distro env var instead of using --hadoopdistro parameter then the logging message is wrong it always says hadoop distro: hadoop26 even if we set hadoop_distro to something else the classpath is built correctly. maybe we should just remove this logging message since we log the actual version used in the next log message.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
263,the hdfs store library should support compression when writing to sequence files support for using compression when writing sequence files either block or record-based compression.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
264,xd gemfire modules fail to deploy in yarn 1 admin on slave1 1 container on slave2 gemfire modules fail to deploy. with the following exception: caused by: java.io.filenotfoundexception: null/modules/common/gemfire-sink.groovy this is because the modules require a xd_home environment variable and this is not set by the yarn deployment. {noformat} offending resource: url [file:null/modules/common/gemfire-sink.groovy] nested exception is java.io.filenotfoundexception: null/modules/common/gemfire-sink.groovy (no such file or directory) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:247) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:202) org.springframework.boot.beandefinitionloader.load(beandefinitionloader.java:178) org.springframework.boot.beandefinitionloader.load(beandefinitionloader.java:138) org.springframework.boot.beandefinitionloader.load(beandefinitionloader.java:127) org.springframework.boot.springapplication.load(springapplication.java:620) org.springframework.boot.springapplication.run(springapplication.java:315) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:139) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:211) org.springframework.xd.dirt.module.moduledeployer.dodeploy(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:200) org.springframework.xd.dirt.server.deploymentlistener.deploymodule(deploymentlistener.java:363) org.springframework.xd.dirt.server.deploymentlistener.deploystreammodule(deploymentlistener.java:332) org.springframework.xd.dirt.server.deploymentlistener.onchildadded(deploymentlistener.java:179) org.springframework.xd.dirt.server.deploymentlistener.childevent(deploymentlistener.java:147) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) caused by: org.springframework.beans.factory.parsing.beandefinitionparsingexception: configuration problem: error evaluating groovy script: null/modules/common/gemfire-sink.groovy (no such file or directory) offending resource: url [file:null/modules/common/gemfire-sink.groovy] nested exception is java.io.filenotfoundexception: null/modules/common/gemfire-sink.groovy (no such file or directory) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:247) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:202) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:181) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:217) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:188) org.springframework.beans.factory.groovy.groovybeandefinitionreader.importbeans(groovybeandefinitionreader.java:337) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.codehaus.groovy.reflection.cachedmethod.invoke(cachedmethod.java:90) groovy.lang.metamethod.domethodinvoke(metamethod.java:324) org.codehaus.groovy.runtime.metaclass.closuremetaclass.invokemethod(closuremetaclass.java:368) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1016) org.codehaus.groovy.runtime.callsite.pogometaclasssite.callcurrent(pogometaclasssite.java:66) org.codehaus.groovy.runtime.callsite.callsitearray.defaultcallcurrent(callsitearray.java:49) org.codehaus.groovy.runtime.callsite.abstractcallsite.callcurrent(abstractcallsite.java:133) org.codehaus.groovy.runtime.callsite.abstractcallsite.callcurrent(abstractcallsite.java:141) beans$_run_closure1.docall(beans:4) beans$_run_closure1.docall(beans) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.codehaus.groovy.reflection.cachedmethod.invoke(cachedmethod.java:90) groovy.lang.metamethod.domethodinvoke(metamethod.java:324) org.codehaus.groovy.runtime.metaclass.closuremetaclass.invokemethod(closuremetaclass.java:278) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1016) groovy.lang.closure.call(closure.java:423) groovy.lang.closure.call(closure.java:417) org.springframework.beans.factory.groovy.groovybeandefinitionreader.invokebeandefiningclosure(groovybeandefinitionreader.java:426) org.springframework.beans.factory.groovy.groovybeandefinitionreader$1.call(groovybeandefinitionreader.java:223) groovy.lang.closure.call(closure.java:439) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.codehaus.groovy.reflection.cachedmethod.invoke(cachedmethod.java:90) groovy.lang.metamethod.domethodinvoke(metamethod.java:324) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1207) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1016) groovy.lang.metaclassimpl.invokepropertyormissing(metaclassimpl.java:1253) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1209) groovy.lang.metaclassimpl.invokemethod(metaclassimpl.java:1016) org.codehaus.groovy.runtime.callsite.pogometaclasssite.callcurrent(pogometaclasssite.java:66) org.codehaus.groovy.runtime.callsite.callsitearray.defaultcallcurrent(callsitearray.java:49) org.codehaus.groovy.runtime.callsite.abstractcallsite.callcurrent(abstractcallsite.java:133) org.codehaus.groovy.runtime.callsite.abstractcallsite.callcurrent(abstractcallsite.java:141) beans.run(beans:1) groovy.lang.groovyshell.evaluate(groovyshell.java:649) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:243) ... 29 more caused by: java.io.filenotfoundexception: null/modules/common/gemfire-sink.groovy (no such file or directory) java.io.fileinputstream.open(native method) java.io.fileinputstream.<init>(fileinputstream.java:146) java.io.fileinputstream.<init>(fileinputstream.java:101) sun.net.www.protocol.file.fileurlconnection.connect(fileurlconnection.java:90) sun.net.www.protocol.file.fileurlconnection.getinputstream(fileurlconnection.java:188) org.springframework.core.io.urlresource.getinputstream(urlresource.java:168) org.springframework.core.io.support.encodedresource.getreader(encodedresource.java:132) org.springframework.beans.factory.groovy.groovybeandefinitionreader.loadbeandefinitions(groovybeandefinitionreader.java:243) ... 79 more {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
265,improve exception handling for zookeeper data access currently we have many catch(exception) blocks that simply wrap and rethrow runtimeexceptions. we should create at least a top-level runtimeexception of our own within the xd exception hierarchy and possibly a hierarchy of runtimeexceptions extending from that and mapping to the various checked exceptions that can occur in zookeeper data access. also we should not be re-wrapping those exceptions that are already runtimeexceptions so we should consider a zookeeperexceptionhandler (and although i'm typically hesitant to recommend it this might be a case where a static util method is the right approach).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
266,as a spring xd developer i'd like to move {{trigger}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline.,2,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
267,as a user i created a composed job with over 10 child jobs in the workflow i expected to see 'a' job in the execution list page without any pagination but instead i noticed empty pagination to skip to next page.,1,4,0.0027609235048294068,1.6666666666666672,0,1,0,1,0
268,spike: research request/reply support to kafka message bus the scope is to research the available options to provide request/reply support for kafka. * document findings * pocs previous desc: the bindrequestor and bindreplier methods of the message bus need to be implemented.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
269,as a qa i'd like to include acceptance test coverage for hdfs-dataset module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
270,hdfs sink module,0,0,0.0025889062881469726,8.333333333333332,1,1,0,1,0
271,accessing admin rest apis on cf returns unexpected results as an s-c-d user i'm trying to access {{admin}} rest endpoints running on cf but i'm getting ssl authentication errors.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
272,container reconnection to zk fails intermittently as reported by matt stine: after closing and reopening a laptop the following stack trace appears in the container log: {noformat} 00:47:28226 info main-eventthread state.connectionstatemanager:194 - state change: reconnected 00:47:28226 info connectionstatemanager-0 zookeeper.zookeeperconnection:255 - >>> curator connected event: reconnected 00:47:28322 error connectionstatemanager-0 listen.listenercontainer:96 - listener (org.springframework.xd.dirt.zookeeper.zookeeperconnection$delegatingconnectionstatelistener@6abf4158) threw an exception java.lang.runtimeexception: java.lang.runtimeexception: org.apache.zookeeper.keeperexception$nodeexistsexception: keepererrorcode = nodeexists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a at org.springframework.xd.dirt.server.containerregistrar.registerwithzookeeper(containerregistrar.java:301) at org.springframework.xd.dirt.server.containerregistrar.access$100(containerregistrar.java:93) at org.springframework.xd.dirt.server.containerregistrar$containerattributesregisteringzookeeperconnectionlistener.onconnect(containerregistrar.java:316) at org.springframework.xd.dirt.zookeeper.zookeeperconnection$delegatingconnectionstatelistener.statechanged(zookeeperconnection.java:257) at org.apache.curator.framework.state.connectionstatemanager$2.apply(connectionstatemanager.java:222) at org.apache.curator.framework.state.connectionstatemanager$2.apply(connectionstatemanager.java:218) at org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) at com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:293) at org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) at org.apache.curator.framework.state.connectionstatemanager.processevents(connectionstatemanager.java:215) at org.apache.curator.framework.state.connectionstatemanager.access$000(connectionstatemanager.java:42) at org.apache.curator.framework.state.connectionstatemanager$1.call(connectionstatemanager.java:110) at java.util.concurrent.futuretask.run(futuretask.java:262) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) at java.lang.thread.run(thread.java:744) caused by: java.lang.runtimeexception: org.apache.zookeeper.keeperexception$nodeexistsexception: keepererrorcode = nodeexists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a at org.springframework.xd.dirt.container.store.zookeepercontainerattributesrepository.save(zookeepercontainerattributesrepository.java:75) at org.springframework.xd.dirt.container.store.zookeepercontainerattributesrepository.save(zookeepercontainerattributesrepository.java:42) at org.springframework.xd.dirt.server.containerregistrar.registerwithzookeeper(containerregistrar.java:295) ... 15 more caused by: org.apache.zookeeper.keeperexception$nodeexistsexception: keepererrorcode = nodeexists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a at org.apache.zookeeper.keeperexception.create(keeperexception.java:119) at org.apache.zookeeper.keeperexception.create(keeperexception.java:51) at org.apache.zookeeper.zookeeper.create(zookeeper.java:783) at org.apache.curator.framework.imps.createbuilderimpl$11.call(createbuilderimpl.java:676) at org.apache.curator.framework.imps.createbuilderimpl$11.call(createbuilderimpl.java:660) at org.apache.curator.retryloop.callwithretry(retryloop.java:107) at org.apache.curator.framework.imps.createbuilderimpl.pathinforeground(createbuilderimpl.java:656) at org.apache.curator.framework.imps.createbuilderimpl.protectedpathinforeground(createbuilderimpl.java:441) at org.apache.curator.framework.imps.createbuilderimpl.forpath(createbuilderimpl.java:431) at org.apache.curator.framework.imps.createbuilderimpl.forpath(createbuilderimpl.java:44) at org.springframework.xd.dirt.container.store.zookeepercontainerattributesrepository.save(zookeepercontainerattributesrepository.java:69) ... 17 more {noformat} this can occur if zk does not remove the ephemeral node before the container creates a new one. this can be fixed in the following ways: * remove the existing ephemeral node if it already exists * register containers with a new uuid upon every new connection for now i'll implement the first solution.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
273,as a user i'd like to enable ha on {{namenode}} without having to enable custom configuration. more details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
274,"add acceptance test to extract and assert payload from json object to enrich the acceptance test i'd like to evaluate json object to extract ""good"" and ""bad"" instead of just relying on a basic filter test to assert the payload content.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
275,create gemfire test port https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/gemfire_stream_tests need to consider how to start the server maybe use the jvm fork utilities? look into spring-data-gemfire as well.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
276,containerlistener to redeploy modules based on stream order. when redeploying in the case of a container failure the modules are now redeployed in a random order. the list of modules in the failed container needs to be sorted based on its position in a given stream and then redeployed.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
277,as a spring xd developer i'd like to move {{cassandra}} module from xd to s-c-s repo so i can use it as {{sink}} to build streaming pipeline.,4,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
278,embed local message bus in dirt as default for singlenode currently all message bus implementations are removed from the runtime classpath and loaded on demand from the file system according to the transport setting. custom module projects that include in container testing must install messagebus-local on the local file system. this is currently configured as a task for module build scripts. this is also a dependency for testing in the ide and developers need to execute the build task or configure the messagebus manually. embedding the local mb for the singlenode application (local is not a valid transport for distributed) eliminates this step.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
279,remove mr1 jar from cdh5 hadoop build there is an hadoop-core-2.5.0-mr1-cdh5.3.3.jar in the lib/cdh5 directory - we need to remove that from the dist,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
280,add bash based scripts of simple module create to src/main/scripts,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
281,disable the jmx setting in singlenodemainintegrationtests.testconfiguration set the enablejmx to false because contexts are not getting destroyed properly and in some cases prevents testsystempropertiesoverridesdefault from running successfully.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
282,add incremental load feature to batch docs the incremental load introduced with xd-2309 should be added to the batch docs,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
283,as a spring xd developer i'd like to move {{mqtt}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline.,2,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
284,as a user i would like to have shell interface to the spring-cloud-data rest api. the scope for this jira could be limited to stream commands.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
285,"facing issue while running spring xd batch job on hdp version 2.3.2.0-2950 ***version spring xd version : spring-xd-1.3.0.release spring-xd-1.3.0.release-yarn os & version: linux 2.6.32-431.29.2.el6.x86_64 java version: java version ""1.7.0_65"" ***description the simple word count map reduce job using spring xd is failing with inline error message. ***steps to recreate the problem 1. created a jar for simple word count map reduce job. 2. created jar using information given in ( http://docs.spring.io/spring-hadoop/docs/2.0.2.release/reference/html/hadoop.html#hadoop:tasklet ) 3. once the final jar was ready uploaded using ""module upload --name test_mr_module --type job --file /home/user/jar/samplemrjob.jar"" 4. after that created and deployed job using ""job create --name test_mr_job --definition test_mr_module --deploy"" 5. finally launched using ""job launch test_mr_job"" which failed with inline error. ***describe xd deployment : distributed deployment type : distributed - yarn ( on aws ec2 cloud ) number of xd-admin’s and xd-container’s : 1 admin and 3 containers ***describe other components transport: redis 3.0.1 zookeeper: version 3.4.6.2.3.2.0-2950 hadoop deployment data platform : hortonworks hdp 2.3.2.0-2950 rdbms: mysql ***error message: ***************************************************** 05:29:52673 info deploymentspathchildrencache-0 container.deploymentlistener - deploying job 'test_mr_job' 05:29:53655 info deploymentspathchildrencache-0 container.deploymentlistener - deploying module [moduledescriptor@6e5af900 modulename = 'test_mr_module' modulelabel = 'test_mr_module' group = 'test_mr_job' sourcechannelname = [null] sinkchannelname = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]] 05:30:24351 error inbound.job:test_mr_job-redis:queue-inbound-channel-adapter1 step.abstractstep - encountered an error executing step teststep in job test_mr_job java.lang.illegalargumentexception: unable to parse '/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework' as a uri check the setting for mapreduce.application.framework.path at org.apache.hadoop.mapreduce.jobsubmitter.addmrframeworktodistributedcache(jobsubmitter.java:443) . . . at org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.access$300(redisqueuemessagedrivenendpoint.java:54) at org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint$listenertask.run(redisqueuemessagedrivenendpoint.java:323) at org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:55) at java.lang.thread.run(thread.java:745) caused by: java.net.urisyntaxexception: illegal character in path at index 11: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework at java.net.uri$parser.fail(uri.java:2848) at java.net.uri$parser.checkchars(uri.java:3021) at java.net.uri$parser.parsehierarchical(uri.java:3105) at java.net.uri$parser.parse(uri.java:3063) at java.net.uri.<init>(uri.java:588) at org.apache.hadoop.mapreduce.jobsubmitter.addmrframeworktodistributedcache(jobsubmitter.java:441) *****************************************************",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
286,fix jobrepotests to use different batch job repo currently the jobrepotests use the same batch job repository that the xd runtime uses. since the batch job repo doesn't delete the job instances there would be stale data from this test.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
287,create a shell command for stopping all job executions,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
288,as a user i'd like to start multiple instances of {{xd-container}}'s through the rpm scripts so i can easily spin-up instances on the same node/vm.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
289,enhancements to gemfire cq source the gemfire cq source needs some enhancements: * enable locator configuration * consider decoupling from json. currently designed to work with gemfire-json-server to avoid dependence on specific domain objects on the client and server side. so produces json strings from pdxinstance(s) stored in the cache.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
290,as a xd admin i'd like to upgrade to spring boot 1.2.0 release and the associated dependencies so that we can catch up with the latest features bug-fixes and enhancements. *following xd dependencies needs upgraded to sync-up with boot 1.2.0 release:* <activemq.version>5.10.0</activemq.version> <aspectj.version>1.8.4</aspectj.version> <commons-dbcp2.version>2.0.1</commons-dbcp2.version> <h2.version>1.4.182</h2.version> <hibernate.version>dd4.3.7.final</hibernate.version> <hibernate-validator.version>5.1.3.final</hibernate-validator.version> <hikaricp.version>2.2.5</hikaricp.version> <hornetq.version>2.4.5.final</hornetq.version> <httpasyncclient.version>4.0.2</httpasyncclient.version> <httpclient.version>4.3.6</httpclient.version> <jackson.version>2.4.4</jackson.version> <janino.version>2.6.1</janino.version> <jetty.version>9.2.4.v20141103</jetty.version> <jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version> <joda-time.version>2.5</joda-time.version> <jolokia.version>1.2.3</jolokia.version> <junit.version>4.12</junit.version> <liquibase.version>3.3.0</liquibase.version> <log4j.version>1.2.17</log4j.version> <log4j2.version>2.1</log4j2.version> <mockito.version>1.10.8</mockito.version> <mongodb.version>2.12.4</mongodb.version> <mysql.version>5.1.34</mysql.version> <reactor.version>1.1.5.release</reactor.version> <reactor-spring.version>1.1.3.release</reactor-spring.version> <servlet-api.version>3.1.0</servlet-api.version> <spring.version>4.1.3.release</spring.version> <spring-batch.version>3.0.2.release</spring-batch.version> <spring-data-releasetrain.version>evans-sr1</spring-data-releasetrain.version> <spring-hateoas.version>0.16.0.release</spring-hateoas.version> <spring-mobile.version>1.1.3.release</spring-mobile.version> <spring-security.version>3.2.5.release</spring-security.version> <tomcat.version>8.0.15</tomcat.version> <undertow.version>1.1.1.final</undertow.version>,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
291,update twittersearchtest to handle the latest release of twittersearch the changes to twittersearch means that it will send multiple messages during the duration of the test. to support these changes: 1) remove assertreceived. since the number of messages is indeterminate 2) change file sink that captures the results to append mode. because each message will overwrite the previous messages result.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
292,remove all deprecated compile warnings run a clean gradle build to identify all warnings.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,0,0
293,add list command for aggregatecounter,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
294,improve support for custom headers when using kafka message bus i understand kafka natively does not have the concept of message headers. however spring integration messages do and a lot of si components are built specifically for dealing with message headers (header-enricher header-filter header-value-router etc...). in addition message headers are very useful for tracking meta-information about messages as they progress through a system. with the implementation of https://jira.spring.io/browse/xd-3621 spring xd has limited support for custom headers when using kafka as a transport. i say limited because it is required to list all custom headers explicitly in servers.yml in order for the headers to be retained by the messagebus. this is less than ideal because it means that it is necessary to know all potential custom header values a user will require before starting the environment. it would be nice to extend this functionality so that it is not necessary to list custom headers in the configuration. instead when operating in mode=embeddedheaders spring xd will simply embeds all headers in the kafka message. or alternatively allow for a wildcard in the 'headers' configuration option so that it is not necessary to exhaustively list all possible custom header values prior to starting the system.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
295,"modules/scd deployers: how to provide ""cloud connector"" support currently s-c-s modules all come with baked in support for multiple cloud binding technologies: {code:xml} <!-- lattice core dependency that activates cloudlattice profiles when running on lattice --> <dependency> <groupid>org.springframework.cloud</groupid> <artifactid>spring-cloud-lattice-core</artifactid> <version>${spring-cloud-lattice.version}</version> <optional>true</optional> </dependency> <!-- cloud connector dependencies --> <!-- lattice connector dependency to create services info from lattice --> <dependency> <groupid>org.springframework.cloud</groupid> <artifactid>spring-cloud-lattice-connector</artifactid> <version>${spring-cloud-lattice.version}</version> <optional>true</optional> </dependency> <!-- cf connector dependency to create services info from cf --> <dependency> <groupid>org.springframework.cloud</groupid> <artifactid>spring-cloud-cloudfoundry-connector</artifactid> <optional>true</optional> </dependency> <!-- dependency to connect to detected cloud services --> <dependency> <groupid>org.springframework.cloud</groupid> <artifactid>spring-cloud-spring-service-connector</artifactid> <optional>true</optional> </dependency> {code} should the deployers add those at runtime instead?",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
296,adapt springone 2012 ui code from keynote demo of election results to use xd existing code: https://github.com/ghillert/springone2012,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
297,add support for creating named cron triggers simple cron based triggers,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
298,as a user i'd like to have the option to gracefully shutdown the stream so when it is _undeployed_ while in the middle of its operation we would want to complete its journey to the sink before xd stops the stream. *use case:* one of the streams has a custom module that performs archive extraction. when this stream is ‘undeployed’ while in the middle of extraction it looks like the message goes to the dlq. however we would like the message to complete its journey to the sink of the queue before xd stops the stream. is this possible?,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
299,tap fixture refactoring the tap fixture does not need to inherit from abstractmodulefixture replace modulename method with moduletotap. the current tap syntax is: tap:stream:<streamname>.<modulelabel> and not tap:stream:<streamname>.<modulelabel>.<modulename> as currently implemented by the label fixture.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
300,as a s-c-d developer i'd like to enhance integration test coverage for {{lattice}} spi so i can continuously evaluate functionalities via ci pipeline.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
301,"as a module author i want to be able to test my code in ""next to real world"" conditions (ie integration testing but not really): - i want all my module wiring to be testable - i want all my module configuration (@configurationproperties) to be in effect and i want to be able to test various combination of props - i want to be able to send data to my module and assert what is coming at the other end - i want an idiomatic way of asserting the above (eg integration with hamcrest etc) - i dont want to have to send data to an actual bus (redis rabbit etc)",4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
302,move redis connection metadata logging into the code closest to establishing that connection xd-106 included detailed logging about the redis metadata within the rediscontainerlistener but it seems as though that info could be logged somewhere closer to the establishment of a redis connection for the xd runtime (and could be logged even if this listener whose main role is to capture container-related events is not enabled).,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
303,validate processing modules declare the required channels validate that modules have required channels declared according to their type. currently the stream deployer accepts processors with no input but the stream doesn't complete. we should fail earlier and more loudly.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
304,"surface better exception information to client in trying to upgrade to latest si i encountered a failing test because it expects an error message to contain something but si changes make it disappear (the problem is an si exception now has an explicit message and so does not expose its cause message anymore) this however is the manifest of a deeper ""problem"". we currently expose the getmessage() of any generic exception caught in the vnderror rest construct. but this is not enough. things that we can consider are: 1) adding the whole stacktrace of the caught exception as a string. this is not very good at it leaks java specific details 2) unwrap the caught exception to get to the deepest cause. this may not be what we want everytime 3) construct a vnderrors (note the 's') made of each layered exception 4) similar to 1) but not using the stacktrace only the messages of each cause etc",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
305,"shell does not report failed deploy attempt during the slow network tests the user undeployed a stream and then immediately redeployed the same stream to get the modules on different containers. the deployment failed as reflected in the stacktrace below from the admin server however the the shell did not report an error and the user could not deploy the stream. * the stream in question is ""http|log"" * the shell did not report any error. * stream list does show the state of the stream as failed. * executing a stream deploy fails with the following error: ** command failed org.springframework.xd.rest.client.impl.springxdexception: the stream named 'foo' is already deployed * undeploy and deploy of the stream worked. 17:54:39487 info deployer server.streamdeploymentlistener - deployment status for stream 'foo': deploymentstatus{state=failederror(s)=org.apache.zookeeper.keeperexception$nonodeexception: keepererrorcode = nonode for /xd/deployments/modules/allocated/73f0a93d-e213-414d-8337-6c04409ec210/foo.source.http.1/status org.apache.zookeeper.keeperexception.create(keeperexception.java:111) org.apache.zookeeper.keeperexception.create(keeperexception.java:51) org.apache.zookeeper.zookeeper.getdata(zookeeper.java:1155) org.apache.curator.framework.imps.getdatabuilderimpl$4.call(getdatabuilderimpl.java:302) org.apache.curator.framework.imps.getdatabuilderimpl$4.call(getdatabuilderimpl.java:291) org.apache.curator.retryloop.callwithretry(retryloop.java:107) org.apache.curator.framework.imps.getdatabuilderimpl.pathinforeground(getdatabuilderimpl.java:287) org.apache.curator.framework.imps.getdatabuilderimpl.forpath(getdatabuilderimpl.java:279) org.apache.curator.framework.imps.getdatabuilderimpl.forpath(getdatabuilderimpl.java:41) org.springframework.xd.dirt.server.moduledeploymentwriter.writedeployment(moduledeploymentwriter.java:205) org.springframework.xd.dirt.server.moduledeploymentwriter.writedeployment(moduledeploymentwriter.java:163) org.springframework.xd.dirt.server.streamdeploymentlistener.deploystream(streamdeploymentlistener.java:166) org.springframework.xd.dirt.server.streamdeploymentlistener.onchildadded(streamdeploymentlistener.java:100) org.springframework.xd.dirt.server.initialdeploymentlistener$eventhandler.call(initialdeploymentlistener.java:217) org.springframework.xd.dirt.server.initialdeploymentlistener$eventhandler.call(initialdeploymentlistener.java:186) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) } 17:54:39496 info deployer server.streamdeploymentlistener - stream stream{name='foo'} deployment attempt complete",0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
306,update source syslog section to use shell commands instead of curl see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#syslog,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
307,investigate jmx object naming of deployed modules and inbound/outbound channel adapters. the object naming is still not ideal for xd since si conventions add some noise. likely need to design and implement a custom naming strategy,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
308,ui provide fixed version numbers for npm and bower dependencies,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
309,as a user i'd like to have the option of _compression_ for both rabbit _source_ and _sink_ modules so that can further enhance the performance characteristics.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
310,spring xd processor module classloader issue: classnotfoundexception see http://stackoverflow.com/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
311,jms source can only connect to localhost can't connect to remote activemq instance. setup a jms-activemq.properties file with amq.url=tcp://:ec2-54-198-157-91.compute-1.amazonaws.com:61616. source always refers to defaults of tcp://localhost:61616. localhost works,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
312,ui: implement job deploy/undeploy from the job definitions page from xd-1023 the job status(deployed/undeployed) is available from jobinstance repository and a job can be deployed/undeployed correctly. implement job deploy/undeploy for a given job from jobdefinitions page and indicate status of the job definition (deployed/undeployed).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
313,as a developer i'd like to add {{undeployed}} status for cf spi so i can represent the correct status instead of the current {{unknown}} state.,3,4,0.0027609235048294068,8.333333333333332,1,1,0,0,0
314,create ootb batch job for export and processing multiple files from hdfs to jdbc same setup as xd-987 for itemreader and itemprocessor but should write to hdfs. one can assume that the table structure has been created already external to the batch job execution.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
315,as a developer i'd like to port {{field-value-counter}} module from xd to s-c-s repo so i can use it as {{sink}} module to build streaming pipeline.,2,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
316,as a cf user i'd like to have the ability to override the yarn config location so that i can change where the custom module _uber-jar_ can be stored and retrieved.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
317,strict flag for jdbchdfs h2. narrative as a developer when using jdbchdfs's incremental imports i need to be notified that something went wrong in a previous run of the jdbchdfs job so that i can take the appropriate actions based on the data previously imported. h2. back story as the incremental import currently works if the job fails half way through there is no check on the next run to see if the last run failed or not and how to address partially imported data.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
318,as a field engineer i'd like to have a comparison of spark streaming examples in spring xd so that it is easy to relate from implementation standpoint.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
319,"create an easier short-cut for launching adhoc batch jobs currently for adhoc launching of batch jobs you have to use: {code} stream create --name mytriggerstream --definition ""trigger > job:hellospringxd"" {code} for renewed triggering of the job you have to undeploy and then redeploy the job. it would be nice if there was possibly a slightly simpler way of doing this. just fyi - as a different approach you can also use the http source: {source} job create --name myjob --definition ""myjob"" stream create --name myjobhttp --definition ""http > job:http"" http post --data ""{}"" {source}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
320,add documentation for connecting to hdfs with ha namenode,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
321,support multiple admin servers on a same host by default xd admin server uses hsqldb as data source for batch job repository and uses the default port 9101 specific database location and dbname. this makes the existence of multiple admin server on a same host not possible.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
322,fix doc related to zk install amongst (maybe) other things the doc says we don't ship zk: http://docs.spring.io/spring-xd/docs/1.0.0.build-snapshot/reference/html/#_setting_up_zookeeper,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,1,0
323,compute progress information for job composition as an xd user i'd like to see an aggregated progress bar for a job that is embeds multiple jobs within itself.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
324,vary producer threads (xd-b-2) send 1m messages of 1000 bytes via the generator vary the number of producer threads. measure the msg/sec rate and calculate the data transfer rate in mb/sec. *number of threads* * 2 * 4 * 8,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
325,"stream definition completion rest layer + shell adapter provide the infrastructure for http get /completions?start='http | file --d"" that would return a list of possible completions (in this case returning the file option names that start with ""d"") this story is about (and only about): - having that rest controller delegating to some ""completionsengine"" - implementing the spring shell converter that talks to that it's an empty shell useless (but easy to do) without the actual ""completionsengine""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
326,update spring-data-hadoop version to 2.1.0.rc1 update spring-data-hadoop version to 2.1.0.rc1. this also includes updating the following: - adding hadoop26 (apache hadoop 2.6.0) as distro - adding hdp22 (hortonworks hdp 2.2) as distro - set default distro to hadoop26 - update cdh5 to version 5.3.0 - remove older distros - hadoop24 hdp21,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
327,as a qa i'd like to include acceptance test coverage for _timestampfile_ batch job so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
328,"create tests for stream/job deployments path data verification based on the discussion here: https://github.com/spring-projects/spring-xd/pull/852#issuecomment-43356579 we would like to have tests created for verifying the stream/job deployments path ""data""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
329,update to spring batch admin 1.3.0.rc1,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
330,configure servers to use vanillahealthendpoint the standard simplehealthindicator that boot performs a database test that fails in xd-container since it does not require the use of a database.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
331,add command for tap creation,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
332,add pre-compiled redis distributions for the selective os platforms,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
333,sqooprunner should use resource manager scheduler option in sqooprunner we manually set rm address fs address and yarn classpath. yarnconfiguration.rm_scheduler_address is also needed for appmaster to function properly. current workaround is to use config values which gets imported automatically: {code} spring: hadoop: config: yarn.resourcemanager.scheduler.address: <host>:8030 {code},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
334,remove dynamically created producers when producers are created/bound dynamically (e.g. from the router sink) they are not unbound when the module is undeployed. there is currently no metadata in the binding to provide that functionality. it is not critical because the producers are just sitting there (and may be reused if the module is redeployed but it is a leak and should be addressed at some time.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
335,update spring-amqp to 1.3.1.release,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
336,as a user i'd like flo graphs as screenshots while referring to the batch dsl so it will be easy for me to relate to concepts.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
337,allow aggregate-counter to increment by some value of the message currently the aggregate counter only adds +1 to the individual values even though support is there to add any increment. this ticket is about surfacing a spel expression on the message to choose the increment,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
338,add unregistration support to the channel registry,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
339,as a spring xd user i want to have the ability to customize the encoders and decoders used by the kafka source sink and bus so that i can customize data formats and choose the most appropriate strategy,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
340,fix cloud connector dependencies and service resolution this jira addresses couple of issues: 1) when the modules are deployed into cloud environment there is an issue where local configuration beans collide with cloud service beans. we witnessed an issue where there are two `redisconnectionfactory` beans registered in the same application context. we need to have a control the way in which the auto configuration gets invoked and service beans are created. 2) we need to align the cloud connector dependencies into a common place so that we don't have to specify them at various places like (scs scs-binder scs-modules) etc. it is a good idea to have these dependencies specified in scs-modules so that it get used subsequently by scs when the module is assembled at runtime.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
341,xd container can not be started before the admin server the job single partitioned step support (from singlestep-partitioner-support.xml) has the batch job daos (loaded from batch.xml). during container startup when the jobexecutiondao bean is initialized it makes the db connection to the underlying batch database (which admin server initializes). here is the exception: 15:30:03600 info main xml.xmlbeandefinitionreader:316 - loading xml bean definitions from class path resource [meta-inf/spring-xd/batch/batch.xml] 15:30:06154 warn main annotation.configurationclassenhancer:318 - @bean method stepscopeconfiguration.stepscope is non-static and returns an object assignable to spring's beanfactorypostprocessor interface. this will result in a failure to process annotations such as @autowired @resource and @postconstruct within the method's declaring @configuration class. add the 'static' modifier to this method to avoid these container lifecycle issues see @bean javadoc for complete details 15:30:06705 info main support.postprocessorregistrationdelegate$beanpostprocessorchecker:309 - bean 'org.springframework.xd.dirt.server.parentconfiguration$jmxconfiguration' of type [class org.springframework.xd.dirt.server.parentconfiguration$jmxconfiguration] is not eligible for getting processed by all beanpostprocessors (for example: not eligible for auto-proxying) 15:30:07266 info main annotation.annotationmbeanexporter:416 - registering beans for jmx exposure on startup 15:30:07291 info main annotation.annotationmbeanexporter:896 - bean with name 'xdparentconfigmbeanexporter' has been autodetected for jmx exposure 15:30:07299 info main annotation.annotationmbeanexporter:659 - located managed bean 'xdparentconfigmbeanexporter': registering with jmx server as mbean [org.springframework.integration.monitor:name=xdparentconfigmbeanexportertype=integrationmbeanexporter] 15:30:09637 info main concurrent.threadpooltaskscheduler:165 - initializing executorservice 'scheduler' 15:56:08788 info main concurrent.threadpooltaskscheduler:203 - shutting down executorservice 'scheduler' 15:56:08806 info main annotation.annotationmbeanexporter:434 - unregistering jmx-exposed beans on shutdown 15:56:08853 info main autoconfigure.autoconfigurationreportlogginginitializer:118 - error starting applicationcontext. to display the auto-configuration report enabled debug logging (start with --debug) 15:56:08854 info main listener.classpathloggingapplicationlistener:54 - application failed to start with classpath: [file:/users/iperumal/workspace/spring-xd/modules/processor/scripts/ file:/users/iperumal/workspace/spring-xd/spring-xd-dirt/bin/ file:/users/iperumal/workspace/spring-xd/spring-xd-test/bin/ file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-test/4.0.0.m3/74e696bad60aab349c74f52839eb43ed0e1ce0e2/spring-integration-test-4.0.0.m3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-amqp/4.0.0.m3/32dd5001acffd82391d756cf3b5ba73ca4075aed/spring-integration-amqp-4.0.0.m3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-redis/4.0.0.m3/ed5e47b6844212bb88c112c559556b4cb3d6b087/spring-integration-redis-4.0.0.m3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop/2.0.0.m4/9f1acbf66f3a97d42a8f5b00eb0c0cad11562730/spring-data-hadoop-2.0.0.m4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-redis/1.1.1.release/e2d5e9cfdaaa3fbcc2a8d4bdbe06daf771cb4e39/spring-data-redis-1.1.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.0.1.release/cb996939c8d48ae55ec933041f17e7fba4d9e27d/spring-context-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context-support/4.0.1.release/94dc23c49a74f3f4b894b29416b08202e5976f49/spring-context-support-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.0.1.release/b93b2c39b09ff858a42db85a0a9a8ce232a6779/spring-tx-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.0.1.release/367212c3b84c63a48220efa0fe8e9a3a937fcf68/spring-test-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.lambdaworks/lettuce/2.3.3/1366615be02807a568c5f2d3a4475a3d27a879a6/lettuce-2.3.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.hsqldb/hsqldb/2.3.0/93306187b1a782f2b929d12536022185487037d2/hsqldb-2.3.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/7.0.42/3827da9ca05ff115f239a2372bd44cfd729c692d/tomcat-jdbc-7.0.42.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/2.4/b1b6ea3b7e4aa4f492509a4952029cd8e48019ad/commons-io-2.4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.1.0/a14306a090eec2fa91017b77ac079361f68e1830/groovy-all-2.1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.0/9b473564e792c2bdf1449da1f0b1b5bff9805704/objenesis-1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.9.5/c3264abeea62c4d2f367e21484fbb40c7e256393/mockito-core-1.9.5.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.1/5043bfebc3db072ed80fbd362e7caf00e885d8ae/commons-logging-1.1.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.0.1.release/e39774d97c9dadfe49e6dfd16e3868bc1e390554/spring-core-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.0.1.release/605582e95fb62b43fb4a843babdcf739f3497e92/spring-beans-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/aopalliance/aopalliance/1.0/235ba8b489512805ac13a8f9ea77a1ca5ebe3e8/aopalliance-1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.0.1.release/ff68e4cfdbb2be3e8d8a7f34e7cbacc1860dfe75/spring-aop-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.0.1.release/452cb22401e868a1e79677dd22b6a3097fc603fa/spring-expression-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.3.release/33b967f6abaa0a496318bff2ce96e6da6285a54d/spring-retry-1.0.3.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.0.1.release/829829afd9135368faa1e3a5261404f602a2e939/spring-messaging-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-core/4.0.0.m3/12b445cfa896b906facd2be289adcdfe839f6104/spring-integration-core-4.0.0.m3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-amqp/1.3.0.m2/e668db16a4206e96531b978e5978868ba0ebf4e9/spring-amqp-1.3.0.m2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.rabbitmq/amqp-client/3.2.2/9e4485e734415e84ea3caea25650f8651f388a3a/amqp-client-3.2.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-rabbit/1.3.0.m2/ceb54c437d2d00c3a22d59982922f24fbf78c8a/spring-rabbit-1.3.0.m2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.6/ce53b0a0e2cfbb27e8a59d38f79a18a5c6a8d2b0/slf4j-api-1.6.6.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.6.6/ec497945fdcaf7fd970ae9931b9bbfaf735d385e/jcl-over-slf4j-1.6.6.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.0.1.release/7d46d07d44f56af7cdcbba53ff671c5487f9547/spring-jdbc-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.2/2bf96b7aa8b611c177d329452af1dc933e14501c/commons-cli-1.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/xmlenc/xmlenc/0.52/d82554efbe65906d83b3d97bd7509289e9db561a/xmlenc-0.52.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.4/4216af16d38465bbab0f3dff8efa14204f7a399a/commons-codec-1.4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-httpclient/commons-httpclient/3.0.1/d6364bcc1b2b2aa69d008602d36a700453648560/commons-httpclient-3.0.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-math/2.1/b3c4bdc2778ddccceb8da2acec3e37bfa41303e9/commons-math-2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2.1/761ea405b9b37ced573d2df0d1e3a4e0f9edc668/commons-collections-3.2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.4/16313e02a793435009f1e458fa4af5d879f6fb11/commons-lang-2.4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils/1.7.0/5675fd96b29656504b86029551973d60fb41339b/commons-beanutils-1.7.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-digester/commons-digester/1.8/dc6a73fdbd1fa3f0944e8497c6c872fa21dca37e/commons-digester-1.8.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils-core/1.8.0/175dc721f87e4bc5cc0573f990e28c3cf9117508/commons-beanutils-core-1.8.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-configuration/commons-configuration/1.6/32cadde23955d7681b0d94a2715846d20b425235/commons-configuration-1.6.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/oro/oro/2.0.8/5592374f834645c4ae250f4c9fbb314c9369d698/oro-2.0.8.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-net/commons-net/1.4.1/abb932adb2c10790c1eaa4365d3ac2a1ac7cb700/commons-net-1.4.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-el/commons-el/1.0/1df2c042b3f2de0124750241ac6c886dbfa2cc2c/commons-el-1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.eclipse.jdt/core/3.1.1/88c83ce444cf46d02494da37c9fa1eebc9ce9cea/core-3.1.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-core/1.2.1/3e5874122a26a735162a380627210779b41bfd59/hadoop-core-1.2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-streaming/1.2.1/4baac190cf4cd4a6d085780cbcab1a89493f932b/hadoop-streaming-1.2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-tools/1.2.1/b08c16bd0448fbcadab67c4f8df837c094fdc91e/hadoop-tools-1.2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-core/2.0.0.m4/ff4cefb0870d61fdc9efe26d118310c02b5eafbb/spring-data-hadoop-core-2.0.0.m4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-batch/2.0.0.m4/47de250d5d9b48ed1319a747e3b06fdc46d939ef/spring-data-hadoop-batch-2.0.0.m4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.6.6.final/e4e40738ce9bee0a92389cb739c94d7839778647/netty-3.6.6.final.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/7.0.42/f0049ac94514d69231c41ed96238efb94ffdd9cf/tomcat-juli-7.0.42.jar file:/users/iperumal/workspace/spring-xd/spring-xd-analytics/bin/ file:/users/iperumal/workspace/spring-xd/spring-xd-tuple/bin/ file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.2.2/3c8f6018eaa72d43b261181e801e6f8676c16ef6/jackson-databind-2.2.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-infrastructure/3.0.0.build-snapshot/cfaea737589c43c54ff338ae27e1bee477620176/spring-batch-infrastructure-3.0.0.build-snapshot.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.eaio.uuid/uuid/3.2/77ba5105d949cd589aff75400d9f7d3676691a46/uuid-3.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.2.2/285cb9c666f0f0f3dd8a1be04e1f457eb7b15113/jackson-annotations-2.2.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.2.2/d20be6a5ddd6f8cfd36ebf6dea329873a1c41f1b/jackson-core-2.2.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.6.2.release/e96a0458cdc3179ca70c880f42315bb75df4faf5/spring-data-commons-1.6.2.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.1/8f79e353ef77da6710e1f10d34fc3698eaaacbca/joda-time-2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.5/cd5970bd13fa85f7bed41ca606d6daf7cbf1365/jcl-over-slf4j-1.7.5.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.5/6edffc576ce104ec769d954618764f39f0f0f10d/slf4j-log4j12-1.7.5.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/nl.jqno.equalsverifier/equalsverifier/1.1.3/60cd685f314a9cebfd0595d88fea45fba2f47918/equalsverifier-1.1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.5/6b262da268f8ad9eff941b25503a9198f0a0ac93/slf4j-api-1.7.5.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.1/63db1176f16448172611266154e4f6d39a0e1e68/objenesis-1.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/2.2/59afed7ab65e7ec6585d5bc60556c3cbd203532b/cglib-nodep-2.2.jar file:/users/iperumal/workspace/spring-xd/spring-xd-rest-domain/bin/ file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.hateoas/spring-hateoas/0.8.0.release/819c25e1ff12b7fca483d76b4e7d20221f621fcd/spring-hateoas-0.8.0.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-manager/1.3.0.m1/5afc7442417af8c46ae51480ed2b83943283d449/spring-batch-admin-manager-1.3.0.m1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-core/3.0.0.build-snapshot/8168f58716cd305040eaa87c82dc61822b03415c/spring-batch-core-3.0.0.build-snapshot.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.13/3c304d70f42f832e0a86d45bd437f692129299a4/jackson-core-asl-1.9.13.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.0.1.release/2ace92025f042e1d3ddfdbba093172e3572ac130/spring-web-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.0.1.release/2dbc91a6413115f7ffbe94f0fa9bc9fda3281d90/spring-webmvc-4.0.1.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.3/dc13ae4faca6df981fc7aeb5a522d9db446d5d50/objenesis-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.2/81d61b7f33ebeab314e07de0cc596f8e858d97/slf4j-api-1.7.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjrt/1.6.6/ff58f520e1a304b8a02b8cea8b96b1b8e5b25b0/aspectjrt-1.6.6.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.6.6/c0383be877cfa4ec6b62202c942a89a6264a2be6/aspectjweaver-1.6.6.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-pool/commons-pool/1.3/3231230c1d7631b66a74d1c4653cfd65a6f9ea0/commons-pool-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-dbcp/commons-dbcp/1.2.2/4fd4c6110e9bca3a655b717eb2e5920febb8403d/commons-dbcp-1.2.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/1.4/a8762d07e76cfde2395257a5da47ba7c1dbd3dce/commons-io-1.4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.1/4763ecc9d78781c915c07eb03e90572c7ff04205/commons-lang-2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-fileupload/commons-fileupload/1.2.1/384faa82e193d4e4b0546059ca09572654bc3970/commons-fileupload-1.2.1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/net.sf.ehcache/ehcache-core/2.3.0/e59473c71a31e8e19da4fbc7028585c8ed51d69f/ehcache-core-2.3.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2/f951934aa5ae5a88d7e6dfaa6d32307d834a88be/commons-collections-3.2.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.freemarker/freemarker/2.3.15/c8cfe522476fcec8da5c980d58bf62d6ab0cf27c/freemarker-2.3.15.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-resources/1.3.0.m1/bdf7d5afc02397385fce8731409f606e54d4d033/spring-batch-admin-resources-1.3.0.m1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.2.release/d673c90a9fd8f0de5f20d53d61047849f707f42b/spring-retry-1.0.2.release.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/javax.batch/javax.batch-api/1.0/65392d027a6eb369fd9fcd1b75cae150e25ac03c/javax.batch-api-1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.ibm.jbatch/com.ibm.jbatch-tck-spi/1.0/8ac869b0a60bff1a15eba0fb6398942410396938/com.ibm.jbatch-tck-spi-1.0.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/xpp3/xpp3_min/1.1.4c/19d4e90b43059058f6e056f794f0ea4030d60b86/xpp3_min-1.1.4c.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/com.thoughtworks.xstream/xstream/1.3/3f755b1a46744302712b1b962c4ab64de392f477/xstream-1.3.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jettison/jettison/1.1/1a01a2a1218fcf9faa2cc2a6ced025bdea687262/jettison-1.1.jar file:/users/iperumal/workspace/spring-xd/spring-xd-module/bin/ file:/users/iperumal/workspace/spring-xd/spring-xd-module-spi/bin/ file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.0.0.rc1/7830d0dd26f75841d8b5c2c72c42b864b1192ddb/spring-boot-autoconfigure-1.0.0.rc1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.0.0.ga/b6bd7f9d78f6fdaa3c37dae18a4bd298915f328e/validation-api-1.0.0.ga.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/4.3.1.final/49b31d8ea51fa21cc78a89e9d4ddb11d6bfb4669/hibernate-validator-4.3.1.final.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.0.0.rc1/7e53b72a368c495a482d3a213ad6338f8f7afcfa/spring-boot-1.0.0.rc1.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.1.0.cr2/28725380c07f917ace4e511db21cc45e9ae5a72b/jboss-logging-3.1.0.cr2.jar file:/users/iperumal/workspace/spring-xd/spring-xd-hadoop/bin/ file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-store/2.0.0.m4/1d3d691c0e6952ba26724339668e17040c368683/spring-data-hadoop-store-2.0.0.m4.jar file:/users/iperumal/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.0/71c46e2313e9288...,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
342,"deleting a stream with reference to named channel disconnects channel from all streams the following sequence results in ""dispatcher has no subscribers"" error (stack trace below) because deleting stream2 disconnects stream1 from the foo channel. current work on xd-685 has infrastructure for disconnecting just the channels involved in a stream so should make it easier to fix this issue once merged. stream create stream1 --definition ""time > :foo"" stream create stream2 --definition ""http > :foo"" stream create stream3 --definition "":foo > file"" stream destroy stream2 // expect file sink to still get time but instead blows up b/c // deleteoutbound(""foo"") killed links b/w foo and both local output channels server stack trace: 10:47:11921 error task-scheduler-6 handler.logginghandler:140 - org.springframework.integration.messagedeliveryexception: dispatcher has no subscribers for channel 'simplemodule [name=time type=source group=stream1 index=0].output'. org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:81) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:97) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:199) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:51) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:143) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:141) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:273) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:49) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:268) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:53) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:439) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:303) java.util.concurrent.futuretask.run(futuretask.java:138) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:98) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:206) java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) java.lang.thread.run(thread.java:680) caused by: org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:109) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) ... 24 more 10:47:12924 error task-scheduler-6 handler.logginghandler:140 - org.springframework.integration.messagedeliveryexception: dispatcher has no subscribers for channel 'simplemodule [name=time type=source group=stream1 index=0].output'. org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:81) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:97) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:199) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:51) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:143) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:141) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:273) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:49) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:268) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:53) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:439) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:303) java.util.concurrent.futuretask.run(futuretask.java:138) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:98) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:206) java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) java.lang.thread.run(thread.java:680) caused by: org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:109) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) ... 24 more 10:47:13926 error task-scheduler-4 handler.logginghandler:140 - org.springframework.integration.messagedeliveryexception: dispatcher has no subscribers for channel 'simplemodule [name=time type=source group=stream1 index=0].output'. org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:81) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:97) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:199) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:51) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:143) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:141) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:273) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:49) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:268) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:53) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:439) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:303) java.util.concurrent.futuretask.run(futuretask.java:138) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:98) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:206) java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) java.lang.thread.run(thread.java:680) caused by: org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:109) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) ... 24 more 10:47:14928 error task-scheduler-4 handler.logginghandler:140 - org.springframework.integration.messagedeliveryexception: dispatcher has no subscribers for channel 'simplemodule [name=time type=source group=stream1 index=0].output'. org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:81) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:97) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:199) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:51) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:143) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:141) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:273) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:49) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:268) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:53) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:439) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:303) java.util.concurrent.futuretask.run(futuretask.java:138) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:98) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:206) java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) java.lang.thread.run(thread.java:680) caused by: org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:109) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) ... 24 more 10:47:15930 error task-scheduler-1 handler.logginghandler:140 - org.springframework.integration.messagedeliveryexception: dispatcher has no subscribers for channel 'simplemodule [name=time type=source group=stream1 index=0].output'. org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:81) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:97) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:199) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:51) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:143) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:141) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:273) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:49) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:268) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:53)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
343,add spring-xd-hadoop distro specific sub-projects we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (pivotal hd) to pull in transitive dependencies for correct hadoop distro,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
344,build.gradle doesn't handle a small handful of libraries trying to build spring-xd for the first resulted in lots of errors inside sts (i had an empty .m2 repo).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
345,"add validation on tap definitions that checks for module names that are part of the stream definition try: {code} stream create --name aa --definition ""time | log"" tap create --name t1 --definition ""tap aa.log | log"" {code} results in: {code} command failed org.springframework.xd.rest.client.impl.springxdexception: java.lang.nullpointerexception {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
346,"filejdbc job broken in distributed mode the filejdbc job is broken in distributed mode (redis and rabbit) to reproduce: export xd_transport=rabbit start xd-admin start xd-container start shell and create this job: {code} >job create mydata --definition ""filejdbc --names=col1col2col3 --resources=file:///home/trisberg/test/input/*.csv --initializedatabase=true"" --deploy >job launch mydata {code} results in job starting but never completing: {code} >job execution list id job name start time step execution count execution status deployment status definition status -- -------- ------------------------------------ -------------------- ---------------- ----------------- ----------------- 0 mydata 2014-07-11 15:44:33 america/new_york 0 started deployed exists {code} steps: {code} step id step name reads writes commits rollbacks duration status details 0 step1-master 0 0 0 0 -1405349644032 ms executing 1 step1-master:partition0 292 292 3 0 302 ms completed 2 step1-master:partition1 292 292 3 0 203 ms completed 3 step1-master:partition2 292 292 3 0 193 ms completed {code} when using redis i also get this stacktrace in container: {code} 15:40:51220 info deploymentspathchildrencache-0 boot.springapplication - started application in 1.965 seconds (jvm running for 66.949) 15:40:51220 info deploymentspathchildrencache-0 core.simplemodule - initialized module: simplemodule [name=filejdbc type=job group=job1 index=0 @64a28a58] 15:40:51233 info deploymentspathchildrencache-0 redis.redismessagebus - binding requestor: job1.0 15:40:51236 info deploymentspathchildrencache-0 redis.redismessagebus - binding replier: job1.0 15:40:51243 info deploymentspathchildrencache-0 module.moduledeployer - deployed simplemodule [name=filejdbc type=job group=job1 index=0 @64a28a58] 15:40:57110 error inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.redismessagebus$1 - failed to deliver message retries exhausted message sent to queue 'errors:name' org.springframework.messaging.messagehandlingexception: error occurred in message handler [org.springframework.integration.aggregator.aggregatingmessagehandler#0] org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:84) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy84.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor89.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy78.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.xd.dirt.integration.redis.redismessagebus$1$1.dowithretry(redismessagebus.java:251) org.springframework.xd.dirt.integration.redis.redismessagebus$1$1.dowithretry(redismessagebus.java:247) org.springframework.retry.support.retrytemplate.doexecute(retrytemplate.java:263) org.springframework.retry.support.retrytemplate.execute(retrytemplate.java:168) org.springframework.xd.dirt.integration.redis.redismessagebus$1.dosend(redismessagebus.java:247) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.endpoint.messageproducersupport.sendmessage(messageproducersupport.java:98) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.popmessageandsend(redisqueuemessagedrivenendpoint.java:211) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.access$300(redisqueuemessagedrivenendpoint.java:50) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint$listenertask.run(redisqueuemessagedrivenendpoint.java:290) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) java.lang.thread.run(thread.java:744) caused by: java.lang.illegalstateexception: null correlation not allowed. maybe the correlationstrategy is failing? org.springframework.util.assert.state(assert.java:385) org.springframework.integration.aggregator.abstractcorrelatingmessagehandler.handlemessageinternal(abstractcorrelatingmessagehandler.java:383) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) ... 60 more 15:41:00129 error inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.redismessagebus$1 - failed to deliver message retries exhausted message sent to queue 'errors:name' org.springframework.messaging.messagehandlingexception: error occurred in message handler [org.springframework.integration.aggregator.aggregatingmessagehandler#0] org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:84) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy84.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor89.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy78.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.xd.dirt.integration.redis.redismessagebus$1$1.dowithretry(redismessagebus.java:251) org.springframework.xd.dirt.integration.redis.redismessagebus$1$1.dowithretry(redismessagebus.java:247) org.springframework.retry.support.retrytemplate.doexecute(retrytemplate.java:263) org.springframework.retry.support.retrytemplate.execute(retrytemplate.java:168) org.springframework.xd.dirt.integration.redis.redismessagebus$1.dosend(redismessagebus.java:247) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.endpoint.messageproducersupport.sendmessage(messageproducersupport.java:98) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.popmessageandsend(redisqueuemessagedrivenendpoint.java:211) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint.access$300(redisqueuemessagedrivenendpoint.java:50) org.springframework.integration.redis.inbound.redisqueuemessagedrivenendpoint$listenertask.run(redisqueuemessagedrivenendpoint.java:290) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) java.lang.thread.run(thread.java:744) caused by: java.lang.illegalstateexception: null correlation not allowed. maybe the correlationstrategy is failing? org.springframework.util.assert.state(assert.java:385) org.springframework.integration.aggregator.abstractcorrelatingmessagehandler.handlemessageinternal(abstractcorrelatingmessagehandler.java:383) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) ... 60 more {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
347,as a s-c-d developer i'd like to experiment how do we resolve and then add module dependent jar's to boot loader so i have an approach to handle external libraries required by ootb modules.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
348,check whether the field exists or not in #jsonpath evaluation i am parsing json(source) into csv in transform function all of my json records may not have all the fields. some records have only field1field2.. some other records have all 3 fields. if the specific field is not exists in specific record that record got rejected.(by saying field is not exist) could you please let me know how to check the field exists or not. here my expression part of the stream transform --expression=#jsonpath(payload'$.field1').concat('|').concat(#jsonpath(payload'$.field2')).concat('|').concat(#jsonpath(payload'$.field3')) my spring xd version is 1-0-0-m7,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
349,add acceptance tests for stream with sources of tcp http and time and sinks of file and log need to be able to test the following sources: tcp http time,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
350,"exception when accessing cdh4 namenode get exception when accessing cdh4 from shell - java.lang.unsupportedoperationexception: this is supposed to be overridden by subclasses. com.google.protobuf.generatedmessage.getunknownfields most likely due to protobuf-java-2.5.0.jar being on the main classpath now full stack trace: {code} trisberg@carbon:~/test$ ./spring-xd-1.0.0.build-snapshot/shell/bin/xd-shell --hadoopdistro cdh4 16:55:22680 warn main conf.configuration:824 - fs.default.name is deprecated. instead use fs.defaultfs _____ __ _______ / ___| (-) \ \ / / _ \ \ `--. _ __ _ __ _ _ __ __ _ \ v /| | | | `--. \ '_ \| '__| | '_ \ / _` | / ^ \| | | | /\__/ / |_) | | | | | | | (_| | / / \ \ |/ / \____/| .__/|_| |_|_| |_|\__ | \/ \/___/ | | __/ | |_| |___/ extreme data 1.0.0.build-snapshot | admin server target: http://localhost:9393 welcome to the spring xd shell. for assistance hit tab or type ""help"". xd:>hadoop config fs --namenode hdfs://cdh4:8020 xd:>hadoop fs ls / hadoop configuration changed re-initializing shell... 16:55:28853 warn spring shell util.nativecodeloader:62 - unable to load native-hadoop library for your platform... using builtin-java classes where applicable -ls: fatal internal error java.lang.unsupportedoperationexception: this is supposed to be overridden by subclasses. com.google.protobuf.generatedmessage.getunknownfields(generatedmessage.java:180) org.apache.hadoop.hdfs.protocol.proto.clientnamenodeprotocolprotos$getfileinforequestproto.getserializedsize(clientnamenodeprotocolprotos.java:30108) com.google.protobuf.abstractmessagelite.tobytestring(abstractmessagelite.java:49) org.apache.hadoop.ipc.protobufrpcengine$invoker.constructrpcrequest(protobufrpcengine.java:149) org.apache.hadoop.ipc.protobufrpcengine$invoker.invoke(protobufrpcengine.java:193) com.sun.proxy.$proxy43.getfileinfo(unknown source) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:164) org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:83) com.sun.proxy.$proxy43.getfileinfo(unknown source) org.apache.hadoop.hdfs.protocolpb.clientnamenodeprotocoltranslatorpb.getfileinfo(clientnamenodeprotocoltranslatorpb.java:629) org.apache.hadoop.hdfs.dfsclient.getfileinfo(dfsclient.java:1545) org.apache.hadoop.hdfs.distributedfilesystem.getfilestatus(distributedfilesystem.java:819) org.apache.hadoop.fs.filesystem.globstatusinternal(filesystem.java:1646) org.apache.hadoop.fs.filesystem.globstatus(filesystem.java:1592) org.apache.hadoop.fs.filesystem.globstatus(filesystem.java:1567) org.apache.hadoop.fs.shell.pathdata.expandasglob(pathdata.java:271) org.apache.hadoop.fs.shell.command.expandargument(command.java:224) org.apache.hadoop.fs.shell.command.expandarguments(command.java:207) org.apache.hadoop.fs.shell.command.processrawarguments(command.java:190) org.apache.hadoop.fs.shell.command.run(command.java:154) org.apache.hadoop.fs.fsshell.run(fsshell.java:254) org.springframework.xd.shell.hadoop.fsshellcommands.run(fsshellcommands.java:412) org.springframework.xd.shell.hadoop.fsshellcommands.runcommand(fsshellcommands.java:407) org.springframework.xd.shell.hadoop.fsshellcommands.ls(fsshellcommands.java:110) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.util.reflectionutils.invokemethod(reflectionutils.java:196) org.springframework.shell.core.simpleexecutionstrategy.invoke(simpleexecutionstrategy.java:64) org.springframework.shell.core.simpleexecutionstrategy.execute(simpleexecutionstrategy.java:48) org.springframework.shell.core.abstractshell.executecommand(abstractshell.java:127) org.springframework.shell.core.jlineshell.promptloop(jlineshell.java:530) org.springframework.shell.core.jlineshell.run(jlineshell.java:178) java.lang.thread.run(thread.java:744) {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
351,add eclipse target to ec2 build.gradle. so that the code format matches that of the xd project.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
352,avoid false negative test failures related to hsqldb when executing tests and failures occur (should be easy to simulate with a forced failure) several other side-effect failures occur with the following error: {code} caused by: java.lang.illegalargumentexception: hsqldb could not be started. maybe another instance is already running on 0.0.0.0:13583 ? {code} it seems that the failing tests are not properly cleaning up so the hsqldb instance they started is still running thereby causing the other failures. in the case i last witnessed this on a dev branch i had a valid failure in localcontrolredisdatainitializationtests (the environmentmatchestransport method specifically) and typeconvertingstreamtests. so perhaps a good way to start exploring this issue is to simulate a failure in one or both of those classes. the false negatives i'm seeing are in the following: {code} localsinglenodeinitializationtests.environmentmatchestransport rabbitsinglenodeinitializationtests.environmentmatchestransport redissinglenodeinitializationtests.environmentmatchestransport filesourcemoduletests.classmethod localsinglenodestreamdeploymentintegrationtests.classmethod rabbitsinglenodestreamdeploymentintegrationtests.classmethod rabbitsinglenodestreamdeploymentintegrationtests.classmethod {code} they all seem to be tests that start the singlenodeapplication.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
353,job execution restart fails with npe create a job launch it but make it fail (eg filejdbc with missing file) job execution list => it's there as failed. good job execution restart <theid> ==> fails with npe: {noformat} 16:59:42160 error http-nio-9393-exec-7 rest.restcontrolleradvice:191 - caught exception while handling a request java.lang.nullpointerexception org.springframework.batch.core.job.abstractjob.execute(abstractjob.java:351) org.springframework.batch.core.launch.support.simplejoblauncher$1.run(simplejoblauncher.java:135) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.batch.core.launch.support.simplejoblauncher.run(simplejoblauncher.java:128) sun.reflect.generatedmethodaccessor157.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.batch.core.configuration.annotation.simplebatchconfiguration$passthruadvice.invoke(simplebatchconfiguration.java:117) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy39.run(unknown source) org.springframework.batch.admin.service.simplejobservice.restart(simplejobservice.java:179) org.springframework.xd.dirt.plugins.job.distributedjobservice.restart(distributedjobservice.java:77) org.springframework.xd.dirt.rest.batchjobexecutionscontroller.restartjobexecution(batchjobexecutionscontroller.java:146) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springfram {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
354,out of the box batch jobs should add xdjobexecutionlistener and xdstepexecutionlistener to show best practice our batch jobs should include these listeners so that notifications can be sent. in particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move/delete the file,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
355,support for @configuration based module definitions,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
356,add email source,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
357,as a user i'd like to have the option of _aws_ sink so that i can write data into s3 directly. *reference:* [spring integration aws extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws],4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
358,zip created by publish 1.1 only contains the shell. xd gemfire directories in the zip file are missing.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
359,introduce wire.js into the xd admin ui we should consider moving to wire.js to encourage dependency injection in the ui javascript code. see here: https://github.com/cujojs/wire/blob/master/docs/get.md,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
360,user wants ability to test multiple processors in a chain,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
361,xd ec2 needs to bootstrap zookeeper at installation time. startup zookeeper on ec2 cluster instances.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
362,as a developer i want to be able to connect to multiple external systems for the same binding type so that i can read data from a system and write it to another.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
363,"move --deletefiles out of resourcesintojdbcjobmoduleoptionsmetadata currently the filedeletion listeners are added to filepollhdfs and filejdbc ootb job modules so that the files are deleted after successful completion of jobs that write the file into hdfs/jdbc. we have ""--deletefiles"" option in resourcesintojdbcjobmoduleoptionsmetadata (from https://github.com/spring-projects/spring-xd/pull/562) which makes it available for hdfsjdbc job module as well. but it is not supported yet as it involves deletion of hdfs files. we need the file deletion listeners for the hdfsjdbc and hdfsmongodb job modules so that if opted to delete files it can be supported.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
364,as a spring xd user i'd like to create streaming pipelines so i can take advantage of latest specs from both xd and spark/spark streaming.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
365,enhance jdbc sink test to include more options to enrich acceptance test i'd like to add coverage to jdbc sink by including *-- driverclass* and *-- url* options.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
366,add support for specifying an undeploy-condition for stream definitions in some scenarios like when performing exploratory data-analysis on streaming data one often create a stream keep it running for some time (or until some condition is met) and then stop the stream and start to investigate the collected data. it would be cool to be able to specify some undeploy condition like e.g. a timeout after x minutes no. of events collected a specific counter past a given threshold file-size greater then x etc.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
367,using custom classes for module properties leads to classnotfoundexception attached is module properties file. both custom java classes referenced in the properties are available in the jar file under _spring_xd_home/xd/module/<the-module>/lib_ directory. following exception is thrown: {code}6:26:03064 1.0.2.release error http-nio-9393-exec-4 rest.restcontrolleradvice - caught exception while handling a request java.lang.illegalstateexception: can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.bindingstrategy org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.makesimplemoduleoptions(defaultmoduleoptionsmetadataresolver.java:137) org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.resolvenormalmetadata(defaultmoduleoptionsmetadataresolver.java:193) org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.resolve(defaultmoduleoptionsmetadataresolver.java:154) org.springframework.xd.module.options.delegatingmoduleoptionsmetadataresolver.resolve(delegatingmoduleoptionsmetadataresolver.java:44) org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.resolve(environmentawaremoduleoptionsmetadataresolver.java:127) org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:173) org.springframework.xd.dirt.stream.abstractdeployer.save(abstractdeployer.java:95) org.springframework.xd.dirt.rest.xdcontroller.save(xdcontroller.java:223) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.web.method.support.invocablehandlermethod.invoke(invocablehandlermethod.java:215) org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:132) org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:749) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:689) org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:83) org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:938) org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:870) org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:961) org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:863) javax.servlet.http.httpservlet.service(httpservlet.java:646) org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:837) javax.servlet.http.httpservlet.service(httpservlet.java:727) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:303) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.boot.actuate.trace.webrequesttracefilter.dofilterinternal(webrequesttracefilter.java:110) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.boot.actuate.autoconfigure.endpointwebmvcautoconfiguration$applicationcontextheaderfilter.dofilterinternal(endpointwebmvcautoconfiguration.java:280) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.security.web.filterchainproxy.dofilterinternal(filterchainproxy.java:186) org.springframework.security.web.filterchainproxy.dofilter(filterchainproxy.java:160) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:77) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:88) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.springframework.boot.actuate.autoconfigure.metricfilterautoconfiguration$metricsfilter.dofilterinternal(metricfilterautoconfiguration.java:89) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:241) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:208) org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:220) org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:122) org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:501) org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:171) org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:103) org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:116) org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:408) org.apache.coyote.http11.abstracthttp11processor.process(abstracthttp11processor.java:1070) org.apache.coyote.abstractprotocol$abstractconnectionhandler.process(abstractprotocol.java:611) org.apache.tomcat.util.net.nioendpoint$socketprocessor.dorun(nioendpoint.java:1736) org.apache.tomcat.util.net.nioendpoint$socketprocessor.run(nioendpoint.java:1695) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) org.apache.tomcat.util.threads.taskthread$wrappingrunnable.run(taskthread.java:61) java.lang.thread.run(thread.java:745){code} please see attached patch file this seems to be enough to resolve the problem.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
368,prevent deploying modules of same type on a given stream/job when new leadership election happens when the leadership election happens the new deployment supervisor's container listener tries to deploy unallocated modules (via arrivingcontainermoduleredeployer) into existing container that has the modules of the same type on a given stream/job already deployed. currently on a given stream/job we don't allow more than one deployment of the same module type and there by avoiding any conflicting properties for the given module type.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
369,add infrastructure support for admin ui as an user i'd like to have the ability to setup infrastructure to develop/enhance ui functionality. this is including but not limited to: - ui designs (mockup's) - unit testing - ci - js 'minification',0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
370,add command for listing streams,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
371,fix text-table rendering,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
372,upgrade sdr to get rid of temporary no-op serializer spring data redis 1.1 m2 added the ability to use redistemplate with binary data. we should switch to that instead of the no-op serializer we were forced to implement previously.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
373,wordcount failed to run in cloudera vm 5.7 i download the spring xd example projects and run through the steps acccording the readme file for the project. i tried to change the hadoop-site.xml server.yml and wordcount.xml files but i failed get the . i am blocked by this issue. thank you very much in advance for help. best regards.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
374,ui: analytics tab - ensure that graphs are responsive even for relatively large resolutions e.g. 1024px the graph breaks the browser window. we should ensure that the graphs work on smaller screens.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
375,as a user i'd like to have google's [protocol buffer|https://code.google.com/p/protobuf/] codec option so that i can serialize/deserialize objects based on its native specifications.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
376,xd container not closing file descriptors currently when running the {{p-spring-xd}} stream tests we run into an issue where the xd container starts throwing errors because it cannot open the module configuration file. this happens reliably after 3-4 days of running and always fails on the same {{modules.yml}} configuration file. this is not to say that the file leak is guaranteed to be related to the {{modules.yml}} but it's certainly a place to start looking. a restart of the container (only) causes the error to go away for 3-4 days at which point it reappears indicating that the problem is definitely in the xd container and not in the operating system's configuration. failure stack trace: {noformat} [xd admin] 1.2.0.rc1 info deploymentsupervisor-0 zk.zkstreamdeploymenthandler - deployment status for stream 'end-to-end-http-9630': deploymentstatus{state=failederror(s)=java.lang.illegalstateexception: java.io.filenotfoundexception: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (too many open files) at org.springframework.beans.factory.config.yamlprocessor.handleprocesserror(yamlprocessor.java:186) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:178) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:138) at org.springframework.boot.env.yamlpropertysourceloader$processor.process(yamlpropertysourceloader.java:100) at org.springframework.boot.env.yamlpropertysourceloader.load(yamlpropertysourceloader.java:57) at org.springframework.boot.env.propertysourcesloader.load(propertysourcesloader.java:126) at org.springframework.boot.context.config.configfileapplicationlistener$loader.loadintogroup(configfileapplicationlistener.java:381) at org.springframework.boot.context.config.configfileapplicationlistener$loader.load(configfileapplicationlistener.java:369) at org.springframework.boot.context.config.configfileapplicationlistener$loader.load(configfileapplicationlistener.java:339) at org.springframework.boot.context.config.configfileapplicationlistener.addpropertysources(configfileapplicationlistener.java:174) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver$1.apply(environmentawaremoduleoptionsmetadataresolver.java:229) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.loadpropertysources(environmentawaremoduleoptionsmetadataresolver.java:219) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.lookupenvironment(environmentawaremoduleoptionsmetadataresolver.java:181) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.access$000(environmentawaremoduleoptionsmetadataresolver.java:61) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver$moduleoptionsmetadatawithdefaults.<init>(environmentawaremoduleoptionsmetadataresolver.java:144) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.resolve(environmentawaremoduleoptionsmetadataresolver.java:132) at org.springframework.xd.dirt.stream.xdstreamparser.buildmoduledescriptors(xdstreamparser.java:206) at org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:122) at org.springframework.xd.dirt.stream.streamfactory.createstream(streamfactory.java:84) at org.springframework.xd.dirt.server.admin.deployment.zk.deploymentloader.loadstream(deploymentloader.java:101) at org.springframework.xd.dirt.server.container.deploymentlistener.deploystreammodule(deploymentlistener.java:331) at org.springframework.xd.dirt.server.container.deploymentlistener.onchildadded(deploymentlistener.java:181) at org.springframework.xd.dirt.server.container.deploymentlistener.childevent(deploymentlistener.java:149) at org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) at org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) at org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) at com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) at org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) at org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) at org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) at org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) at java.lang.thread.run(thread.java:745) caused by: java.io.filenotfoundexception: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (too many open files) at java.io.fileinputstream.open0(native method) at java.io.fileinputstream.open(fileinputstream.java:195) at java.io.fileinputstream.<init>(fileinputstream.java:138) at java.io.fileinputstream.<init>(fileinputstream.java:93) at sun.net.www.protocol.file.fileurlconnection.connect(fileurlconnection.java:90) at sun.net.www.protocol.file.fileurlconnection.getinputstream(fileurlconnection.java:188) at org.springframework.core.io.urlresource.getinputstream(urlresource.java:168) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:158) ... 36 more java.lang.illegalstateexception: java.io.filenotfoundexception: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (too many open files) at org.springframework.beans.factory.config.yamlprocessor.handleprocesserror(yamlprocessor.java:186) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:178) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:138) at org.springframework.boot.env.yamlpropertysourceloader$processor.process(yamlpropertysourceloader.java:100) at org.springframework.boot.env.yamlpropertysourceloader.load(yamlpropertysourceloader.java:57) at org.springframework.boot.env.propertysourcesloader.load(propertysourcesloader.java:126) at org.springframework.boot.context.config.configfileapplicationlistener$loader.loadintogroup(configfileapplicationlistener.java:381) at org.springframework.boot.context.config.configfileapplicationlistener$loader.load(configfileapplicationlistener.java:369) at org.springframework.boot.context.config.configfileapplicationlistener$loader.load(configfileapplicationlistener.java:339) at org.springframework.boot.context.config.configfileapplicationlistener.addpropertysources(configfileapplicationlistener.java:174) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver$1.apply(environmentawaremoduleoptionsmetadataresolver.java:229) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.loadpropertysources(environmentawaremoduleoptionsmetadataresolver.java:219) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.lookupenvironment(environmentawaremoduleoptionsmetadataresolver.java:181) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.access$000(environmentawaremoduleoptionsmetadataresolver.java:61) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver$moduleoptionsmetadatawithdefaults.<init>(environmentawaremoduleoptionsmetadataresolver.java:144) at org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.resolve(environmentawaremoduleoptionsmetadataresolver.java:132) at org.springframework.xd.dirt.stream.xdstreamparser.buildmoduledescriptors(xdstreamparser.java:206) at org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:122) at org.springframework.xd.dirt.stream.streamfactory.createstream(streamfactory.java:84) at org.springframework.xd.dirt.server.admin.deployment.zk.deploymentloader.loadstream(deploymentloader.java:101) at org.springframework.xd.dirt.server.container.deploymentlistener.deploystreammodule(deploymentlistener.java:331) at org.springframework.xd.dirt.server.container.deploymentlistener.onchildadded(deploymentlistener.java:181) at org.springframework.xd.dirt.server.container.deploymentlistener.childevent(deploymentlistener.java:149) at org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) at org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) at org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) at com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) at org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) at org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) at org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) at org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.executors$runnableadapter.call(executors.java:511) at java.util.concurrent.futuretask.run(futuretask.java:266) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) at java.lang.thread.run(thread.java:745) caused by: java.io.filenotfoundexception: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (too many open files) at java.io.fileinputstream.open0(native method) at java.io.fileinputstream.open(fileinputstream.java:195) at java.io.fileinputstream.<init>(fileinputstream.java:138) at java.io.fileinputstream.<init>(fileinputstream.java:93) at sun.net.www.protocol.file.fileurlconnection.connect(fileurlconnection.java:90) at sun.net.www.protocol.file.fileurlconnection.getinputstream(fileurlconnection.java:188) at org.springframework.core.io.urlresource.getinputstream(urlresource.java:168) at org.springframework.beans.factory.config.yamlprocessor.process(yamlprocessor.java:158) ... 36 more } {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
377,packaging of guava 17 results in failure to deploy mapreduce job to hadoop 2.4 based distros trying to deploy the hashtagcount batch sample [1] to hadoop 2.4.1 or hortonworks hdp 2.1 fails with an illegalaccesserror exception. looks like a guava versioning issue - swapping out guava-17.0.jar for guava-11.0.2.jar in the xd/lib directory solves it. mark p suggested we try 16.0.1 which is what curator uses and that seems to work as well. looking into changing the build to not force 17.0 which is the io platform version. http://upstream-tracker.org/java/compat_reports/guava/16.0.1_to_17.0/src_compat_report.html i get the following exception: {code} 16:42:22214 info deployer server.jobdeploymentlistener - deployment status for job 'hashtagcountjob': deploymentstatus{state=deployed} 16:42:27315 warn task-scheduler-2 mapreduce.jobsubmitter - no job jar file set. user classes may not be found. see job or job#setjar(string). 16:42:27325 error task-scheduler-2 step.abstractstep - encountered an error executing step hashtagcount in job hashtagcountjob java.lang.illegalaccesserror: tried to access method com.google.common.base.stopwatch.<init>()v from class org.apache.hadoop.mapreduce.lib.input.fileinputformat org.apache.hadoop.mapreduce.lib.input.fileinputformat.getsplits(fileinputformat.java:369) org.apache.hadoop.mapreduce.jobsubmitter.writenewsplits(jobsubmitter.java:493) org.apache.hadoop.mapreduce.jobsubmitter.writesplits(jobsubmitter.java:510) org.apache.hadoop.mapreduce.jobsubmitter.submitjobinternal(jobsubmitter.java:394) org.apache.hadoop.mapreduce.job$10.run(job.java:1285) org.apache.hadoop.mapreduce.job$10.run(job.java:1282) java.security.accesscontroller.doprivileged(native method) javax.security.auth.subject.doas(subject.java:415) org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1556) org.apache.hadoop.mapreduce.job.submit(job.java:1282) org.apache.hadoop.mapreduce.job.waitforcompletion(job.java:1303) org.apache.hadoop.mapreduce.job$$fastclassbyspringcglib$$a048cbfe.invoke(<generated>) org.springframework.cglib.proxy.methodproxy.invoke(methodproxy.java:204) org.springframework.aop.framework.cglibaopproxy$cglibmethodinvocation.invokejoinpoint(cglibaopproxy.java:708) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.aop.support.delegatingintroductioninterceptor.doproceed(delegatingintroductioninterceptor.java:133) org.springframework.aop.support.delegatingintroductioninterceptor.invoke(delegatingintroductioninterceptor.java:121) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.cglibaopproxy$dynamicadvisedinterceptor.intercept(cglibaopproxy.java:644) org.apache.hadoop.mapreduce.job$$enhancerbyspringcglib$$875ec891.waitforcompletion(<generated>) org.springframework.data.hadoop.mapreduce.jobexecutor$2.run(jobexecutor.java:199) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.data.hadoop.mapreduce.jobexecutor.startjobs(jobexecutor.java:170) org.springframework.data.hadoop.batch.mapreduce.jobtasklet.execute(jobtasklet.java:90) org.springframework.batch.core.step.tasklet.taskletstep$chunktransactioncallback.dointransaction(taskletstep.java:406) org.springframework.batch.core.step.tasklet.taskletstep$chunktransactioncallback.dointransaction(taskletstep.java:330) org.springframework.transaction.support.transactiontemplate.execute(transactiontemplate.java:133) org.springframework.batch.core.step.tasklet.taskletstep$2.doinchunkcontext(taskletstep.java:271) org.springframework.batch.core.scope.context.stepcontextrepeatcallback.doiniteration(stepcontextrepeatcallback.java:77) org.springframework.batch.repeat.support.repeattemplate.getnextresult(repeattemplate.java:368) org.springframework.batch.repeat.support.repeattemplate.executeinternal(repeattemplate.java:215) org.springframework.batch.repeat.support.repeattemplate.iterate(repeattemplate.java:144) org.springframework.batch.core.step.tasklet.taskletstep.doexecute(taskletstep.java:257) org.springframework.batch.core.step.abstractstep.execute(abstractstep.java:198) org.springframework.batch.core.job.simplestephandler.handlestep(simplestephandler.java:148) org.springframework.batch.core.job.flow.jobflowexecutor.executestep(jobflowexecutor.java:64) org.springframework.batch.core.job.flow.support.state.stepstate.handle(stepstate.java:67) org.springframework.batch.core.job.flow.support.simpleflow.resume(simpleflow.java:162) org.springframework.batch.core.job.flow.support.simpleflow.start(simpleflow.java:141) org.springframework.batch.core.job.flow.flowjob.doexecute(flowjob.java:134) org.springframework.batch.core.job.abstractjob.execute(abstractjob.java:304) org.springframework.batch.core.launch.support.simplejoblauncher$1.run(simplejoblauncher.java:135) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.batch.core.launch.support.simplejoblauncher.run(simplejoblauncher.java:128) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.batch.core.configuration.annotation.simplebatchconfiguration$passthruadvice.invoke(simplebatchconfiguration.java:127) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy44.run(unknown source) org.springframework.batch.integration.launch.joblaunchingmessagehandler.launch(joblaunchingmessagehandler.java:50) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.expression.spel.support.reflectivemethodexecutor.execute(reflectivemethodexecutor.java:63) org.springframework.expression.spel.ast.methodreference.getvalueinternal(methodreference.java:122) org.springframework.expression.spel.ast.methodreference.access$000(methodreference.java:44) org.springframework.expression.spel.ast.methodreference$methodvalueref.getvalue(methodreference.java:258) org.springframework.expression.spel.ast.compoundexpression.getvalueinternal(compoundexpression.java:84) org.springframework.expression.spel.ast.spelnodeimpl.gettypedvalue(spelnodeimpl.java:114) org.springframework.expression.spel.standard.spelexpression.getvalue(spelexpression.java:111) org.springframework.integration.util.abstractexpressionevaluator.evaluateexpression(abstractexpressionevaluator.java:159) org.springframework.integration.util.messagingmethodinvokerhelper.processinternal(messagingmethodinvokerhelper.java:268) org.springframework.integration.util.messagingmethodinvokerhelper.process(messagingmethodinvokerhelper.java:142) org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:75) org.springframework.integration.handler.serviceactivatinghandler.handlerequestmessage(serviceactivatinghandler.java:71) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:170) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) sun.reflect.generatedmethodaccessor98.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy125.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor97.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy123.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) sun.reflect.generatedmethodaccessor98.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy125.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor97.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy123.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.endpoint.pollingconsumer.handlemessage(pollingconsumer.java:74) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:205) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:55) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:149) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:146) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:284) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:278) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:54) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$201(scheduledthreadpoolexecutor.java:178) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:292) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) {code} [1] https://github.com/spring-projects/spring-xd-samples,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
378,investigate and create moduleid class for modulemetadata the id field in modulemetadata is using module id that is derived from module parameters which varies between stream and job modules. we can come up with moduleid class that applies for both stream/job modules and can be used in modulemetadata.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
379,the hdfs store library should support writing to sequence files support for writing sequence files without compression need a means to specify the key/value to be used,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
380,add filepollhdfs acceptance tests,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
381,need to create a persistent-job-registry in order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the mapjobregistry. ==== testability. ==== the admin will need to be see all jobs created by its containers.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
382,update rpm and brew recipes,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
383,improve resilience of route creation/removal the cf implementation requires that a route be created for each new app. this works fine on the happy path but is brittle. for example it will fail if the route required already exists.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
384,"ui: user should be able to view job detail from a specific job execution at job executions page on clicking ""details"" link on a job execution row user should see the job details. job detail page will show all the information about the job where as the table listing of jobs on the execution tab may have omitted some columns or aggregated values to convey information more easily.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
385,as a user i want to know my configuration options are for enabling ssl/https and basic authentication for administration endpoints so that i can secure my application.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
386,"add propertyaccessor for tuple fields in spel example using name: {code} filter --expression=""payload.myfield.startswith('foo')"" {code} example using index: {code} filter --expression=""payload.2.startswith('foo')"" {code} this should support nested keys as well: {code} filter --expression=""payload.myfield.subfield.startswith('foo')"" {code}",0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
387,as a user i want to configure docker xd containers using service discovery so that i can have tools to manage how processes and services in a cluster can find and talk to one another.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
388,modify startup script of xd shell to allow specifying hadoop distro to use,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
389,as a qa i'd like to benchmark _sqoop_ vs. _jdbchdfs_ batch job so that i can compare and contrast performance stats.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
390,when creating a job with the fixed-delay parameter in the shell command fails need to change the name from fixed-delay to fixed_delay or fixeddelay. system rejects the '-'.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
391,as a developer i'd like to review the current sonar violations so that i can fix the relevant and update the irrelevant ones as invalid.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
392,add support for time/sequence-size windowed offset updates,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
393,triggersourceoptionsmetadata - change dateformat to be iso 8601 compliant (with timezone) to bring in line with the rest of default date-formats change the date format to yyyy-mm-dd hh:mm:ss in triggersourceoptionsmetadata,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
394,singlenode fails to start from external module singlenode fails to start using spring-xd-dirt-1.0.0.release.jar see https://github.com/dturanski/xd-test the root cause of the error: java.lang.nosuchmethoderror: javax.servlet.servletcontext.addservlet(ljava/lang/stringljavax/servlet/servlet)ljavax/servlet/servletregistration$dynamic indicating an incompatible servlet version is being pulled in by default.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
395,delete post module and cf profile this would get rid of the cf specific post module keeping the general abstraction of 'http' source across cf and non-cf environments.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
396,"fix redis fieldvaluecounter repo save() method that method is actually currently never called but : - the case where a mapping already exists is not covered (outstanding todo comment) - the semantics of the method should just be to ""save and override""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
397,as a developer i'd like to add {{undeployed}} status for lattice spi so i can represent the correct status instead of the current {{unknown}} state.,3,4,0.0027609235048294068,1.6666666666666672,0,1,0,0,0
398,stream destroy fails to remove if the underlying modules have been removed. in short if you attempt to destroy a stream that has had its modules removed the destroy will fail. 1) so if i create my own processor:x and use the processor in a stream. 2) i then shutdown the admin and container. 3) delete the processor:x from the $xd_home/modules directory 4) restart the admin and container. 5) if you do a stream list the stream that used the processor.x is still present. 6) but you can not delete the stream because of the exception below. [to reproduce using payload conversion example] 1) follow the instructions to install and use the mytupleprocessor module in a stream. 2) now shutdown the admin and container 3) rm -rf $xd_home/modules/processor/mytupleprocessor.xml 4) rm -rf $xd_home/lib/payload-conversion.jar 5) startup your admin and container 6) stream all destroy. then type 'y'<return> 6a) the shell will report ommand failed org.springframework.xd.rest.client.impl.springxdexception: no content to map due to end-of-input at [source: java.io.stringreader@5b8bd3d0 line: 1 column: 1] 6b) the admin server will report 11:59:43543 error http-nio-9393-exec-1 rest.restcontrolleradvice:199 - caught exception while handling a request org.springframework.xd.dirt.zookeeper.zookeeperaccessexception: no content to map due to end-of-input at [source: java.io.stringreader@648849d5 line: 1 column: 1] org.springframework.xd.dirt.zookeeper.zookeeperutils.wrapthrowable(zookeeperutils.java:47) org.springframework.xd.dirt.zookeeper.zookeeperutils.wrapthrowable(zookeeperutils.java:31) org.springframework.xd.dirt.zookeeper.zookeeperutils.wrapandthrowignoring(zookeeperutils.java:65) org.springframework.xd.dirt.module.store.zookeepermoduledefinitionrepository.findbynameandtype(zookeepermoduledefinitionrepository.java:95) org.springframework.xd.dirt.stream.xdstreamparser.resolvemoduletype(xdstreamparser.java:300) org.springframework.xd.dirt.stream.xdstreamparser.determinetype(xdstreamparser.java:196) org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:152) org.springframework.xd.dirt.stream.streamdeployer.beforedelete(streamdeployer.java:116) org.springframework.xd.dirt.stream.streamdeployer.beforedelete(streamdeployer.java:43) org.springframework.xd.dirt.stream.abstractdeployer.delete(abstractdeployer.java:246) org.springframework.xd.dirt.stream.abstractdeployer.deleteall(abstractdeployer.java:169) org.springframework.xd.dirt.stream.abstractinstancepersistingdeployer.deleteall(abstractinstancepersistingdeployer.java:100) org.springframework.xd.dirt.rest.xdcontroller.deleteall(xdcontroller.java:110) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.web.method.support.invocablehandlermethod.invoke(invocablehandlermethod.java:215) org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:132) org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:749) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:689) org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:83) org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:938) org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:870) org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:961) org.springframework.web.servlet.frameworkservlet.dodelete(frameworkservlet.java:885) javax.servlet.http.httpservlet.service(httpservlet.java:653) org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:837) javax.servlet.http.httpservlet.service(httpservlet.java:728) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:305) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.trace.webrequesttracefilter.dofilter(webrequesttracefilter.java:115) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.autoconfigure.endpointwebmvcautoconfiguration$applicationcontextfilterconfiguration$1.dofilterinternal(endpointwebmvcautoconfiguration.java:137) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:77) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:88) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.autoconfigure.metricfilterautoconfiguration$metricsfilter.dofilterinternal(metricfilterautoconfiguration.java:85) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:222) org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:123) org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:472) org.apache.catalina.valves.remoteipvalve.invoke(remoteipvalve.java:680) org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:171) org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:99) org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:118) org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:407) org.apache.coyote.http11.abstracthttp11processor.process(abstracthttp11processor.java:1004) org.apache.coyote.abstractprotocol$abstractconnectionhandler.process(abstractprotocol.java:589) org.apache.tomcat.util.net.nioendpoint$socketprocessor.run(nioendpoint.java:1680) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:724) caused by: com.fasterxml.jackson.databind.jsonmappingexception: no content to map due to end-of-input at [source: java.io.stringreader@648849d5 line: 1 column: 1] com.fasterxml.jackson.databind.jsonmappingexception.from(jsonmappingexception.java:164) com.fasterxml.jackson.databind.objectmapper._initforreading(objectmapper.java:3036) com.fasterxml.jackson.databind.objectmapper._readmapandclose(objectmapper.java:2978) com.fasterxml.jackson.databind.objectmapper.readvalue(objectmapper.java:2098) org.springframework.xd.dirt.module.store.zookeepermoduledefinitionrepository.findbynameandtype(zookeepermoduledefinitionrepository.java:82) ... 61 more,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
399,create directory structures and move existing ui code into spring xd repository create a directory structure that best benefits ui development. the copying of the ui files and other gradle build tasks so that the ui can be run inside the embedded servlet container of xd will be a seperate story,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
400,adminserver fails on hdp 2.3 submitting xd on yarn for hdp 2.3 fails due to some solr issue in boot - https://github.com/spring-projects/spring-boot/issues/2795 the xd-admin sysout is: {code} started : adminserverapplication documentation: https://github.com/spring-projects/spring-xd/wiki 02:51:36624 error main boot.springapplication - application startup failed java.lang.illegalstateexception: error processing condition on org.springframework.boot.autoconfigure.solr.solrautoconfiguration.solrserver org.springframework.boot.autoconfigure.condition.springbootcondition.matches(springbootcondition.java:58) org.springframework.context.annotation.conditionevaluator.shouldskip(conditionevaluator.java:102) org.springframework.context.annotation.configurationclassbeandefinitionreader.loadbeandefinitionsforbeanmethod(configurationclassbeandefinitionreader.java:178) org.springframework.context.annotation.configurationclassbeandefinitionreader.loadbeandefinitionsforconfigurationclass(configurationclassbeandefinitionreader.java:140) org.springframework.context.annotation.configurationclassbeandefinitionreader.loadbeandefinitions(configurationclassbeandefinitionreader.java:116) org.springframework.context.annotation.configurationclasspostprocessor.processconfigbeandefinitions(configurationclasspostprocessor.java:333) org.springframework.context.annotation.configurationclasspostprocessor.postprocessbeandefinitionregistry(configurationclasspostprocessor.java:243) org.springframework.context.support.postprocessorregistrationdelegate.invokebeandefinitionregistrypostprocessors(postprocessorregistrationdelegate.java:273) org.springframework.context.support.postprocessorregistrationdelegate.invokebeanfactorypostprocessors(postprocessorregistrationdelegate.java:98) org.springframework.context.support.abstractapplicationcontext.invokebeanfactorypostprocessors(abstractapplicationcontext.java:673) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:519) org.springframework.boot.springapplication.refresh(springapplication.java:686) org.springframework.boot.springapplication.run(springapplication.java:320) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:139) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:129) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:129) org.springframework.xd.dirt.server.admin.adminserverapplication.run(adminserverapplication.java:95) org.springframework.xd.dirt.server.admin.adminserverapplication.main(adminserverapplication.java:79) caused by: java.lang.illegalargumentexception: @conditionalonmissingbean annotations must specify at least one bean (type name or annotation) org.springframework.util.assert.istrue(assert.java:68) org.springframework.boot.autoconfigure.condition.onbeancondition$beansearchspec.<init>(onbeancondition.java:223) org.springframework.boot.autoconfigure.condition.onbeancondition.getmatchoutcome(onbeancondition.java:92) org.springframework.boot.autoconfigure.condition.springbootcondition.matches(springbootcondition.java:45) ... 17 more 02:51:36628 warn main annotation.annotationconfigapplicationcontext - exception thrown from lifecycleprocessor on context close java.lang.illegalstateexception: lifecycleprocessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.annotationconfigapplicationcontext@1cf1df22: startup date [fri oct 02 02:51:31 utc 2015] root of context hierarchy org.springframework.context.support.abstractapplicationcontext.getlifecycleprocessor(abstractapplicationcontext.java:414) org.springframework.context.support.abstractapplicationcontext.doclose(abstractapplicationcontext.java:966) org.springframework.context.support.abstractapplicationcontext.close(abstractapplicationcontext.java:925) org.springframework.boot.springapplication.run(springapplication.java:342) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:139) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:129) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:129) org.springframework.xd.dirt.server.admin.adminserverapplication.run(adminserverapplication.java:95) org.springframework.xd.dirt.server.admin.adminserverapplication.main(adminserverapplication.java:79) 02:51:36642 error main admin.adminserverapplication - error processing condition on org.springframework.boot.autoconfigure.solr.solrautoconfiguration.solrserver {code},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
401,user wants the ability to persist the final state of a job (success or failure),0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
402,add accepted type logic to module a module can declare one ore more payload types it will accept. this will inform the runtime re. automatic payload conversion. this can be done in the module xml configuration and processed by streamplugin,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
403,add acceptance tests for fieldvaluecounts and aggregatecounts to enrich acceptance tests i'd like to have test coverage to evaluate _fieldvaluecounts_ and _aggregatecounts_ for a given scenario.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
404,command to list taps,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
405,as a user i'd like to have a redis based _aggregation_ over field-value counters so that i can continuously write the aggregation in redis as we ingest more data. *scope:* * port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/old---aggregate-field-value-counters]. * identify gaps * update reference documentation,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
406,custom job with rabbitmq dependencies hi i've develop a custom job which have to publish message on rabbitmq when it's finished. to develop this module i'veto include this libraries: * com.rabbitmq:amqp-client:jar * org.springframework.amqp:spring-rabbit:jar * org.springframework.amqp:spring-amqp:jar my job use this writer: org.springframework.batch.item.amqp.amqpitemwriter i've this error log: {noformat} support.defaultamqpheadermapper - skipping header 'amqp_deliverymode' since it is not of expected type [class org.springframework.amqp.core.messagedeliverymode] it is [class org.springframework.amqp.core.messagedeliverymode] {noformat} this is typically due to a library loaded several times. what is the solution to resolve this? i'd like to use the same libraries has rabbitmq source/sink or the transport bus. does module classloader isolated from others? thanks mickaël,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
407,"remove ""singlenode"" prefix from embeddedhsql propery in singlenode profile the prefix ""singlenode"" in embeddedhsql option property defined in singlenode profile seems to be an overhead as it only exists in singlenode profile. also we don't need a system property ""xd_singlenode_embedhsql"" as config/servers.yml can be used to override the default (from application.yml)",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
408,standardize naming and unit for options across modules we should standardize on the options between modules: idletimeout - timeout rolloversize - rollover also need to standardize on unit used for timeout - should this be s or ms?,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
409,"as a user i'd like to have an optional _trace_ as inline deployment properties for _stream_ so that i can declare which _module_ in the stream needs to be traced for logging or notifications. this gives the flexibility to track the stage progress between individual modules. *example:* {code:xml} xd:> stream create foo ""http | log"" xd:> stream deploy foo --properties ""module.http.tracemodule.log.trace"" (or) xd:> stream deploy foo --properties ""module.*.trace"" {code} wildcard wiretap config: http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap",5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
410,as a developer i'd like to revisit the existing design and identify known limitations and/or the gaps.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
411,convert current rest servlet to spring mvc,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
412,ui: refactor schedule and launch screen under deployments the current screen layout is problematic in cases where there are many deployments. having a dedicated page for launching or scheduling jobs may be desirable. alternatively a light-box-based approach may be possible but i personally don't favor that.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
413,as a user i need a 'sandbox' docker image so that i can get started to experiment xd deployment with the following setup: * ubuntu os * full xd jar * java 7.x * redis * rabbitmq,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
414,as a spring xd developer i'd like to move {{mongo}} module from xd to s-c-s-m repo so i can use it as source to build streaming pipeline.,2,2,0.0026664945483207705,1.6666666666666672,0,1,0,0,0
415,as a user i'd like to have the option of editing the deployed/undeployed stream so that i don't have to destroy to just change any deployment property.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
416,"richer module options metadata module options are currently implemented using propertysourcesplaceholderconfigurer doing simple ""text"" replacements. this story proposes to introduce a richer model for module options which could take the following xml representation (keeping in mind that there would be an underlying set of classes that could also apply to e.g. @configuration approach): {code:xml} <xd:params> <xd:param name=""port"" help=""the http port to listen on"" /> </xd:params> {code} so the very first obvious benefit is providing help metadata. the second one is an easy way to list available option names without resorting to brittle propertysourcesplaceholderconfigurer hacks (we wouldn't for example detect xd.stream.name or xd_transport as a valid option) one could also specify defaults/computations this time benefiting from spel everywhere: {code:xml} <xd:params> <xd:param name=""directory"" default=""headers.directory"" /> </xd:params> {code} lastly this opens the door to better type checking / combinations / optionality support: {code:xml} <xd:params valid=""fixeddelay || cron""> <xd:param name=""fixeddelay"" type=""int"" /> <xd:param name=""cron"" type=""string"" /> </xd:params> {code} the 'valid' attribute can e.g. be evaluated by spel. some final remarks: - that construct can be compatible with our current approach by behaving as a propertysource itself (instead of creating a propertysource the streamplugin would give this new bean the java.util.properties) - plugins could benefit from a hook in that construct and advertise the fact that they expect/provide new options (e.g. --inputtype) there is a slight problem though which is that if this construct lives in the same appcontext as the module definition itself then the appcontext needs to be refreshed for the logic to kick in. one could circumvent that using profiles or we could rely on a different filename convention (e.g. <module>-params.xml)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
417,add udp support to reactor-syslog source module currently the reactor-syslog source module only supports tcp. once we add udp support we can probably remove the existing syslog-tcp and syslog-udp modules.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
418,as a developer i want to have a {{binderfactory}} abstraction so that i can support multiple binder types in the future.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
419,admin ui deploys job with wrong module count when deploying a job through admin ui with a count of 0 the module is actually deployed with count 1. more info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties],0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
420,optimize abstractsinglenodestreamdeploymentintegrationtests xd singlenode currenly initialized in @before should be @beforeclass. in this case must be re-initialized for each transport but not for each @test.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
421,add a test for ${xd.stream.name} inside the dsl definition of a stream,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
422,fix 'cluster/containers' rest endpoint with security enabled once the container's management server is secured the admin server needs to know which rest template to use to get the message rates from the deployed modules inside the containers.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
423,as a spring xd user i'd like to have [ipython notebook|http://ipython.org/notebook.html] integration so i can perform interactive data computations in real-time.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
424,rest - do not redirect after logout in the following pr we removed the *restlogoutsuccesshandler*. https://github.com/spring-projects/spring-xd/pull/1562 this is necessary though for rest calls and the admin ui. otherwise some weird ui behavior might occur due to the http redirect.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,0,0
425,permgen errors after running for a long time leaving the runtime running (e.g. as singlenode) ends up in permgen errors,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
426,as a developer i'd like to split {{admin}} artifact packaged with hadoop distro specific libraries so i could avoid adding all variations of hadoop libraries under one project.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
427,document mongodb source,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
428,module delete command should only provide completions with composed modules there is no point in providing completion with something that will fail when the user tries it. the information about a module being a composed is now available at the rest layer so should be used,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
429,as a developer i'd like to upgrade _reactor-ip_ and _syslog_ modules to reactor 2.0 so that we can sync up with the latest release.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
430,the state of a task or job should be recorded such that it can be monitored by a user the state of a task or job should be recorded such that it can be monitored by a user.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
431,add twitter oauth properties file to config dir those property keys should then be provided as defaults for the placeholders in source/twittersearch.xml,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
432,placeholder for spring xd lab,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
433,add deploy/undeploy commands for taps,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
434,"update getting started chapter to include a section on starting the shell. the chapter on how to start up the shell should ocme right after ""start the runtime"" and before ""create the stream""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
435,move ephemeral nodes from /xd/streams to /xd/deployments/streams to have a clear separation of definition vs runtime information move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. same for jobs.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
436,as a developer i'd like to upgrade to kafka 0.8.2 so i can leverage the latest features in order to test the performance characteristics.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
437,"add documentation for a 'stdin' source module in order to support ingestion from stdin the suggested approach is to do the following. xd:>stream create --definition ""tcp --decoder=lf | log"" --name foo $ cat my.log | netcat localhost 1234 so while this is really a tcp based ingestion case once can use pipe or redirect of stdin/err in order to achieve the same goal. it should appear as a source module in the docs on par with other source modules in its own section.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
438,"sxd's gemfire-server wrapper script can't handle absolute paths w/o extra slash absolute paths fail: gemfire-server /users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml (this failse see error below) you have to add an extra forward slash at the beginning (//users) to get it to work: gemfire-server //users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml (this works) ---------------- the log and error ---------------------- dbeauregard-mbp:~ dbeauregard$ gemfire-server /users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml 09:39:33772 info main gemfire.cacheserver:50 - starting cache server 09:39:33884 info main support.filesystemxmlapplicationcontext:513 - refreshing org.springframework.context.support.filesystemxmlapplicationcontext@2ba119b3: startup date [fri apr 04 09:39:33 mdt 2014] root of context hierarchy 09:39:33949 info main xml.xmlbeandefinitionreader:316 - loading xml bean definitions from file [/users/dbeauregard/users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml] exception in thread ""main"" org.springframework.beans.factory.beandefinitionstoreexception: ioexception parsing xml document from file [/users/dbeauregard/users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml] nested exception is java.io.filenotfoundexception: users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml (no such file or directory) org.springframework.beans.factory.xml.xmlbeandefinitionreader.loadbeandefinitions(xmlbeandefinitionreader.java:343) org.springframework.beans.factory.xml.xmlbeandefinitionreader.loadbeandefinitions(xmlbeandefinitionreader.java:303) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:180) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:216) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:187) org.springframework.beans.factory.support.abstractbeandefinitionreader.loadbeandefinitions(abstractbeandefinitionreader.java:251) org.springframework.context.support.abstractxmlapplicationcontext.loadbeandefinitions(abstractxmlapplicationcontext.java:127) org.springframework.context.support.abstractxmlapplicationcontext.loadbeandefinitions(abstractxmlapplicationcontext.java:93) org.springframework.context.support.abstractrefreshableapplicationcontext.refreshbeanfactory(abstractrefreshableapplicationcontext.java:129) org.springframework.context.support.abstractapplicationcontext.obtainfreshbeanfactory(abstractapplicationcontext.java:540) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:454) org.springframework.context.support.filesystemxmlapplicationcontext.<init>(filesystemxmlapplicationcontext.java:140) org.springframework.context.support.filesystemxmlapplicationcontext.<init>(filesystemxmlapplicationcontext.java:84) org.springframework.xd.gemfire.cacheserver.main(cacheserver.java:52) caused by: java.io.filenotfoundexception: users/dbeauregard/software/spring-xd/spring-xd-1.0.0.m5/gemfire/config/my-demo.xml (no such file or directory) java.io.fileinputstream.open(native method) java.io.fileinputstream.<init>(fileinputstream.java:146) org.springframework.core.io.filesystemresource.getinputstream(filesystemresource.java:114) org.springframework.beans.factory.xml.xmlbeandefinitionreader.loadbeandefinitions(xmlbeandefinitionreader.java:329) ... 13 more",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
439,empty parameter sent to job when launched from ui job gets a empty key:value pair when launching the job from the admin-ui.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
440,composing jobs via the dsl h2. narrative as a developer i want to be able to construct jobs using a dsl similar to the current syntax for streams. h2. back story streams currently provide a dsl for assembling modules into flows (streams) that consist of a source n processors and a sink. while constructing the steps of jobs themselves would be difficult in this manor creating flows of jobs (essentially a job that consists only of job steps) would be very useful. it would allow a developer to create something like the following: {code} filejdbc | mycustomjob | jdbchdfs {code} this approach also allows the existing packaging/module registry/etc to work out of the box. this gets us closer to what oozie provides out of the box without the need to create custom jobs to do the orchestration.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
441,fix random configuration in securedshelltests since the securedshelltests initialize singlenode app in a static way the random configuration needs to be setup statically as well.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
442,"temporary race condition between deployment and ""runtime modules"" command the ""runtime modules"" command can show a failure between the deployment command and the actual deployment on the container node especially if there is a network hop. this clears up once the module is fully deployed. {code} xd:>stream create --name trois3 --definition ""time | jdbc"" --deploy created and deployed new stream 'trois3' xd:>runtime modules command failed org.springframework.xd.rest.client.impl.springxdexception: java.lang.runtimeexception: org.apache.zookeeper.keeperexception$nonodeexception: keepererrorcode = nonode for /xd/deployments/modules/bc95653e-9da5-4738-beb2-f215e4003318/trois3.source.time-0/metadata xd:>runtime modules module container id options -------------------- ------------------------------------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- trois3.source.time-0 bc95653e-9da5-4738-beb2-f215e4003318 {format=yyyy-mm-dd hh:mm:ss fixeddelay=1} wintu.sink.jdbc-1 bc95653e-9da5-4738-beb2-f215e4003318 {tablename=${xd.stream.name} url=jdbc:hsqldb:hsql://carbon:9102/xdjob columns=payload driverclassname=org.hsqldb.jdbc.jdbcdriver initializedatabase=false initializerscript=init_db.sql username=sa} trois3.sink.jdbc-1 d0ad8eda-be27-46ac-86be-e43b5d9921af {tablename=${xd.stream.name} url=jdbc:hsqldb:hsql://carbon:9102/xdjob columns=payload driverclassname=org.hsqldb.jdbc.jdbcdriver initializedatabase=false initializerscript=init_db.sql username=sa} wintu.source.time-0 befa5f27-aac3-4d94-9171-77c07036ec75 {format=yyyy-mm-dd hh:mm:ss fixeddelay=1} {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
443,as a user i want to be able to provide my own rowmapper<tuple> implementation to enrich the jdbc data. my use case requires me to add timestamp field and a delete flag field to records before they get written to hdfs. to do it i have to implement a itemreaderfactory and perhaps extend namecolumnjdbcitemreader. this is to override the afterpropertyset method to change the default implementation. otherwise i have to write my own processor that can add these fields to tuples and since tuples are immutable i would have to recreate the tuples with additional fields in the processor. for large load this could be big overhead. i would love to know any other technique to implement such a use case.,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
444,hdfs itemwriter base integration of core hdfs writer functionality with spring batch.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
445,investigate travis issues we are currently facing issues with travis. determine the root cause isolate the bottleneck and resolve the issues.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
446,the hdfs sink should support writing pojos to hdfs using avro/kite sdk with support for partitioning support for partitioning on a field e.g. date.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
447,"user wants ability to cancel a running task from scd cli user should be able to execute a task cancel <task name>. which will terminate a running task. and set the state of the task to ""cancelled"".",0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
448,update jobs section to use shell,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
449,use correct fs_default_name_key constant based on hadoop version used keep getting the following warning: warn spring shell conf.configuration:817 - fs.default.name is deprecated. instead use fs.defaultfs should switch to use the runtime value of the fs_default_name_key constant based on hadoop version used.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
450,as a developer i'd like to update all the module docs to also include _shortdescription_ so that it's available for users to learn more about the module.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
451,"as a s-c-d developer i'd like to support multiple app instances: * this is simply to make controlling app instances more clever. potentially we could use deployment properties to define different yarn app instances like: {code} cloud-data:>stream deploy --name ticktock --properties ""module.*.yarn.app.name=app"" cloud-data:>stream deploy --name ticktock --properties ""module.time.yarn.app.name=app"" {code} * motivation to this is that different yarn apps can have different queues and priorities. yarn administrator can define that some app queues have higher priority to reserve resources from * using deployment properties like this allows to customize runtime parameters like how much we try to reserve mem/cpu for modules etc.",2,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
452,as a developer i'd like to create an annotation ({{@enablemodule}}) driven programming model for modules so instead of explicitly defining i/o channels as beans on the module for classes annotated with {{@enablemodule}} the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types. the {{@input}} and {{@output}} annotations will be used to indicate the input and output channels of the module.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
453,improve deploymentverifier when stream state is complete as part of xd-1591 {{deploymentverifier}} was modified to take the node structure into account. as indicated in the review below the implementation does not take module properties (such as count) into account: https://github.com/spring-projects/spring-xd/pull/939/files#r13730134 this means the implementation is incorrect. for now this won't affect us since all tests at the moment are single node. however this can be drastically improved (and simplified) once xd-1270 is completed. at that point we'll be able to simply read a single zk node to determine if/when a deployment succeeded.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
454,"classpath issues with gemfire-json-server sink the gemfire client for springxd is throwing java.lang.noclassdeffounderror for the class com/gemstone/gemfire/cache/client/internal/pingop after a stream sinking to gemfire-json-server is destroyed. issue starts after destroying a stream which makes me think we might be unloading the jar files from the classpath while still keeping a connection to the gemfire server. steps to reproduce: 1) create a region in gemfire to test e.g.: gfsh>create region --name=stocks --type=replicate member | status ------- | ------------------------------------- server1 | region ""/stocks"" created on ""server1"" 2) create a simple stream in spring xd that writes to that region in gemfire-json-server. deploy it for single node and let it run for a few seconds. e.g.: xd$ stream create streamx --definition ""trigger --fixeddelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\""msft\"")&format=json&env=store://datatables.org/alltableswithkeys''' --httpmethod=get | splitter --expression=#jsonpath(payload'$.query.results.quote') | gemfire-json-server --uselocator=true --host=localhost --port=10334 --regionname=stocks --keyexpression=payload.getfield('symbol')"" --deploy 3) destroy the stream e.g.: xd$ stream destroy streamx 3) wait a few seconds and check the xd-singlenode output.. you'll see the exception as following: [error 2015/03/13 11:04:52.437 pdt <pooltimer-client-pool-14> tid=0x15a] unexpected error in pool task <com.gemstone.gemfire.cache.client.internal.liveserverpinger$pingtask@635c9341> java.lang.noclassdeffounderror: com/gemstone/gemfire/cache/client/internal/pingop com.gemstone.gemfire.cache.client.internal.liveserverpinger$pingtask.run2(liveserverpinger.java:83) com.gemstone.gemfire.cache.client.internal.poolimpl$pooltask.run(poolimpl.java:1197) java.util.concurrent.executors$runnableadapter.call(executors.java:511) java.util.concurrent.futuretask.runandreset(futuretask.java:308) com.gemstone.gemfire.internal.scheduledthreadpoolexecutorwithkeepalive$delegatingscheduledfuture.run(scheduledthreadpoolexecutorwithkeepalive.java:252) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617) java.lang.thread.run(thread.java:745)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
455,"throughput in a stream with any processor one of the goal for a micro benchmark is to compare throughput difference between two types of streams: 1. source | sink 2. source | processor | sink for this test i used reactor-tcp source throughput-sampler as sink and created a noop processor. tests were performed on a single node container with direct binding turned on for all streams. 1. throughput for ""source|sink"" {noformat} stream create reactortcp --definition ""reactor-ip --transport=tcp --port=4000 | throughput-sampler"" stream deploy reactortcp --properties module.*.count=0 {noformat} on my system i get following numbers: throughput sampled for 5000000 items: 345423/s in 14475ms elapsed time 2. throughput for ""source|processor|sink"" code for noopprocessor is available here: https://github.com/parikhkc/xd-noop-processor {noformat} stream create reactornoop --definition ""reactor-ip --transport=tcp --port=5000 | noopprocessor | throughput-sampler"" stream deploy reactornoop --properties module.*.count=0 {noformat} on the same system the throughput reduces to less then 70k/sec. throughput sampled for 5000000 items: 67250/s in 74349ms elapsed time yourkit shows 50% of cpu time on following thread: {noformat} * ringbuffer-17 [runnable] [daemon] java.lang.reflect.method.getparameterannotations() method.java:770 org.springframework.xd.integration.reactor.net.netserverinboundchanneladapter$1.accept(object) netserverinboundchanneladapter.java:53 reactor.net.abstractnetchannel$3.accept(event) abstractnetchannel.java:131 reactor.net.abstractnetchannel$3.accept(object) abstractnetchannel.java:128 reactor.event.routing.argumentconvertingconsumerinvoker.invoke(consumer class object) argumentconvertingconsumerinvoker.java:73 reactor.event.routing.consumerfilteringeventrouter.route(object event list consumer consumer) consumerfilteringeventrouter.java:78 reactor.event.dispatch.abstractlifecycledispatcher.route(abstractlifecycledispatcher$task) abstractlifecycledispatcher.java:64 reactor.event.dispatch.abstractsinglethreaddispatcher$singlethreadtask.run() abstractsinglethreaddispatcher.java:50 reactor.event.dispatch.ringbufferdispatcher$3.onevent(ringbufferdispatcher$ringbuffertask long boolean) ringbufferdispatcher.java:115 reactor.event.dispatch.ringbufferdispatcher$3.onevent(object long boolean) ringbufferdispatcher.java:112 com.lmax.disruptor.batcheventprocessor.run() batcheventprocessor.java:128 java.lang.thread.run() thread.java:745 {noformat}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
456,"spelparseexception is thrown when using empty string ("""") inside of an expression i can only reproduce this when using single quotes around the expression: {code} stream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \""\"")' | log"" --deploy true {code} the following two alternatives work fine though: {code} # using trim on a single space stream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \"" \"".trim())' | log"" --deploy true # not using single quotes or spaces in the expression stream create test --definition ""http | transform --expression=payload.replace(\""abc\""\""\"") | log"" --deploy true {code}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
457,ability to tap spark streaming processor output we need to support adding a tap stream that connects to spark streaming processor module's output channel.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
458,support xd runtime on docker,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
459,ui: add analytics tab,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
460,"streams sending to job queue issue look at the below stream definition. this gets to ""deployed"" state even without the corresponding job. and then from there the same job or any other job can't be deployed and it goes to a hung state. here is an example of the stream definition: stream create --name jobname --definition ""file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"" --deploy",0,3,0.0052426445484161375,1.6666666666666672,0,0,0,1,0
461,as a follow-up action from module registry refactoring we would have to clean-up deprecated functions _(ex: download of module definitions)_ within our codebase. it may also be necessary to clean-up shell and admin-ui modules.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
462,create documentation for zk runtime,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
463,as a user i'd like to have the option of _kerberized_ hdfs sink so that i can leverage kerberos (open source distributed authentication system) for secured data writes into hadoop.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
464,add bridge module add a bridge module per xd-956 to support definitions like topic:foo > queue:bar . convenient for testing for xd-1066,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
465,integrate code coverage reports into the ci process not sure if this is best done via sonar our sonar build plan the nightly one or the frequent one off master... open question is if we want to fail a build do to code coverage levels.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
466,improve acceptance testing coverage the scope is to address the sub-tasks linked with this story.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
467,as a developer i'd like to troubleshoot the performance issues with rabbit as message bus implementation so i can isolate the bottleneck and fix as appropriate.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
468,"os commands no longer supports whitespace/arguments in m6 os commands i.e. ""!"" doesn't support arguments in m6 it did in m5. the following gives an error: xd:>! ls / you cannot specify option '' more than once in a single command no arguments or whitespace works: xd:>! ls command is:ls spring-shell.log xd-shell xd-shell.bat",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
469,restore previous cmdline library to populate options expected benefits are --key<space>value as well as --key=value on the command line (eg xd-1108) nice usage screen,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,1,0
470,as a user i'd like to have the option to provide file based security configurations so that i can access the endpoints in a secured manner. ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within file based security layer. reference: [securing web app|https://spring.io/guides/gs/securing-web/],4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
471,as a devops i would prefer having my module registry located in centralized github repository. this would allow all the admins and containers in the cluster pointing to the same module registry. any new module upload would be pushed to the same github repo which will make the cluster always be in sync on the module registry.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
472,as a user i'd like to refer to ootb batch jobs and the documentation so i can jump to the right job section and review details.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
473,messagechannelitemwriter h2. narrative as a user of xd i want to be able to use a job as a source. to do so we need the output of a job to be written to a message channel h2. acceptance criteria # create a new itemwriter in the spring batch project to write to a spring integration message channel.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
474,add rest resource sink would be nice to have a sink for rest resources. might be configurable with an endpoint uri. basic auth details would be a nice to have too. would perform a post to the endpoint passing the payload.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
475,jsonstringtoobjecttransformertests fail on mac if local machine name is not in /etc/hosts when running the gradlew build the jsonstringtoobjecttransformertests unit test failed. the cause is enumerated below: caused by: com.gemstone.gemfire.internal.tcp.connectionexception: while creating serversocket and stub on port 0 with address glenns-mbp/192.168.1.254 if i added 127.0.0.1 glenns-mbp to my /etc/hosts the tests succeeded.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
476,as a user i'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that i can operationalize existing data pipelines and also take advantage of latest xd features.,2,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
477,add docs (or reference) for standard shell commands (e.g. script) http://stackoverflow.com/questions/24819401/how-to-get-spring-xd-to-deploy-a-predefined-set-of-streams-and-taps-on-startup it is documented here https://github.com/spring-projects/spring-xd/wiki/shell#executing-a-script but maybe it should also be at the top of the appendix? https://github.com/spring-projects/spring-xd/wiki/shellreference,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
478,as a spring xd user i'd like to make spi implementation profile aware so i can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
479,add docs for deleting a simple stream. curl -x delete http://localhost:8080/streams/ticktock,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
480,add acceptance test to include gemfire use case to enrich acceptance test i'd like to have basic coverage to evaluate gemfire use cases. an example would be to ingest data from http source and write it to gemfire server.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
481,upgrade to spring boot 1.2.0 as to prepare for 1.1 release we would like to upgrade to spring boot 1.2.0 (rc1) (depends on spring 4.1.2) so that we can leverage the new features enhancement and bug fixes. [spring boot milestones|https://github.com/spring-projects/spring-boot/milestones],0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
482,deployed modules are not redeployed properly once the container come back online deployed component s are not deployed to the containers that failed and restarted. we have 3 containers and 3 jobs where all jobs are deployed evenly one job per container. however when two of the containers fail and come back up we end up with 3 jobs on 1 container. see attached document for detail.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
483,step execution count is zero for the job execution list result for the job execution list the step execution count for each job execution is always set to zero. for a single job execution display command the step execution count is set correctly.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
484,update batch job docs to cover triggers as a source,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
485,easily switch between a single process that performs all admin and processing tasks to one that has a dedicated admin processes and distributed processing containers.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
486,single step partition support on filejdbc module uses module's datasource the filejdbc module's single step partition support configures to use jdbc module's datasource rather than xd's batch datasource. ``` org.springframework.messaging.messagehandlingexception: org.springframework.jdbc.uncategorizedsqlexception: preparedstatementcallback uncategorized sqlexception for sql [select job_execution_id start_time end_time status exit_code exit_message create_time last_updated version job_configuration_location from batch_job_execution where job_execution_id = ?] sql state [null] error code [0] [sqlite_error] sql error or missing database (no such table: batch_job_execution) nested exception is java.sql.sqlexception: [sqlite_error] sql error or missing database (no such table: batch_job_execution) org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:78) org.springframework.integration.handler.serviceactivatinghandler.handlerequestmessage(serviceactivatinghandler.java:71) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:170) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy117.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor107.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy115.send(unknown source) org.springframework.xd.dirt.integration.bus.localmessagebus$3.handlemessage(localmessagebus.java:188) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.access$000(unicastingdispatcher.java:48) org.springframework.integration.dispatcher.unicastingdispatcher$1.run(unicastingdispatcher.java:92) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:744) caused by: org.springframework.jdbc.uncategorizedsqlexception: preparedstatementcallback uncategorized sqlexception for sql [select job_execution_id start_time end_time status exit_code exit_message create_time last_updated version job_configuration_location from batch_job_execution where job_execution_id = ?] sql state [null] error code [0] [sqlite_error] sql error or missing database (no such table: batch_job_execution) nested exception is java.sql.sqlexception: [sqlite_error] sql error or missing database (no such table: batch_job_execution) org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:84) org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) org.springframework.jdbc.support.abstractfallbacksqlexceptiontranslator.translate(abstractfallbacksqlexceptiontranslator.java:81) org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:660) org.springframework.jdbc.core.jdbctemplate.query(jdbctemplate.java:695) org.springframework.jdbc.core.jdbctemplate.query(jdbctemplate.java:727) org.springframework.jdbc.core.jdbctemplate.query(jdbctemplate.java:737) org.springframework.jdbc.core.jdbctemplate.queryforobject(jdbctemplate.java:811) org.springframework.batch.core.repository.dao.jdbcjobexecutiondao.getjobexecution(jdbcjobexecutiondao.java:267) org.springframework.batch.core.explore.support.simplejobexplorer.getstepexecution(simplejobexplorer.java:142) org.springframework.batch.integration.partition.stepexecutionrequesthandler.handle(stepexecutionrequesthandler.java:52) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.expression.spel.support.reflectivemethodexecutor.execute(reflectivemethodexecutor.java:63) org.springframework.expression.spel.ast.methodreference.getvalueinternal(methodreference.java:122) org.springframework.expression.spel.ast.methodreference.access$000(methodreference.java:44) org.springframework.expression.spel.ast.methodreference$methodvalueref.getvalue(methodreference.java:258) org.springframework.expression.spel.ast.compoundexpression.getvalueinternal(compoundexpression.java:84) org.springframework.expression.spel.ast.spelnodeimpl.gettypedvalue(spelnodeimpl.java:114) org.springframework.expression.spel.standard.spelexpression.getvalue(spelexpression.java:111) org.springframework.integration.util.abstractexpressionevaluator.evaluateexpression(abstractexpressionevaluator.java:159) org.springframework.integration.util.messagingmethodinvokerhelper.processinternal(messagingmethodinvokerhelper.java:268) org.springframework.integration.util.messagingmethodinvokerhelper.process(messagingmethodinvokerhelper.java:142) org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:75) ... 41 more caused by: java.sql.sqlexception: [sqlite_error] sql error or missing database (no such table: batch_job_execution) org.sqlite.db.newsqlexception(db.java:383) org.sqlite.db.newsqlexception(db.java:387) org.sqlite.db.throwex(db.java:374) org.sqlite.nesteddb.prepare(nesteddb.java:134) org.sqlite.db.prepare(db.java:123) org.sqlite.prepstmt.<init>(prepstmt.java:42) org.sqlite.conn.preparestatement(conn.java:404) org.sqlite.conn.preparestatement(conn.java:399) org.sqlite.conn.preparestatement(conn.java:383) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.apache.tomcat.jdbc.pool.proxyconnection.invoke(proxyconnection.java:126) org.apache.tomcat.jdbc.pool.jdbcinterceptor.invoke(jdbcinterceptor.java:109) org.apache.tomcat.jdbc.pool.disposableconnectionfacade.invoke(disposableconnectionfacade.java:80) com.sun.proxy.$proxy109.preparestatement(unknown source) org.springframework.jdbc.core.jdbctemplate$simplepreparedstatementcreator.createpreparedstatement(jdbctemplate.java:1557) org.springframework.jdbc.core.jdbctemplate.execute(jdbctemplate.java:638) ... 63 more 12:23:37941 info main-eventthread server.containerregistrar:254 - undeploying module [moduledescriptor@d192973 modulename = 'filejdbc' modulelabel = 'filejdbc' group = 'csvjdbcjob0' sourcechannelname = [null] sinkchannelname = [null] sinkchannelname = [null] index = 0 type = job parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv' 'initializedatabase' -> 'true' 'names' -> 'col1col2col3' 'deletefiles' -> 'true' 'driverclassname' -> 'org.sqlite.jdbc' 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'] children = list[[empty]]] 12:23:37941 info main-eventthread module.moduledeployer:158 - removed simplemodule [name=filejdbc type=job group=csvjdbcjob0 index=0 @73cc35b5] 12:23:37944 error task-scheduler-1 step.abstractstep:225 - encountered an error executing step step1-master in job csvjdbcjob0 org.springframework.integration.messagetimeoutexception: timeout occurred before all partitions returned org.springframework.batch.integration.partition.messagechannelpartitionhandler.handle(messagechannelpartitionhandler.java:141) org.springframework.batch.core.partition.support.partitionstep.doexecute(partitionstep.java:106) org.springframework.batch.core.step.abstractstep.execute(abstractstep.java:198) org.springframework.batch.core.job.simplestephandler.handlestep(simplestephandler.java:148) org.springframework.batch.core.job.flow.jobflowexecutor.executestep(jobflowexecutor.java:64) org.springframework.batch.core.job.flow.support.state.stepstate.handle(stepstate.java:67) org.springframework.batch.core.job.flow.support.simpleflow.resume(simpleflow.java:162) org.springframework.batch.core.job.flow.support.simpleflow.start(simpleflow.java:141) org.springframework.batch.core.job.flow.flowjob.doexecute(flowjob.java:134) org.springframework.batch.core.job.abstractjob.execute(abstractjob.java:304) org.springframework.batch.core.launch.support.simplejoblauncher$1.run(simplejoblauncher.java:135) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.batch.core.launch.support.simplejoblauncher.run(simplejoblauncher.java:128) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.batch.core.configuration.annotation.simplebatchconfiguration$passthruadvice.invoke(simplebatchconfiguration.java:127) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy44.run(unknown source) org.springframework.batch.integration.launch.joblaunchingmessagehandler.launch(joblaunchingmessagehandler.java:50) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.expression.spel.support.reflectivemethodexecutor.execute(reflectivemethodexecutor.java:63) org.springframework.expression.spel.ast.methodreference.getvalueinternal(methodreference.java:122) org.springframework.expression.spel.ast.methodreference.access$000(methodreference.java:44) org.springframework.expression.spel.ast.methodreference$methodvalueref.getvalue(methodreference.java:258) org.springframework.expression.spel.ast.compoundexpression.getvalueinternal(compoundexpression.java:84) org.springframework.expression.spel.ast.spelnodeimpl.gettypedvalue(spelnodeimpl.java:114) org.springframework.expression.spel.standard.spelexpression.getvalue(spelexpression.java:111) org.springframework.integration.util.abstractexpressionevaluator.evaluateexpression(abstractexpressionevaluator.java:159) org.springframework.integration.util.messagingmethodinvokerhelper.processinternal(messagingmethodinvokerhelper.java:268) org.springframework.integration.util.messagingmethodinvokerhelper.process(messagingmethodinvokerhelper.java:142) org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:75) org.springframework.integration.handler.serviceactivatinghandler.handlerequestmessage(serviceactivatinghandler.java:71) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:170) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy117.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.generatedmethodaccessor107.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy115.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:109) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:94) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.simplemessagehandlermetrics.handlemessage(simplemessagehandlermetrics.java:106) org.springframework.integration.monitor.simplemessagehandlermetrics.invoke(simplemessagehandlermetrics.java:86) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy117.handlemessage(unknown source) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:...,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
487,"ui should quote parameters containing a space trying to deploy the `timestampfile` job using the ui. seems the ui doesn't quote string parameters that contains a space so the job creation fails. keeping all the defaults i get the following ""resulting definition"" in the ui: timestampfile --restartable=false --directory=/tmp/xd/output/ --fileextension=txt --filename=${xd.job.name} --format=yyyy-mm-dd hh:mm:ss --dateformat=yyyy-mm-dd --makeunique=true (note: the --format parameter has a space) which causes: xd100e:(pos 128): found unexpected data after stream definition: 'hh' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileextension=txt --filename=${xd.job.name} --format=yyyy-mm-dd hh:mm:ss --dateformat=yyyy-mm-dd --makeunique=true *^",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
488,readme has conflicting cf information in https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/readme.md#running-on-cloud-foundry the section starting 'now we can configure the app' needs to be revised - the information is both out of date and even if up-to-date misleading (it includes some values as if they are universal when they are really just examples).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
489,as a user i'd like to have an option to disable db requirement so that i can setup to use dirt runtime when stream processing is the only requirement.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
490,"support exponential moving average in richgauge this could easily be supported in the existing gauge by adding a setalpha method to richgaugeservice and adding the extra parameter ""alpha"" to the gauge data (https://en.wikipedia.org/wiki/exponential_moving_average). if not set it would default to the current behaviour (simple mean) otherwise it would calculate the exponential moving average in place of the mean.",0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
491,document mqtt source and sink,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
492,normalize and refactor component packaging decomposition normalize and refactor as needed functionality currently included in - spring-integration-core (localchannelregistry) - spring-integration-module (module types upon which flow are built) - xd-module (depend module types common to dirt and spring integration) - spring-integration-flow (flow specific types namespace support etc),0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
493,as a developer i'd like to move 'serialization codec' from spring xd repo into si so i can update spring xd to inherit the features/functionalities via maven dependency.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
494,gradle launch task is broken spring xd has a gradle task available in the build called launch that starts a single node instance. this is currently broken. the command i was using for this command was: {code} $ ./gradlew clean build -x test -x javadoc launch {code},0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
495,as a developer i'd like to measure the baseline serialization characteristics in xd so i can determine the areas of performance improvements.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
496,remotefiletohadooptests fails on 1.1.x this error surfaced recently as a result of a fix to a bug in hostnotwindowsrule which disabled this test in all environments. now the test has been reactivated it is failing on the 1.1.x branch. the test runs ok on master. {noformat} encountered an error executing step step1-master in job job org.springframework.messaging.messagedeliveryexception: failed to send message to channel 'null' nested exception is java.lang.illegalstateexception: threadpooltaskexecutor not initialized org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:292) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.xd.dirt.integration.bus.local.localmessagebus$3.handlemessage(localmessagebus.java:262) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:115) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:45) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:95) org.springframework.integration.handler.abstractmessageproducinghandler.sendoutput(abstractmessageproducinghandler.java:248) org.springframework.integration.handler.abstractmessageproducinghandler.produceoutput(abstractmessageproducinghandler.java:171) org.springframework.integration.handler.abstractmessageproducinghandler.sendoutputs(abstractmessageproducinghandler.java:119) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:105) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:115) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:45) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:95) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:85) org.springframework.batch.integration.partition.messagechannelpartitionhandler.handle(messagechannelpartitionhandler.java:224) org.springframework.batch.core.partition.support.partitionstep.doexecute(partitionstep.java:106) org.springframework.batch.core.step.abstractstep.execute(abstractstep.java:198) org.springframework.batch.core.job.simplestephandler.handlestep(simplestephandler.java:148) org.springframework.batch.core.job.flow.jobflowexecutor.executestep(jobflowexecutor.java:64) org.springframework.batch.core.job.flow.support.state.stepstate.handle(stepstate.java:67) org.springframework.batch.core.job.flow.support.simpleflow.resume(simpleflow.java:165) org.springframework.batch.core.job.flow.support.simpleflow.start(simpleflow.java:144) org.springframework.batch.core.job.flow.flowjob.doexecute(flowjob.java:134) org.springframework.batch.core.job.abstractjob.execute(abstractjob.java:304) org.springframework.batch.core.launch.support.simplejoblauncher$1.run(simplejoblauncher.java:135) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.batch.core.launch.support.simplejoblauncher.run(simplejoblauncher.java:128) org.springframework.batch.integration.x.remotefiletohadooptests.testsimple(remotefiletohadooptests.java:161) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:483) org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50) org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:47) org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:26) org.springframework.test.context.junit4.statements.runbeforetestmethodcallbacks.evaluate(runbeforetestmethodcallbacks.java:73) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.springframework.test.context.junit4.statements.runaftertestmethodcallbacks.evaluate(runaftertestmethodcallbacks.java:82) org.springframework.test.context.junit4.statements.springrepeat.evaluate(springrepeat.java:73) org.junit.runners.parentrunner.runleaf(parentrunner.java:325) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:217) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:83) org.junit.runners.parentrunner$3.run(parentrunner.java:290) org.junit.runners.parentrunner$1.schedule(parentrunner.java:71) org.junit.runners.parentrunner.runchildren(parentrunner.java:288) org.junit.runners.parentrunner.access$000(parentrunner.java:58) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268) org.springframework.test.context.junit4.statements.runbeforetestclasscallbacks.evaluate(runbeforetestclasscallbacks.java:61) org.springframework.test.context.junit4.statements.runaftertestclasscallbacks.evaluate(runaftertestclasscallbacks.java:68) org.springframework.xd.test.hostnotwindowsrule$1.evaluate(hostnotwindowsrule.java:38) org.junit.rules.runrules.evaluate(runrules.java:20) org.junit.runners.parentrunner.run(parentrunner.java:363) org.springframework.test.context.junit4.springjunit4classrunner.run(springjunit4classrunner.java:163) org.junit.runner.junitcore.run(junitcore.java:137) com.intellij.junit4.junit4ideatestrunner.startrunnerwithargs(junit4ideatestrunner.java:74) com.intellij.rt.execution.junit.junitstarter.preparestreamsandstart(junitstarter.java:211) com.intellij.rt.execution.junit.junitstarter.main(junitstarter.java:67) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:483) com.intellij.rt.execution.application.appmain.main(appmain.java:134) caused by: java.lang.illegalstateexception: threadpooltaskexecutor not initialized org.springframework.util.assert.state(assert.java:385) org.springframework.scheduling.concurrent.threadpooltaskexecutor.getthreadpoolexecutor(threadpooltaskexecutor.java:221) org.springframework.scheduling.concurrent.threadpooltaskexecutor.execute(threadpooltaskexecutor.java:252) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:89) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) ... 76 more java.lang.assertionerror: expected :exitcode=completedexitdescription= actual :exitcode=failedexitdescription= <click to see difference> org.junit.assert.fail(assert.java:88) org.junit.assert.failnotequals(assert.java:834) org.junit.assert.assertequals(assert.java:118) org.junit.assert.assertequals(assert.java:144) org.springframework.batch.integration.x.remotefiletohadooptests.testsimple(remotefiletohadooptests.java:162) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50) org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:47) org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:26) org.springframework.test.context.junit4.statements.runbeforetestmethodcallbacks.evaluate(runbeforetestmethodcallbacks.java:73) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.springframework.test.context.junit4.statements.runaftertestmethodcallbacks.evaluate(runaftertestmethodcallbacks.java:82) org.springframework.test.context.junit4.statements.springrepeat.evaluate(springrepeat.java:73) org.junit.runners.parentrunner.runleaf(parentrunner.java:325) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:217) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:83) org.junit.runners.parentrunner$3.run(parentrunner.java:290) org.junit.runners.parentrunner$1.schedule(parentrunner.java:71) org.junit.runners.parentrunner.runchildren(parentrunner.java:288) org.junit.runners.parentrunner.access$000(parentrunner.java:58) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268) org.springframework.test.context.junit4.statements.runbeforetestclasscallbacks.evaluate(runbeforetestclasscallbacks.java:61) org.springframework.test.context.junit4.statements.runaftertestclasscallbacks.evaluate(runaftertestclasscallbacks.java:68) org.springframework.xd.test.hostnotwindowsrule$1.evaluate(hostnotwindowsrule.java:38) org.junit.rules.runrules.evaluate(runrules.java:20) org.junit.runners.parentrunner.run(parentrunner.java:363) org.springframework.test.context.junit4.springjunit4classrunner.run(springjunit4classrunner.java:163) org.junit.runner.junitcore.run(junitcore.java:137) com.intellij.junit4.junit4ideatestrunner.startrunnerwithargs(junit4ideatestrunner.java:74) com.intellij.rt.execution.junit.junitstarter.preparestreamsandstart(junitstarter.java:211) com.intellij.rt.execution.junit.junitstarter.main(junitstarter.java:67) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) com.intellij.rt.execution.application.appmain.main(appmain.java:134) {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
497,upgrade grunt/node plugins upgrade in 1.0.x branch what was done in this commit on master. https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
498,modules that depend on httpclient fail when running on yarn on hadoop 2.4.x and later trying to run a twitterstream on yarn on hdp 2.1 and get the following: {code} 14/08/08 12:12:50 error server.containerregistrar: exception deploying module org.springframework.beans.factory.beancreationexception: error creating bean with name 'org.springframework.integration.x.twitter.twitterstreamchanneladapter#0' defined in url [file:./spring-xd-yarn-1.0.0.release.zip/modules/source/twitterstream/config/twitterstream.xml]: cannot resolve reference to bean 'twittertemplate' while setting constructor argument nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name 'twittertemplate' defined in url [file:./spring-xd-yarn-1.0.0.release.zip/modules/source/twitterstream/config/twitterstream.xml]: instantiation of bean failed nested exception is org.springframework.beans.beaninstantiationexception: could not instantiate bean class [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:336) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvevalueifnecessary(beandefinitionvalueresolver.java:108) org.springframework.beans.factory.support.constructorresolver.resolveconstructorarguments(constructorresolver.java:646) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:140) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1114) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1017) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:475) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:302) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:228) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:298) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:193) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:703) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:760) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:482) org.springframework.boot.springapplication.refresh(springapplication.java:691) org.springframework.boot.springapplication.run(springapplication.java:320) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:142) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:203) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:98) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:88) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:78) org.springframework.xd.dirt.server.containerregistrar.deploymodule(containerregistrar.java:231) org.springframework.xd.dirt.server.containerregistrar.deploystreammodule(containerregistrar.java:577) org.springframework.xd.dirt.server.containerregistrar.onchildadded(containerregistrar.java:447) org.springframework.xd.dirt.server.containerregistrar.access$800(containerregistrar.java:95) org.springframework.xd.dirt.server.containerregistrar$deploymentlistener.childevent(containerregistrar.java:826) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:744) caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'twittertemplate' defined in url [file:./spring-xd-yarn-1.0.0.release.zip/modules/source/twitterstream/config/twitterstream.xml]: instantiation of bean failed nested exception is org.springframework.beans.beaninstantiationexception: could not instantiate bean class [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:278) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1114) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1017) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:475) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:302) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:228) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:298) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:193) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:328) ... 41 more caused by: org.springframework.beans.beaninstantiationexception: could not instantiate bean class [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.beanutils.instantiateclass(beanutils.java:164) org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:125) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:270) ... 50 more caused by: java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.http.client.httpcomponentsclienthttprequestfactory.<init>(httpcomponentsclienthttprequestfactory.java:74) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator$1.<init>(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator.createrequestfactory(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector.getrequestfactory(clienthttprequestfactoryselector.java:52) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplatewithculledmessageconverters(abstractoauth1apibinding.java:188) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplate(abstractoauth1apibinding.java:169) org.springframework.social.oauth1.abstractoauth1apibinding.<init>(abstractoauth1apibinding.java:70) org.springframework.social.twitter.api.impl.twittertemplate.<init>(twittertemplate.java:79) sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) java.lang.reflect.constructor.newinstance(constructor.java:526) org.springframework.beans.beanutils.instantiateclass(beanutils.java:148) ... 52 more {code},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
499,profile / improve performance of tuplebuilder see discussion at https://github.com/spring-projects/spring-xd/pull/1311 1) there seems to be unused simpledateformat in tuplebuilder which hurst perf 2) more generally should take some time to profile / micro-benchmark tuplebuilder,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
500,gemfire-json-server multiple pdxtypes types i am using springxd to ingest tweets to a gemfire-json-server sink. i am running into an issue where the json documents get defined as a pdx type twice. see the reweet_count field below. this causes problems later when using oql to access this data. incompatible types. what are the recommended ways to resolve this? the field type should account for the largest possible value which is unknown because it is twitter. this would likely be a int or long. i was asked to log this as a sxd jira issue but i am not sure if the problem is in sxd or gemfire. [info 2015/04/25 06:51:28.767 cst <twittersource-1-1> tid=0x53] defining: pdxtype[ dsid=0typenum=1 name=__gemfire_json fields=[ id:string:0:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=-1 from_user:string:1:1:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=1 created_at:string:2:2:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=2 text:string:3:3:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=3 language_code:string:4:4:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=4 retweet_count:short:5:4:idx0(relativeoffset)=-3:idx1(vlfoffsetindex)=-1 retweet:boolean:6:4:idx0(relativeoffset)=-1:idx1(vlfoffsetindex)=-1]] [info 2015/04/25 06:51:29.307 cst <twittersource-1-1> tid=0x53] defining: pdxtype[ dsid=0typenum=2 name=__gemfire_json fields=[ id:string:0:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=-1 from_user:string:1:1:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=1 created_at:string:2:2:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=2 text:string:3:3:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=3 language_code:string:4:4:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=4 retweet_count:byte:5:4:idx0(relativeoffset)=-2:idx1(vlfoffsetindex)=-1 retweet:boolean:6:4:idx0(relativeoffset)=-1:idx1(vlfoffsetindex)=-1]],0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
501,initial xd on cloudfoundry support first take on this involves - being able to deploy the two separate applications: xd-admin & xd-container - being able to cf-service provided redis & rabbit for internal needs of xd - to some extent make modules smart and cf aware (e.g. http source uses correct port),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
502,as a user i'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.,3,4,0.0027609235048294068,1.6666666666666672,0,1,0,0,0
503,as a s-c-d developer i'd like to enhance integration test coverage for {{yarn}} spi so i can continuously evaluate functionalities via ci pipeline.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
504,as a user i'd like to consume multiple topic-partitions so i can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
505,remove unused post module references,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
506,update doc about modules and spring the doc at http://docs.spring.io/spring-xd/docs/1.0.0.m3/reference/html/#_modules_and_spring refers to an old version of the counter sink when it was still hardwired to use redis. the text next to it that explains placeholders is out of date (with respect to the redis placeholders),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
507,update docs for gemfire sink to include locator configuration,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
508,add kafka-based implementation for abstractsinglenodestreamdeploymentintegrationtests,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
509,module options are not trimmed spring xd 1.1 container will throw following exception: {code} java.lang.illegalstateexception: can't find class used for type of option 'myfield': string org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.makesimplemoduleoptions(defaultmoduleoptionsmetadataresolver.java:147) org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.resolvenormalmetadata(defaultmoduleoptionsmetadataresolver.java:202) org.springframework.xd.module.options.defaultmoduleoptionsmetadataresolver.resolve(defaultmoduleoptionsmetadataresolver.java:164) org.springframework.xd.module.options.delegatingmoduleoptionsmetadataresolver.resolve(delegatingmoduleoptionsmetadataresolver.java:44) org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver.resolve(environmentawaremoduleoptionsmetadataresolver.java:127) org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:174) org.springframework.xd.dirt.stream.abstractdeployer.save(abstractdeployer.java:96) ... {code} when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myfield.type value): {code} options.myfield.description = this is my field options.myfield.type = string {code} can the property values be trimmed before comparing to defaultmoduleoptionsmetadataresolver#short_classnames map to avoid this problem?,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
510,provide a property on twittersearch to enable the object-to-json transformer twitter search source should produce json or pojo. the pojo requires a custom wrapper class that is json friendly (e.g. zero arg constructor). the twittersearch module should have a parameter --json true/false (default true) to control the output type.,0,4,0.002760923206806183,1.6666666666666672,0,0,0,0,0
511,hdfs sink should default to hdfs://localhost:8020 the current default is hdfs://localhost:9000 but most new distributions/installs use 8020,0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
512,command for creating a job optional --autostart switch to also deploy the job,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
513,redis backed aggregate counters should return results inclusive of startend time interval an aggregate counter query should return results inclusive of start and end time [startend] for time resolutions minute hour day month.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
514,support pagination in list() command for jobs see xd-477,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
515,shell integration tests should be able to be run across all transports automate running integration tests on all supported transports,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
516,batch hashtag count throws exception when launched 1) update instructions to mention --hadoopdistro for both singlenode and shell. else demo will not work. 2) pom needs to be updated to use 1.2.1 at the least. 3) i can see where hdfs is writing the results 4) throws npe stacktrace is attached.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
517,clean up mismatches and bugs in how mdoule options and server configuration is handled.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
518,spike: research zookeeper-based mechanism for partitioned job management the current implementation of partitioned job management is entirely based on message exchange over the message bus in a request reply scenario. this creates challenges when it comes to using certain types of transports as well as acknowledging crashes. to that effect the option of using a different partitioned job coordination strategy that relies on a distributed computing coordination mechanism such as zookeeper should be investigated.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
519,switch to use lettuce driver for redis replace the use of jedis with lettuce as it has higher performance,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
520,as a user i'd like to have the option to provide security configurations so that i can access rest endpoints in a secured manner. ideally all the listed [rest|https://github.com/spring-projects/spring-xd/wiki/rest-api#xd-resources] endpoints needs to be wrapped within a security layer. *scope of this spike:* * research spring security and spring boot and the ootb features * design considerations and approach for xd * developer experience ** how users will be configuring security credentials? ** how dsl shell will be handled? ** how admin ui will be handled?,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,1,0
521,payload conversion sample throws exception. after updating the dependency to use the snapshot (even with m5) the conversion throws an exception. stacktrace attached.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
522,documentation that introduces taps put on the guide as a section in an 'input-stream' wiki page.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
523,support for hadoop name node ha configuration hadoop supports namenode ha with two name nodes running one being active and other in standby. if the active name node fails the standby name node has all the data readily available and can start serving requests. in this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime. this is to ensure spring xd stream can handle a name node failure for instance when writing a hdfs sink seamlessly,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
524,"step execution progress shell command to use coherent id (jobexecutionid:stepexecutionid) instead of using jobexecutionid and stepexecutionid as two separate options for the ""job execution step progress"" command we can have a single option with id mentioned as (jobexecutionid:stepexecutionid)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
525,"gpfdist may fail to shutdown with backlog in a case where reactor's ringbuffer is full and thus handling backpressure by blocking `onnext` shutdown phase where `oncomplete` is send will cause a deadlock. this is shown by a thread dump during a shutdown. this will basically break further deployments for this stream in distributed mode while single node will show more errors during undeployment. {code} ""pool-7-thread-1"" #58 prio=5 os_prio=0 tid=0x979fe800 nid=0x54de runnable [0x986ad000] java.lang.thread.state: timed_waiting (parking) sun.misc.unsafe.park(native method) java.util.concurrent.locks.locksupport.parknanos(locksupport.java:338) reactor.jarjar.com.lmax.disruptor.singleproducersequencer.next(singleproducersequencer.java:122) reactor.jarjar.com.lmax.disruptor.singleproducersequencer.next(singleproducersequencer.java:97) reactor.jarjar.com.lmax.disruptor.ringbuffer.next(ringbuffer.java:246) reactor.core.processor.util.ringbuffersubscriberutils.onnext(ringbuffersubscriberutils.java:30) reactor.core.processor.ringbufferprocessor.onnext(ringbufferprocessor.java:575) {code} {code} ""main-eventthread"" #19 daemon prio=5 os_prio=0 tid=0x9b93a400 nid=0x54b1 runnable [0x9aefe000] java.lang.thread.state: timed_waiting (parking) sun.misc.unsafe.park(native method) java.util.concurrent.locks.locksupport.parknanos(locksupport.java:338) reactor.jarjar.com.lmax.disruptor.singleproducersequencer.next(singleproducersequencer.java:122) reactor.jarjar.com.lmax.disruptor.singleproducersequencer.next(singleproducersequencer.java:97) reactor.jarjar.com.lmax.disruptor.ringbuffer.next(ringbuffer.java:246) reactor.core.processor.util.ringbuffersubscriberutils.oncomplete(ringbuffersubscriberutils.java:54) reactor.core.processor.ringbufferprocessor.oncomplete(ringbufferprocessor.java:585) org.springframework.xd.greenplum.gpfdist.gpfdistmessagehandler.dostop(gpfdistmessagehandler.java:170) {code} i've been crafting workaround for this by trying to wait reactor stream/buffer to get drained by gpdb and finally as last resort forcing processor in reactor to shutdown.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
526,as a s-c-d developer i'd like to add test coverage to test {{shell}} commands in isolation so i don't have to run end-to-end full stream deployment based functional tests. more details [here|https://docs.google.com/document/d/18unqragvgo0bhdvdsvg3x78gdbeqxa_ln_c6jj0ypkw/edit#].,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
527,produce kafka baseline numbers on rackspace,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
528,add configuration files for hornetmq jms provider. see https://jira.spring.io/browse/xd-1684 requires update to gradle 2.1,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
529,update to reactor 2.0 build snapshots,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
530,"improve module options support note from pr #365 - which has been merged - providing the initial level of support... pending issues (to be addressed in another pr?): - [x] complex case - [x] default values for complex case when option is not surfaced back to the module (eg ""suffix"" in our canonical example) - [ ] plugin provided options and values - [ ] descriptive defaults instead of actual defaults (e.g. \<use stream name\>) - [ ] jsr303 validation",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
531,message bus optimizations (kafka + redis),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
532,as a user i'd like to have the option of _batching_ for the rabbit _sink_ so that i can write data in batches as opposed to one-at-a-time.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
533,as a user i'd like to have the option of _hawq_ sink so that i can write data directly into hawq via pxf extensions through avro/parquet format.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
534,display a counter,0,0,0.0025889062881469726,8.333333333333332,1,1,0,1,0
535,add global http interceptor in order to centralize error logging theoretically i would have liked to centralize logging of http/resource calls global more substantially - but see this limitation: https://github.com/angular/angular.js/issues/4013,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
536,detect invalid deployment properties in the bus detect properties the bus doesn't support.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
537,create si components that wrap reactor's tcp server,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
538,sqooptasklet not using hadoop configuration hey guys i'm trying to use a sqooptasklet but for some reason it is not getting the hadoop configuration. in the attached sqoop job configuration using the sqooprunner class directly works without problems but the sqooptasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log). could please you guys help me to solve this problem? thanks in advance. regards,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
539,as a spring xd user i need to listen on a jms topic and ingest the messages so i can process the messages. currently the module only allows for queues,2,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
540,document monitoring & management features this section should discuss what is exposed via jmx how you can view it in jconsole and how you can view it over http via jolikia. in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream that indicate the number of messages processed per section.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
541,as a user i'm trying to delete the custom module using the {{module delete}} command via shell though the command is successfully i'm still seeing the associated artifact (_.jar file_) present in the custom_modules folder. refer to [so thread|http://stackoverflow.com/questions/30984922/springxd-module-delete-command-does-not-delete-the-uploaded-jar-file] for more details.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
542,automate provisioning story for xd,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
543,"can't access hdfs using webhdfs protocol http://localhost:8080:>hadoop config fs --namenode webhdfs://localhost:50070 http://localhost:8080:>hadoop fs ls / hadoop configuration changed re-initializing shell... run hdfs shell failed. message is: org/mortbay/util/ajax/json this was on a hadoop 1.0.1 install the hdfs http interface was available $ curl -i ""http://localhost:50070/webhdfs/v1/tmp?op=getfilestatus"" http/1.1 200 ok content-type: application/json transfer-encoding: chunked server: jetty(6.1.26) {""filestatus"":{""accesstime"":0""blocksize"":0""group"":""supergroup""""length"":0""modificationtime"":1365015846724""owner"":""mpollack""""pathsuffix"":""""""permission"":""777""""replication"":0""type"":""directory""}}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
544,user wants the ability to exclude certain days (like holidays) for a trigger to fire. commonly called calendar support,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
545,avoid use of module name twice in location when using a custom modules see https://github.com/springsource/spring-xd/pull/240#discussion_r6045724,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
546,update deployment guide to include verbose gc the deployment guide https://github.com/spring-projects/spring-xd/wiki/deployment should have instructions on turning on verbose gc for production applications. the gc log tends to be verbose so running it in development is not desirable. however having the gc log in production is very helpful for troubleshooting slow/unresponsive applications.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
547,copy spring-xd-codec to scs as spring-cloud-streams-codec create the equivalent library in spring-cloud-streams,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
548,"spark streaming integration with kafka message does not respect offsetstoretopic config option the property ""xd.messagebus.kafka.offsetstoretopic"" was added to kafka message bus which is not updated to spark streaming message bus properties that will be transferred to spark cluster for streaming module deployment. we also need a better approach to re-use the message bus properties so that we don't have to update the properties in connection property names.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
549,as a spring xd developer i'd like to port {{http}} module from xd to s-c-s repo so i can use it as {{source}} module in streaming pipeline.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
550,update to spring shell 1.1 rc1,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
551,xd-shell from 1.0.1 doesn't work with 1.0.0 ga admin targeting xd-shell from 1.0.1 to 1.0.0 ga admin server fails server-unknown:>admin config info ------------- ------------------------------------------------------------- result unable to contact xd admin server at 'http://localhost:9393'. target http://localhost:9393 timezone used pacific standard time (utc -8:00) ------------- ------------------------------------------------------------- ------------------------------------------------------------------------------- an exception ocurred during targeting: java.lang.nullpointerexception at org.springframework.xd.rest.client.impl.springxdtemplate.<init>(springxdtemplate.java:110) at org.springframework.xd.rest.client.impl.springxdtemplate.<init>(springxdtemplate.java:137) at org.springframework.xd.shell.command.configcommands.target(configcommands.java:106) at org.springframework.xd.shell.command.configcommands.afterpropertiesset(configcommands.java:191),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
552,"provide user friendly messages when dealing with invalid gemfire sink xd:>stream create --name testgemfire --definition ""http --port=8887 | gemfire"" 16:20:28503 warn spring shell client.resttemplate:524 - post request for ""http://localhost:8080/streams"" resulted in 500 (internal server error) invoking error handler command failed org.springframework.xd.rest.client.impl.springxdexception: org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name 'region' defined in null: could not resolve placeholder 'regionname' in string value ""${regionname}""",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
553,as a developer i'd like to complete the remaining work with debs challenge so i can submit by the deadline.,2,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
554,add command for deploying a stream deploy a named stream. the stream must exist in the streamrepository,0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
555,as a user i'd like to refer to documentation while migrating to 1.3 release.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
556,create a stubbed out job controller,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
557,"xd yarn deployment requires the ability to set permsize when deploying xd using java 7 the user must be able to set the permsize to a value larger than the default. the reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source & sink more than 2 times stream deployment begins to fail. the only exception that was captured was the following: {noformat} exception in thread ""ec2test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor"" exception: java.lang.outofmemoryerror thrown from the uncaughtexceptionhandler in thread ""ec2test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor {noformat} logs are not available at this time.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
558,"as a user i'm trying to compose a job just with one definition however i'm getting the following error message which could be misinterpreted. {code} xd:>job create salsa --definition timestampfile successfully created job 'salsa' xd:>job create foo --definition ""salsa || salsa"" successfully created job 'foo' xd:>job create foo222 --definition ""salsa"" command failed org.springframework.xd.rest.client.impl.springxdexception: could not find module with name 'salsa' and type 'job' {code}",1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
559,enable @value etc in module options metadata a placeholder to investigate what can be done with spring configuration in module options metadata classes to simplify/enhance property configuration. with @configuration modules these may now be beans in the module context.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
560,ui: for hadoop steps - provide a link to the mapreduce job details in hadoop.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
561,create rest api for getting information on all steps of a given job execution adopted functionality from spring batch admin should include springmvc test framework style tests get /batch/jobs/executions/{executionid}/steps - get information on all steps of a given job execution,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
562,add config dir to classpath to support custom properties-locations the transform filter and script processor modules support passing in a properties-location for script variables. we need a default location on the classpath for users to provide custom properties files.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
563,add index-based access to tuplepropertyaccessor,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
564,add test cases for defaultcontainermatcher,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
565,as a xd user i'd like to orchestrate composed jobs so i can bring multiple jobs into single workflow and operationalize.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
566,as a developer i'd like to port {{log}} module from xd to s-c-s repo so i can use it as {{sink}} modules to build streaming pipeline.,2,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
567,interacting with xd on yarn 1. how we talk to the xd instance(s) on yarn 2. there is a rest interface which location can be exposed either via resource manager or appmaster 3. technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface implementation(i.e. thrift or spring int),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
568,as a developer i'd like to upgrade to reactor 2.0.4 release so i could leverage the latest improvements and bug-fixes.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
569,user should be able to provide job deployment properties at the job definitions page user should be able to provide the job deployment manifest (module count criteria etc.),0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
570,create xd module for syslog-tcp-reactor still keep existing one.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
571,create simple gague service a gauge just stores a number. implementations for in-memory and redis.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
572,nodes can not connect with admin using redis as transport this has happened more than once where a node fails for whatever reason and when it is restarted it does not receive requests from the admin server. this could be file handle count based. since this is not rabbit as a transport i'm not chasing this down yet. but felt it needed to be recorded.,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
573,add visual representation of job workflow in executions list page as an xd user i'd like to be able to visually differentiate between job-composition workflow and single job.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
574,job definition is deleted after restart the srping xd service in single node mode job definition is deleted after restart the srping xd service in single node mode repro step: 1.start service as single node 2.create a batch module 3.create a job based on batch module 4.restart service expect result: job definition is displayed on the job list actual result: job list is empty all job definitions are missed,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
575,"spring_rabbitmq_addresses environment variable is ignored when trying to configure xd to use a rabbitmq instance other than the default localhost:5672 a user is supposedto updated the ""spring_rabbitmq_addresses"" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file. in this case xd is ignoring this environment variable. h3. steps to reproduce # set the transport by using ""export xd_transport=rabbit"" # set the spring_rabbitmq_addresses by ""export spring_rabbitmq_addresses=foo:5672"" # startup a admin container on your local machine # deploy ticktock #* this should fail #* start up a local rabbitmq #* deploy a new ticktock and stream will deploy.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
576,spring xd shell should maintain single log file (per user?) currently xd-shell script packaged in spring xd dist creates spring-shell.log file in invocation directory. when xd-shell is added to $path user will usually invoke the script from many directories leaving log files all over the file system. would it be possible to keep the log files in one predefined location (e.g. $home/.spring-shell.log or $dist/shell/logs/spring-shell.log)?,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
577,"add back classifier = 'dist' to distzip build target add back ""classifier = 'dist'"" to distzip build target - it was was accidentally removed.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
578,create low volume http stress test the test https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/httpbash is very simple it doesn't even check the results. a small change to https://github.com/spring-projects/spring-xd/blob/master/spring-xd-test-fixtures/src/main/java/org/springframework/xd/test/generator/simplehttpgenerator.java so that number of messages to post is specified would be part of this work.,0,2,0.0026664945483207705,1.6666666666666672,0,0,0,0,0
579,update readme.txt to include instructions on how to build building xd should not be part of the out first out of the box experience but we should include some instructions on what targets are available such as distxd.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
580,support default values for options derived out of ${} placeholders the logic can be found in defaultmoduleoptionsmetadatacollector but caused problems in the initial pr. revisit if needed,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
581,integration tests for xd installer,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
582,as a spring xd developer i'd like to move {{tcp-client}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline.,2,4,0.0027609235048294068,1.6666666666666672,0,1,0,0,0
583,"kafka sink: support async producer the kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). async producers batch messages (at the risk of message loss). add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element {{async=""$\{async\}""}}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
584,"remove the constraint on job module batch job id to be ""job"" currently the job module's batch job's bean id should be ""job"". this also causes the job name to be 'actual-job-name + "".job""' and the batch job controllers require to search for job with suffix "".job"". removing this constraint would help us avoiding these.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
585,as a spring xd developer i'd like to port {{analytic-pmml}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline.,4,2,0.0026111719012260437,1.6666666666666672,0,1,0,0,0
586,add support for pivotal hd 2.1 (xd 1.0.2 release) *xd 1.0.2 release + phd 2.1 upgrade - action items:* * update to shdp 2.0.3 * add hadoop 2.5 (hadoop25) * change phd 2.x from phd20 to phd21 * test phd 2.0 with phd21 * document that both phd 2.1 and phd 2.0 is supported with phd21,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
587,"list streams/jobs based with deployed modules currently there is a ""stream list""/""job list"" which shows the status of a given stream/job along with the dsl. and there is ""runtime modules"" which shows all the deployed modules with their container info. we need a better rest endpoint that gives all the deployed modules for a given stream/job along with the status.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
588,move kafka @rule to a separate repo as an s-c-d developer i'd like to move kafka {{@rule}} to a separate repo so i can consume the test fixtures in different projects.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
589,user should be able to specify deploy properties for jobs when clicking deploy from the job definitions page user should be able to specify the deployment manifest (module count module criteria etc.),0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
590,more dsl work: checking behaviour for non-deployable streams with support for substreams/parameterized streams now in the parser it will be possible to create a stream that cannot be deployed: it may not fit the source/processor*/sink structure or it is a parameterized stream with no default values for parameters. need to check how xd is going to handle these - after creating them attempting to 'deploy' them should return appropriate errors. (they should exist in the stream directory).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
591,"when using file as a source and sink user can not use file sink --mode cluster type: singlenode machine: mac pr: https://github.com/spring-projects/spring-xd/pull/1624https://github.com/spring-projects/spring-xd/pull/1626 stream that reproduces the problem: {noformat} stream create foo --definition ""filein: file --dir=/tmp/xd/a0180520-c7fa-4d9d-8cc3-e36fbf59496a --pattern=de59d1b8-f99c-4c43-a8c0-2f6043546689.out --mode=contents | fileout: file --binary=true --mode=replace "" {noformat} error message: {noformat} command failed org.springframework.xd.rest.client.impl.springxdexception: error with option(s) for module file of type sink: mode: failed to convert property value of type 'java.lang.string' to required type 'org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode' for property 'mode' nested exception is java.lang.illegalstateexception: cannot convert value of type [java.lang.string] to required type [org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode] for property 'mode': no matching editors or conversion strategy found {noformat} stacktrace: {noformat} 2015-05-19 14:30:56329 1.2.0.snap error qtp671416633-35 rest.restcontrolleradvice - caught exception while handling a request org.springframework.xd.dirt.plugins.moduleconfigurationexception: error with option(s) for module file of type sink: mode: failed to convert property value of type 'java.lang.string' to required type 'org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode' for property 'mode' nested exception is java.lang.illegalstateexception: cannot convert value of type [java.lang.string] to required type [org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode] for property 'mode': no matching editors or conversion strategy found org.springframework.xd.dirt.plugins.moduleconfigurationexception.frombindexception(moduleconfigurationexception.java:55) org.springframework.xd.dirt.stream.xdstreamparser.buildmoduledescriptors(xdstreamparser.java:191) org.springframework.xd.dirt.stream.xdstreamparser.parse(xdstreamparser.java:122) org.springframework.xd.dirt.stream.abstractdeployer.validatebeforesave(abstractdeployer.java:115) org.springframework.xd.dirt.rest.xdcontroller.save(xdcontroller.java:260) sun.reflect.generatedmethodaccessor191.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:221) org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:137) org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:110) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:776) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:705) org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:85) org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:959) org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:893) org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:966) org.springframework.web.servlet.frameworkservlet.dopost(frameworkservlet.java:868) javax.servlet.http.httpservlet.service(httpservlet.java:755) org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:842) javax.servlet.http.httpservlet.service(httpservlet.java:848) org.eclipse.jetty.servlet.servletholder.handle(servletholder.java:684) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1496) org.springframework.boot.actuate.autoconfigure.endpointwebmvcautoconfiguration$applicationcontextheaderfilter.dofilterinternal(endpointwebmvcautoconfiguration.java:291) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:77) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:87) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.springframework.boot.actuate.trace.webrequesttracefilter.dofilterinternal(webrequesttracefilter.java:102) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.springframework.security.web.filterchainproxy.dofilterinternal(filterchainproxy.java:186) org.springframework.security.web.filterchainproxy.dofilter(filterchainproxy.java:160) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.springframework.boot.actuate.autoconfigure.metricfilterautoconfiguration$metricsfilter.dofilterinternal(metricfilterautoconfiguration.java:90) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:107) org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467) org.eclipse.jetty.servlet.servlethandler.dohandle(servlethandler.java:499) org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:137) org.eclipse.jetty.security.securityhandler.handle(securityhandler.java:557) org.eclipse.jetty.server.session.sessionhandler.dohandle(sessionhandler.java:231) org.eclipse.jetty.server.handler.contexthandler.dohandle(contexthandler.java:1086) org.eclipse.jetty.servlet.servlethandler.doscope(servlethandler.java:428) org.eclipse.jetty.server.session.sessionhandler.doscope(sessionhandler.java:193) org.eclipse.jetty.server.handler.contexthandler.doscope(contexthandler.java:1020) org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:135) org.eclipse.jetty.server.handler.handlerwrapper.handle(handlerwrapper.java:116) org.eclipse.jetty.server.server.handle(server.java:370) org.eclipse.jetty.server.abstracthttpconnection.handlerequest(abstracthttpconnection.java:494) org.eclipse.jetty.server.abstracthttpconnection.content(abstracthttpconnection.java:982) org.eclipse.jetty.server.abstracthttpconnection$requesthandler.content(abstracthttpconnection.java:1043) org.eclipse.jetty.http.httpparser.parsenext(httpparser.java:865) org.eclipse.jetty.http.httpparser.parseavailable(httpparser.java:240) org.eclipse.jetty.server.asynchttpconnection.handle(asynchttpconnection.java:82) org.eclipse.jetty.io.nio.selectchannelendpoint.handle(selectchannelendpoint.java:667) org.eclipse.jetty.io.nio.selectchannelendpoint$1.run(selectchannelendpoint.java:52) org.eclipse.jetty.util.thread.queuedthreadpool.runjob(queuedthreadpool.java:608) org.eclipse.jetty.util.thread.queuedthreadpool$3.run(queuedthreadpool.java:543) java.lang.thread.run(thread.java:745) caused by: org.springframework.validation.bindexception: org.springframework.validation.beanpropertybindingresult: 1 errors field error in object 'target' on field 'mode': rejected value [replace] codes [typemismatch.target.modetypemismatch.modetypemismatch.org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$modetypemismatch] arguments [org.springframework.context.support.defaultmessagesourceresolvable: codes [target.modemode] arguments [] default message [mode]] default message [failed to convert property value of type 'java.lang.string' to required type 'org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode' for property 'mode' nested exception is java.lang.illegalstateexception: cannot convert value of type [java.lang.string] to required type [org.springframework.xd.dirt.modules.metadata.filesinkoptionsmetadata$mode] for property 'mode': no matching editors or conversion strategy found] org.springframework.xd.module.options.pojomoduleoptionsmetadata.bindandvalidate(pojomoduleoptionsmetadata.java:205) org.springframework.xd.module.options.pojomoduleoptionsmetadata.interpolate(pojomoduleoptionsmetadata.java:139) org.springframework.xd.module.options.flattenedcompositemoduleoptionsmetadata.interpolate(flattenedcompositemoduleoptionsmetadata.java:152) org.springframework.xd.module.options.environmentawaremoduleoptionsmetadataresolver$moduleoptionsmetadatawithdefaults.interpolate(environmentawaremoduleoptionsmetadataresolver.java:168) org.springframework.xd.dirt.stream.xdstreamparser.buildmoduledescriptors(xdstreamparser.java:188) ... 61 more {noformat}",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
592,pagination for containers it is limited to only 20 hi customer has 48 containers but it only shows 20 containers. we need pagination to browse all containers.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
593,process for creating and deploying custom xd modules,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
594,update instructions to how to setup admin to use rdbms. need to update instructions to discuss the setup of the relational database requirement for the xd-admin.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
595,"properly render defaults for ""module info"" that use \n \t etc. characters line \t \n etc. should be either escaped or rendered as human readable variants in module info (eg <newline>)",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
596,add polling twitter source i've created a source module for polling a twitter timeline using the spring integration twitter inbound adapter. i've placed my api keys in the modules.yml file and verified that they are picked up by the twitterstream and twitterseach modules that come with springxd. however they are not picked up by my custom module. i viewed the source for both the stream and and the search and i feel my project is near identical in configuration. am i missing something or are these properties somehow special for just the two twitter sources that come with springxd? i'd like to get this working and commit it to the project.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
597,"job stuck in ""deploying"" state when no containers are available a job gets stuck in ""deploying"" state when a job is deployed when there are no containers available. when a container is started after this event the job doesn't automatically start because of the job is stuck in the ""deploying"" state instead of the ""failed"" state. refer to https://github.com/spring-projects/spring-xd/blob/193088dc164c73e07d7b4509de22241b28bf42b3/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/jobdeploymentlistener.java update of the status in zookeeper is inside the nocontainerexception catch block. this works correctly for streams.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
598,as a user i'd like to use the admin-ui and flo with consistent look and feel.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
599,create test with jdbc sink and initializedb=false see https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#l96 and https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#l64 the second assert has initializedb=false and so there are double the number of rows running the job a second time.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
600,add ability to copy job from http site to containers download zipped job modules from a http site and deploy them to modules on the admin & containers before container is started.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
601,as a qa i'd like to include acceptance test coverage for _json-tuple_ processor module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.77251607550301,0,1,0,0,0
602,automatically align version for tomcat components from platform https://github.com/spring-projects/spring-xd/commit/db66aa2a329a6fc7ef89a340dd4d562fa70d14a4 introduces org.apache.tomcat.embed:tomcat-embed-logging-log4j which is not covered by platform. yet we should lookup the version to use from other tomcat artifacts using some gradle magic,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
603,as a developer i'd like to port {{aggregate-counter}} module from xd to s-c-s repo so i can use it as {{sink}} module to build streaming pipeline.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
604,as a user i'd like to have the option to configure default access control for endpoints so that i can grant access by _admin_ or _viewer_ roles.,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
605,module launcher properties improvments improve spring cloud stream module launcher/resolver properties: 1) support comma separated remoterepositories 2) classify/group the properties,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
606,the new scsm twitterstream module should produce same json as old xd source the new scsm twitterstream module uses a different format than xd 1.x source module. it should match what twitter uses so existing processors etc. will continue to work.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
607,batch jobs executions by jobname causes stackoverflow whether it's after applying https://github.com/spring-projects/spring-xd/pull/1034/ or not this causes the following problem: {noformat} .... com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:644) com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) com.fasterxml.jackson.databind.ser.beanpropertywriter.serializeasfield(beanpropertywriter.java:541) com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:644) com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:100) com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:21) com.fasterxml.jackson.databind.ser.std.asarrayserializerbase.serialize(asarrayserializerbase.java:183) com.fasterxml.jackson.databind.ser.beanpropertywriter.serializeasfield(beanpropertywriter.java:541) com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:644) com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) com.fasterxml.jackson.databind.ser.beanpropertywriter.serializeasfield(beanpropertywriter.java:541) com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:644) com.fasterxml.jackson.databind.ser.beanserializer.serialize(beanserializer.java:152) com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:100) com.fasterxml.jackson.databind.ser.impl.indexedlistserializer.serializecontents(indexedlistserializer.java:21) caused by: java.lang.stackoverflowerror java.lang.classloader.defineclass1(native method) java.lang.classloader.defineclass(classloader.java:800) java.security.secureclassloader.defineclass(secureclassloader.java:142) java.net.urlclassloader.defineclass(urlclassloader.java:449) java.net.urlclassloader.access$100(urlclassloader.java:71) java.net.urlclassloader$1.run(urlclassloader.java:361) java.net.urlclassloader$1.run(urlclassloader.java:355) java.security.accesscontroller.doprivileged(native method) java.net.urlclassloader.findclass(urlclassloader.java:354) java.lang.classloader.loadclass(classloader.java:425) sun.misc.launcher$appclassloader.loadclass(launcher.java:308) java.lang.classloader.loadclass(classloader.java:358) com.fasterxml.jackson.databind.ser.std.beanserializerbase.serializefields(beanserializerbase.java:660) ... 1011 more {noformat},0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
608,spark streaming plugin shouldn't need tap listener cache since spark streaming doesn't use zk to keep track taps being created we don't need the tap listener cache setup at the container startup.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
609,the command line for xd-admin and xd-container to support an additional option pipeprotocol that is used to determine the middleware for sending admin requests and data between processing steps the name 'pipeprotocol' is tentative. 1. the command line scripts for xd-admin and xd-container would support a --pipeprotocol option with the default being to use redis. (otherwise use xd-singlenode). 2. the xd-admin and xd-container scripts will use the value of pipeprotocol to set the java system property xd.pipeprotocol when launching the app.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
610,streamdeployer.deleteall() does not handle dependency tracking create a composed module use it in a stream delete all streams. try to delete the composed module => fails thinking that it's still used by the stream,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
611,"create fsshell based module to copy a file to hdfs spring batch workflows are great for complex hadoop operations but if i want to create a simple processor that executes some hadoop fs in groovy it would be nice to do this: {code} <service-activator output-channel=""output"" input-channel=""input""> <hadoop:script id=""loadscript"" language=""groovy""> def outputpath = ""${hdfspath}"" fsh.put(""-"" outputpath) </hadoop:script> </service-activator> {code} the goal of this hadoop script is to use in a stream like this:""file | script"" that puts a file byte for byte to hdfs. an enhanced hdfs sink that's optimized for binary data like images/pdfs might be more elegant but i was hoping that this would work. this script gets ignored by spring xd. but even if it didn't i am not sure the ""-"" stdin put would work as hoped.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
612,jdbchdfstests sporadically fail acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged xd-2309. additional tests were added but used fixed timeouts. will replace them with waitforjob.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
613,update spring-xd-extension-reactor dependency currently the reactorenv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project. this enables boot's reactorautoconfiguration to initialize the reactor environment we have the reactor setup configured for both admin and container server applications. since reactor environment is not being used by container and only used by the reactor-syslog module we can move the reactorenv bean definition in reactor-syslog module. there is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
614,remove usage of <context:property-placeholder location=.../> in module defitions this doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc. this is in hdfs and some others.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
615,home wiki page improvements add more structure more easily find the reference guide. the style that is here https://github.com/snowplow/snowplow/wiki is nice.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
616,as a user i'd like to use boot-based {{modulerunner}} for use in container-managed environments so i can run xd without _xd-containers_. scope: * complete the remaining deployment properties work,5,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
617,create redisprotocol.xml that will load all the redis specific implementations to suppor the xd container runtime and administration the redis specific beans that are defined in the current launcher.xml should move into this configuration file.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
618,logging is not producing a log file * need to add a -dxd.home=$xd_home to the start scripts else all files will write to the /logs directory. * need to update .bat files to use % for env variables instead of $. * need to rename logger.config to logging.config so that boot will pick up the log config files. * admin needs to use xd-admin-logger configs instead of xd-container-logger * renamed logging file for singlenode from admin.log to singlenode.log,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
619,update twittersearch to use spring integration support,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
620,ensure proper lifecycle shutdown of processors in broadcastermessagehandler and multiplebroadcastermessagehandler,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
621,as a user i'd like to use kafka source through simple consumer api (as opposed to high-level) so that i can gain full control to offsets and partition assignment deterministically. *spike scope*: - study simple consumer api functionality - document findings approach and next steps,5,1,0.0026434442400932313,1.6666666666666672,0,1,0,1,0
622,build scripts can refer hadoop distro sub projects in a unique place based on this change https://github.com/spring-projects/spring-xd/commit/87b97a0b4651f862e8a639697745ad232bb42e6a the gradle build scripts now refer to two different places to check for the list of hadoop distro sub projects. we can simplify this to make it available in one place so that maintenance will be easier.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
623,serialization of chunkcontext fails using kryo,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
624,create a simple counter service a simple counters can increment/decrement a number. implementations for in-memory and redis.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
625,"inconsistent test failure with mqtt script test in ci environment mqtt_tests under src/tests/scripts fail inconsistently with the following exception stacktrace: severe: xd.mqtt.client.id.src: timed out as no activity keepalive=60000 lastoutboundactivity=1395174955434 lastinboundactivity=1395174895434 13:36:55442 error http-nio-9393-exec-7 inbound.mqttpahomessagedrivenchanneladapter:66 - exception while connecting and subscribing retrying client is currently disconnecting (32102) org.eclipse.paho.client.mqttv3.internal.exceptionhelper.createmqttexception(exceptionhelper.java:27) org.eclipse.paho.client.mqttv3.internal.clientcomms.disconnect(clientcomms.java:409) org.eclipse.paho.client.mqttv3.mqttasyncclient.disconnect(mqttasyncclient.java:524) org.eclipse.paho.client.mqttv3.mqttclient.disconnect(mqttclient.java:250) org.eclipse.paho.client.mqttv3.mqttclient.disconnect(mqttclient.java:243) org.springframework.integration.mqtt.inbound.mqttpahomessagedrivenchanneladapter.connectandsubscribe(mqttpahomessagedrivenchanneladapter.java:104) org.springframework.integration.mqtt.inbound.mqttpahomessagedrivenchanneladapter.dostart(mqttpahomessagedrivenchanneladapter.java:63) org.springframework.integration.endpoint.abstractendpoint.start(abstractendpoint.java:84) org.springframework.context.support.defaultlifecycleprocessor.dostart(defaultlifecycleprocessor.java:173) org.springframework.context.support.defaultlifecycleprocessor.access$200(defaultlifecycleprocessor.java:51) org.springframework.context.support.defaultlifecycleprocessor$lifecyclegroup.start(defaultlifecycleprocessor.java:346) org.springframework.context.support.defaultlifecycleprocessor.startbeans(defaultlifecycleprocessor.java:149) org.springframework.context.support.defaultlifecycleprocessor.start(defaultlifecycleprocessor.java:91) org.springframework.context.support.abstractapplicationcontext.start(abstractapplicationcontext.java:1180) org.springframework.xd.module.core.simplemodule.start(simplemodule.java:270) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:250) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:238) org.springframework.xd.dirt.module.moduledeployer.handledeploy(moduledeployer.java:179) org.springframework.xd.dirt.module.moduledeployer.handlemessageinternal(moduledeployer.java:150) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.config.serviceactivatorfactorybean$1.handlerequestmessage(serviceactivatorfactorybean.java:83) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:170) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:114) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:93) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:260) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:241) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:205) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:199) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:177) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) org.springframework.xd.dirt.stream.deploymentmessagesender.senddeploymentrequests(deploymentmessagesender.java:57) org.springframework.xd.dirt.stream.abstractdeployer.senddeploymentrequests(abstractdeployer.java:163) org.springframework.xd.dirt.stream.abstractdeployer.basicdeploy(abstractdeployer.java:204) org.springframework.xd.dirt.stream.abstractinstancepersistingdeployer.deploy(abstractinstancepersistingdeployer.java:78) org.springframework.xd.dirt.rest.xdcontroller.deploy(xdcontroller.java:142) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:616) org.springframework.web.method.support.invocablehandlermethod.invoke(invocablehandlermethod.java:215) org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:132) org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:749) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:690) org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:83) org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:945) org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:876) org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:961) org.springframework.web.servlet.frameworkservlet.doput(frameworkservlet.java:874) javax.servlet.http.httpservlet.service(httpservlet.java:650) org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:837) javax.servlet.http.httpservlet.service(httpservlet.java:728) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:305) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.trace.webrequesttracefilter.dofilter(webrequesttracefilter.java:114) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.autoconfigure.endpointwebmvcautoconfiguration$applicationcontextfilterconfiguration$1.dofilterinternal(endpointwebmvcautoconfiguration.java:128) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.web.filter.hiddenhttpmethodfilter.dofilterinternal(hiddenhttpmethodfilter.java:77) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.web.filter.httpputformcontentfilter.dofilterinternal(httpputformcontentfilter.java:85) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.springframework.boot.actuate.autoconfigure.metricfilterautoconfiguration$metricsfilter.dofilterinternal(metricfilterautoconfiguration.java:84) org.springframework.web.filter.onceperrequestfilter.dofilter(onceperrequestfilter.java:108) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java:243) org.apache.catalina.core.applicationfilterchain.dofilter(applicationfilterchain.java:210) org.apache.catalina.core.standardwrappervalve.invoke(standardwrappervalve.java:222) org.apache.catalina.core.standardcontextvalve.invoke(standardcontextvalve.java:123) org.apache.catalina.authenticator.authenticatorbase.invoke(authenticatorbase.java:472) org.apache.catalina.valves.remoteipvalve.invoke(remoteipvalve.java:680) org.apache.catalina.core.standardhostvalve.invoke(standardhostvalve.java:171) org.apache.catalina.valves.errorreportvalve.invoke(errorreportvalve.java:99) org.apache.catalina.core.standardenginevalve.invoke(standardenginevalve.java:118) org.apache.catalina.connector.coyoteadapter.service(coyoteadapter.java:407) org.apache.coyote.http11.abstracthttp11processor.process(abstracthttp11processor.java:1004) org.apache.coyote.abstractprotocol$abstractconnectionhandler.process(abstractprotocol.java:589) org.apache.tomcat.util.net.nioendpoint$socketprocessor.run(nioendpoint.java:1680) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1146) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:679) 13:36:55465 info http-nio-9393-exec-7 module.moduledeployer:240 - deployed simplemodule [name=mqtt type=source group=mqttsourcetest index=0 @38946002] http/1.1 200 ok server: mochiweb/1.1 webmachine/1.10.0 (never breaks eye contact) date: tue 18 mar 2014 20:36:55 gmt content-type: application/json content-length: 16 cache-control: no-cache {""routed"":false}cat: /tmp/xdtest/basic/mqttsourcetest.out: no such file or directory bamboo@w1-kodiak-hd006:/data/bamboo-home/xml-data/build-dir/xd-scripts-rs/spring-xd/src/test/scripts$ mar 18 2014 1:38:55 pm org.eclipse.paho.client.mqttv3.internal.clientstate checkforactivity severe: xd.mqtt.client.id.src: timed out as no activity keepalive=60000 lastoutboundactivity=1395175075488 lastinboundactivity=1395175015488 13:38:55490 error task-scheduler-2 inbound.mqttpahomessagedrivenchanneladapter:141 - exception while connecting and subscribing client is disconnected (32101) org.eclipse.paho.client.mqttv3.internal.exceptionhelper.createmqttexception(exceptionhelper.java:27) org.eclipse.paho.client.mqttv3.internal.clientcomms.disconnect(clientcomms.java:405) org.eclipse.paho.client.mqttv3.mqttasyncclient.disconnect(mqttasyncclient.java:524) org.eclipse.paho.client.mqttv3.mqttclient.disconnect(mqttclient.java:250) org.eclipse.paho.client.mqttv3.mqttclient.disconnect(mqttclient.java:243) org.springframework.integration.mqtt.inbound.mqttpahomessagedrivenchanneladapter.connectandsubscribe(mqttpahomessagedrivenchanneladapter.java:104) org.springframework.integration.mqtt.inbound.mqttpahomessagedrivenchanneladapter.access$300(mqttpahomessagedrivenchanneladapter.java:37) org.springframework.integration.mqtt.inbound.mqttpahomessagedrivenchanneladapter$1.run(mqttpahomessagedrivenchanneladapter.java:137) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:54) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask$sync.innerrunandreset(futuretask.java:351) java.util.concurrent.futuretask.runandreset(futuretask.java:178) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$201(scheduledthreadpoolexecutor.java:165) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:267) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1146) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:679)",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
626,few integration tests fail if jmx is enabled if jmx is enabled some of the integration tests fail. this is similar to what we see in xd-1295. one example of this case is the test classes that extend streamtestsupport. in streamtestsupport the @beforeclass has this line: moduledeployer = containercontext.getbean(moduledeployer.class) when jmx is enable the integrationmbeanexporter creates jdkdynamicproxy for the moduledeployer (since it is of type messagehandler) and thereby the above line to get bean by the implementing class type (moduledeployer) fails. there are few other places where we use to refer the implementing classes on getbean(). looks like we need to fix those as well.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
627,support serialization/deserialization of message payloads across jvms across all transports. string -> byte[] (string.getbytes()) byte[] -> byte[] (no serialization) pojo -> configured serialization,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
628,ui: ability to deploy stream with deployment properties admin ui currently allows job to be deployed with deployment properties we need similar way to deploy stream with the deployment properties (module count container matching criteria).,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
629,as a user i'd like to have the description for each of the modules so that i can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).,5,1,0.0026434442400932313,1.6666666666666672,0,1,0,1,0
630,update jclouds to 1.8 have to update the code because of deprecation and to get ready for 2.0.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
631,"update hadoop instructions in the xd-samples batchhashtagcount and batchwordcount projects need ""hadoop fs ls"" instructions need to be updated.",0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
632,test source module in isolation register the module under test and deploy the module verify output across all transports examples be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml pass in some property file for parameters to be replaced and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality. test that sending json results in media-type header is set to json test that sending pojo -> pojo test that sending tuple -> tuple test that sending a (json) string -> string test that sending raw bytes -> raw bytes,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
633,containers should listen for module deployment requests and their deletions the admin leader will write each module deployment request to a child node of /xd/deployments for a selected container (see xd-1399). that container-specific (persistent) child node needs to be created by the container at the same time as it creates its ephemeral node under /xd/containers. the container should then deploy the module. if that same node is subsequently deleted the container should undeploy the module.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
634,"the shell distribution zip is missing hadoop26 libraries the spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries so we get the following exception when starting the shell: exception in thread ""main"" java.lang.noclassdeffounderror: org/apache/hadoop/conf/configuration",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
635,as a pm i'd like to have test coverage for both kafka source and sink modules so that we can assert its functionality as part of the ci builds.,5,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
636,prepare blog post for m1,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
637,no way to remove a job from job repository if its gone from job definitions i am trying to deploy a job i destroyed after running a few times. i removed all the jobs using job all destroy. when i try to recreate the same name job it is saying it already exists. jobcontroller.java save() method is throwing the exception if job exists in job repository database but they are gone from job definition list. these jobs were originally created using xd template rest client dynamically but that should not make any difference. this leaves me in an inconsistent state between xd definitions/job repository. how do i get rid of the job without having to log in to the database and play with the job repository tables. i had to delete data folder for myself to continue development. there should be a force mechanism to recreate a job with the same name a flag that by passes this validation against the repository or overwrites the information in the repository.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
638,as a user i want to be able to provide the partitioning logic for a named destination so that i can control the ordering of outbound messages.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
639,create sample module projects create one or more sample module projects in the spring xd examples repo to serve as templates for spring xd module projects. similar to https://github.com/dturanski/sidslmodule these should include unit and single node integration tests and demonstrate the use of spring xd build and packaging tools and other module development support. this may be split out into separate tasks but should include a sample for source processor sink and job using @configuration or xml configuration (either as separate samples or using build profiles).,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
640,restrict job launcher with more than one batch job configured in job module currently the job launcher launches all the batch jobs configured in the job module. please refer modulejoblauncher's executebatchjob(). this makes the jobregistry registers with multiple batch jobs under the same spring xd job name (group name). also it is understood that having multiple jobs configuration under the same config xml is uncommon.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
641,as a developer i'd like to certify spring xd against phd 3.0 so i can synchronize with the latest odp based bits.,3,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
642,dsl needs to have wildcard support for taps wildcard support for associating inbound and outbound channels with modules. the wild card will be represented by an asterisk '*'. example: myemailsource > tap:job:* send message to all jobs myemailsource > tap:* send message to all stream/job taps myemailsource > :*foo* send message to all channels that contain the channels that contains the word 'foo' tap:*bar > myemailsource,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
643,"filesourcetest needs to apply label to source and sink * currently acceptance filesource acceptance tests are failing ** this is because the sink that tests the result for the file source test is a filesink. both use the ""file"" token. thus causing a failure * simplefilesource and simplefilesink needs to support a label method. * update testfilesource to use the labels.",0,1,0.0026434442400932313,1.6666666666666672,0,0,0,1,0
644,rabbit sink acceptance tests,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
645,ensure xd samples share common version dependencies currently samples use separate build scripts so the xd versions etc. may all be different. there should be a top level build script or at least a way to ensure the same version dependencies,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
646,add create() and deploy() methods to tapdeployer see https://docs.google.com/a/gopivotal.com/drawings/d/1kcnbvsprbjgc10itf9cskwst8wgcjgg3wgzfkqlcazu/edit,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
647,design and budget perf env for xd on rackspace provide design for how we are going to run xd and kafka on rackspace. this includes the base design for the kafka perf tests environment. this will be used to provide a budget for the cloud resources for the performance environment.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
648,admin should fail immediately if rabbit is not running container currently does that.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
649,refactor to use restoperations the current implementation makes use of cf-java-client which is relatively heavy for our needs. it should be removed in favour of a bespoke restoperations wrapper. see https://github.com/zteve/test-cc-oauth for sample code.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
650,"add to acceptance test ec2 ci build plan a stage that uses xd distributed mode with rabbit see https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements ""stages are comprised of one or more jobs which run in parallel"" we would like the tests across the rabbit and redis transport to occur in parallel.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
651,esper based complex event processing module i would like to see a module created that supports complex event processing. i have reviewed gemfire continuous query but was not able to find a feature for time windows. i have used esper in the past for this type of processing.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
652,"map column names with underscore to camelcase style keys for jdbc sink we need to add support for matching column names with underscores like ""user_name"" and map them to camel case style keys like ""username"" in the jdbcmessagepayloadtransformer.",0,4,0.0027609235048294068,1.6666666666666672,0,0,0,1,0
653,fix hardcoded redis port from tests kparikh-mbpro:spring-xd kparikh$ grep -r 6379 * | grep java spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/common/redisrepositoriesconfig.java: cf.setport(6379) spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/gaugehandlertests.java: cf.setport(6379) spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/richgaugehandlertests.java: cf.setport(6379) spring-xd-dirt/src/test/java/org/springframework/xd/dirt/listener/rediscontainereventlistenertest.java: cf.setport(6379),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
654,as a user i'd like to upgrade spring xd from 1.2 rc to 1.2 ga using the ambari plugin so i can work on the latest release bits. i'd like to refer to the documentation to do so.,1,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
655,document tuple data structure on xd wiki,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
656,"configuration conflict when using ""--transport"" ""local"" ""--store"" ""redis"" ""--disablejmx"" ""true"" ""--analytics"" ""redis"" results in both in-memory and redis based definitions of richgaugeservice - can't satisfy autowiring because there are two candidates. had to change --analytics=memory to get the application context to load.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
657,tuplebuilder.fromstring() should not overwrite original id and timestamp fields when converting a json string to a tuple the json may contain id. this method should handle this. same with timestamp,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
658,add a sqoop example,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
659,as a user i want to know how to enable and configure ldap as an authentication provider for the administration server so that i can set up my security configuration accordingly.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
660,as a developer i'd like to upgrade to reactor 2.0 rc1 release so that we can synchronize with stable dependencies.,4,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
661,ui - setup sauce labs integration we should have a facility to easily test the e2e protractor tests against a variety of common browsers including ie. sauce labs seems to be the service to use.,0,0,0.0025889062881469726,8.333333333333332,1,1,0,1,0
662,as a user i'd like to refer to documentation in wiki so that i can setup and configure kafka as a message bus as recommended.,2,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
663,"improve module deployment distribution when a container joins the xd cluster (via zookeeper) it triggers stream/job module deployments for modules that need to be deployed. if multiple containers are being started at around the same time this can result in the first few containers taking all of the deployments while leaving the rest without any deployments. to solve this we will introduce a ""quiet period"" where no deployments will be triggered within _n_ seconds of a container joining where _n_ will have a default value (perhaps 5 to 10 seconds). this value will be configurable.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
664,"ui: list of streams causes ""undefined is not an option"" see screenshot. the error is caused when loading all stream definitions in method *loadstreamdefinitions*. only 1 or two streams exist in the system.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
665,simplify/refactor ui controllers the ui controllers in spring-xd/spring-xd-ui/app/scripts/controllers.js definitions look overly complicated to get the modularization work. we can possibly refactor and make it look clean especially we will follow this as the example for subsequent controllers definitions.,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
666,update sink's gemfire section to use shell commands instead of curl see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#gemfire,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
667,add tasklet to stream from (s)ftp to hdfs,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
668,on specific shutdown scenarios the stream resumes from the start of the bus topic https://github.com/spring-projects/spring-xd/issues/1727,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
669,define developer-facing interfaces for spark streaming modules,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
670,as a qa i'd like to include acceptance test coverage for _mail_ source module so that i can validate the functionality as part of every ci build.,3,5,0.0026218307018280027,1.77251607550301,0,1,0,0,0
671,tests sporadically fail when checking send counts with rabbit as transport tests that use verifysendcounts to validate whether data was sent to all the modules in a stream occasionally fail. this is because sometimes it takes 2 or more sends to get the data transmitted between modules. with the current test structure this is considered a failure. is this the correct behavior?,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
672,have a version of get /modules that returns full info similar to the detailedmoduledefinitionresource that is returned when querying a single module but would be returned when listing (provided a ?full flag has been turned on),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
673,set default hadoop name node for shell currently you have to set the default name node every time your start the shell. we should do 2 things: - provide a default name node set default hadoop name node for shell: hdfs://localhost:8020 - should we provide some form of persistence? it kind of sucks that you have to re-specify the name node every time the shell starts up {code} xd:>hadoop fs ls / you must set fs url before run fs commands {code},0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
674,create a shell command processor and sink create processor and sink modules that can execute a shell command using stdin and stdout to stream data.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
675,as a user deploying xd on yarn i need a convenient way to get info like the admin port for my current deployment. best way for now would be to add an info command to the xd-yarn script. with the latest changes the admin server runs on a random port when we deploy to yarn. in order for the user to connect they would have to query zookeeper. this is inconvenient.,4,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
676,develop tasklet to execute a job h2. narrative as the system i would like a way to launch a previously deployed job module from another job module. h2. back story for the composed job story we will have a driver job that consists of each step that represents the execution of a job. this story is the creation of a {{tasklet}} that will launch the child job and upon it's completion set the results of the driver's step to that of the slave job's results.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
677,add ui screen shots to docs for new features in alpha * stepexecutioncontext * stepexecutionprogress * jobscheduler * stream page * job definition (xd1615),0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
678,"handling jobexecution stop action if the jobexecution is completed currently the flag ""stoppable"" on jobexecutioninforesource is used to find if the jobexecution can be stopped. since this flag is set to true even if the jobexecution status is completed the jobexecution can still say it can be stopped.",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,0,0
679,illegalstateexception when deploying orphaned stream modules upon a matching container arrival upon a matching container arrival if there are orphaned stream modules to be deployed then following exception is thrown: java.lang.illegalstateexception: container missing at org.springframework.util.assert.state(assert.java:385) at org.springframework.xd.dirt.core.streamdeploymentspath.hasdeploymentinfo(streamdeploymentspath.java:275) at org.springframework.xd.dirt.core.streamdeploymentspath.build(streamdeploymentspath.java:233) at org.springframework.xd.dirt.server.containerlistener.getcontainersforstreammodule(containerlistener.java:337) at org.springframework.xd.dirt.server.containerlistener.redeploystreams(containerlistener.java:278) at org.springframework.xd.dirt.server.containerlistener.onchildadded(containerlistener.java:186) at org.springframework.xd.dirt.server.containerlistener.childevent(containerlistener.java:155),0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
680,as a s-c-s developer i'd like to setup ci builds for s-c-s builds so i can incrementally build and test code commits automatically.,3,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
681,use parentlastclassloader to create the modules applicationcontext. the parentlastclassloader is located in the spring-hadoop project. it will resolve classes first looking at the child context and then the parent. this works well for xd since the we want and dependencies of the module to be considered first and if not found resolve against the parent. it would be possible to even include other versions of .jars already in the parent classloaders (e.g. spring integration jars) but for now we will not immediately test that case. simplemodule needs to change to that we can pass in the classloader to use for creating the application context. the current implementation creates a genericapplicationcontext as a field initializer...that should change to be in the ctor. moduledeployer should implement .beanclassloaderaware. the classloader passed in to the beanclassloaderaware callback will be used as the ‘parent’ when creating the parentlastclassloader. the url[] to pass into parentlastclassloader should be ‘null’ or an empty array in this case of an older style module. (hopefully parentlastclassloader allows that type of fallback). *implementation suggestions:* the moduledeployer code is where the application context for the module is defined and instantiated. here is a possible impl path. 1. assuming we can always use parentlastclassloader (even for older style modules) then the moduledescriptor needs to return an array of url[] locations for the module geturl(). this is passed into the cto for simplemodule. the ctor then creates a new application context creates the parentclassloader sets the classloader on the application context and then proceeds as normal. 2.abstractmoduleregistry should try and load the resource from two possible locations e.g. ./modules/source/file/config/file.xml or ./modules/source/file.xml the module registry needs to be a bit smarter to know ah i see a config directory let me try ./config/file.xml otherwise just ./file.xml *how to verify it works.* 1. junit test in which one of the moduleregistry implementations points to a test directory that contains both old and new style modules. filemoduleregistry is probably a good choice here. need to test that the new getting for url[] works as expected. 2. existing tests should run as they did before in particular the shell integration tests.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
682,as a user i'd like to see the version and spi type in the `about` section so i can confirm which build of {{admin-ui}} i'm currently using.,1,5,0.0026218307018280027,1.6666666666666672,0,1,0,0,0
683,format option to display runtime module properties in shell the runtime module properties requires a format option when displayed in the shell based on the pr (https://github.com/spring-projects/spring-xd/pull/340) the module properties are stored as string and displayed as is.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
684,switch capital_letters to system.property style in application config,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
685,create an aggregate counter an aggregate counter rolls up counts into discrete time buckets. there is an existing poc implementation in java based off the library https://github.com/thheller/timed-counter the readme there has a good description of the desired feature set.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
686,exclude slf4j transitive dependencies,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
687,update to spring-data-hadoop 2.0.0.m4 update dependencies to spring-data-hadoop 2.0.0.m4,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
688,investigate why netty 3.7 is in xd/lib and not 3.6.6,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
689,refactor test cases to move away from inheritance model of utility methods for streams counters model the api more akin to springxdoperations api.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
690,as a s-c-d user i'd like to have the option of {{gemfire}} spi so i can use {{gemfire}} and the infrastructure to orchestrate s-c-d data microservices.,5,3,0.005275634825229645,1.6666666666666672,0,1,0,1,0
691,refactor containerregistrar decouple from deploymentlistener. make dl a public class to handle deployment related events. remove createsimplemodule() and createcomposedmodule() from dl. this will be delegated to moduledeployer which will eventually be further refactored to use the proposed modulefactory.,0,4,0.0027609235048294068,1.6666666666666672,0,0,0,0,0
692,consider a shared project for pojos that are shareable betweed model and rest layer,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
693,enable --refresh-dependencies into be present when executing gradlew this could be inside gradlew or a .settings file.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
694,"./xd-container --transport local throws numberformatexception ./xd-container [ok] ./xd-container --transport redis [ok] ./xd-container --transport rabbit [ok] ./xd-container --transport local [fail] wkoh-mbp:bin administrator$ ./xd-container --transport local exception in thread ""main"" org.springframework.beans.factory.beancreationexception: error creating bean with name 'org.jolokia.jvmagent.spring.springjolokiaagent#0': invocation of init method failed nested exception is java.lang.numberformatexception: for input string: ""${xd.jmx.port}"" org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.initializebean(abstractautowirecapablebeanfactory.java:1488) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:524) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:461) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:295) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:223) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:292) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:194) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:626) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:932) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:479) org.springframework.xd.dirt.server.containermain.launch(containermain.java:89) org.springframework.xd.dirt.server.containermain.main(containermain.java:72) caused by: java.lang.numberformatexception: for input string: ""${xd.jmx.port}"" java.lang.numberformatexception.forinputstring(numberformatexception.java:48) java.lang.integer.parseint(integer.java:449) java.lang.integer.parseint(integer.java:499) org.jolokia.jvmagent.jolokiaserverconfig.initconfigandvalidate(jolokiaserverconfig.java:211) org.jolokia.jvmagent.jolokiaserverconfig.init(jolokiaserverconfig.java:84) org.jolokia.jvmagent.jolokiaserverconfig.<init>(jolokiaserverconfig.java:68) org.jolokia.jvmagent.spring.springjolokiaagent.afterpropertiesset(springjolokiaagent.java:78) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.invokeinitmethods(abstractautowirecapablebeanfactory.java:1547) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.initializebean(abstractautowirecapablebeanfactory.java:1485) ... 11 more",0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
695,support composed module deletion provided it is not currently used in any stream: v) attempt to destroy a composed module should not be supported at all should not be supported if involved in at least one stream (eb? mf!) should be supported and have no other consequences whatsoever (see iv) (eb?) should be supported and invalidate/destroy streams involving it,0,1,0.0026434442400932313,1.6666666666666672,0,0,0,0,0
696,as a s-c-d developer i'd like to document [running on cloud foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in readme so it can be publicly available as deployment guideline.,2,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
697,parameterize syslog source add support for tcp the syslog source currently is hard-coded to use udp on port 11111. need to parameterize the port and provide an option to use tcp.,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,0,0
698,investigate running xd on cloud foundry,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
699,allow user to configure tests with di with the addition of sinks and sources that require connections with external entities (hadoop jms jdbc ...) the environment setup is getting unwieldy. * integrate springjunit4classrunner.class into acceptance tests. * retrieve environment variables via dependency injection from application.properties. * utilize profiles for --local single node --local cluster --ec2 single node --ec2 cluster,0,5,0.0026218307018280027,1.6666666666666672,0,0,0,1,0
700,create subproject spring-xd-machine-learning-analytics-jpmml using the jppml evaluator provide an implementation of the core abstractions in the spring-xd-machine-learning. the initial code for this has been developed in a separate github repo and is located here https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics-jpmml/src/main/java/org/springframework/xd/analytics/model/jpmml,0,3,0.005275634825229645,1.6666666666666672,0,0,0,1,0
701,with security - unable to upload module once security is enabled one cannot upload modules using the shell any longer.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
702,add xmpp sink,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
703,display an aggregate counter,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
704,filejdbc job throws exception during acceptance tests currently the testfilejdbcjobmultipleinvocations fails on line 156 stating data is different in table that what is expected. currently this is failing on the single admin/container deployment using redis as a transport. also seeing the following exception in the attached log: {noformat} 2.0.0.snap error xdbus.job:ec2job3.0.requests-1 step.abstractstep - encountered an error executing step step1 in job ec2job3 org.springframework.batch.item.itemstreamexception: failed to initialize the reader ... caused by: java.lang.illegalstateexception: input resource must exist (reader is in 'strict' mode): url [file:/tmp/xd/output/filejdbctest/filejdbctest1.out] {noformat} the file is should be present and data present for the test. at least according to the checker on ec2 and local deployments.,0,0,0.0025889062881469726,1.6666666666666672,0,1,0,1,0
