issuekey;doc_clean;adj_storypoint
XD-1695;As a user I'd like to have the option to provide security configurations so that I can access REST endpoints in a secured manner.     Ideally all the listed [REST|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] endpoints needs to be wrapped within a security layer.     *Scope of this spike:*    * Research Spring Security and Spring Boot and the OOTB features   * Design considerations and approach for XD  * Developer experience  ** How users will be configuring security credentials?  ** How DSL shell will be handled?  ** How Admin UI will be handled?;8
XD-1746;As a developer I'd like to have an OOTB MVC-aware HTTP module (with embedded tomcat) so I can use this module to leverage spring-mvc and spring-security features instead of rewriting them within the existing HTTP source module.   * Adds richer support for content-type in the HTTP Source module. See [~jbrisbin] comments: https://github.com/spring-projects/spring-xd/pull/879.  * Adds full header mapping in the source (see comments)  * See SO request: http://stackoverflow.com/questions/29353471/spring-xd-as-a-rest-endpoint;8
XD-2055;As a user I should be able to leverage native _ElasticSearch_ sink so that I can aggregate search and analyze data insights in real-time.;8
XD-2088;As a developer I'd like to have the option of extending the Trigger abstraction so that I can implement my own trigger.;8
XD-2103;As a user I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.;8
XD-2104;As a result of fixing XD-2015 we still cannot execute:  {code} grunt test:e2e {code}  Basically running the tests AND the server together in one process fails. We see the following error: *Fatal error: socket hang up*.  If we separate the protractor execution into 2 separate steps the tests pass:  {code} grunt serve (one console window) grunt protractor:run (second console window) {code}  In the *grunt serve* window you can still observe *Fatal error: socket hang up* being printed out but the tests execute successfully.;8
XD-2121;As a user I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner.    Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within LDAP based security layer.    Reference:  [Authentication using LDAP|https://spring.io/guides/gs/authenticating-ldap/];8
XD-2122;As a user I'd like to have the option to configure default access control for endpoints so that I can grant access by _Admin_ or _Viewer_ roles.;8
XD-2125;As a user I would like to have an option to write data into HBase sink so that I can perform random realtime read/write access on Big Data.;8
XD-2126;As a user I'd like to have the option to write into _File Roll_ sink so that I can store events on the local file system.;8
XD-2135;"As a user I'd like to have the option to explicitly define/configure ""error channel"" so that I can stage and route the errors/exceptions through the dedicated channel and continue ingestion.  *Scenario:* * 'http' source ingest  * failure at either source processor or sink module * regardless of whether it is a custom module or not traverse through the exception to propagate the actual _Caused by:..._ stage the error as payload and route it to the error channel  *Example Configuration:* * error channel definition similar to ""topic.errors.stream.module"" * configure custom exception similar to ""catch=**Exception"" * exception hierarchy ** GlobalException ** DefaultException ** ModuleSpecificException";8
XD-2154;As a user I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don't have to manually move and set it up.    *Scope of this spike:*  * Assess customer requirement brainstorm and document options  * Socialize with the team to collect feedback  * Identify phases  * Create new stories;8
XD-2159;"As a user I need a ""production-ready' Docker Image so that I can use that as a baseline to deploy XD with the following setup.  * Ubuntu OS * Full XD Jar * Java 7.x";8
XD-2163;As a user I need the ability to configure Docker XD Containers so that I can link to external services such as _Rabbit Redis Zookeeper Hadoop Mongo etc_.  Includes pointers to: * Linking/binding attributes * Environment variables;8
XD-2164;As a user I want to configure Docker XD Containers using Service Discovery so that I can have tools to manage how processes and services in a cluster can find and talk to one another.;8
XD-2165;As a user I need to have the ability to create docker images via CI build so that I can build all the components/configurations I need into a Docker image test it and deploy the image to various environments.;8
XD-2166;As a user I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework.;8
XD-2178;As a user I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.;8
XD-2205;As a user I'd like to have a _Python_ processor so that I can efficiently perform data computations and statistical analysis.     Investigate the right approach (native or via stdin/stdout) that fits Spring XD model.    [Integrate Java and Python|https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#Java];8
XD-2206;As a user I'd like to have a _R_ processor so I can efficiently perform data computations and statistical analysis in the context of streaming pipeline.   Investigate the right approach that fits Spring XD model.  *R Java Libraries* [rJava|http://rforge.net/rJava/] [Renjin|http://www.renjin.org/];8
XD-2218;As a user I'd like to define security definitions so that I can configure entity (REST API) specific group/role access policies.;8
XD-2219;As a user I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via DSL Shell.  *Examples:* * Who can create streams? * Who can destroy the streams? * Who can view the streams? ??(defaults to all)??;8
XD-2220;As a user I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via Admin UI.    *Examples:*  * Who can create streams?  * Who can destroy the streams?  * Who can view the streams? ??(defaults to all)??;8
XD-2288;As a user I'd like to have the ability to access the random port (generated by tomcat) of the admin server (via _xd-shell_) so that I can point to the server and continue my interactions.   *Spike Details:* * Research whether connecting _xd-shell_ directly to ZK is a good approach or have a LB in-charge for the interaction. * How about something other than a pointer to a ZK directory in the shell for folks to experiment a bit before getting a LB involved?  *Note:* On some hadoop/hdfs setups access to zk is mandatory from hdfs client libs. There are some HA and federation setups which would anyway require xd shell to get access to zk if fs shell commands are used.;8
XD-2295;As a user I'd like to stream ingest audio and video data so that I can apply predictive analytics algorithms for facial detection.  *Spike scope:* * Research the feasibility of implementing [Motion-JPEG|http://en.wikipedia.org/wiki/Motion_JPEG] * Design specs on Motion-JPEG format  *Note:* [opencv|http://docs.opencv.org/trunk/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html] although having OOTB support it is not platform compatible.;8
XD-2304;As a user I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.    *Spike scope*:  - Study simple consumer API functionality  - Document findings approach and next steps;8
XD-2306;As a user I'd like to push the custom module (built as uber-jar) via a REST API so that I can install the custom module in cluster.;8
XD-2308;As a user I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka.    Consider:  * Kafka as message bus  * Kafka as source;8
XD-2311;As a user I'd like to have a _generator_ source module so that I can create a number of messages of a specified size (similar to Rabbit's PerfTest utility).  Example: generator --numMsgs 10000 --msgSize 1024 --numThreads 1;8
XD-2312;As a user I'd like to have a _perf-meter_ sink that will collect and push metrics to the standard container log file.    Example: perf-meter --numMsgs 1000  Will write to the container log a timestamp message count and message rate every 1000 messages.  The message rate is the value since the last log event.  Default values are those specified above.;8
XD-2313;As a user I'd like to create a stream such as _generator | perf-meter_ so that I can ingest 1M messages of 1000 bytes and one thread using XD's 'singlenode' container and measure performance characteristics.;8
XD-2333;As a PM I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds.;8
XD-2358;As a user I want to be able to control the starting offset of the Kafka source when a stream is deployed so that I can replay a topic if necessary.    Note:  - starting offset is only considered when the stream is deployed  - progress made by modules must survive their crash for a running stream  - undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start     TBD: what happens when streams are undeployed/redeployed - where do they resume from?;8
XD-2359;As a user I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed so that I can colocate with other data sources.;8
XD-2360;As a user I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesn’t take place.;8
XD-2361;As a user I want Spring XD’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed.;8
XD-2368;As a continuation we would like to further investigate Spark develop POC and identify the best appropriate design and implementation for XD.;8
XD-2375;As a user I'd like to have a _reactor-stream_ processor module so that I can ingest data using XD source modules and process them as time-window operations.     *Example 1:*  http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=minavg    This would give you 10 second time window of the min and avg values.    *Example 2:*  Reactor as a module    *Example 3:*  Integration with Spark streaming and reactor;8
XD-2382;As a developer I'd like to setup a performance testing infrastructure (rackspace) so I can start benching Kafka baselines and continue with XD use-cases.;8
XD-2388;As a user I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers.;8
XD-2398;As a user I should be able to leverage native _WebSocket_ sink so that I can take the advantage of full-duplex communications channels over a single TCP connection.;8
XD-2475;As a user I'd like to have the option to setup _batching_ so that I can ingest data in batches as opposed to payload-at-a-time.;8
XD-2477;As a user I'd like to have the option to _stop_ an existing Sqoop job so that I can clean-up resources at the time of completion.;8
XD-2511;As a user I'd like to have a separate _YML_ file to list the deployment manifest properties so that I don't have to include as part of the stream definition.;8
XD-2514;As a user I'd like to have the option of _compression_ for both Rabbit _source_ and _sink_ modules so that can further enhance the performance characteristics.;8
XD-2538;As a user I'd like to have an option to disable DB requirement so that I can setup to use DIRT runtime when stream processing is the only requirement.;8
XD-2542;As a user I'd like to have a flexible RxJava module so that it can as a processor.;8
XD-2543;As a user I'd like to have the option to define access control list (ACLs) so that I can define access controls to the resource by 'each user' and what the privileges are for that 'resource'.    *Spike Scope:*  ** Review customer use cases and come up with design specs  ** Identify the best approach that fits XD runtime  ** Identify scope for DSL and UI   ** Document next steps and phases;8
XD-2548;As a performance tester I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks.     *Scope:*  * Identify the bottlenecks  * Document reasons  * List pros/cons;8
XD-2566;As a developer I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.;8
XD-2615;"As a tester I'd like to add test coverage for ""complex objects"" such protocol buffers any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics.";8
XD-2664;As a developer I'd like to build _Spark Streaming_ as data processors in XD so that we can demonstrate some of the capabilities.    *Implement using:*  * Java / Java Lambdas  * Scala;8
XD-2672;As a scala developer someone could easily deploy the spark streaming module developed using scala.;8
XD-2701;As a developer I'd like to build _Spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.;8
XD-2702;As a developer I'd like to build data pipeline using _Kafka_ as as message bus in XD so that we can demonstrate some of the capabilities.  *Use case to consider:* * Log aggregation and analysis * Lambda architecture ** how to avoid code duplication ** how to eliminate tight coupling of business logic ** how Kafka can be used for reliable reprocessing;8
XD-2703;As a developer I'd like to build batch sample using _Sqoop_ so that we can demonstrate some of the capabilities.  *Use cases to consider:* * JDBC to HDFS * HDFS to JDBC;8
XD-2704;As a consequence   * change gradle script regarding generation of documentation  * remove pushGeneratedDocs task etc  * remove link rewriting that is no longer needed;8
XD-2713;As a field engineer I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint.;8
XD-2714;As a field engineer I'd like to have a comparison of Spark Streaming examples in Spring XD so that it is easy to relate from implementation standpoint.;8
XD-2715;As a PM I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.;8
XD-2716;As a developer I'd like to create a example to demonstrate JDBC to HDFS data movement.;8
XD-2724;As a user I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.;8
XD-2734;As a field engineer I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.;8
XD-2737;"As a user I'd like to have an optional _trace_ as inline deployment properties for _stream_ so that I can declare which _module_ in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.  *Example:*  {code:xml} xd:> stream create foo ""http | log""  xd:> stream deploy foo --properties ""module.http.tracemodule.log.trace""  (or)  xd:> stream deploy foo --properties ""module.*.trace"" {code}  Wildcard wiretap config: http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap";8
XD-2738;"As a user I'd like to have an optional  arbitrary ""side channels"" created so that when creating a module channels other than the primary stream channels (input output) could be added to the bus (i.e. creating a tap channel *within* a flow). The optional ""side channels"" can be used to trace/track module progress.";8
XD-2742;As a developer I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.    [Challenge Details|http://www.debs2015.org/call-grand-challenge.html];8
XD-2747;As a developer I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.;8
XD-2766;As a user I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).;8
XD-2776;As a developer I'd like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance.     I'd like to reproduce baseline performance metrics as identified by the Kafka [engineering team|https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines].;8
XD-2793;As a developer I'd like to fix the offset management with Kafka _source_ module so that I can efficiently perform fetch operation from the given offsets.;8
XD-2795;As a developer I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.;8
XD-2796;As a PM I'd like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf. benchmarks and ref. architectures so that it's easy for anyone to quickly get up and running on XD.;8
XD-2802;As a developer I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc.;8
XD-2835;As a developer I'd like to continue XD-on-Lattice/Diego PoC and will be focused on the design of a pluggable SPI so it is more generally applicable than Lattice with the Receptor API being just one implementation option.;8
XD-2839;As a developer I'd like to host/read Python script (file) from HDFS so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.;8
XD-2840;As a developer I'd like to rebalance partitions as we scale the containers so I don't have to bring down the running stream/job to reestablish dynamic partitions.;8
XD-2844;As a user I'd like to have the OOTB _gpfdist_ sink module so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.;8
XD-2857;As a developer I'd like to remove Hadoop dependencies from root classpath so we don't have to incur the penalty of classloading unnecessary libraries at the startup time.    The goal is to at least try and decouple for situations when HDFS is not used for module registry.;8
XD-2877;As a pre-requisite for XD-2835 and a continuation of XD-2671 split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.;8
XD-2890;As a user I'd like to have the option to read the file line by line so I get the optional OOTB optimum file reading experience.;8
XD-2897;As a user I'd like to have the OOTB module to consume database changes as event streams so I can incrementally synchronize with real-time DB updates with various destinations such as Brokers Hadoop DB etc.;8
XD-2901;As a developer I'd like to deploy a stream in the same container so all modules are colocated within the container. Perhaps also consider building leader election within modules in order to automatically failover the application (stream) from one container to another.;8
XD-2911;As a developer I'd like to bench test cases around {{TupleBuilder}} so I can identify the bottlenecks and tune for performance optimizations.;8
XD-2913;As a developer I'd like to have a simplified UX around parameters for GPDB so I don't have to escape each parameter. The scope is also to test the Sqoop job with SQLServer and GPDB to identify the UX differences.;8
XD-2914;"As a developer I'd like to migrate module deployment from the ""repository"" abstraction (used for stream/job definitions) so I can create it as a pluggable runtime SPI.";8
XD-2915;As a developer I'd like to build isolated Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without the hard requirement for running _xd-containers_.;8
XD-2916;As a developer I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor so I can interact with Diego runtime via Receptor API calls from XD.;8
XD-2917;As a developer I'd like to refactor stream/job definition repository so I can decouple from module deployment concerns.;8
XD-2958;As a developer I'd like to upgrade to Kafka 0.8.2 so I can leverage the latest features in order to test the performance characteristics.;8
XD-2961;As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Note:  1.1.1 > Benched against 0.8.1   1.2 > Benched against 0.8.2;8
XD-2962;As a developer I'd like to document performance benchmark results along with the infrastructure specifics so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.;8
XD-2964;As a developer I'd like to study the state management requirements so I can brainstorm and identify the design to natively add _stateful_ stream processing support in XD.;8
XD-2965;As a developer I'd like to integrate with Spring Data repository that's backed by Kafka _changelog_ so I can leverage the benefits of local data affinity (off-heap) in order to run stateful stream processing logic.;8
XD-2966;As a developer I'd like to add support to _flush_ offsets intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;8
XD-2967;As a developer I'd like to add support to _flush_ state intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;8
XD-2979;As a user I'd like to use the Java receptor client so I can interact with Diego runtime using the Java receptor REST APIs.;8
XD-2980;As a user I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without _xd-containers_.    Scope:  * Complete the remaining deployment properties work;8
XD-2986;As a follow up to XD-2877 experiment with the removal of the list of modules from BaseDefinition and reparse as needed.    Branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2;8
XD-2993;As a Flo developer I'd like to have a new DSL parser so I can easily  detect incorrect module/option values when supplied from the Flo UI.    Example:  MyStream = mail | log  tap:stream:MyStream.bar > log    If parsed separately (which Flo UI does) the current parser endpoint will barf on the second stream because it doesn’t know about the first stream (MyStream).;8
XD-3044;As a user I'd like to have an OOTB _jdbcgpfdist_ batch job so I can read from JDBC and write to HAWQ/GPDB using _gpfdist_ protocol.   The scope is to reuse the existing gpfdist sink code and adapt it to fit the batch model (_gpfdist_ writer).;8
XD-3045;As a developer I'd like to separate mocks vs. real repository coupling from the test infrastructure so it is easy to test against thin layer of dependencies.;8
XD-3071;As a developer I'd like to bench Rabbit on rackspace infrastructure so I can have a sense on how it scales as we add more _xd-container_ nodes.;8
XD-3099;As a user I'd like to have the option to gracefully shutdown the stream so when it is _undeployed_ while in the middle of its operation we would want to complete its journey to the sink before XD stops the stream.    *Use case:*  One of the streams has a custom module that performs archive extraction. When this stream is ‘undeployed’ while in the middle of extraction It looks like the message goes to the DLQ. However we would like the message to complete its journey to the sink of the queue before xd stops the stream. Is this possible?;8
XD-3102;As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Sinks to be included in test:  In-Memory Transport > Hdfs sink  Direct Binding Transport > Hdfs Sink  Kafka > Hdfs Sink;8
XD-3166;As a developer I'd like to publish performance benchmarks along with the infrastructure specifics so the users can use it as a reference while setting up Spring XD cluster.;8
XD-3169;As a developer I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.;8
XD-3192;As a user I'd like to have the module/app specific metrics consumed directly from Boot actuator [export()|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java] API so I can have insight on how it is performing being used and that it works etc.;8
XD-3193;As a developer I'd like to handle module options via pure boot property source management so I can leverage Boot's module [METADATA|http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core Spring XD runtime CP.;8
XD-3194;As a developer I'd like to have a central place to manage external properties for applications across all the environments so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers.;8
XD-3195;As a developer I'd like to troubleshoot the performance issues with Rabbit as message bus implementation so I can isolate the bottleneck and fix as appropriate.;8
XD-3196;As a developer I'd like to migrate the current MASTER branch CI builds to EC2 instances so I can manage them all in one-place reliably.;8
XD-3198;As a developer I'd like to use spring-cloud-config server for spring-bus modules so I can centrally manage external properties.;8
XD-3199;"As a developer I'd like to split up spring-xd dependencies to more fine-grained so I can get the ones ""below the line"" down to spring-bus-* instead of spring-xd-* bundle.";8
XD-3202;As a developer I'd like to investigate channel performance issues in SI 4.2 so I can determine the bottlenecks and take corrective actions to improve overall channel performance.;8
XD-3224;As a developer I'd like to move message-bus from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;8
XD-3225;As a developer I'd like to move 'input/output type conversion' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;8
XD-3226;As a developer I'd like to move 'serialization codec' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;8
XD-3227;As a developer I'd like to develop a “singlenode�? (in a single JVM) implementation of XD Admin SPI (based on Module Launcher) so I can run data pipeline use-cases locally.;8
XD-3228;As a Spring XD user I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF Lattice/Diego.;8
XD-3229;As a s-c-s user I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.;8
XD-3233;As a developer I'd like to create an annotation ({{@EnableModule}}) driven programming model for modules so instead of explicitly defining I/O channels as beans on the module for classes annotated with {{@EnableModule}} the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.    The {{@Input}} and {{@Output}} annotations will be used to indicate the input and output channels of the module.;8
XD-3256;As a developer I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo so I could define the module {{artifactId}} from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.;8
XD-3265;As a Spring XD user I'd like to use {{CloudController}} based implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF.    Relevant repos: [spring-cloud-data|https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers] | [spring-cloud-stream|https://github.com/spring-cloud/spring-cloud-stream]    Please refer to XD-3194 or XD-3229 as sample spike-deliverables (_google doc_) that were completed in the last sprint.;8
XD-3268;As a Spring XD on CF user I'd like to use {{cloudController}} implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics.  *Possible APIs:* {code}  ModuleStatus getStatus(ModuleDescriptor descriptor)  Collection<ModuleDescriptor> listModules()  Map<ModuleDescriptor.Key ModuleStatus>  {code};8
XD-3290;As a Spring XD user I'd like to have [IPython Notebook|http://ipython.org/notebook.html] integration so I can perform interactive data computations in real-time.;8
XD-3292;As a Azure user I'd like to read/write data from Azure Event Hubs. so I can leverage the pub-sub service to process and analyze large volumes of data.;8
XD-3293;As a Spring XD user I'd like to have IPython Notebook integration so I can perform interactive data computations in real-time.;8
XD-3309;As a s-c-s user I'd like to have the option to direct bind _modules_ so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.;8
XD-3314;As a s-c-d developer I'd like to invoke REST APIs via shell so I can validate {{StreamController}} operations.;8
XD-3317;As a s-c-s developer I'd like to investigate the right approach to include external library as dependency (ex: MySQL) so I can decide better handling of libraries which needs loaded and available in root CP at the runtime.;8
XD-3344;As a s-c-d developer I'd like to implement _undeploy_ operation for {{singlenode}} (single JVM) so I can use this target to undeploy a running stream. More details in [this PR|https://github.com/spring-cloud/spring-cloud-data/pull/19].    *Note:* Its a prerequisite to determine consistent _undeploy_ strategy for both {{jobs}} and {{streams}}.;8
XD-3355;As a s-c-d developer I'd like to collaborate with Boot engineering team and derive a strategy for module metadata via {{@ConfigurationProperties}} so I can implement the functionality to support {{shell}} {{autocompletion}} {{flo}} and {{ascii}} documentation in _spring-cloud-data_.     Eric's [gap analysis|https://docs.google.com/document/d/1A-9RpgSNL6SXD61q9eW2YRkrkn3tXk09rdkx7eCKlxY/edit#] document captures all the specifics in detail.;8
XD-3378;As a Spring XD user I'd like to use the latest releases of {{HDP}}/{{PHD}} distros so I can leverage the latest features to create pipelines involving {{HDFS}}.;8
XD-3389;As a Spring XD user I'd like to use redis/sentinel cluster as the 'message bus' so I could create streams and batch pipelines.;8
XD-3419;As a s-c-d developer I'd like to create {{ModuleRegistry}} implementation so I can use this infrastructure to lookup module coordinates by name.;8
XD-3425;As a s-c-d developer I'd like to have {{module info}} {{module list}} {{module register}} and {{module unregister}} commands so I can interact with {{ModuleRegistry}}.;8
XD-3430;As a s-c-d developer I'd like to provide optional key-value pairs as deployment properties so I could leverage them at the runtime to instruct how the modules will be deployed.   _The scope of this story is to specifically support {{count}} to represent {{N}} instances of modules that share the same environment variables._;8
XD-3447;As a s-c-d developer I'd like to produce ref. documentation for s-c-d architecture so I could define 1.x and 2.x deployment differences.;8
XD-3486;As a s-c-d developer I'd like to add support for having different binder types for module's channels so I can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.;8
XD-3488;As a s-c-d developer I'd like to refactor CC SPI deployer with CF java-client so I can improve the overall design and performance.;8
XD-3512;As a s-c-s user I'd like to have {{Gemfire}} message-channel binder so I can use {{Gemfire}} as the messaging middleware for low latency use-cases.;8
XD-3513;As a s-c-d user I'd like to have the option of {{Gemfire}} SPI so I can use {{Gemfire}} and the infrastructure to orchestrate s-c-d data microservices.;8
XD-3514;As a s-c-d user I'd like to have the option of {{Gemfire}} as stream repository so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.;8
XD-3515;As a s-c-d user I'd like to have the option of {{Gemfire}} as module registry so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.;8
XD-3624;As a s-c-d developer I'd like to break the build lifecycle to bundle SPI deployers individually so I don't have to build {{admin}} with all the deployer variations as one whole thing.;8
XD-3635;As a developer I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family so I can continuously evaluate functionalities on every commit.;8
XD-3649;As a user I'd like to use SpEL expressions inline at the stream definition level so I can operate on the payload consistently while using any OOTB including the custom modules.;8
XD-923;As a user I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream/module.;8
XD-1864;"As a user I'd like to have _paging_ support so that I can scroll through the list of streams jobs and containers.     Currently the following error is thrown when we cross >20 rows:    http://localhost:9393/jobs/definitions.json    JSON Response:  {code:xml}  [  	{  		links: [ ]  		logref: ""IllegalStateException""  		message: ""Not all instances were looked at""  	}  ]  {code}    Stack trace:  {code}  15:51:21931 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at    org.springframework.util.Assert.state(Assert.java:385)  {code}";5
XD-2120;As a user I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner.    Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within file based security layer.    Reference:  [Securing Web App|https://spring.io/guides/gs/securing-web/];5
XD-2124;As a user I'd like to have the ability to mass-ingest data from various database systems so that I'm not restricted with the current approach (_jdbchdfs_) that is dependent on JDBC drivers.     *Spike Scope:*  * Identify integration options  * Collaborate to determine the design  * Document outcome (design specs);5
XD-2129;As a user I'd like to have an option of _AWS_ source module so that I can ingest data from Amazon S3 or use the Simple Email Service (SES).  *Reference:* [Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws];5
XD-2131;As a user I'd like to have the option of _AWS_ sink so that I can write data into S3 directly.   *Reference:* [Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws];5
XD-2133;As a user I'd like to have the option of _SOLR_ sink so that I can perform full-text indexing and search through SOLR backend server.;5
XD-2136;"As a user I should not be allowed to create a custom module with a _reserved_ keywords so that I it will avoid confusions from seeing duplicate strings in deployment manifest.  *Example:* We would like to avoid a _custom_ module name of *producer* to eliminate the confusion below: {code}  xd:>stream deploy --name test1 --properties ""module.producer.producer.deliveryMode= PERSISTENTmodule.log.criteria=groups.contains('group1')""  {code}  [List of available reserved keywords|https://github.com/spring-projects/spring-xd/wiki/Deployment#deployment-properties]";5
XD-2137;"As a user I'd like to retain the data partitioning state so that when I restart the containers I continue to write based on the original partitioning strategy.   Currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different _hashCode()_.  *Design consideration:* Mine through the container info to derive the ""partition index"" instead of relying on _hashCode()_.";5
XD-2145;As a user I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth    Technical implementation:    Add ---password and --username to the admin config command.;5
XD-2158;As a user I need a 'sandbox' Docker Image so that I can get started to experiment XD deployment with the following setup:    * Ubuntu OS  * Full XD Jar  * Java 7.x  * Redis  * RabbitMQ;5
XD-2207;As a user I would like to have an option to write data into _Hive_ sink so that I can query and manage large datasets in distributed storage.;5
XD-2226;As a user I'd like to have the flexibility to change the namespace so that I can isolate ZK _metadata_ based on each _tenant_ profile.;5
XD-2228;As a user I'd like to type the _username_ and _password_ to gain access to Admin server so that I don't have to add it in some file hence I don't have to worry about having the password getting logged somewhere.;5
XD-2230;As a user I'd like to leverage _propertieis-location_ parameter while using *Filter* or *Transform* modules so that I can load the user-defined properties included in the external properties file.     Attempting to include the _propertieis-location_ attribute errors out - refer to the attachment.    It could also be beneficial to load user-defined properties through stream definition similar to deployment properties.    Example:  --script=myscript.groovy --variables=foo=bargoo=gaz;5
XD-2268;As a developer I'd like to have a maintenance branch so that I can commit MINOR release _(ex: 1.0.2)_ code changes instead of committing to MASTER.;5
XD-2298;As a user I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.;5
XD-2376;"As a user I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput.     *Example:*  ""http --batchInterval=10 | log""";5
XD-2401;As a developer I'd like to include the following improvements as part of the EC2 CI infrastructure so that we can reliably run the CI builds and also assert over feature functionalities.    *Scope:*  * Enable 'distributed jvm test'  * Change from using artifactory gradle task to a command task (that calls ./gradlew)  * Test w/ embedded hadoop off  * Turn on maxParallelForks;5
XD-2403;As a build manager I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds.     *Scope:*  * Use the environment where Bamboo is running  * Gain access to powershell   * Setup services (redis rabbit etc.)  * Kick-off CI task;5
XD-2420;As a user I'd like to have a common shared location so that I can place the dependent jar's that are required by 2 or more custom modules.   *Current Recommendation:* * Place the dependent jar under xd/lib folder * if it necessary to support different versions of jar's then bundle it in custom module to get around the _classloader_ problem if a older/newer version exist in xd/lib;5
XD-2453;As a QA I'd like to include acceptance test coverage for _shell_ sink module so that I can validate the functionality as part of every CI build.;5
XD-2456;As a QA I'd like to include acceptance test coverage for _spark-app_ batch job so that I can validate the functionality as part of every CI build.;5
XD-2462;As a QA I'd like to include acceptance test coverage for _Kafka_ as a message bus so that I can validate the functionality as part of every CI build.;5
XD-2478;As a user I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively.   We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.;5
XD-2479;As a user I'd like to incremental-data-load so that I can retrieve only rows newer than some previously-imported.;5
XD-2480;As a QA I'd like to benchmark _Sqoop_ vs. _jdbchdfs_ batch job so that I can compare and contrast performance stats.;5
XD-2501;As a XD Admin I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features bug-fixes and enhancements.     *Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:*    <activemq.version>5.10.0</activemq.version>  <aspectj.version>1.8.4</aspectj.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <h2.version>1.4.182</h2.version>  <hibernate.version>dd4.3.7.Final</hibernate.version>  <hibernate-validator.version>5.1.3.Final</hibernate-validator.version>  <hikaricp.version>2.2.5</hikaricp.version>  <hornetq.version>2.4.5.Final</hornetq.version>  <httpasyncclient.version>4.0.2</httpasyncclient.version>  <httpclient.version>4.3.6</httpclient.version>  <jackson.version>2.4.4</jackson.version>  <janino.version>2.6.1</janino.version>  <jetty.version>9.2.4.v20141103</jetty.version>  <jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version>  <joda-time.version>2.5</joda-time.version>  <jolokia.version>1.2.3</jolokia.version>  <junit.version>4.12</junit.version>  <liquibase.version>3.3.0</liquibase.version>  <log4j.version>1.2.17</log4j.version>  <log4j2.version>2.1</log4j2.version>  <mockito.version>1.10.8</mockito.version>  <mongodb.version>2.12.4</mongodb.version>  <mysql.version>5.1.34</mysql.version>  <reactor.version>1.1.5.RELEASE</reactor.version>  <reactor-spring.version>1.1.3.RELEASE</reactor-spring.version>  <servlet-api.version>3.1.0</servlet-api.version>  <spring.version>4.1.3.RELEASE</spring.version>  <spring-batch.version>3.0.2.RELEASE</spring-batch.version>  <spring-data-releasetrain.version>Evans-SR1</spring-data-releasetrain.version>  <spring-hateoas.version>0.16.0.RELEASE</spring-hateoas.version>  <spring-mobile.version>1.1.3.RELEASE</spring-mobile.version>  <spring-security.version>3.2.5.RELEASE</spring-security.version>  <tomcat.version>8.0.15</tomcat.version>  <undertow.version>1.1.1.Final</undertow.version>;5
XD-2515;As a user I'd like to have the option of _batching_ for the Rabbit _sink_ so that I can write data in batches as opposed to one-at-a-time.;5
XD-2557;As a developer I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.;5
XD-2597;As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.    Best way for now would be to add an info command to the xd-yarn script.    With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.;5
XD-2614;As a user I'd like to have Google's [Protocol Buffer|https://code.google.com/p/protobuf/] codec option so that I can serialize/deserialize objects based on its native specifications.;5
XD-2630;As a developer I'd like to use Ambari plugin so that I can provision manage and monitor Spring XD cluster using the same tool I use for Hadoop clusters.;5
XD-2636;As a user I'd like to either use _sql_ or _tableName_ options so that I can build a partitioned job with _where_ clause and strict table-column combo respectively.;5
XD-2656;As a user I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.;5
XD-2661;As a user I'd like to build XD in Windows machine so that I can develop test  and contributed to OSS.;5
XD-2666;As a developer I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits.     The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.;5
XD-2794;As a developer I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.;5
XD-2797;As a developer I'd like to continue Lattice/Diego POC so that I can identify the scope risks and the overall design for a pluggable SPI in XD runtime.;5
XD-2821;As a developer I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors.     This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality hence the current workaround with XD-2486 needs reafctored.;5
XD-2832;"As a developer I'd like to create a custom job module using Java Config so that I don't have to deal with XML configurations. While deploying/launching the following job I get the error attached below.    {code:xml}  job create --name CDK_Global --definition ""customBatchJob"" --deploy  module upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jar  job launch --name CDK_Global  {code}    *Error:*  I'm getting an exception that the job doesn't exist asking if it's deployed";5
XD-2843;As a Spring XD user I want to have the ability to customize the encoders and decoders used by the Kafka source sink and bus so that I can customize data formats and choose the most appropriate strategy;5
XD-2845;As a developer I'd like to setup UI infrastructure so I can integrate admin_ui and Flo.;5
XD-2850;As a developer I'd like to use an efficient approach to read files so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content.     Would the _tasklet_ approach be better as opposed to transmitting data via message bus (as streams)?;5
XD-2852;As a developer I'd like to create a _gpload_ tasklet so I can ingest data from various sources into GPDB in an efficient manner.;5
XD-2858;As a developer I'd like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1).     (0):  {code}  /lib/*.jar:lib/${distro}/*.jar  {code}    (1):  {code}  ${xd.home}/lib/hadoop/${distro}/*.jar  {code}    *Example:*  {code}  http | hdfs --distro=PHD22    http | myCustomModule --classpath=/my/funky/dir    http | jpa --provider=eclipse    jpa:  /config/  /lib/something-that-is-common.jar      /eclipse/eclipse-link-3.2.jar      /hibernate/hibernate-core-5.0.jar    module.classpath = /lib/*.jar:/lib/${provider}/*.jar  {code};5
XD-2879;As a developer I'd like to add support for explicit partition count configuration so I can use this option to cleverly route the payload to the intended consumer (module).;5
XD-2880;As a developer I'd like to add support for dynamic partition subscription for the Kafka source module so I can consume the payload from dynamic partitions.;5
XD-2883;"As a user I'd like to have an option to have the hdfs sink not use a temporary inUseSuffix like .tmp. Instead we should write using the filename specified directly. This could be useful if we use ""Syncable"" writes and the sink fails while the file is open. Without this new option the user would have to explicitly rename the file.";5
XD-2889;As a user I'd like to have the option to version the custom modules so I can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.;5
XD-2907;As a developer I'd like to have the XD + Kafka POC published in samples repo so I can include it as reference architecture for the XD blog.;5
XD-2918;As a developer I'd like to define pluggable runtime SPI so I have the option to choose the implementation based on deployment targets such as CF on-prem Mesos etc.;5
XD-2919;As a developer I'd like to create persistent repository for streams so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.;5
XD-2930;As a developer I'd like to configure HADOOP_USER_NAME environment variable to implement and run-as-user for kerberos secured clusters. This would need some additional work in SHDP.;5
XD-2934;As a user I'd like to parameterize CodeGen Options so I can generate code on the fly as needed.;5
XD-2935;As a user I'd like to parameterize Merge Options so I can incrementally consume the delta with the help of megastore.;5
XD-2938;As a user I need to use XD Sqoop module to support the merge command.  Currently the SqoopRunner createFinalArguments method forces the requirement for connect username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred;5
XD-2947;As a user I'd like to have the ability to use expressions so I can dynamically name directories/files based on the timestamp or other intermediate data point.;5
XD-2955;As a developer I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.;5
XD-2990;As a user I'd like to have the option of reliable HDFS writes (for stream pipelines) so I can get acknowledgement of actual HDFS _commits_ as opposed to just from the message bus.;5
XD-2991;As a developer I’d like override the partition function within my source or processor module so I can send the data to a specific partition.;5
XD-2996;As a developer I want that the Spring XD partitioning process targets Kafka bus partitions directly so that the design of my stream processing application is easier to understand and the order of messages is not altered    Current situation  - Spring XD partitioning logic that builds on top of Kafka partitioning  - The number of Spring XD partitions is not explicitly configured (it's inferred from the number of consumer modules)  - If the concurrency of the consumer modules is 1 then Spring XD partitions are matched 1:1 with Kafka partitions  -  If the concurrency of the consumer modules is n then a Spring XD partition uses n Kafka partitions and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions  - this could be confusing to the end user especially if they are used to the Kafka partitioning process  - this can also lead to changes of ordering between messages as messages within the same Spring XD partitions will be sent to different Kafka partitions (this only happens if the concurrency of the receiving module is higher than 1)    Improvement:  - *For the Kafka message bus* the number of Spring XD partitions does not need to be equal to the number of modules (must be higher or equal though so that consumers can be created) and should be configured explicitly - using the `partitionCount` property - (as an option the module count * concurrency can be used as a default)   - as a result in the case of Kafka there will always be a 1:1 match between Kafka partitions and Spring XD partitions optionally processed by fewer modules than the partition count;5
XD-2997;As a developer I'd like to design and document the approach towards deploying stream in a single container so I can have all modules within a stream colocated.;5
XD-2998;As a developer I'd like to handle the non-default {{ConfigurableConversionService}} tuples in an uniform manner so they're not reset after deserialization.;5
XD-3020;As a user I would like the ability to undeploy or suspend a module without losing the deployment properties.  Currently when temporarily suspending a module an undeploy and redeploy is executed.  During the redeploy the deployment properties need to be added again.  Instead it would be nice if the properties are persisted so they automatically included with the deployment.;5
XD-3024;As a user I'd like to have a REST-API to get all the _counters_ _gauges_ and _rich-gauges_ in a single request so I don't have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.    *Example:*  {code}  /metrics/counters/all (fetches all available counters)  /metrics/gauges/all (fetches all available gauges)  /metrics/rich-gauges/all (fetches all available rich-gauges)  {code};5
XD-3040;As a user I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without _xd-containers_.    Scope:  *;5
XD-3057;As a devops I would prefer having my module registry located in centralized github repository. This would allow all the admins and containers in the cluster pointing to the same module registry. Any new module upload would be pushed to the same github repo which will make the cluster always be in sync on the Module Registry.;5
XD-3144;"As a developer I would like to be able to configure which exceptions thrown by a module should be retryable within the {{RabbitMessageBus}}.  As usual these should be configurable at the bus and/or stream deployment property level.  Also consider disabling retry for kryo deserialization problems. ----  We are running Spring XD with RabbitMQ transport and we'd like to have a way to stop retries in certain situations. In [Spring XD 1.2.0.RC1 docs|http://docs.spring.io/autorepo/docs/spring-xd/1.2.0.RC1/reference/html/] in chapter about RabbitMQ transport in ""A Note About Retry"" section it's written:  {quote}Message deliveries failing with a MessageConversionException (perhaps when using a custom converterClassName) are never retried the assumption being that if a message could not be converted on the first attempt subsequent attempts will also fail.{quote}  Following is unclear: # Are we speaking about {{org.springframework.messaging.converter.MessageConversionException}} or {{org.springframework.amqp.support.converter.MessageConversionException}}? Based on XD-1597 and AMQP-390 it's the latter. # Only {{org.springframework.messaging.converter.MessageConversionException}} is available for custom module developers. Attempting to throw {{org.springframework.amqp.support.converter.MessageConversionException}} which is provided by {{$XD_HOME/lib/messagebus/rabbit/spring-amqp-1.4.5.RELEASE.jar}} results in {{java.lang.ClassNotFoundException}} even after Spring XD is configured to use {{rabbit}} transport. # Throwing  {{org.springframework.messaging.converter.MessageConversionException}} from custom processor module written with Spring Integration's {{transformer}} or {{service-activator}} doesn't stop retries.";5
XD-3197;As a developer I'd like to add an option to support Apache Ambari installed Spring XD on YARN so I can easily establish the cluster up and running.;5
XD-3200;As a user I'm trying to delete the custom module using the {{module delete}} command via shell though the command is successfully I'm still seeing the associated artifact (_.jar file_) present in the custom_modules folder. Refer to [SO thread|http://stackoverflow.com/questions/30984922/springxd-module-delete-command-does-not-delete-the-uploaded-jar-file] for more details.;5
XD-3203;As a developer I'd like to measure the baseline serialization characteristics in XD so I can determine the areas of performance improvements.;5
XD-3204;As a spring-bus lead I'd like to review the current spring-bus architecture and the design specs so I can address any foundation level gaps.;5
XD-3215;As a user I'd like to have the option to specify system properties that will be passed in to the Sqoop job which runs in it's own Java process. This is needed for defining memory usage and also for defining some options for various connector implementations.;5
XD-3217;As a user I'm trying to connect to {{xd-admin}} server with basic security enabled however I'm unable to successfully connect to the server and I get the following error message.      {code:java}  server-unknown:>admin config server --uri http://localhost:9393 --username bob --password bobspwd  Unable to contact XD Admin Server at 'http://localhost:9393'.  {code};5
XD-3231;As a developer I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers so it is setup for HA.;5
XD-3267;As a Spring XD on CF user I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics.    *Possible APIs:*  {code}    ModuleStatus getStatus(ModuleDescriptor descriptor)    Collection<ModuleDescriptor> listModules()    Map<ModuleDescriptor.Key ModuleStatus>    {code};5
XD-3270;As a Spring XD developer I'd like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.;5
XD-3273;As a s-c-s user I'd like to have the modules self-register itself with {{Eureka}} whenever they're installed so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines.;5
XD-3277;As a Spring XD developer I'd like to refactor current controller with SPI calls so I can invoke the respective Admin SPI implementation based on the deployment.     *Controllers to Refactor*  * ContainersController  * StreamsController  * ModulesController  * JobsController;5
XD-3278;As a Spring XD user I'd like to capture module (aka: {{cf apps}}) metrics directly so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently there are two different ways we could consume this information from applications. SI's {{channel()}} and SBoot's {{actuator()}} APIs are the few to explore as part of this scope.;5
XD-3284;As a Spring XD user I'd like to persist module (aka: {{cf apps}}) metrics directly so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently SBoot's {{export()}} API allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). This could be something to explore as part of this scope.;5
XD-3287;As a user I'm trying to setup HA cluster using Ambari installed Spring XD however I'm running into issues with the overrides. More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].;5
XD-3288;As a s-c-s developer I'd like to setup a CI workflow to build bundle and upload the {{module-launcher}} image to DockerHub so I don't have to worry about having a local-private docker registry for development/testing.    It could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] DockerHub location.;5
XD-3310;As a s-c-d developer I'd like to establish the foundation to expose REST-APIs to interact with the {{xd-admin}} and likewise perform CRUD operations to maneuver streaming and batch pipelines.;5
XD-3313;As a spring-cloud-data developer I'd like to use an in-memory stream definition repository so I don't have to spin up a store obviously this will not persist between application executions but it will be useful for a simplified development experience.;5
XD-3316;As a s-c-d developer I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data] so I can build the project continuously on every commits.;5
XD-3318;As a s-c-s developer I'd like to _bootify_ {{ModuleLauncher}} so I can use Spring Boot's support for property setting as well as adding options and new functionality in the future such as CP augmentation.;5
XD-3319;As a s-c-s developer I'd like to investigate the right approach to port {{PHD}} as the provider to support {{HDFS}} module from XD so I can decide better handling of HDFS dependencies which needs loaded and available in root CP at the runtime.;5
XD-3320;As a s-c-d user I'd like to add REST support for stream commands so I can maneuver streaming pipeline backed by StreamController.;5
XD-3337;As a s-c-d developer I'd like to investigate how to include/exclude msg bus/binding jars so I can decide the binding selection and fallback mechanism when there is none setup.;5
XD-3353;As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.;5
XD-3381;"As a module author I want to be able to test my code in ""next to real world"" conditions (ie Integration Testing but not really):  - I want all my module wiring to be testable  - I want all my module configuration (@ConfigurationProperties) to be in effect and I want to be able to test various combination of props  - I want to be able to send data to my module and assert what is coming at the other end  - I want an idiomatic way of asserting the above (eg integration with Hamcrest etc)  - I DONT want to have to send data to an actual bus (redis rabbit etc)";5
XD-3405;As a s-c-d developer I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader so I have an approach to handle external libraries required by OOTB modules.;5
XD-3412;As a Spring XD developer I'd like to port SFTP module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;5
XD-3414;"As a s-c-d developer I'd like to create a new project to contain all the rules associated {{@RedisRule}} contract so it is isolated from core functionalities and reusable by test coverage as needed.      Consider moving this coverage to SI ""commons"" or equivalent.";5
XD-3416;As a s-c-d developer I'd like to create foundation to support _processor_ as OOTB modules so I can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.;5
XD-3444;As a s-c-d developer I'd like to setup {{gh_pages}} branch for s-c-d and s-c-s-m repos so I can start pushing documentation with PR commits.;5
XD-3478;"As a XD developer I'd like to explore repository options for ""composed jobs"" so I have the leverage to read/write composed job definitions.";5
XD-3479;As a XD user I'd like to orchestrate composed jobs so I can bring multiple jobs into single workflow and operationalize.;5
XD-3480;As a s-c-d developer I'd like to add test coverage to test {{shell}} commands in isolation so I don't have to run end-to-end full stream deployment based functional tests.    More details [here|https://docs.google.com/document/d/18uNqRAgVGO0BHdvDsVg3X78gDBeqXA_LN_C6jJ0YpKw/edit#].;5
XD-3481;As a s-c-s developer I'd like to support XD-like features where modules bind to incoming messages via expressions or other mechanism so I can bind message properties to every microservice modules.;5
XD-3482;As a s-c-s-m developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.   See also XD-2250;5
XD-3489;As a s-c-d user I'd like to have the option to choose Hadoop distribution of choice so I can load the right Hadoop libraries in the CP.;5
XD-3498;As a s-c-d developer I'd like to enhance integration test coverage for {{YARN}} SPI so I can continuously evaluate functionalities via CI pipeline.;5
XD-3504;As a s-c-s user I'd like to have the option to use more than one binder connection factory so I can mix and match where I consume and publish data.     More details [here|https://github.com/spring-cloud/spring-cloud-stream/issues/140].;5
XD-3534;As a Spring XD developer I'd like to move {{hdfs-dataset}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;5
XD-3563;As a developer I want to have a {{BinderFactory}} abstraction so that I can support multiple binder types in the future.;5
XD-3564;As a developer I want to be able to connect to multiple types of transports in an application so that I can receive and send messages to different transport types.;5
XD-3565;As a developer I want to be able to connect to multiple external systems for the same binding type so that I can read data from a system and write it to another.;5
XD-3571;As a Spring XD developer I'd like to move {{cassandra}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;5
XD-3572;As a Spring XD developer I'd like to port {{analytic-pmml}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;5
XD-3580;As a s-c-d developer I'd like to explore options to bootstrap and setup Lattice based infrastructure for s-c-d's bare metal deployment.;5
XD-3609;As a data scientist I'd like to have the option to process data using {{flink}} processor so I can take advantage of the streaming machine learning abstractions implemented on top of Flink.;5
XD-3618;As a s-c-d user I'd like to have {{runtime info}} as shell command so I can use this to list the details about the module such as {{host}} {{port}} and the like.;5
XD-3644;As a developer I'd like to enhance test coverage to capture DSL and XML generation variants.;5
XD-3659;As a developer I'd like to split {{admin}} artifact packaged with hadoop distro specific libraries so I could avoid adding all variations of hadoop libraries under one project.;5
XD-3660;As a developer I'd like to create separate repo for YARN SPI so I don't have to bundle all SPI variants under one admin project.;5
XD-3661;As a developer I'd like to upgrade to {{0.6.0}} release of Lattice so I can demonstrate data flow on the latest Lattice improvements.;5
XD-3670;As a developer I'd like to revisit the existing design and identify known limitations and/or the gaps.;5
XD-3671;As a user I'd like to have direct shell commands to scale up/down a given module instance so I can avoid SPI specific CLI commands that needs run outside of data flow.;5
XD-3673;As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629] we would want to fix this experience for Kafka message bus.;5
XD-3692;As a developer I'd like to optimize YARN deployer so I can deploy stream and the modules part of the definition rapidly.;5
XD-3705;As a developer I'd like to upgrade Boot and Spring Cloud Build revisions so I can leverage the latest updates.;5
XD-3715;As a developer I'd like to move k8s SPI to it's own repo.;5
XD-434;As a user I'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics.    *Notes:*  * Spring-AMQP {{RabbitAdmin}} now has a {{getQueueProperties()}} method which returns the number of consumers so it may be possible to use it for this purpose.  * Consider the possibility of _producers_ and/or _queues_ still containing data  * Consider the scenario even after the topics/queues are cleaned-up what to do with fanout exchange?    *Some Further Thoughts*  * Consider using the upcoming Spring AMQP REST API {{RabbitManagementTemplate}} if the timing is not right we could temporarily invoke the rabbit REST API directly.  * Should be optional perhaps via {{stream destroy foo --clean}}  * Should this be done by the admin? Or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange since we undeploy left->right everything can be cleaned up on the consumer side.  * Third option would be new methods on the bus {{cleanConsumer}} etc invoked by the {{StreamPlugin}}  * Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so we'd need the admin url(s) for the cluster.;5
XD-1149;As a system administrator I need to connect to SonicMQ as jms provider    When setting up the correct spring xml file and added the correct jar files to the lib directory I received the following exception---      Question: is there a spot I should be defining the conversion strategy?    {code}    .   ____          _            __ _ _   /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \  ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \   \\/  ___)| |_)| | | | | || (_| |  ) ) ) )    '  |____| .__|_| |_|_| |_\__ | / / / /   =========|_|==============|___/=/_/_/_/   :: Spring Boot ::             (v0.5.0.M6)    15:04:36092 ERROR http-bio-9393-exec-1 rest.RestControllerAdvice:157 - Caught exception while handling a request  org.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)    org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)    org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:137)    org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:157)    org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:242)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:947)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:878)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:946)    org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:848)    javax.servlet.http.HttpServlet.service(HttpServlet.java:647)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:822)    javax.servlet.http.HttpServlet.service(HttpServlet.java:728)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)    org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionFactory' defined in file [/Users/dmarley/sandbox/spring-xd/build/dist/spring-xd/xd/modules/source/jms/config/../../../common/jms-sonic-infrastructure-context.xml]: Initialization of bean failed nested exception is org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory' nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:300)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:296)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:660)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:552)    org.springframework.boot.SpringApplication.run(SpringApplication.java:293)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)    org.springframework.xd.module.SimpleModule.initialize(SimpleModule.java:135)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:239)    org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:229)    org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:214)    org.springframework.xd.dirt.module.ModuleDeployer.handleDeploymentRequest(ModuleDeployer.java:196)    org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:137)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  	... 63 more  Caused by: org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory' nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found    org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:474)    org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:505)    org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:499)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1497)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1192)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)  	... 81 more  Caused by: java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy found    org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:267)    org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:459)  	... 87 more    {code};4
XD-1720;As a consequence of not fixing XD-1289 we should document keys of the form ${xd.stream.name} that are available to users    ${xd.[stream|job].name} and ${xd.container.???} come to mind there may be others;4
XD-1906;As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)    Ideally I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients.;3
XD-2123;As a user I'd like to have the option of _kerberized_ HDFS sink so that I can leverage Kerberos (open source distributed authentication system) for secured data writes into Hadoop.;3
XD-2127;As a user I'd like to have the option of _JMX_ source module so that I can publish/subscribe to JMX notifications.  *Reference:* [Sprint Integration JMX Support|http://docs.spring.io/spring-integration/reference/html/system-management-chapter.html#jmx];3
XD-2128;As a user I'd like to have the option of _WebSocket_ source module so that I can create a interactive communication channel between user's browser session and the runtime to ingest browser based events and activities.  *Reference:* [Spring Integration WebSocket Support|https://github.com/spring-projects/spring-integration/tree/master/spring-integration-websocket/src];3
XD-2130;As a user I'd like to have the option of _Cassandra_ sink so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.;3
XD-2132;As a user I'd like to have the option of _HAWQ_ sink so that I can write data directly into HAWQ via PXF extensions through Avro/Parquet format.;3
XD-2169;As a user I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren't any side effects or impacts to existing functionalities.;3
XD-2179;As a user I'd like to have the option of _HDFS_ source module so that I can ingest data directly from HDFS file system.;3
XD-2180;"As a user I'd like to override the default ""commit-interval"" so that I can configure commit interval depending on data volume.    *Note:*  This would apply for all OOTB jobs that has partition support. The property could be part of _servers.yml_ file.";3
XD-2216;As a user I'd like to have Spring 'Core' upgraded to 4.1.1 (_milestone_ ) so that I can benefit from performance improvements associated with 'compiled' SpEL and other enhancements.;3
XD-2269;As a follow-up action from module registry refactoring we would have to clean-up deprecated functions _(ex: download of module definitions)_ within our codebase.     It may also be necessary to clean-up Shell and Admin-UI modules.;3
XD-2293;As a follow-up to Kafka message bus support we would like to rerun the failing tests after upgrading to new [consumer|https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design] rewrite.   [Response from Kafka support|http://mail-archives.apache.org/mod_mbox/kafka-users/201410.mbox/%3CCAHwHRrWZmLr94eHX1z5i36BYz%2B%3DCisx7GcbW1_Nn7ooNJcShMw%40mail.gmail.com%3E].;3
XD-2383;As a user I'd like to have a Shell command so that I can point to the custom-built _module_ archive and push it to the runtime for immediate usage.;3
XD-2384;As a user I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.;3
XD-2402;As a developer I'd like to investigate the increase in WARN logs so that I can troubleshoot and fix PMD/Sonar violations.  Consider notifying the violations through SONAR configurations. The committer should be notified.;3
XD-2434;As a QA I'd like to include acceptance test coverage for _Mail_ source module so that I can validate the functionality as part of every CI build.;3
XD-2435;As a QA I'd like to include acceptance test coverage for _reactor-ip_ source module so that I can validate the functionality as part of every CI build.;3
XD-2436;As a QA I'd like to include acceptance test coverage for _reactor-syslog_ source module so that I can validate the functionality as part of every CI build.;3
XD-2437;As a QA I'd like to include acceptance test coverage for _SFTP_ source module so that I can validate the functionality as part of every CI build.;3
XD-2438;As a QA I'd like to include acceptance test coverage for _aggregator_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2439;As a QA I'd like to include acceptance test coverage for _analytic-pmml_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2440;As a QA I'd like to include acceptance test coverage for _bridge_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2441;As a QA I'd like to include acceptance test coverage for _http-client_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2442;As a QA I'd like to include acceptance test coverage for _json-tuple_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2443;As a QA I'd like to include acceptance test coverage for both _script_ and _scripts_ processor modules so that I can validate the functionality as part of every CI build.;3
XD-2444;As a QA I'd like to include acceptance test coverage for _splitter_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2445;As a QA I'd like to include acceptance test coverage for _gauge_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2446;As a QA I'd like to include acceptance test coverage for _aggregate-counter_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2447;As a QA I'd like to include acceptance test coverage for _field-value-counter_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2448;As a QA I'd like to include acceptance test coverage for _hdfs-dataset_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2449;As a QA I'd like to include acceptance test coverage for _mail_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2450;As a QA I'd like to include acceptance test coverage for _null_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2451;As a QA I'd like to include acceptance test coverage for _rich_gauge_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2452;As a QA I'd like to include acceptance test coverage for _router_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2454;As a QA I'd like to include acceptance test coverage for _splunk_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2455;As a QA I'd like to include acceptance test coverage for _throughput-sampler_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2457;As a QA I'd like to include acceptance test coverage for _timestampfile_ batch job so that I can validate the functionality as part of every CI build.;3
XD-2471;"As a user I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness    *Things to consider:*  * make global configuration options be ""defaults"" and allow per-deployment overrides  * add options for   ** concurrency  ** compression support";3
XD-2473;As a user I'd like to have the option to _ACK_ messages so that I can guarantee that the message/request sent is successful.;3
XD-2474;"As a user I'd like to have the option to implement _bindRequestor_ and _bindReplier_ so that I can ""bind a producer that expects async replies"" and ""bind a consumer that handles requests from a requestor and asynchronously sends replies"" respectively.";3
XD-2513;As a user I'd like to have the option to _compress_ messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip zip compression and decompression.;3
XD-2523;As a user I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided configure the boot plugin for 'MODULE' layout and other boilerplate build configuration.    This is dependent on Boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187;3
XD-2526;As a QA I'd like to include acceptance test coverage for hdfs-dataset module so that I can validate the functionality as part of every CI build.;3
XD-2527;As a user I'd like to have the option to extend compression support so that I can override the defaults and customize as needed.  Follow-up from this PR: https://github.com/spring-projects/spring-xd/pull/1346;3
XD-2534;As a performance tester I'd like to rerun baseline benchmarks with batching enabled on Rabbit so that I can compare the results with previous performance snapshots.   Note: - batchingEnabled = true - batchingSize = 100 (default)  We could also vary default size to compute and record at granular level.;3
XD-2535;As a performance tester I'd like to re-run baseline benchmarks with compression enabled on Rabbit so that I can compare the results with previous performance snapshots.;3
XD-2550;As a user I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.;3
XD-2551;As a user I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.;3
XD-2552;As a CF user I'd like to have the ability to override the HDFS location so that I can change where the custom module _uber-jar_ can be stored and retrieved.;3
XD-2553;As a CF user I'd like to have the ability to override the YARN config location so that I can change where the custom module _uber-jar_ can be stored and retrieved.;3
XD-2554;As a user I'd like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion.;3
XD-2559;As a user I'd like to have a Redis based _aggregation_ over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.    *Scope:*  * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters].  * Identify gaps  * Update reference documentation;3
XD-2560;As a user I'd like to have a Redis based aggregation over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.  *Scope:* * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters]. * Identify gaps * Update reference documentation;3
XD-2562;As a developer I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon thus eliminating the incorrect CP file generation in eclipse.;3
XD-2590;As a user I'd like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via _servers.yml_ to control the default message size.    *Notes:*  The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. [Related PR|https://github.com/spring-projects/spring-xd/pull/1367].;3
XD-2606;As a user I'd like to have an option to track history so that I get the visibility of stream name module name etc. added as part of the message header.;3
XD-2662;As a developer I'd like to run acceptance test coverage in Windows so that I can evaluate XD functionalities.    The scope is to provision Windows image in EC2 and run acceptance test in the environment. Potentially also try to create this as CI build.;3
XD-2693;As a developer I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience.;3
XD-2699;As a developer I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.;3
XD-2718;As a user I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.;3
XD-2719;As a user I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources.;3
XD-2730;"As a user I'd like to include the deployment manifest from the file so that I don't have spend time typing as ""inline properties"".";3
XD-2757;As a developer I'd like to have the high-level description for each of the modules so that I can use the description (presumably what is captured in javadoc for the module definition) to understand the purpose of the module itself.;3
XD-2784;As a developer I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.;3
XD-2785;As a developer I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.;3
XD-2787;As a developer I'd like to add load generator _source_ module so that I could use it for performance testing use-cases.;3
XD-2788;As a developer I'd like to add load receiving _sink_ module so that I can measure received throughput;3
XD-2805;As a user I'd like to add the Hadoop _namenode_ specifics in a config file so that I don't have to incur the hassle of pointing to the _namenode_ location every time I open a new DSL session but it is automatically configured.;3
XD-2849;As a developer I'd like to create a end-to-end Kafka use-case so I can study demonstrate and verify kafka + xd play that's built for scale and performance.;3
XD-2882;"As a user I'd like to have an option to have the hdfs sink use ""Syncable"" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option.";3
XD-2892;As a developer I'd like to certify Spring XD against PHD 3.0 so I can synchronize with the latest ODP based bits.;3
XD-2896;As a user I'd like to have the configuration option to use an alternative DLQ so I can publish the message this time with additional headers including one that contains the exception (and stack trace).;3
XD-2899;As a developer I would like to connect to the broker that hosts the Rabbit queue so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.;3
XD-2922;As a Spring XD user I'd like to create streaming pipelines so I can take advantage of latest specs from both XD and Spark/Spark Streaming.;3
XD-2936;As a user I'd like to have an option to specify _timeout_ so I can expect the job to not run forever if it is in hung state.;3
XD-2943;As a users I would to be able to execute SQL Statement/Script via a Processor or Job statement.;3
XD-2957;As a developer I'd like to document the Kryo optimization guidelines so the end-users can refer to it while tuning to improve performance.;3
XD-2959;As a developer I'd like to create a Tuple _load-generator_ so I can use it to measure {{Tuple}} based payload performance.;3
XD-2960;As a developer I'd like to create a new _load-generator_ so I can use it to measure highly optimized (kryo serialized) payload to measure the performance differences.;3
XD-2969;As a developer I'd like to have the option of CoAP source module so I can consume data using bandwidth efficient protocol that fits in constrained embedded environment.;3
XD-2973;As a user I'd like to run the sqoop jobs against secured hdfs cluster so I can restrict access to only authorized users.;3
XD-2992;As a user I'd like to consume multiple topic-partitions so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.;3
XD-2999;As a developer I'd like to benchmark a stream with and without {{JMX}} enabled so I can test in isolation and document the differences in performance.;3
XD-3026;As a spring developer I can specify the default value for the module configs at the module config xml file and if no specific overriding options given the default value should get preferred.  Currently I see that by design we want to rely on the default option values from the ModuleOption metadata. But the cases where some module configurations can't have the default (say customerKey for twitterstream module) and would be tempting to just try deploying after changing the twitterstream.xml with the default value expecting it to work.;3
XD-3050;As a developer I'd like to move the project reactor based [data processor module|https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor] from _spring-xd-module_ repo to the core so I can natively use Reactor's Stream API to build processor modules.;3
XD-3061;As a developer I'd like to remove _ID_ and _TimeStamp_ attributes from the {{Tuple}} class so I can improve performance characteristics by not having them go through _serde_ instead we could leverage message headers to collect such information.;3
XD-3072;As a Flo developer I'd like to add improvements to existing Flo parser endpoints so I can streamline the error reporting strategy.;3
XD-3077;As a developer I'd like to default to HDFS as distributed remote location for custom module registry so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.;3
XD-3103;As a developer I'd like to upgrade to 2.0.3 release of Reactor so I can inherit the latest optimizations to further improve XD performance characteristics.;3
XD-3107;As a XD build master I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues so I can evaluate that publish builds works as expected.;3
XD-3164;As a developer I want to be able to override Kafka bus defaults for module consumers and producers so that I can finely tune performance and behaviour.     Such properties should include  - autoCommitEnabledqueueSizemaxWaitfetchSize for consumers  - batchSizebatchTimeout for producers;3
XD-3165;As a PM I'd like to have XD and XD + Ambari RPM scripts into a single public repo so that users can go to a single location to use the respective build scripts.;3
XD-3222;"As a user I would like to connect the Sqoop batch job to Teradata for import jobs.     I have tried the Teradata JDBC driver directly using:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}    but that results in an NPE.    The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz    That one allows me to use the following:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}";3
XD-3223;As a user I would like to be able to configure the logging directory to be outside of what is defined as xd.home. The logging directory is currently hard coded as {code}${xd.home}/logs{code}.    This would be useful for RPM installations where the logs really should be going to `/var/logs/spring-xd` instead of the current `/opt/pivotal/spring-xd/xd/logs` location.;3
XD-3269;As a Spring XD developer I'd like to have a permanent location of SPI implementations so I could use the common repo every time I contribute or enhance the test coverage.;3
XD-3271;As a Spring XD user I'd like to make SPI implementation profile aware so I can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.;3
XD-3281;As a Spring XD developer I'd like to self-register {{xd-admin}} server with {{Eureka}} so I could have admin server exposed as discoverable endpoint.;3
XD-3282;As a s-c-s developer I'd like to setup CI builds for s-c-s builds so I can incrementally build and test code commits automatically.;3
XD-3303;As a user I'd like to refer to documentation while migrating to 1.3 release.;3
XD-3311;As a s-c-d developer I'd like to create {[ModuleRegistry}} stubs so I can create mock streams by interacting with the registry APIs.;3
XD-3312;As a s-c-s developer I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.;3
XD-3315;As a s-c-s developer I'd like to adapt redis {{counter}} from XD to s-c-s so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards.;3
XD-3322;As a s-c-s developer I'd like to setup CI infrastructure for {{spring-cloud-stream-modules}} (s-c-s-m) repo so I can build the project continuously on every commits.;3
XD-3343;As a s-c-s developer I'd like to create a public screencast of {{firehose| counter}} pipe so I can demonstrate s-c-s and the development experience.;3
XD-3348;As a s-c-d developer I'd like to add support for _profiles_ to the core {{Admin}} application so I can back the stream repository with respective backend strategy. For example: {{local}} profile would use in-memory strategy to store the metadata.;3
XD-3350;As a s-c-d developer I'd like to add support to expose counter (metrics) endpoints so I can consume to feed the dashboards to demonstrate {{firehose | counter}} pipe.;3
XD-3357;As a Spring XD user I'm trying to use a custom MongoDB Batch job however I'm getting an error running it against 1.2.0/1.2.1 release while the same works with older releases of Spring XD. More details in this [SO thread|http://stackoverflow.com/questions/31838720/mongodb-batch-job-broken-in-spring-xd-1-2-0].;3
XD-3379;As a Spring XD developer I'd like to create a section on migration strategy from {{1.2}} to {{1.3}} releases so I can document new improvements and backward incompatibility specifics.;3
XD-3393;As a s-c-d developer I'd like to upgrade {{receptor-client}} to comply with latest {{Receptor}} API changes so I can sync-up and take advantage of the recent improvements.;3
XD-3400;As a s-c-d user I'd like to have the option to support passing definition parameters into YARN container so I can effectively use those _params_ within the module running inside the container.;3
XD-3401;As a s-c-d developer I'd like to add support to deploy YARN App into HDFS automatically so I can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.;3
XD-3407;As a s-c-d developer I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader so we could use this as a reference while porting modules with external dependencies.;3
XD-3411;As a s-c-d developer I'd like to move the external library to its own project so we have a clear separation of functionalities in s-c-d repo.;3
XD-3418;As a s-c-s developer I'd like to enable {{offline}} mode for {{AetherModuleResolver}} so I can pull the module artifacts from local instead of remote maven repo.;3
XD-3445;As a s-c-s developer I'd like to fix the {{Kafka}} binder so I can create messaging microservices apps and successfully bind them to an operational Kafka broker.;3
XD-3448;As a s-c-d developer I'd like to study [Concourse CI|http://concourse.ci/] so I can understand how to use it for s-c-d going forward.;3
XD-3454;As a module author I would like to apply RxJava processor module with spring cloud stream.;3
XD-3467;As a s-c-d developer I'd like to add support for hadoop commands in shell so I can use it to query the hadoop file system.;3
XD-3487;As a s-c-d developer I'd like to pass any overrides via external config file so I can influence and override the default module configurations. (ex: module resolution from a different maven coordinate).;3
XD-3493;As a XD developer I'd like to upgrade to SI 4.2 Spring 4.2.1 and AMQP 1.5 dependencies so I can take advantage of the latest improvements.;3
XD-3496;As a s-c-d developer I'd like to enhance integration test coverage for {{Lattice}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3497;As a s-c-d developer I'd like to enhance integration test coverage for {{CC}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3499;As a s-c-d developer I'd like to enhance unit test coverage for {{Lattice}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3500;As a s-c-d developer I'd like to enhance unit test coverage for {{YARN}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3505;As a s-c-d user I'm unable to push admin app to CF due to SSL certification errors while bootstrapping.     Consider adding [CF trusted certificate|https://github.com/pivotal-cf/cloudfoundry-certificate-truster] as a CF SPI dependency.    Adding CF trusted certificate as dependency doesn't help either:    {code}  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.Validator.validate(Validator.java:260)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)  > Fri Sep 25 2015 12:55:32 GMT-...  {code};3
XD-3508;As a XD developer I'd like to refactor and replace {{codec}} code from XD with SI library so I don't have to maintain duplicate code.;3
XD-3581;As a spring-cloud-stream user I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.;3
XD-3595;As a s-c-d developer I'd like to add test coverage for {{StreamController}} so I can verify API contracts at build time.;3
XD-3622;As a developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{source}} module to build streaming pipeline.;3
XD-3629;As a user I'd like to enable HA on {{namenode}} without having to enable custom configuration.     More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].;3
XD-3641;As a developer I'd like to review and refactor {{JobLaunchingTasklet}} so I can improve performance characteristics.;3
XD-3654;As a user I'd like to refer to 'job orchestration' documentation so I can use it as guideline for building batch workflows.;3
XD-3656;As a developer I'd like to add {{undeployed}} status for YARN SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3674;As a developer I'd like to create separate repo for CF SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3675;As a developer I'd like to create separate repo for Lattice SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3676;As a developer I'd like to create separate repo for K8s SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3677;As a developer I'd like to create separate repo for Mesos SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3678;As a developer I'd like to add {{undeployed}} status for CF SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3679;As a developer I'd like to add {{undeployed}} status for Lattice SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3682;As a developer I'd like to add {{undeployed}} status for Mesos SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3684;As a user I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.;3
XD-3702;As a developer I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module so that I can take advantage of the native Kafka partitioning and message ordering support.;3
XD-3714;As a developer I'd like to upgrade Spring XD's ambari plugin to 1.3 release.;3
XD-1132;As a Spring XD user I need to listen on a JMS Topic and ingest the messages so I can process the messages.    Currently the module only allows for Queues;2
XD-2044;As a user I'd like to have the option to use the _SFTP_ source module so that I can access transfer and mange files over any reliable data streams.    *Reference:*  [Spring Integration SFTP Adapter|http://docs.spring.io/spring-integration/reference/html/sftp.html]    Need to consider the infrastructure for testing.;2
XD-2106;As a user I'd like to have the ability to visually explore XD's cluster view so that I'm aware where the components are deployed and how they are connected within the topology.;2
XD-2231;As a user I'd like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository (metadata persistence).     The scope of this task is to have the configuration specifics documented in the wiki.;2
XD-2261;As a user I'd like to have the option to configure permissions so that I'll have the flexibility to bind permissions (REST endpoint) to a specific role.   Default Roles: * Admin (CRUD) * Viewer (R);2
XD-2296;As a user I'd like to have a config parameter preferably in _servers.yml_ file so that I can enable/disable message rates in the cluster view.;2
XD-2347;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended.;2
XD-2652;As a user I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.;2
XD-2673;As a user I'd like to refer to Hive sample so that I can use that as a reference to integrate Hive to query and analyze.;2
XD-2694;As a developer I'd like the {{publish-maven.gradle}} script to use values for dependencies (e.g. Spring Boot and {{hadoop-common}}) from our central dependency list (in this case {{dependencies.properties}}) so that I don't have to update them manually anymore.;2
XD-2698;As a developer I want to have to run Kafka tests on an external broker so that I reduce the footprint of the build process.;2
XD-2762;As a build manager I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA.     *Location for 1.1.0 RELEASE:*  http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/;2
XD-2786;As a developer I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.;2
XD-2815;As a user I'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.;2
XD-2838;As a developer I'd like to update all the module docs to also include _shortDescription_ so that it's available for users to learn more about the module.;2
XD-2888;As a user I'd like to also have the capability to upload the custom module through maven/gradle targets so I can automate the installation of custom module fragments.;2
XD-2900;As a developer I'd like to synchronize with the latest Gemfire version (8.1?) so I can leverage the latest Gemfire features and as well support updated BDS stack.    This effort in XD depends on Spring Data Gosling GA release which in turn depends on Gemfire 8.1 release timelines.;2
XD-2905;As a developer I'd like to complete the remaining work with DEBS challenge so I can submit by the deadline.;2
XD-2906;As a developer I'd like to add a new CI build to include _install_ target so I can verify the target expectations as it is often time consuming to verify it in the development environment.;2
XD-2933;As a user I'd like to parameterize all Import Options so I can eliminate the need for {{—args}} option since it gets confusing.;2
XD-3052;As a developer I'd like to move the project reactor based [gpfdist|https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist] from spring-xd-module repo to the core so I can natively use this sink to write to GPDB/HAWQ.;2
XD-3068;As a user I would like to specify the default output channel when the channel name resolution doesn't occur. In cases where I won't prefer to lose the data and like to investigate the messages from errorChannel or that sort.;2
XD-3110;As a developer I'd like to clean-up compiler and javadoc warnings from the build so we don't see  the warnings in build sysout.;2
XD-3118;As a user I'd like to start multiple instances of {{xd-container}}'s through the RPM scripts so I can easily spin-up instances on the same node/vm.;2
XD-3139;As a user I'd like to refer to the analytics tab docs so I can understand how to use various widgets from streaming pipeline.;2
XD-3239;As a developer I'd like to move 1.2.x branch to EC2 infrastructure so I can reliably run CI test suites.;2
XD-3260;As a developer I'd like to move 'serialization codec' from Spring XD repo into SI so I can update Spring XD to inherit the features/functionalities via maven dependency.;2
XD-3274;As a s-c-s user I'd like to search the modules by it's name aside from the default {{spring.application.name}} offered by boot so I can also fetch modules by it's name.;2
XD-3275;As a s-c-s user I'd like to store module metadata in {{Eureka}} so I can use the repository to determine the current state.;2
XD-3276;As a s-c-s user I'd like to have my modules add/update it's current state to Eureka so I can use the repository to discover the current sate of the module as needed.;2
XD-3283;As a Spring XD developer I'd like to port {{FTP/SFTP}} modules from XD to s-c-s repo so I can use them as {{source}} modules to build streaming pipeline.;2
XD-3338;As a s-c-d developer I'd like to add as many jars via a bom (e.g. hadoop distro deps) so I don't have to explicitly worry about individual but related libraries.;2
XD-3339;As a s-c-d developer I'd like to add support for dependency resolution so when two or more modules use different version of jars (ex: direct binding of two modules that include different versions of spring data) I have the capability to resolve and include the right bits at runtime.;2
XD-3362;As a Spring XD developer I'd like to port {{http}} module from XD to s-c-s repo so I can use it as {{source}} module in streaming pipeline.;2
XD-3363;As a Spring XD developer I'd like to port {{tcp}} module from XD to s-c-s repo so I can use it as {{source}} module to build streaming pipeline.;2
XD-3364;As a Spring XD developer I'd like to move {{twitterstream}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;2
XD-3365;As a Spring XD developer I'd like to move {{twittersearch}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;2
XD-3366;As a Spring XD developer I'd like to port {{filter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3367;As a Spring XD developer I'd like to port {{transform}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3368;As a Spring XD developer I'd like to port {{router}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3369;As a Spring XD developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3370;As a Spring XD developer I'd like to port {{FTP/SFTP}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.;2
XD-3374;As a Spring XD developer I'd like to move {{redis}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3375;As a Spring XD developer I'd like to move {{rabbit}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3376;As a Spring XD developer I'd like to move {{gemfire}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3388;As a Spring XD developer I'd like to move {{trigger}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3397;As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.;2
XD-3403;"As a s-c-d developer I'd like to support multiple app instances:  * This is simply to make controlling app instances more clever. Potentially we could use deployment properties to define different yarn app instances like:    {code}  cloud-data:>stream deploy --name ticktock --properties ""module.*.yarn.app.name=app""     cloud-data:>stream deploy --name ticktock --properties ""module.time.yarn.app.name=app""  {code}    * Motivation to this is that different yarn apps can have different queues and priorities. Yarn administrator can define that some app queues have higher priority to reserve resources from    * Using deployment properties like this allows to customize runtime parameters like how much we try to reserve mem/cpu for modules etc.";2
XD-3404;As a s-c-d developer I'd like to make the deployer work asynchronously so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.;2
XD-3408;As a s-c-d developer I'd like to add support to add external libraries so I can consume such dependencies for modules in an uniform way.;2
XD-3409;As a s-c-d developer I'd like to enforce external libraries from overriding any existing library in the uber-jar.;2
XD-3426;As a s-c-d developer I'd like to have {{module info}} shell command so I can query each of the module specifics such as description and support options.;2
XD-3427;As a s-c-d developer I'd like to have {{module list}} shell command so I can query and list all the modules supported within the {{ModuleRegistry}}.;2
XD-3428;As a s-c-d developer I'd like to have {{module register}} shell command so I can register new modules in the {{ModuleRegistry}}.;2
XD-3429;As a s-c-d developer I'd like to have {{module unregister}} shell command so I can unregister an existing module from the {{ModuleRegistry}}.;2
XD-3463;As a s-c-d developer I'd like to document [Running on Cloud Foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in README so it can be publicly available as deployment guideline.;2
XD-3483;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{source}} to build streaming pipeline.;2
XD-3484;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3485;As a s-c-d developer I'd like to move {{rabbit}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3501;"As a user I'm not able to shutdown {{container}} from Admin UI with the following stream definition deployed.    {code}  stream create swagataTestIssue --definition ""jdbc --query='select employee_id employee_name employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy   {code}    More details [here|https://issuetracker.springsource.com/browse/VESC-504].";2
XD-3523;As a Spring XD developer I'd like to move {{jms}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3524;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3525;As a Spring XD developer I'd like to move {{mongo}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3526;As a Spring XD developer I'd like to move {{mqtt}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3527;As a Spring XD developer I'd like to move {{reactor-ip}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3528;As a Spring XD developer I'd like to move {{stdout}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3529;As a Spring XD developer I'd like to move {{syslog}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3530;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3531;As a Spring XD developer I'd like to move {{tcp}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3532;As a Spring XD developer I'd like to move {{tcp-client}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3533;As a Spring XD developer I'd like to move {{gpfdist}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3535;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3536;As a Spring XD developer I'd like to move {{mongo}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3537;As a Spring XD developer I'd like to move {{mqtt}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3538;As a Spring XD developer I'd like to move {{null}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3539;As a Spring XD developer I'd like to move {{shell}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3540;As a Spring XD developer I'd like to move {{splunk}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3541;As a Spring XD developer I'd like to move {{tcp}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3542;As a Spring XD developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3543;As a Spring XD developer I'd like to port {{aggregator}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3544;As a Spring XD developer I'd like to port {{http-client}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3545;As a Spring XD developer I'd like to port {{json-to-tuple}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3546;As a Spring XD developer I'd like to port {{object-to-json}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3547;As a Spring XD developer I'd like to port {{script}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3548;As a Spring XD developer I'd like to port {{shell}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3549;As a Spring XD developer I'd like to port {{splitter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3593;As a SCDF user I want to be able to register artifacts as libraries so that I can reference them in include and exclude statements.;2
XD-3599;As a s-c-s user I'd like to use {{kinesis}} module so I can use it as {{source}} module to build streaming pipeline.;2
XD-3600;As a s-c-s user I'd like to use {{kinesis}} module so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3602;As a developer I'd like to port {{Log}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.;2
XD-3605;As a developer I'd like to port {{field-value-counter}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3606;As a developer I'd like to port {{aggregate-counter}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3607;As a developer I'd like to port {{gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3608;As a developer I'd like to port {{rich-gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3619;As a s-c-d user I'd like to deploy data flow on YARN so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.;2
XD-3631;As a user I'd like to use the latest release of {{gemfire}} sink so I can create a streaming pipeline to land data in gemfire.;2
XD-3653;As a user I cannot use {{admin-ui}} on the master build. It won't come up.;2
XD-3662;As a developer I'd like to replace all references of Spring XD with Spring Cloud Data Flow.;2
XD-3663;As a user I'm trying to load Job - Modules page in admin-ui but I'm seeing exceptions in console and the page wouldn't load.     {code}  Failed to convert value of type 'java.lang.String' to required type 'org.springframework.cloud.dataflow.core.ArtifactType' nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @org.springframework.web.bind.annotation.RequestParam org.springframework.cloud.dataflow.core.ArtifactType for value 'job' nested exception is java.lang.IllegalArgumentException: No enum constant org.springframework.cloud.dataflow.core.ArtifactType.job  {code};2
XD-3664;As a developer I'd like to replace all {{Job(s)}} references with {{Task(s)}}.;2
XD-3672;As a developer I'd like to submit a PR for existing work on Mesos SPI.;2
XD-3688;As a developer I'd like to be able to clean Rabbit binder broker artifacts using the REST API.    When the Rabbit Bus was ported from XD the bus cleaner was ported as {{RabbitBindingCleaner}} but the REST API to invoke it was not ported over.;2
XD-3732;As a developer I'm adding new overrides to {{server.yml}} file however the overridden properties do not reflect even after the restart of server.;2
XD-2030;As a temporary work around to fix XD-1935 make producible media type to 'application/json' for Job executions GET request endpoints.;1
XD-2090;As a user I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach.     11/20: Update: Scope of this task is to create an example to demonstrate and document the capability.;1
XD-2119;As a user I'd like to have the option to enable HTTPS so that I can access XD's Admin server [endpoints|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] over secured communication.    Technical Implementation:    This functionality is available in Spring Boot 1.2.0 M1 and has been backported into the 1.1.x branch to be released under Spring 1.1.7.  We can test against 1.1.7 SNAPSHOT.    Working through the way to update the build file to pick up a new version of boot is a bit tricky :(;1
XD-2138;As a user I'd like to have the data partition strategy state preserved so that when I add/delete modules they are able to dynamically adapt to the strategy.  This is already included as part of the GA release. This story is to account for the testing effort.;1
XD-2143;As a user I'd like to have the option of _Basic Auth_ so that I'm challenged to provide _user name_ and _password_ when making a request.    Technical Implementation:    This functionality is provided in Spring Boot 1.1.x it should be a matter of adding the spring boot security starter dependency to the spring-xd-dirt project.      It will be controlled using the spring boot property server.basic.enabled = true/false.  Our default in application.yml for this property should be false.;1
XD-2144;As a user I'd like to have the option to provide single-user security configurations so that I can override them as needed.    *Reference:*  [Spring Boot - Security|http://docs.spring.io/spring-boot/docs/1.1.x-SNAPSHOT/reference/html/boot-features-security.html]    *Scope:*  Configurations can be provided through _servers.yml_ file.;1
XD-2146;As a user I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.;1
XD-2147;As a user I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.;1
XD-2181;As a user I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints so that I can secure my application.;1
XD-2182;As a user I want to know how to enable and configure LDAP as an authentication provider for the administration server so that I can set up my security configuration accordingly.;1
XD-2246;As a user I'd like to have the flexibility to specify config options for IP and Hostname so that I can list the correct configuration for XD Admin and XD Container servers in the Admin-UI and Shell.;1
XD-2348;As a user I'd like to refer to documentation in wiki so that I can setup and configure Spark as a Batch job as recommended.;1
XD-2349;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended.;1
XD-2377;"As a user I'd like to have API and Documentation links in the [""About""|https://github.com/spring-projects/spring-xd/blob/master/spring-xd-ui/app/scripts/shared/views/about.html] section within _admin-ui_.     It would be ideal to have the version # dynamically replaced for every release.";1
XD-2483;As a user I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.;1
XD-2498;"As a user I'd like to use the _Mail_ sink to connect to secured IMAP and/or SMTP mail servers. Currently the sink doesn't support TLS.    _Mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}  <util:properties id=""javaMailProperties"">    <prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</prop>    <prop key=""mail.imap.socketFactory.fallback"">false</prop>    <prop key=""mail.store.protocol"">imaps</prop>    <prop key=""mail.debug"">false</prop>  </util:properties>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]";1
XD-2499;As a user I'd like to use _partitionResultsTimeout_ attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki.     *Note:*  The property should be available for all the jobs that import 3 OOTB jobs have it imported (ref. attachment);1
XD-2531;As a user I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options.;1
XD-2541;As a user I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.;1
XD-2571;As a developer I'd like to upgrade _reactor-ip_ and _syslog_ modules to Reactor 2.0 so that we can sync up with the latest release.;1
XD-2609;"As a user I'm trying to list streams (>20) in admin-ui to use the pagination however I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_.    Version: 1.1.0 SNAPSHOT (master build)  Distributed: 1 admin and 2 containers    *Steps to reproduce:*  1) Deploy the following streams.  stream create foo1 --definition ""time | log"" --deploy  stream create foo2 --definition ""time | log"" --deploy  stream create foo3 --definition ""time | log"" --deploy  stream create foo4 --definition ""time | log"" --deploy  stream create foo5 --definition ""time | log"" --deploy  stream create foo6 --definition ""time | log"" --deploy  stream create foo7 --definition ""time | log"" --deploy  stream create foo8 --definition ""time | log"" --deploy  stream create foo9 --definition ""time | log"" --deploy  stream create foo10 --definition ""time | log"" --deploy  stream create foo11 --definition ""time | log"" --deploy  stream create foo12 --definition ""time | log"" --deploy  stream create foo13 --definition ""time | log"" --deploy  stream create foo14 --definition ""time | log"" --deploy  stream create foo15 --definition ""time | log"" --deploy  stream create foo16 --definition ""time | log"" --deploy  stream create foo17 --definition ""time | log"" --deploy  stream create foo18 --definition ""time | log"" --deploy  stream create foo19 --definition ""time | log"" --deploy  stream create foo20 --definition ""time | log"" --deploy  stream create foo21 --definition ""time | log"" --deploy  stream create foo22 --definition ""time | log"" --deploy    2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs.    *Error:*  16:55:19107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207)    org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178)    org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63)";1
XD-2635;"As a user I'd like to refer to the wiki so that I can create a job with 'partitions' that in turn expects _tableName_ and _columns_ be explicitly included in the job definition.     It is also beneficial to call-out _sql_ and _tableName_ metadata options are mutually exclusive. Following logic in _JdbcHdfsOptionsMetadata_ needs documented.    {code:java}  @AssertTrue(message = ""Use ('tableName' AND 'columns') when using partition column"")  boolean isPartitionedWithTableName() {  	if (StringUtils.hasText(partitionColumn)) {  		return StringUtils.hasText(tableName) && !StringUtils.hasText(sql)  	}  	else {  		return true  	}  }  {code}";1
XD-2665;As a PM I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014.;1
XD-2667;As a developer I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits.;1
XD-2681;"As a developer I'd like to refer to wiki so that I can configure machines with recommended _ulimit_ setting for XD's distributed setup.    *Note:*  Recommended _ulimit_ setting is 10K under ""Troubleshooting"" (new) section    *Exception:* (reason to increase _ulimit_)  8:25:52266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bd  a341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)";1
XD-2686;As a user I'd like to see the 'date' in logs so that I can troubleshoot issues that had occurred on a specific day and time.    Property that needs adjusted:  https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11;1
XD-2717;As a stream definer when defining a stream ending with a file sink I would like to have more flexibility for naming the file.    Add an alternative {{--nameExpression}} option allowing complete control over the {{finename-generator-expression}} attribute.    See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069;1
XD-2775;As a developer I'd like to upgrade to SHDP 2.1.2 GA so that I can sync-up with latest features.;1
XD-2778;As a developer I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.    Perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting] section in our wiki.;1
XD-2791;As a build manager I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.    The scope is to isolate the remaining test failures perhaps experiment with new AMI images until we have a solid infrastructure to fix the failing tests.;1
XD-2869;As a user I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself.;1
XD-2881;As a developer I need to investigate the differences in dependency versions so when I create/deploy custom modules in XD I don't run into CP/CL issues.;1
XD-2902;As a developer I'd like to upgrade to SI milestone/GA release so I can synchronize with JMX improvements.      This is dependent on SI Milestone and GA release timelines.;1
XD-2903;As a developer I'd like to upgrade to SI Kafka release so I can synchronize with latest improvements and bug fixes.;1
XD-2904;As a user I'd like to upgrade to Spring Boot 1.2.3 release do I can leverage the latest improvements and bug fixes.    We should also sync-up the following dependency updates to [synchronize with Boot|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml]:  {code}  <logback.version>1.1.3</logback.version>  <jackson.version>2.5.1</jackson.version>  <gemfire.version>8.0.0</gemfire.version>  <h2.version>1.4.185</h2.version>  <javax-mail.version>1.5.3</javax-mail.version>  <undertow.version>1.2.3.Final</undertow.version>  <joda-time.version>2.7</joda-time.version>  <nekohtml.version>1.9.21</nekohtml.version>  <activemq.version>5.11.1</activemq.version>  <antlr2.version>2.7.7</antlr2.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <tomcat.version>8.0.21</tomcat.version>  <aspectj.version>1.8.5</aspectj.version>  <groovy.version>2.4.3</groovy.version>  <crashub.version>1.3.1</crashub.version>  <jetty.version>9.2.9.v20150224</jetty.version>  <elasticsearch.version>1.4.4</elasticsearch.version>  <flyway.version>3.2.1</flyway.version>  <freemarker.version>2.3.22</freemarker.version>  <jdom2.version>2.0.6</jdom2.version>  <liquibase.version>3.3.2</liquibase.version>  <mockito.version>1.10.19</mockito.version>  mongodb.version>2.13.0</mongodb.version>  <slf4j.version>1.7.11</slf4j.version>  <spring-cloud-connectors.version>1.1.1.RELEASE</spring-cloud-connectors.version>  <spring-security.version>4.0.1.RELEASE</spring-security.version>  <jedis.version>2.6.2</jedis.version>  <spring-ws.version>2.2.1.RELEASE</spring-ws.version>  {code};1
XD-2910;As a developer I'd like to revisit performance benchmarks with new improvements so I can verify the optimizations around _jdbchdfs_.;1
XD-2921;As a developer I'd like to add documentation on escape quotes so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.;1
XD-2929;As a developer I'd like to document how to nest batch jobs and workflows in XD so it will be easy for end-users to use it as reference.;1
XD-2945;As a user I want to be able to provide my own RowMapper<Tuple> implementation to enrich the jdbc data.   My use case requires me to add timestamp field and a delete flag field to records before they get written to HDFS. To do it I have to implement a ItemReaderFactory and perhaps extend NameColumnJdbcItemReader. This is to override the afterPropertySet method to change the default implementation.  Otherwise I have to write my own Processor that can add these fields to Tuples and since tuples are immutable I would have to recreate the tuples with additional fields in the processor. For large load this could be big overhead.  I would love to know any other technique to implement such a use case.;1
XD-2956;As a developer I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}} so I can refactor in order to improve performance throughput.;1
XD-2971;As a user I'd like to refer to the documentation to configure the properties file so I can use it as recommended to represent the deployment manifest.;1
XD-3003;As a user I'd like to have the option to change the default Sqoop _metastore_ so I can implement a DB of my choice and not tied to default specifications.    Refer to this [thread|http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore] for more details.;1
XD-3019;As a user I'd like to refer to the documentation so I can configure HDFS backed module registry (XD-2287) as recommended.;1
XD-3037;As a user I want to have a documentation that shows how to configure multiple topics with Kafka source module.;1
XD-3043;As a user I'd like to use the GF source along with native GF authentication enabled so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured.     See this [SC post|https://gopivotal-com.socialcast.com/messages/24377202] for more details.;1
XD-3076;"As a user I'd like to use the _Mail_ source to connect to secured IMAP and/or SMTP mail servers.     _Mail_ source config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}     <beans:beans profile=""default"">          <util:properties id=""javaMailProperties"">              <beans:prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</beans:prop>              <beans:prop key=""mail.imap.socketFactory.fallback"">false</beans:prop>              <beans:prop key=""mail.store.protocol"">imaps</beans:prop>              <beans:prop key=""mail.debug"">false</beans:prop>          </util:properties>      </beans:beans>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]";1
XD-3097;As a user I'd like to have shell to automatically configure itself against an environment I have setup.  This really came up with ambari work where shell can be anywhere in a cluster. Best I was able to do for now is to build an init file for commands(ambari xd-shell deploy already knows locations/addresses for xd admin and namenode): {code} $ cat /etc/springxd/conf/xd-shell.init  admin config server http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 {code}  and then run those after starting xd-shell: {code} server-unknown:>script --file /etc/springxd/conf/xd-shell.init admin config server http://ambari-2.localdomain:9393 Successfully targeted http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 Script required 0.662 seconds to execute xd:> {code};1
XD-3105;As a developer I'd like to have JMX turned-off by default so I can take advantage of the performance throughput benefits.;1
XD-3127;As a user I'd like to refer to OOTB batch jobs and the documentation so I can jump to the right job section and review details.;1
XD-3140;As a user I'd like to have a landing page with higher-order links for sources processors sinks and jobs so I can jump to right section from one place.;1
XD-3152;As a developer I'd like to update to the 4.1.5 SI release so I can pickup the latest improvements to message channels.;1
XD-3153;As a developer I'd like to update to SI Kafka extension 1.2.0 so I can leverage the latest performance improvements.;1
XD-3154;As a developer I'd like to update to Spring Hadoop 2.2.0 GA release so I can leverage the latest improvements.;1
XD-3156;As a developer I would like to create DSL based jobs using Spring XD.   Currently BatchJobRegistryBeanPostProcessor implementation has an assumption in postProcessAfterInitialization( ) method (line 92). It checks if the beans are instanceof StepParserStepFactoryBean which is XML based steps. Therefore any XD step listeners for tap events are not getting registered effectively I'm not getting any Step events out of my DSL based jobs.  Apparently everything else is working alright for the Java DSL job. Java DSL jobs are far easier to write Test/Integration Tests with.  Please review issue type - I was not sure if this was a bug or improvement i supposed it is an improvement.;1
XD-3157;As a developer I in the new development of component (source/processor/sink) how to get the module id and container id  Because components need to generate log log information must include the unique identifier   xd:>runtime modules;1
XD-3170;As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.  The documentation also needs some more information on `Reliable` receiver.;1
XD-3173;"As a user I'd like to be able to understand the root cause of an error on the {{http}} shell command.  When an exception occurs on an {{http}} shell command the user gets  {{""Failed to access http endpoint %s"" target}}  No information from the exception is conveyed to the user (nor is it logged by the admin).";1
XD-3205;As a user I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin so I can work on the latest release bits. I'd like to refer to the documentation to do so.;1
XD-3211;As a user I would like to use fsUri = file:// to use Hadoop LocalFileSystem instead of a running cluster. In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job. The quickest way to solve this was to change the fsUri to file://. and it should have just worked.   This will work alright for singlenode setups for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing.;1
XD-3230;As a developer I'd like to upgrade to Reactor 2.0.4 release so I could leverage the latest improvements and bug-fixes.;1
XD-3238;As a developer I'd like to complete the remaining Kryo optimization changes so I can polish and get the guidelines documented appropriately.;1
XD-3341;As a s-c-d developer I'd like to publish the s-c-d image to DockerHub so I can incrementally push the latest commits to the remote location.;1
XD-3346;As a XD user I'm trying to access URI (- GET /jobs/executions//steps//progress => hasRole('ROLE_VIEW')) but it fails with 403 forbidden error for the role with view access. More details [here|https://issuetracker.springsource.com/browse/VESC-475].    Another URL with the same error: http://<HOST>:9393/streams/definitions.json?page=0&size=10;1
XD-3398;As a s-c-s developer I'd like to create auto configuration for {{singlenode}} binder configuration/properties so I can automatically configure the Spring application based on the dependencies.;1
XD-3406;As a s-c-s developer I'd like to refactor the current {{ModuleLauncher}} contract with Boot's {{JarLauncher}} API so we don't have to maintain duplicate functionality.;1
XD-3462;As a s-c-d user I'd like to create a new banner so I can embed and display the banner when the shell server boots-up.     Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?;1
XD-3466;As a s-c-d developer I'd like to add _hdfs_ sink to module registry so I can use this module to build streaming pipeline and write to Hadoop.;1
XD-3492;As a XD developer I'd like to move header-enricher from modules repo to XD proper.;1
XD-3494;As a s-c-d developer I'd like to document the use of BOM templates so the general audience can use it as a reference to include external libraries dynamically.;1
XD-3590;As a XD developer I'd like to reproduce and fix anomalies as listed [here|https://github.com/spring-projects/spring-xd-admin-ui-client/issues/9].;1
XD-3596;As a s-c-d user I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time.;1
XD-3627;As a developer I'd like to get rid off {{XDRuntimeException}} from XD.;1
XD-3633;As a user I'd like to use SFTP source module so I can create streaming pipeline with it. However I cannot see SFTP as OOTB module listed on: {{module list}} and as well as the module bits are not available in [maven repo|http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/].;1
XD-3636;As a Flo user I'd like to have {{timeout}} and {{pollInterval}} as global options at the DSL level so I can override the defaults at will.;1
XD-3637;As a developer I'd like to upgrade to SI 4.2.1 release so I can take advantage of the latest improvements.;1
XD-3651;As a module developer I would like the JsonStringToTupleConverter in the Spring Cloud Streams project to maintain the types provided in the JSON string and not convert everything to a String representation.;1
XD-3665;As a user I'm trying to load Task Task Deployment and Task Executions page but I'm seeing an error {{(Error fetching data. Is the XD server running?)}} instead.;1
XD-3666;As a user I'd like to use the admin-ui and flo with consistent look and feel.;1
XD-3667;"As a developer I'd like to troubleshoot and fix {{root}} level access over CF SPI REST calls they're broke at the moment.     Access for following calls fail:    {code}    href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/streams""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/tasks""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters/{name}""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/modules""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/completions/stream{?startdetailLevel}""  {code}";1
XD-3668;As a user I'd like to see the version and SPI type in the `about` section so I can confirm which build of {{admin-ui}} I'm currently using.;1
XD-3669;As a user I'd like Flo Graphs as screenshots while referring to the batch DSL so it will be easy for me to relate to concepts.;1
XD-3680;As a developer I'd like to add support for {{undeployed}} status consistently across all the deployers so I can present the correct status instead of the current {{unknown}}. This is applicable for existing streams without any deployment context associated with it.;1
XD-3681;As a developer I'd like to add {{undeployed}} status for k8s SPI so I can represent the correct status instead of the current {{unknown}} state.;1
XD-3683;"As a user I'm trying to compose a job just with one definition however I'm getting the following error message which could be misinterpreted.    {code}  xd:>job create salsa --definition timestampfile  Successfully created job 'salsa'  xd:>job create foo --definition ""salsa || salsa""  Successfully created job 'foo'  xd:>job create foo222 --definition ""salsa""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'salsa' and type 'job'  {code}";1
XD-3695;As a developer I'd like to upgrade to 2.2.1 GA release so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.;1
XD-3696;As a developer I'd like to upgrade to SI 4.2.2.GA release so I can leverage the latest improvements.;1
XD-3698;As a user I created a composed job with over 10 child jobs in the workflow I expected to see 'a' job in the execution list page without any pagination but instead I noticed empty pagination to skip to next page.;1
XD-3699;As a developer I'd like to remove the hardcoded buildpack reference since the latest 1.6.2 ER release includes all the features required by Data Flow.;1
XD-3706;As a user I'm trying to use {{counter}} sink with {SpEL}} expression but I'm not able to use them in combination. It [throws|https://github.com/spring-cloud/spring-cloud-stream-modules/blob/master/counter-sink/src/main/java/org/springframework/cloud/stream/module/metrics/CounterSinkProperties.java#L77] {{exactly one of 'name' and 'nameExpression' must be set}} as error message.;1
XD-3707;"As a user I'm trying to get all job definitions but the first 20 alone are returned.    Job samples:  {code}  job create aaa --definition ""hello"" --deploy  job create bbb --definition ""hello"" --deploy  job create ccc --definition ""hello"" --deploy  job create ddd --definition ""hello"" --deploy  job create eee --definition ""hello"" --deploy  job create fff --definition ""hello"" --deploy  job create ggg --definition ""hello"" --deploy  job create hhh --definition ""hello"" --deploy  job create iii --definition ""hello"" --deploy  job create jjj --definition ""hello"" --deploy  job create kkk --definition ""hello"" --deploy  job create lll --definition ""hello"" --deploy  job create mmm --definition ""hello"" --deploy  job create nnn --definition ""hello"" --deploy  job create ooo --definition ""hello"" --deploy  job create ppp --definition ""hello"" --deploy  job create qqq --definition ""hello"" --deploy  job create rrr --definition ""hello"" --deploy  job create sss --definition ""hello"" --deploy  job create ttt --definition ""hello"" --deploy  job create uuu --definition ""hello"" --deploy  job create vvv --definition ""hello"" --deploy  job create www --definition ""hello"" --deploy  job create xxx --definition ""hello"" --deploy  job create yyy --definition ""hello"" --deploy  job create zzz --definition ""hello"" --deploy  job create aaa1 --definition ""hello"" --deploy  job create bbb1 --definition ""hello"" --deploy  job create ccc1 --definition ""hello"" --deploy  job create ddd1 --definition ""hello"" --deploy  job create eee1 --definition ""hello"" --deploy  {code}    Request:  {{http://localhost:9393/jobs/definitions.json}} - returns top 20 the other experiments with page size of either 0 or -1 still brings the top 20.";1
XD-3708;As a developer I'd want to document the limitations of HSQL DB when using composed jobs.;1
XD-3718;As a user I want to be able to provide the partitioning logic for a named destination so that I can control the ordering of outbound messages.;1
XD-3741;As a Flo for Spring XD user I would like to be able to create a new stream using the graphicat UI.     This flow should be shown in a graphical way also in definition tab.  !http://example.com/image.png!  Right now it doesn't happen due to a javascript error.    {code}  TypeError: this.node.getTransformToElement is not a function      at Object.VElement.bbox (http://localhost:9393/admin-ui/lib/joint/src/vectorizer.js:323:36)      at joint.dia.ElementView.joint.dia.CellView.extend.positionRelative (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2740:51)      at null.<anonymous> (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2710:18)      at http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1177:23      at eval (eval at createIterator (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1:0) <anonymous>:10:9)      at Function.forEach (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:3645:9)      at joint.dia.ElementView.joint.dia.CellView.extend.update (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2700:11)      at bound [as update] (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1005:21)      at joint.dia.ElementView.joint.dia.CellView.extend.render (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2903:14)      at joint.dia.Paper.Backbone.View.extend.addCell (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:5004:14)(anonymous function) @ :9393/admin-ui/lib/angular/angular.js:11500  :9393!attachment-name.jpg|thumbnail!  {code};1
