issuekey;doc_clean;storypoint_label
XD-1132;As a Spring XD user I need to listen on a JMS Topic and ingest the messages so I can process the messages.    Currently the module only allows for Queues;2
XD-1695;As a user I'd like to have the option to provide security configurations so that I can access REST endpoints in a secured manner.     Ideally all the listed [REST|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] endpoints needs to be wrapped within a security layer.     *Scope of this spike:*    * Research Spring Security and Spring Boot and the OOTB features   * Design considerations and approach for XD  * Developer experience  ** How users will be configuring security credentials?  ** How DSL shell will be handled?  ** How Admin UI will be handled?;5
XD-1746;As a developer I'd like to have an OOTB MVC-aware HTTP module (with embedded tomcat) so I can use this module to leverage spring-mvc and spring-security features instead of rewriting them within the existing HTTP source module.   * Adds richer support for content-type in the HTTP Source module. See [~jbrisbin] comments: https://github.com/spring-projects/spring-xd/pull/879.  * Adds full header mapping in the source (see comments)  * See SO request: http://stackoverflow.com/questions/29353471/spring-xd-as-a-rest-endpoint;5
XD-1864;"As a user I'd like to have _paging_ support so that I can scroll through the list of streams jobs and containers.     Currently the following error is thrown when we cross >20 rows:    http://localhost:9393/jobs/definitions.json    JSON Response:  {code:xml}  [  	{  		links: [ ]  		logref: ""IllegalStateException""  		message: ""Not all instances were looked at""  	}  ]  {code}    Stack trace:  {code}  15:51:21931 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at    org.springframework.util.Assert.state(Assert.java:385)  {code}";4
XD-1906;As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)    Ideally I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients.;3
XD-2030;As a temporary work around to fix XD-1935 make producible media type to 'application/json' for Job executions GET request endpoints.;1
XD-2044;As a user I'd like to have the option to use the _SFTP_ source module so that I can access transfer and mange files over any reliable data streams.    *Reference:*  [Spring Integration SFTP Adapter|http://docs.spring.io/spring-integration/reference/html/sftp.html]    Need to consider the infrastructure for testing.;2
XD-2055;As a user I should be able to leverage native _ElasticSearch_ sink so that I can aggregate search and analyze data insights in real-time.;5
XD-2088;As a developer I'd like to have the option of extending the Trigger abstraction so that I can implement my own trigger.;5
XD-2090;As a user I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach.     11/20: Update: Scope of this task is to create an example to demonstrate and document the capability.;1
XD-2103;As a user I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.;5
XD-2104;As a result of fixing XD-2015 we still cannot execute:  {code} grunt test:e2e {code}  Basically running the tests AND the server together in one process fails. We see the following error: *Fatal error: socket hang up*.  If we separate the protractor execution into 2 separate steps the tests pass:  {code} grunt serve (one console window) grunt protractor:run (second console window) {code}  In the *grunt serve* window you can still observe *Fatal error: socket hang up* being printed out but the tests execute successfully.;5
XD-2106;As a user I'd like to have the ability to visually explore XD's cluster view so that I'm aware where the components are deployed and how they are connected within the topology.;2
XD-2119;As a user I'd like to have the option to enable HTTPS so that I can access XD's Admin server [endpoints|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] over secured communication.    Technical Implementation:    This functionality is available in Spring Boot 1.2.0 M1 and has been backported into the 1.1.x branch to be released under Spring 1.1.7.  We can test against 1.1.7 SNAPSHOT.    Working through the way to update the build file to pick up a new version of boot is a bit tricky :(;1
XD-2120;As a user I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner.    Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within file based security layer.    Reference:  [Securing Web App|https://spring.io/guides/gs/securing-web/];4
XD-2121;As a user I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner.    Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within LDAP based security layer.    Reference:  [Authentication using LDAP|https://spring.io/guides/gs/authenticating-ldap/];5
XD-2122;As a user I'd like to have the option to configure default access control for endpoints so that I can grant access by _Admin_ or _Viewer_ roles.;5
XD-2123;As a user I'd like to have the option of _kerberized_ HDFS sink so that I can leverage Kerberos (open source distributed authentication system) for secured data writes into Hadoop.;3
XD-2124;As a user I'd like to have the ability to mass-ingest data from various database systems so that I'm not restricted with the current approach (_jdbchdfs_) that is dependent on JDBC drivers.     *Spike Scope:*  * Identify integration options  * Collaborate to determine the design  * Document outcome (design specs);4
XD-2125;As a user I would like to have an option to write data into HBase sink so that I can perform random realtime read/write access on Big Data.;5
XD-2126;As a user I'd like to have the option to write into _File Roll_ sink so that I can store events on the local file system.;5
XD-2127;As a user I'd like to have the option of _JMX_ source module so that I can publish/subscribe to JMX notifications.  *Reference:* [Sprint Integration JMX Support|http://docs.spring.io/spring-integration/reference/html/system-management-chapter.html#jmx];3
XD-2128;As a user I'd like to have the option of _WebSocket_ source module so that I can create a interactive communication channel between user's browser session and the runtime to ingest browser based events and activities.  *Reference:* [Spring Integration WebSocket Support|https://github.com/spring-projects/spring-integration/tree/master/spring-integration-websocket/src];3
XD-2129;As a user I'd like to have an option of _AWS_ source module so that I can ingest data from Amazon S3 or use the Simple Email Service (SES).  *Reference:* [Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws];4
XD-2130;As a user I'd like to have the option of _Cassandra_ sink so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.;3
XD-2131;As a user I'd like to have the option of _AWS_ sink so that I can write data into S3 directly.   *Reference:* [Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws];4
XD-2132;As a user I'd like to have the option of _HAWQ_ sink so that I can write data directly into HAWQ via PXF extensions through Avro/Parquet format.;3
XD-2133;As a user I'd like to have the option of _SOLR_ sink so that I can perform full-text indexing and search through SOLR backend server.;4
XD-2135;"As a user I'd like to have the option to explicitly define/configure ""error channel"" so that I can stage and route the errors/exceptions through the dedicated channel and continue ingestion.  *Scenario:* * 'http' source ingest  * failure at either source processor or sink module * regardless of whether it is a custom module or not traverse through the exception to propagate the actual _Caused by:..._ stage the error as payload and route it to the error channel  *Example Configuration:* * error channel definition similar to ""topic.errors.stream.module"" * configure custom exception similar to ""catch=**Exception"" * exception hierarchy ** GlobalException ** DefaultException ** ModuleSpecificException";5
XD-2136;"As a user I should not be allowed to create a custom module with a _reserved_ keywords so that I it will avoid confusions from seeing duplicate strings in deployment manifest.  *Example:* We would like to avoid a _custom_ module name of *producer* to eliminate the confusion below: {code}  xd:>stream deploy --name test1 --properties ""module.producer.producer.deliveryMode= PERSISTENTmodule.log.criteria=groups.contains('group1')""  {code}  [List of available reserved keywords|https://github.com/spring-projects/spring-xd/wiki/Deployment#deployment-properties]";4
XD-2137;"As a user I'd like to retain the data partitioning state so that when I restart the containers I continue to write based on the original partitioning strategy.   Currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different _hashCode()_.  *Design consideration:* Mine through the container info to derive the ""partition index"" instead of relying on _hashCode()_.";4
XD-2138;As a user I'd like to have the data partition strategy state preserved so that when I add/delete modules they are able to dynamically adapt to the strategy.  This is already included as part of the GA release. This story is to account for the testing effort.;1
XD-2143;As a user I'd like to have the option of _Basic Auth_ so that I'm challenged to provide _user name_ and _password_ when making a request.    Technical Implementation:    This functionality is provided in Spring Boot 1.1.x it should be a matter of adding the spring boot security starter dependency to the spring-xd-dirt project.      It will be controlled using the spring boot property server.basic.enabled = true/false.  Our default in application.yml for this property should be false.;1
XD-2144;As a user I'd like to have the option to provide single-user security configurations so that I can override them as needed.    *Reference:*  [Spring Boot - Security|http://docs.spring.io/spring-boot/docs/1.1.x-SNAPSHOT/reference/html/boot-features-security.html]    *Scope:*  Configurations can be provided through _servers.yml_ file.;1
XD-2145;As a user I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth    Technical implementation:    Add ---password and --username to the admin config command.;4
XD-2146;As a user I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.;1
XD-2147;As a user I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.;1
XD-2154;As a user I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don't have to manually move and set it up.    *Scope of this spike:*  * Assess customer requirement brainstorm and document options  * Socialize with the team to collect feedback  * Identify phases  * Create new stories;5
XD-2158;As a user I need a 'sandbox' Docker Image so that I can get started to experiment XD deployment with the following setup:    * Ubuntu OS  * Full XD Jar  * Java 7.x  * Redis  * RabbitMQ;4
XD-2159;"As a user I need a ""production-ready' Docker Image so that I can use that as a baseline to deploy XD with the following setup.  * Ubuntu OS * Full XD Jar * Java 7.x";5
XD-2163;As a user I need the ability to configure Docker XD Containers so that I can link to external services such as _Rabbit Redis Zookeeper Hadoop Mongo etc_.  Includes pointers to: * Linking/binding attributes * Environment variables;5
XD-2164;As a user I want to configure Docker XD Containers using Service Discovery so that I can have tools to manage how processes and services in a cluster can find and talk to one another.;5
XD-2165;As a user I need to have the ability to create docker images via CI build so that I can build all the components/configurations I need into a Docker image test it and deploy the image to various environments.;5
XD-2166;As a user I need a document covering our recommendations for deploying a XD cluster using Mesos with the Marathon Framework.;5
XD-2169;As a user I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren't any side effects or impacts to existing functionalities.;3
XD-2178;As a user I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.;5
XD-2179;As a user I'd like to have the option of _HDFS_ source module so that I can ingest data directly from HDFS file system.;3
XD-2180;"As a user I'd like to override the default ""commit-interval"" so that I can configure commit interval depending on data volume.    *Note:*  This would apply for all OOTB jobs that has partition support. The property could be part of _servers.yml_ file.";3
XD-2181;As a user I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints so that I can secure my application.;1
XD-2182;As a user I want to know how to enable and configure LDAP as an authentication provider for the administration server so that I can set up my security configuration accordingly.;1
XD-2205;As a user I'd like to have a _Python_ processor so that I can efficiently perform data computations and statistical analysis.     Investigate the right approach (native or via stdin/stdout) that fits Spring XD model.    [Integrate Java and Python|https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#Java];5
XD-2206;As a user I'd like to have a _R_ processor so I can efficiently perform data computations and statistical analysis in the context of streaming pipeline.   Investigate the right approach that fits Spring XD model.  *R Java Libraries* [rJava|http://rforge.net/rJava/] [Renjin|http://www.renjin.org/];5
XD-2207;As a user I would like to have an option to write data into _Hive_ sink so that I can query and manage large datasets in distributed storage.;4
XD-2216;As a user I'd like to have Spring 'Core' upgraded to 4.1.1 (_milestone_ ) so that I can benefit from performance improvements associated with 'compiled' SpEL and other enhancements.;3
XD-2218;As a user I'd like to define security definitions so that I can configure entity (REST API) specific group/role access policies.;5
XD-2219;As a user I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via DSL Shell.  *Examples:* * Who can create streams? * Who can destroy the streams? * Who can view the streams? ??(defaults to all)??;5
XD-2220;As a user I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via Admin UI.    *Examples:*  * Who can create streams?  * Who can destroy the streams?  * Who can view the streams? ??(defaults to all)??;5
XD-2226;As a user I'd like to have the flexibility to change the namespace so that I can isolate ZK _metadata_ based on each _tenant_ profile.;4
XD-2228;As a user I'd like to type the _username_ and _password_ to gain access to Admin server so that I don't have to add it in some file hence I don't have to worry about having the password getting logged somewhere.;4
XD-2230;As a user I'd like to leverage _propertieis-location_ parameter while using *Filter* or *Transform* modules so that I can load the user-defined properties included in the external properties file.     Attempting to include the _propertieis-location_ attribute errors out - refer to the attachment.    It could also be beneficial to load user-defined properties through stream definition similar to deployment properties.    Example:  --script=myscript.groovy --variables=foo=bargoo=gaz;4
XD-2231;As a user I'd like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository (metadata persistence).     The scope of this task is to have the configuration specifics documented in the wiki.;2
XD-2246;As a user I'd like to have the flexibility to specify config options for IP and Hostname so that I can list the correct configuration for XD Admin and XD Container servers in the Admin-UI and Shell.;1
XD-2261;As a user I'd like to have the option to configure permissions so that I'll have the flexibility to bind permissions (REST endpoint) to a specific role.   Default Roles: * Admin (CRUD) * Viewer (R);2
XD-2268;As a developer I'd like to have a maintenance branch so that I can commit MINOR release _(ex: 1.0.2)_ code changes instead of committing to MASTER.;4
XD-2269;As a follow-up action from module registry refactoring we would have to clean-up deprecated functions _(ex: download of module definitions)_ within our codebase.     It may also be necessary to clean-up Shell and Admin-UI modules.;3
XD-2288;As a user I'd like to have the ability to access the random port (generated by tomcat) of the admin server (via _xd-shell_) so that I can point to the server and continue my interactions.   *Spike Details:* * Research whether connecting _xd-shell_ directly to ZK is a good approach or have a LB in-charge for the interaction. * How about something other than a pointer to a ZK directory in the shell for folks to experiment a bit before getting a LB involved?  *Note:* On some hadoop/hdfs setups access to zk is mandatory from hdfs client libs. There are some HA and federation setups which would anyway require xd shell to get access to zk if fs shell commands are used.;5
XD-2293;As a follow-up to Kafka message bus support we would like to rerun the failing tests after upgrading to new [consumer|https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design] rewrite.   [Response from Kafka support|http://mail-archives.apache.org/mod_mbox/kafka-users/201410.mbox/%3CCAHwHRrWZmLr94eHX1z5i36BYz%2B%3DCisx7GcbW1_Nn7ooNJcShMw%40mail.gmail.com%3E].;3
XD-2295;As a user I'd like to stream ingest audio and video data so that I can apply predictive analytics algorithms for facial detection.  *Spike scope:* * Research the feasibility of implementing [Motion-JPEG|http://en.wikipedia.org/wiki/Motion_JPEG] * Design specs on Motion-JPEG format  *Note:* [opencv|http://docs.opencv.org/trunk/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html] although having OOTB support it is not platform compatible.;5
XD-2296;As a user I'd like to have a config parameter preferably in _servers.yml_ file so that I can enable/disable message rates in the cluster view.;2
XD-2298;As a user I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.;4
XD-2304;As a user I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.    *Spike scope*:  - Study simple consumer API functionality  - Document findings approach and next steps;5
XD-2306;As a user I'd like to push the custom module (built as uber-jar) via a REST API so that I can install the custom module in cluster.;5
XD-2308;As a user I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka.    Consider:  * Kafka as message bus  * Kafka as source;5
XD-2311;As a user I'd like to have a _generator_ source module so that I can create a number of messages of a specified size (similar to Rabbit's PerfTest utility).  Example: generator --numMsgs 10000 --msgSize 1024 --numThreads 1;5
XD-2312;As a user I'd like to have a _perf-meter_ sink that will collect and push metrics to the standard container log file.    Example: perf-meter --numMsgs 1000  Will write to the container log a timestamp message count and message rate every 1000 messages.  The message rate is the value since the last log event.  Default values are those specified above.;5
XD-2313;As a user I'd like to create a stream such as _generator | perf-meter_ so that I can ingest 1M messages of 1000 bytes and one thread using XD's 'singlenode' container and measure performance characteristics.;5
XD-2333;As a PM I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds.;5
XD-2347;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended.;2
XD-2348;As a user I'd like to refer to documentation in wiki so that I can setup and configure Spark as a Batch job as recommended.;1
XD-2349;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended.;1
XD-2358;As a user I want to be able to control the starting offset of the Kafka source when a stream is deployed so that I can replay a topic if necessary.    Note:  - starting offset is only considered when the stream is deployed  - progress made by modules must survive their crash for a running stream  - undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start     TBD: what happens when streams are undeployed/redeployed - where do they resume from?;5
XD-2359;As a user I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed so that I can colocate with other data sources.;5
XD-2360;As a user I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesn’t take place.;5
XD-2361;As a user I want Spring XD’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed.;5
XD-2368;As a continuation we would like to further investigate Spark develop POC and identify the best appropriate design and implementation for XD.;5
XD-2375;As a user I'd like to have a _reactor-stream_ processor module so that I can ingest data using XD source modules and process them as time-window operations.     *Example 1:*  http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=minavg    This would give you 10 second time window of the min and avg values.    *Example 2:*  Reactor as a module    *Example 3:*  Integration with Spark streaming and reactor;5
XD-2376;"As a user I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput.     *Example:*  ""http --batchInterval=10 | log""";4
XD-2377;"As a user I'd like to have API and Documentation links in the [""About""|https://github.com/spring-projects/spring-xd/blob/master/spring-xd-ui/app/scripts/shared/views/about.html] section within _admin-ui_.     It would be ideal to have the version # dynamically replaced for every release.";1
XD-2382;As a developer I'd like to setup a performance testing infrastructure (rackspace) so I can start benching Kafka baselines and continue with XD use-cases.;5
XD-2383;As a user I'd like to have a Shell command so that I can point to the custom-built _module_ archive and push it to the runtime for immediate usage.;3
XD-2384;As a user I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.;3
XD-2388;As a user I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers.;5
XD-2398;As a user I should be able to leverage native _WebSocket_ sink so that I can take the advantage of full-duplex communications channels over a single TCP connection.;5
XD-2401;As a developer I'd like to include the following improvements as part of the EC2 CI infrastructure so that we can reliably run the CI builds and also assert over feature functionalities.    *Scope:*  * Enable 'distributed jvm test'  * Change from using artifactory gradle task to a command task (that calls ./gradlew)  * Test w/ embedded hadoop off  * Turn on maxParallelForks;4
XD-2402;As a developer I'd like to investigate the increase in WARN logs so that I can troubleshoot and fix PMD/Sonar violations.  Consider notifying the violations through SONAR configurations. The committer should be notified.;3
XD-2403;As a build manager I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds.     *Scope:*  * Use the environment where Bamboo is running  * Gain access to powershell   * Setup services (redis rabbit etc.)  * Kick-off CI task;4
XD-2420;As a user I'd like to have a common shared location so that I can place the dependent jar's that are required by 2 or more custom modules.   *Current Recommendation:* * Place the dependent jar under xd/lib folder * if it necessary to support different versions of jar's then bundle it in custom module to get around the _classloader_ problem if a older/newer version exist in xd/lib;4
XD-2434;As a QA I'd like to include acceptance test coverage for _Mail_ source module so that I can validate the functionality as part of every CI build.;3
XD-2435;As a QA I'd like to include acceptance test coverage for _reactor-ip_ source module so that I can validate the functionality as part of every CI build.;3
XD-2436;As a QA I'd like to include acceptance test coverage for _reactor-syslog_ source module so that I can validate the functionality as part of every CI build.;3
XD-2437;As a QA I'd like to include acceptance test coverage for _SFTP_ source module so that I can validate the functionality as part of every CI build.;3
XD-2438;As a QA I'd like to include acceptance test coverage for _aggregator_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2439;As a QA I'd like to include acceptance test coverage for _analytic-pmml_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2440;As a QA I'd like to include acceptance test coverage for _bridge_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2441;As a QA I'd like to include acceptance test coverage for _http-client_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2442;As a QA I'd like to include acceptance test coverage for _json-tuple_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2443;As a QA I'd like to include acceptance test coverage for both _script_ and _scripts_ processor modules so that I can validate the functionality as part of every CI build.;3
XD-2444;As a QA I'd like to include acceptance test coverage for _splitter_ processor module so that I can validate the functionality as part of every CI build.;3
XD-2445;As a QA I'd like to include acceptance test coverage for _gauge_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2446;As a QA I'd like to include acceptance test coverage for _aggregate-counter_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2447;As a QA I'd like to include acceptance test coverage for _field-value-counter_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2448;As a QA I'd like to include acceptance test coverage for _hdfs-dataset_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2449;As a QA I'd like to include acceptance test coverage for _mail_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2450;As a QA I'd like to include acceptance test coverage for _null_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2451;As a QA I'd like to include acceptance test coverage for _rich_gauge_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2452;As a QA I'd like to include acceptance test coverage for _router_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2453;As a QA I'd like to include acceptance test coverage for _shell_ sink module so that I can validate the functionality as part of every CI build.;4
XD-2454;As a QA I'd like to include acceptance test coverage for _splunk_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2455;As a QA I'd like to include acceptance test coverage for _throughput-sampler_ sink module so that I can validate the functionality as part of every CI build.;3
XD-2456;As a QA I'd like to include acceptance test coverage for _spark-app_ batch job so that I can validate the functionality as part of every CI build.;4
XD-2457;As a QA I'd like to include acceptance test coverage for _timestampfile_ batch job so that I can validate the functionality as part of every CI build.;3
XD-2462;As a QA I'd like to include acceptance test coverage for _Kafka_ as a message bus so that I can validate the functionality as part of every CI build.;4
XD-2471;"As a user I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness    *Things to consider:*  * make global configuration options be ""defaults"" and allow per-deployment overrides  * add options for   ** concurrency  ** compression support";3
XD-2473;As a user I'd like to have the option to _ACK_ messages so that I can guarantee that the message/request sent is successful.;3
XD-2474;"As a user I'd like to have the option to implement _bindRequestor_ and _bindReplier_ so that I can ""bind a producer that expects async replies"" and ""bind a consumer that handles requests from a requestor and asynchronously sends replies"" respectively.";3
XD-2475;As a user I'd like to have the option to setup _batching_ so that I can ingest data in batches as opposed to payload-at-a-time.;5
XD-2477;As a user I'd like to have the option to _stop_ an existing Sqoop job so that I can clean-up resources at the time of completion.;5
XD-2478;As a user I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively.   We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.;4
XD-2479;As a user I'd like to incremental-data-load so that I can retrieve only rows newer than some previously-imported.;4
XD-2480;As a QA I'd like to benchmark _Sqoop_ vs. _jdbchdfs_ batch job so that I can compare and contrast performance stats.;4
XD-2483;As a user I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.;1
XD-2498;"As a user I'd like to use the _Mail_ sink to connect to secured IMAP and/or SMTP mail servers. Currently the sink doesn't support TLS.    _Mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}  <util:properties id=""javaMailProperties"">    <prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</prop>    <prop key=""mail.imap.socketFactory.fallback"">false</prop>    <prop key=""mail.store.protocol"">imaps</prop>    <prop key=""mail.debug"">false</prop>  </util:properties>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]";1
XD-2499;As a user I'd like to use _partitionResultsTimeout_ attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki.     *Note:*  The property should be available for all the jobs that import 3 OOTB jobs have it imported (ref. attachment);1
XD-2501;As a XD Admin I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features bug-fixes and enhancements.     *Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:*    <activemq.version>5.10.0</activemq.version>  <aspectj.version>1.8.4</aspectj.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <h2.version>1.4.182</h2.version>  <hibernate.version>dd4.3.7.Final</hibernate.version>  <hibernate-validator.version>5.1.3.Final</hibernate-validator.version>  <hikaricp.version>2.2.5</hikaricp.version>  <hornetq.version>2.4.5.Final</hornetq.version>  <httpasyncclient.version>4.0.2</httpasyncclient.version>  <httpclient.version>4.3.6</httpclient.version>  <jackson.version>2.4.4</jackson.version>  <janino.version>2.6.1</janino.version>  <jetty.version>9.2.4.v20141103</jetty.version>  <jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version>  <joda-time.version>2.5</joda-time.version>  <jolokia.version>1.2.3</jolokia.version>  <junit.version>4.12</junit.version>  <liquibase.version>3.3.0</liquibase.version>  <log4j.version>1.2.17</log4j.version>  <log4j2.version>2.1</log4j2.version>  <mockito.version>1.10.8</mockito.version>  <mongodb.version>2.12.4</mongodb.version>  <mysql.version>5.1.34</mysql.version>  <reactor.version>1.1.5.RELEASE</reactor.version>  <reactor-spring.version>1.1.3.RELEASE</reactor-spring.version>  <servlet-api.version>3.1.0</servlet-api.version>  <spring.version>4.1.3.RELEASE</spring.version>  <spring-batch.version>3.0.2.RELEASE</spring-batch.version>  <spring-data-releasetrain.version>Evans-SR1</spring-data-releasetrain.version>  <spring-hateoas.version>0.16.0.RELEASE</spring-hateoas.version>  <spring-mobile.version>1.1.3.RELEASE</spring-mobile.version>  <spring-security.version>3.2.5.RELEASE</spring-security.version>  <tomcat.version>8.0.15</tomcat.version>  <undertow.version>1.1.1.Final</undertow.version>;4
XD-2511;As a user I'd like to have a separate _YML_ file to list the deployment manifest properties so that I don't have to include as part of the stream definition.;5
XD-2513;As a user I'd like to have the option to _compress_ messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip zip compression and decompression.;3
XD-2514;As a user I'd like to have the option of _compression_ for both Rabbit _source_ and _sink_ modules so that can further enhance the performance characteristics.;5
XD-2515;As a user I'd like to have the option of _batching_ for the Rabbit _sink_ so that I can write data in batches as opposed to one-at-a-time.;4
XD-2523;As a user I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided configure the boot plugin for 'MODULE' layout and other boilerplate build configuration.    This is dependent on Boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187;3
XD-2526;As a QA I'd like to include acceptance test coverage for hdfs-dataset module so that I can validate the functionality as part of every CI build.;3
XD-2527;As a user I'd like to have the option to extend compression support so that I can override the defaults and customize as needed.  Follow-up from this PR: https://github.com/spring-projects/spring-xd/pull/1346;3
XD-2531;As a user I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options.;1
XD-2534;As a performance tester I'd like to rerun baseline benchmarks with batching enabled on Rabbit so that I can compare the results with previous performance snapshots.   Note: - batchingEnabled = true - batchingSize = 100 (default)  We could also vary default size to compute and record at granular level.;3
XD-2535;As a performance tester I'd like to re-run baseline benchmarks with compression enabled on Rabbit so that I can compare the results with previous performance snapshots.;3
XD-2538;As a user I'd like to have an option to disable DB requirement so that I can setup to use DIRT runtime when stream processing is the only requirement.;5
XD-2541;As a user I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.;1
XD-2542;As a user I'd like to have a flexible RxJava module so that it can as a processor.;5
XD-2543;As a user I'd like to have the option to define access control list (ACLs) so that I can define access controls to the resource by 'each user' and what the privileges are for that 'resource'.    *Spike Scope:*  ** Review customer use cases and come up with design specs  ** Identify the best approach that fits XD runtime  ** Identify scope for DSL and UI   ** Document next steps and phases;5
XD-2548;As a performance tester I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks.     *Scope:*  * Identify the bottlenecks  * Document reasons  * List pros/cons;5
XD-2550;As a user I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.;3
XD-2551;As a user I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios.;3
XD-2552;As a CF user I'd like to have the ability to override the HDFS location so that I can change where the custom module _uber-jar_ can be stored and retrieved.;3
XD-2553;As a CF user I'd like to have the ability to override the YARN config location so that I can change where the custom module _uber-jar_ can be stored and retrieved.;3
XD-2554;As a user I'd like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion.;3
XD-2557;As a developer I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.;4
XD-2559;As a user I'd like to have a Redis based _aggregation_ over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.    *Scope:*  * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters].  * Identify gaps  * Update reference documentation;3
XD-2560;As a user I'd like to have a Redis based aggregation over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.  *Scope:* * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters]. * Identify gaps * Update reference documentation;3
XD-2562;As a developer I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon thus eliminating the incorrect CP file generation in eclipse.;3
XD-2566;As a developer I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.;5
XD-2571;As a developer I'd like to upgrade _reactor-ip_ and _syslog_ modules to Reactor 2.0 so that we can sync up with the latest release.;1
XD-2590;As a user I'd like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via _servers.yml_ to control the default message size.    *Notes:*  The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. [Related PR|https://github.com/spring-projects/spring-xd/pull/1367].;3
XD-2597;As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.    Best way for now would be to add an info command to the xd-yarn script.    With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.;4
XD-2606;As a user I'd like to have an option to track history so that I get the visibility of stream name module name etc. added as part of the message header.;3
XD-2609;"As a user I'm trying to list streams (>20) in admin-ui to use the pagination however I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_.    Version: 1.1.0 SNAPSHOT (master build)  Distributed: 1 admin and 2 containers    *Steps to reproduce:*  1) Deploy the following streams.  stream create foo1 --definition ""time | log"" --deploy  stream create foo2 --definition ""time | log"" --deploy  stream create foo3 --definition ""time | log"" --deploy  stream create foo4 --definition ""time | log"" --deploy  stream create foo5 --definition ""time | log"" --deploy  stream create foo6 --definition ""time | log"" --deploy  stream create foo7 --definition ""time | log"" --deploy  stream create foo8 --definition ""time | log"" --deploy  stream create foo9 --definition ""time | log"" --deploy  stream create foo10 --definition ""time | log"" --deploy  stream create foo11 --definition ""time | log"" --deploy  stream create foo12 --definition ""time | log"" --deploy  stream create foo13 --definition ""time | log"" --deploy  stream create foo14 --definition ""time | log"" --deploy  stream create foo15 --definition ""time | log"" --deploy  stream create foo16 --definition ""time | log"" --deploy  stream create foo17 --definition ""time | log"" --deploy  stream create foo18 --definition ""time | log"" --deploy  stream create foo19 --definition ""time | log"" --deploy  stream create foo20 --definition ""time | log"" --deploy  stream create foo21 --definition ""time | log"" --deploy  stream create foo22 --definition ""time | log"" --deploy    2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs.    *Error:*  16:55:19107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207)    org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178)    org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63)";1
XD-2614;As a user I'd like to have Google's [Protocol Buffer|https://code.google.com/p/protobuf/] codec option so that I can serialize/deserialize objects based on its native specifications.;4
XD-2615;"As a tester I'd like to add test coverage for ""complex objects"" such protocol buffers any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics.";5
XD-2630;As a developer I'd like to use Ambari plugin so that I can provision manage and monitor Spring XD cluster using the same tool I use for Hadoop clusters.;4
XD-2635;"As a user I'd like to refer to the wiki so that I can create a job with 'partitions' that in turn expects _tableName_ and _columns_ be explicitly included in the job definition.     It is also beneficial to call-out _sql_ and _tableName_ metadata options are mutually exclusive. Following logic in _JdbcHdfsOptionsMetadata_ needs documented.    {code:java}  @AssertTrue(message = ""Use ('tableName' AND 'columns') when using partition column"")  boolean isPartitionedWithTableName() {  	if (StringUtils.hasText(partitionColumn)) {  		return StringUtils.hasText(tableName) && !StringUtils.hasText(sql)  	}  	else {  		return true  	}  }  {code}";1
XD-2636;As a user I'd like to either use _sql_ or _tableName_ options so that I can build a partitioned job with _where_ clause and strict table-column combo respectively.;4
XD-2652;As a user I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.;2
XD-2656;As a user I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.;4
XD-2661;As a user I'd like to build XD in Windows machine so that I can develop test  and contributed to OSS.;4
XD-2662;As a developer I'd like to run acceptance test coverage in Windows so that I can evaluate XD functionalities.    The scope is to provision Windows image in EC2 and run acceptance test in the environment. Potentially also try to create this as CI build.;3
XD-2664;As a developer I'd like to build _Spark Streaming_ as data processors in XD so that we can demonstrate some of the capabilities.    *Implement using:*  * Java / Java Lambdas  * Scala;5
XD-2665;As a PM I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014.;1
XD-2666;As a developer I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits.     The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.;4
XD-2667;As a developer I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits.;1
XD-2672;As a scala developer someone could easily deploy the spark streaming module developed using scala.;5
XD-2673;As a user I'd like to refer to Hive sample so that I can use that as a reference to integrate Hive to query and analyze.;2
XD-2681;"As a developer I'd like to refer to wiki so that I can configure machines with recommended _ulimit_ setting for XD's distributed setup.    *Note:*  Recommended _ulimit_ setting is 10K under ""Troubleshooting"" (new) section    *Exception:* (reason to increase _ulimit_)  8:25:52266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bd  a341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)";1
XD-2686;As a user I'd like to see the 'date' in logs so that I can troubleshoot issues that had occurred on a specific day and time.    Property that needs adjusted:  https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11;1
XD-2693;As a developer I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience.;3
XD-2694;As a developer I'd like the {{publish-maven.gradle}} script to use values for dependencies (e.g. Spring Boot and {{hadoop-common}}) from our central dependency list (in this case {{dependencies.properties}}) so that I don't have to update them manually anymore.;2
XD-2698;As a developer I want to have to run Kafka tests on an external broker so that I reduce the footprint of the build process.;2
XD-2699;As a developer I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.;3
XD-2701;As a developer I'd like to build _Spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.;5
XD-2702;As a developer I'd like to build data pipeline using _Kafka_ as as message bus in XD so that we can demonstrate some of the capabilities.  *Use case to consider:* * Log aggregation and analysis * Lambda architecture ** how to avoid code duplication ** how to eliminate tight coupling of business logic ** how Kafka can be used for reliable reprocessing;5
XD-2703;As a developer I'd like to build batch sample using _Sqoop_ so that we can demonstrate some of the capabilities.  *Use cases to consider:* * JDBC to HDFS * HDFS to JDBC;5
XD-2704;As a consequence   * change gradle script regarding generation of documentation  * remove pushGeneratedDocs task etc  * remove link rewriting that is no longer needed;5
XD-2713;As a field engineer I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint.;5
XD-2714;As a field engineer I'd like to have a comparison of Spark Streaming examples in Spring XD so that it is easy to relate from implementation standpoint.;5
XD-2715;As a PM I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.;5
XD-2716;As a developer I'd like to create a example to demonstrate JDBC to HDFS data movement.;5
XD-2717;As a stream definer when defining a stream ending with a file sink I would like to have more flexibility for naming the file.    Add an alternative {{--nameExpression}} option allowing complete control over the {{finename-generator-expression}} attribute.    See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069;1
XD-2718;As a user I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.;3
XD-2719;As a user I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources.;3
XD-2724;As a user I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.;5
XD-2730;"As a user I'd like to include the deployment manifest from the file so that I don't have spend time typing as ""inline properties"".";3
XD-2734;As a field engineer I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.;5
XD-2737;"As a user I'd like to have an optional _trace_ as inline deployment properties for _stream_ so that I can declare which _module_ in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.  *Example:*  {code:xml} xd:> stream create foo ""http | log""  xd:> stream deploy foo --properties ""module.http.tracemodule.log.trace""  (or)  xd:> stream deploy foo --properties ""module.*.trace"" {code}  Wildcard wiretap config: http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap";5
XD-2738;"As a user I'd like to have an optional  arbitrary ""side channels"" created so that when creating a module channels other than the primary stream channels (input output) could be added to the bus (i.e. creating a tap channel *within* a flow). The optional ""side channels"" can be used to trace/track module progress.";5
XD-2742;As a developer I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.    [Challenge Details|http://www.debs2015.org/call-grand-challenge.html];5
XD-2747;As a developer I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.;5
XD-2757;As a developer I'd like to have the high-level description for each of the modules so that I can use the description (presumably what is captured in javadoc for the module definition) to understand the purpose of the module itself.;3
XD-2762;As a build manager I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA.     *Location for 1.1.0 RELEASE:*  http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/;2
XD-2766;As a user I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).;5
XD-2775;As a developer I'd like to upgrade to SHDP 2.1.2 GA so that I can sync-up with latest features.;1
XD-2776;As a developer I'd like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance.     I'd like to reproduce baseline performance metrics as identified by the Kafka [engineering team|https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines].;5
XD-2778;As a developer I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.    Perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting] section in our wiki.;1
XD-2784;As a developer I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.;3
XD-2785;As a developer I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.;3
XD-2786;As a developer I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.;2
XD-2787;As a developer I'd like to add load generator _source_ module so that I could use it for performance testing use-cases.;3
XD-2788;As a developer I'd like to add load receiving _sink_ module so that I can measure received throughput;3
XD-2791;As a build manager I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.    The scope is to isolate the remaining test failures perhaps experiment with new AMI images until we have a solid infrastructure to fix the failing tests.;1
XD-2793;As a developer I'd like to fix the offset management with Kafka _source_ module so that I can efficiently perform fetch operation from the given offsets.;5
XD-2794;As a developer I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.;4
XD-2795;As a developer I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.;5
XD-2796;As a PM I'd like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf. benchmarks and ref. architectures so that it's easy for anyone to quickly get up and running on XD.;5
XD-2797;As a developer I'd like to continue Lattice/Diego POC so that I can identify the scope risks and the overall design for a pluggable SPI in XD runtime.;4
XD-2802;As a developer I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc.;5
XD-2805;As a user I'd like to add the Hadoop _namenode_ specifics in a config file so that I don't have to incur the hassle of pointing to the _namenode_ location every time I open a new DSL session but it is automatically configured.;3
XD-2815;As a user I'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.;2
XD-2821;As a developer I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors.     This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality hence the current workaround with XD-2486 needs reafctored.;4
XD-2832;"As a developer I'd like to create a custom job module using Java Config so that I don't have to deal with XML configurations. While deploying/launching the following job I get the error attached below.    {code:xml}  job create --name CDK_Global --definition ""customBatchJob"" --deploy  module upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jar  job launch --name CDK_Global  {code}    *Error:*  I'm getting an exception that the job doesn't exist asking if it's deployed";4
XD-2835;As a developer I'd like to continue XD-on-Lattice/Diego PoC and will be focused on the design of a pluggable SPI so it is more generally applicable than Lattice with the Receptor API being just one implementation option.;5
XD-2838;As a developer I'd like to update all the module docs to also include _shortDescription_ so that it's available for users to learn more about the module.;2
XD-2839;As a developer I'd like to host/read Python script (file) from HDFS so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.;5
XD-2840;As a developer I'd like to rebalance partitions as we scale the containers so I don't have to bring down the running stream/job to reestablish dynamic partitions.;5
XD-2843;As a Spring XD user I want to have the ability to customize the encoders and decoders used by the Kafka source sink and bus so that I can customize data formats and choose the most appropriate strategy;4
XD-2844;As a user I'd like to have the OOTB _gpfdist_ sink module so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.;5
XD-2845;As a developer I'd like to setup UI infrastructure so I can integrate admin_ui and Flo.;4
XD-2849;As a developer I'd like to create a end-to-end Kafka use-case so I can study demonstrate and verify kafka + xd play that's built for scale and performance.;3
XD-2850;As a developer I'd like to use an efficient approach to read files so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content.     Would the _tasklet_ approach be better as opposed to transmitting data via message bus (as streams)?;4
XD-2852;As a developer I'd like to create a _gpload_ tasklet so I can ingest data from various sources into GPDB in an efficient manner.;4
XD-2857;As a developer I'd like to remove Hadoop dependencies from root classpath so we don't have to incur the penalty of classloading unnecessary libraries at the startup time.    The goal is to at least try and decouple for situations when HDFS is not used for module registry.;5
XD-2858;As a developer I'd like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1).     (0):  {code}  /lib/*.jar:lib/${distro}/*.jar  {code}    (1):  {code}  ${xd.home}/lib/hadoop/${distro}/*.jar  {code}    *Example:*  {code}  http | hdfs --distro=PHD22    http | myCustomModule --classpath=/my/funky/dir    http | jpa --provider=eclipse    jpa:  /config/  /lib/something-that-is-common.jar      /eclipse/eclipse-link-3.2.jar      /hibernate/hibernate-core-5.0.jar    module.classpath = /lib/*.jar:/lib/${provider}/*.jar  {code};4
XD-2869;As a user I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself.;1
XD-2877;As a pre-requisite for XD-2835 and a continuation of XD-2671 split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.;5
XD-2879;As a developer I'd like to add support for explicit partition count configuration so I can use this option to cleverly route the payload to the intended consumer (module).;4
XD-2880;As a developer I'd like to add support for dynamic partition subscription for the Kafka source module so I can consume the payload from dynamic partitions.;4
XD-2881;As a developer I need to investigate the differences in dependency versions so when I create/deploy custom modules in XD I don't run into CP/CL issues.;1
XD-2882;"As a user I'd like to have an option to have the hdfs sink use ""Syncable"" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option.";3
XD-2883;"As a user I'd like to have an option to have the hdfs sink not use a temporary inUseSuffix like .tmp. Instead we should write using the filename specified directly. This could be useful if we use ""Syncable"" writes and the sink fails while the file is open. Without this new option the user would have to explicitly rename the file.";4
XD-2888;As a user I'd like to also have the capability to upload the custom module through maven/gradle targets so I can automate the installation of custom module fragments.;2
XD-2889;As a user I'd like to have the option to version the custom modules so I can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.;4
XD-2890;As a user I'd like to have the option to read the file line by line so I get the optional OOTB optimum file reading experience.;5
XD-2892;As a developer I'd like to certify Spring XD against PHD 3.0 so I can synchronize with the latest ODP based bits.;3
XD-2896;As a user I'd like to have the configuration option to use an alternative DLQ so I can publish the message this time with additional headers including one that contains the exception (and stack trace).;3
XD-2897;As a user I'd like to have the OOTB module to consume database changes as event streams so I can incrementally synchronize with real-time DB updates with various destinations such as Brokers Hadoop DB etc.;5
XD-2899;As a developer I would like to connect to the broker that hosts the Rabbit queue so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.;3
XD-2900;As a developer I'd like to synchronize with the latest Gemfire version (8.1?) so I can leverage the latest Gemfire features and as well support updated BDS stack.    This effort in XD depends on Spring Data Gosling GA release which in turn depends on Gemfire 8.1 release timelines.;2
XD-2901;As a developer I'd like to deploy a stream in the same container so all modules are colocated within the container. Perhaps also consider building leader election within modules in order to automatically failover the application (stream) from one container to another.;5
XD-2902;As a developer I'd like to upgrade to SI milestone/GA release so I can synchronize with JMX improvements.      This is dependent on SI Milestone and GA release timelines.;1
XD-2903;As a developer I'd like to upgrade to SI Kafka release so I can synchronize with latest improvements and bug fixes.;1
XD-2904;As a user I'd like to upgrade to Spring Boot 1.2.3 release do I can leverage the latest improvements and bug fixes.    We should also sync-up the following dependency updates to [synchronize with Boot|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml]:  {code}  <logback.version>1.1.3</logback.version>  <jackson.version>2.5.1</jackson.version>  <gemfire.version>8.0.0</gemfire.version>  <h2.version>1.4.185</h2.version>  <javax-mail.version>1.5.3</javax-mail.version>  <undertow.version>1.2.3.Final</undertow.version>  <joda-time.version>2.7</joda-time.version>  <nekohtml.version>1.9.21</nekohtml.version>  <activemq.version>5.11.1</activemq.version>  <antlr2.version>2.7.7</antlr2.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <tomcat.version>8.0.21</tomcat.version>  <aspectj.version>1.8.5</aspectj.version>  <groovy.version>2.4.3</groovy.version>  <crashub.version>1.3.1</crashub.version>  <jetty.version>9.2.9.v20150224</jetty.version>  <elasticsearch.version>1.4.4</elasticsearch.version>  <flyway.version>3.2.1</flyway.version>  <freemarker.version>2.3.22</freemarker.version>  <jdom2.version>2.0.6</jdom2.version>  <liquibase.version>3.3.2</liquibase.version>  <mockito.version>1.10.19</mockito.version>  mongodb.version>2.13.0</mongodb.version>  <slf4j.version>1.7.11</slf4j.version>  <spring-cloud-connectors.version>1.1.1.RELEASE</spring-cloud-connectors.version>  <spring-security.version>4.0.1.RELEASE</spring-security.version>  <jedis.version>2.6.2</jedis.version>  <spring-ws.version>2.2.1.RELEASE</spring-ws.version>  {code};1
XD-2905;As a developer I'd like to complete the remaining work with DEBS challenge so I can submit by the deadline.;2
XD-2906;As a developer I'd like to add a new CI build to include _install_ target so I can verify the target expectations as it is often time consuming to verify it in the development environment.;2
XD-2907;As a developer I'd like to have the XD + Kafka POC published in samples repo so I can include it as reference architecture for the XD blog.;4
XD-2910;As a developer I'd like to revisit performance benchmarks with new improvements so I can verify the optimizations around _jdbchdfs_.;1
XD-2911;As a developer I'd like to bench test cases around {{TupleBuilder}} so I can identify the bottlenecks and tune for performance optimizations.;5
XD-2913;As a developer I'd like to have a simplified UX around parameters for GPDB so I don't have to escape each parameter. The scope is also to test the Sqoop job with SQLServer and GPDB to identify the UX differences.;5
XD-2914;"As a developer I'd like to migrate module deployment from the ""repository"" abstraction (used for stream/job definitions) so I can create it as a pluggable runtime SPI.";5
XD-2915;As a developer I'd like to build isolated Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without the hard requirement for running _xd-containers_.;5
XD-2916;As a developer I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor so I can interact with Diego runtime via Receptor API calls from XD.;5
XD-2917;As a developer I'd like to refactor stream/job definition repository so I can decouple from module deployment concerns.;5
XD-2918;As a developer I'd like to define pluggable runtime SPI so I have the option to choose the implementation based on deployment targets such as CF on-prem Mesos etc.;4
XD-2919;As a developer I'd like to create persistent repository for streams so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.;4
XD-2921;As a developer I'd like to add documentation on escape quotes so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.;1
XD-2922;As a Spring XD user I'd like to create streaming pipelines so I can take advantage of latest specs from both XD and Spark/Spark Streaming.;3
XD-2929;As a developer I'd like to document how to nest batch jobs and workflows in XD so it will be easy for end-users to use it as reference.;1
XD-2930;As a developer I'd like to configure HADOOP_USER_NAME environment variable to implement and run-as-user for kerberos secured clusters. This would need some additional work in SHDP.;4
XD-2933;As a user I'd like to parameterize all Import Options so I can eliminate the need for {{—args}} option since it gets confusing.;2
XD-2934;As a user I'd like to parameterize CodeGen Options so I can generate code on the fly as needed.;4
XD-2935;As a user I'd like to parameterize Merge Options so I can incrementally consume the delta with the help of megastore.;4
XD-2936;As a user I'd like to have an option to specify _timeout_ so I can expect the job to not run forever if it is in hung state.;3
XD-2938;As a user I need to use XD Sqoop module to support the merge command.  Currently the SqoopRunner createFinalArguments method forces the requirement for connect username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred;4
XD-2943;As a users I would to be able to execute SQL Statement/Script via a Processor or Job statement.;3
XD-2945;As a user I want to be able to provide my own RowMapper<Tuple> implementation to enrich the jdbc data.   My use case requires me to add timestamp field and a delete flag field to records before they get written to HDFS. To do it I have to implement a ItemReaderFactory and perhaps extend NameColumnJdbcItemReader. This is to override the afterPropertySet method to change the default implementation.  Otherwise I have to write my own Processor that can add these fields to Tuples and since tuples are immutable I would have to recreate the tuples with additional fields in the processor. For large load this could be big overhead.  I would love to know any other technique to implement such a use case.;1
XD-2947;As a user I'd like to have the ability to use expressions so I can dynamically name directories/files based on the timestamp or other intermediate data point.;4
XD-2955;As a developer I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.;4
XD-2956;As a developer I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}} so I can refactor in order to improve performance throughput.;1
XD-2957;As a developer I'd like to document the Kryo optimization guidelines so the end-users can refer to it while tuning to improve performance.;3
XD-2958;As a developer I'd like to upgrade to Kafka 0.8.2 so I can leverage the latest features in order to test the performance characteristics.;5
XD-2959;As a developer I'd like to create a Tuple _load-generator_ so I can use it to measure {{Tuple}} based payload performance.;3
XD-2960;As a developer I'd like to create a new _load-generator_ so I can use it to measure highly optimized (kryo serialized) payload to measure the performance differences.;3
XD-2961;As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Note:  1.1.1 > Benched against 0.8.1   1.2 > Benched against 0.8.2;5
XD-2962;As a developer I'd like to document performance benchmark results along with the infrastructure specifics so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.;5
XD-2964;As a developer I'd like to study the state management requirements so I can brainstorm and identify the design to natively add _stateful_ stream processing support in XD.;5
XD-2965;As a developer I'd like to integrate with Spring Data repository that's backed by Kafka _changelog_ so I can leverage the benefits of local data affinity (off-heap) in order to run stateful stream processing logic.;5
XD-2966;As a developer I'd like to add support to _flush_ offsets intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;5
XD-2967;As a developer I'd like to add support to _flush_ state intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;5
XD-2969;As a developer I'd like to have the option of CoAP source module so I can consume data using bandwidth efficient protocol that fits in constrained embedded environment.;3
XD-2971;As a user I'd like to refer to the documentation to configure the properties file so I can use it as recommended to represent the deployment manifest.;1
XD-2973;As a user I'd like to run the sqoop jobs against secured hdfs cluster so I can restrict access to only authorized users.;3
XD-2979;As a user I'd like to use the Java receptor client so I can interact with Diego runtime using the Java receptor REST APIs.;5
XD-2980;As a user I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without _xd-containers_.    Scope:  * Complete the remaining deployment properties work;5
XD-2986;As a follow up to XD-2877 experiment with the removal of the list of modules from BaseDefinition and reparse as needed.    Branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2;5
XD-2990;As a user I'd like to have the option of reliable HDFS writes (for stream pipelines) so I can get acknowledgement of actual HDFS _commits_ as opposed to just from the message bus.;4
XD-2991;As a developer I’d like override the partition function within my source or processor module so I can send the data to a specific partition.;4
XD-2992;As a user I'd like to consume multiple topic-partitions so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.;3
XD-2993;As a Flo developer I'd like to have a new DSL parser so I can easily  detect incorrect module/option values when supplied from the Flo UI.    Example:  MyStream = mail | log  tap:stream:MyStream.bar > log    If parsed separately (which Flo UI does) the current parser endpoint will barf on the second stream because it doesn’t know about the first stream (MyStream).;5
XD-2996;As a developer I want that the Spring XD partitioning process targets Kafka bus partitions directly so that the design of my stream processing application is easier to understand and the order of messages is not altered    Current situation  - Spring XD partitioning logic that builds on top of Kafka partitioning  - The number of Spring XD partitions is not explicitly configured (it's inferred from the number of consumer modules)  - If the concurrency of the consumer modules is 1 then Spring XD partitions are matched 1:1 with Kafka partitions  -  If the concurrency of the consumer modules is n then a Spring XD partition uses n Kafka partitions and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions  - this could be confusing to the end user especially if they are used to the Kafka partitioning process  - this can also lead to changes of ordering between messages as messages within the same Spring XD partitions will be sent to different Kafka partitions (this only happens if the concurrency of the receiving module is higher than 1)    Improvement:  - *For the Kafka message bus* the number of Spring XD partitions does not need to be equal to the number of modules (must be higher or equal though so that consumers can be created) and should be configured explicitly - using the `partitionCount` property - (as an option the module count * concurrency can be used as a default)   - as a result in the case of Kafka there will always be a 1:1 match between Kafka partitions and Spring XD partitions optionally processed by fewer modules than the partition count;4
XD-2997;As a developer I'd like to design and document the approach towards deploying stream in a single container so I can have all modules within a stream colocated.;4
XD-2998;As a developer I'd like to handle the non-default {{ConfigurableConversionService}} tuples in an uniform manner so they're not reset after deserialization.;4
XD-2999;As a developer I'd like to benchmark a stream with and without {{JMX}} enabled so I can test in isolation and document the differences in performance.;3
XD-3003;As a user I'd like to have the option to change the default Sqoop _metastore_ so I can implement a DB of my choice and not tied to default specifications.    Refer to this [thread|http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore] for more details.;1
XD-3019;As a user I'd like to refer to the documentation so I can configure HDFS backed module registry (XD-2287) as recommended.;1
XD-3020;As a user I would like the ability to undeploy or suspend a module without losing the deployment properties.  Currently when temporarily suspending a module an undeploy and redeploy is executed.  During the redeploy the deployment properties need to be added again.  Instead it would be nice if the properties are persisted so they automatically included with the deployment.;4
XD-3024;As a user I'd like to have a REST-API to get all the _counters_ _gauges_ and _rich-gauges_ in a single request so I don't have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.    *Example:*  {code}  /metrics/counters/all (fetches all available counters)  /metrics/gauges/all (fetches all available gauges)  /metrics/rich-gauges/all (fetches all available rich-gauges)  {code};4
XD-3026;As a spring developer I can specify the default value for the module configs at the module config xml file and if no specific overriding options given the default value should get preferred.  Currently I see that by design we want to rely on the default option values from the ModuleOption metadata. But the cases where some module configurations can't have the default (say customerKey for twitterstream module) and would be tempting to just try deploying after changing the twitterstream.xml with the default value expecting it to work.;3
XD-3037;As a user I want to have a documentation that shows how to configure multiple topics with Kafka source module.;1
XD-3040;As a user I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without _xd-containers_.    Scope:  *;4
XD-3043;As a user I'd like to use the GF source along with native GF authentication enabled so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured.     See this [SC post|https://gopivotal-com.socialcast.com/messages/24377202] for more details.;1
XD-3044;As a user I'd like to have an OOTB _jdbcgpfdist_ batch job so I can read from JDBC and write to HAWQ/GPDB using _gpfdist_ protocol.   The scope is to reuse the existing gpfdist sink code and adapt it to fit the batch model (_gpfdist_ writer).;5
XD-3045;As a developer I'd like to separate mocks vs. real repository coupling from the test infrastructure so it is easy to test against thin layer of dependencies.;5
XD-3050;As a developer I'd like to move the project reactor based [data processor module|https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor] from _spring-xd-module_ repo to the core so I can natively use Reactor's Stream API to build processor modules.;3
XD-3052;As a developer I'd like to move the project reactor based [gpfdist|https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist] from spring-xd-module repo to the core so I can natively use this sink to write to GPDB/HAWQ.;2
XD-3057;As a devops I would prefer having my module registry located in centralized github repository. This would allow all the admins and containers in the cluster pointing to the same module registry. Any new module upload would be pushed to the same github repo which will make the cluster always be in sync on the Module Registry.;4
XD-3061;As a developer I'd like to remove _ID_ and _TimeStamp_ attributes from the {{Tuple}} class so I can improve performance characteristics by not having them go through _serde_ instead we could leverage message headers to collect such information.;3
XD-3068;As a user I would like to specify the default output channel when the channel name resolution doesn't occur. In cases where I won't prefer to lose the data and like to investigate the messages from errorChannel or that sort.;2
XD-3071;As a developer I'd like to bench Rabbit on rackspace infrastructure so I can have a sense on how it scales as we add more _xd-container_ nodes.;5
XD-3072;As a Flo developer I'd like to add improvements to existing Flo parser endpoints so I can streamline the error reporting strategy.;3
XD-3076;"As a user I'd like to use the _Mail_ source to connect to secured IMAP and/or SMTP mail servers.     _Mail_ source config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}     <beans:beans profile=""default"">          <util:properties id=""javaMailProperties"">              <beans:prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</beans:prop>              <beans:prop key=""mail.imap.socketFactory.fallback"">false</beans:prop>              <beans:prop key=""mail.store.protocol"">imaps</beans:prop>              <beans:prop key=""mail.debug"">false</beans:prop>          </util:properties>      </beans:beans>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]";1
XD-3077;As a developer I'd like to default to HDFS as distributed remote location for custom module registry so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.;3
XD-3097;As a user I'd like to have shell to automatically configure itself against an environment I have setup.  This really came up with ambari work where shell can be anywhere in a cluster. Best I was able to do for now is to build an init file for commands(ambari xd-shell deploy already knows locations/addresses for xd admin and namenode): {code} $ cat /etc/springxd/conf/xd-shell.init  admin config server http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 {code}  and then run those after starting xd-shell: {code} server-unknown:>script --file /etc/springxd/conf/xd-shell.init admin config server http://ambari-2.localdomain:9393 Successfully targeted http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 Script required 0.662 seconds to execute xd:> {code};1
XD-3099;As a user I'd like to have the option to gracefully shutdown the stream so when it is _undeployed_ while in the middle of its operation we would want to complete its journey to the sink before XD stops the stream.    *Use case:*  One of the streams has a custom module that performs archive extraction. When this stream is ‘undeployed’ while in the middle of extraction It looks like the message goes to the DLQ. However we would like the message to complete its journey to the sink of the queue before xd stops the stream. Is this possible?;5
XD-3102;As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Sinks to be included in test:  In-Memory Transport > Hdfs sink  Direct Binding Transport > Hdfs Sink  Kafka > Hdfs Sink;5
XD-3103;As a developer I'd like to upgrade to 2.0.3 release of Reactor so I can inherit the latest optimizations to further improve XD performance characteristics.;3
XD-3105;As a developer I'd like to have JMX turned-off by default so I can take advantage of the performance throughput benefits.;1
XD-3107;As a XD build master I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues so I can evaluate that publish builds works as expected.;3
XD-3110;As a developer I'd like to clean-up compiler and javadoc warnings from the build so we don't see  the warnings in build sysout.;2
XD-3118;As a user I'd like to start multiple instances of {{xd-container}}'s through the RPM scripts so I can easily spin-up instances on the same node/vm.;2
XD-3127;As a user I'd like to refer to OOTB batch jobs and the documentation so I can jump to the right job section and review details.;1
XD-3139;As a user I'd like to refer to the analytics tab docs so I can understand how to use various widgets from streaming pipeline.;2
XD-3140;As a user I'd like to have a landing page with higher-order links for sources processors sinks and jobs so I can jump to right section from one place.;1
XD-3144;"As a developer I would like to be able to configure which exceptions thrown by a module should be retryable within the {{RabbitMessageBus}}.  As usual these should be configurable at the bus and/or stream deployment property level.  Also consider disabling retry for kryo deserialization problems. ----  We are running Spring XD with RabbitMQ transport and we'd like to have a way to stop retries in certain situations. In [Spring XD 1.2.0.RC1 docs|http://docs.spring.io/autorepo/docs/spring-xd/1.2.0.RC1/reference/html/] in chapter about RabbitMQ transport in ""A Note About Retry"" section it's written:  {quote}Message deliveries failing with a MessageConversionException (perhaps when using a custom converterClassName) are never retried the assumption being that if a message could not be converted on the first attempt subsequent attempts will also fail.{quote}  Following is unclear: # Are we speaking about {{org.springframework.messaging.converter.MessageConversionException}} or {{org.springframework.amqp.support.converter.MessageConversionException}}? Based on XD-1597 and AMQP-390 it's the latter. # Only {{org.springframework.messaging.converter.MessageConversionException}} is available for custom module developers. Attempting to throw {{org.springframework.amqp.support.converter.MessageConversionException}} which is provided by {{$XD_HOME/lib/messagebus/rabbit/spring-amqp-1.4.5.RELEASE.jar}} results in {{java.lang.ClassNotFoundException}} even after Spring XD is configured to use {{rabbit}} transport. # Throwing  {{org.springframework.messaging.converter.MessageConversionException}} from custom processor module written with Spring Integration's {{transformer}} or {{service-activator}} doesn't stop retries.";4
XD-3152;As a developer I'd like to update to the 4.1.5 SI release so I can pickup the latest improvements to message channels.;1
XD-3153;As a developer I'd like to update to SI Kafka extension 1.2.0 so I can leverage the latest performance improvements.;1
XD-3154;As a developer I'd like to update to Spring Hadoop 2.2.0 GA release so I can leverage the latest improvements.;1
XD-3156;As a developer I would like to create DSL based jobs using Spring XD.   Currently BatchJobRegistryBeanPostProcessor implementation has an assumption in postProcessAfterInitialization( ) method (line 92). It checks if the beans are instanceof StepParserStepFactoryBean which is XML based steps. Therefore any XD step listeners for tap events are not getting registered effectively I'm not getting any Step events out of my DSL based jobs.  Apparently everything else is working alright for the Java DSL job. Java DSL jobs are far easier to write Test/Integration Tests with.  Please review issue type - I was not sure if this was a bug or improvement i supposed it is an improvement.;1
XD-3157;As a developer I in the new development of component (source/processor/sink) how to get the module id and container id  Because components need to generate log log information must include the unique identifier   xd:>runtime modules;1
XD-3164;As a developer I want to be able to override Kafka bus defaults for module consumers and producers so that I can finely tune performance and behaviour.     Such properties should include  - autoCommitEnabledqueueSizemaxWaitfetchSize for consumers  - batchSizebatchTimeout for producers;3
XD-3165;As a PM I'd like to have XD and XD + Ambari RPM scripts into a single public repo so that users can go to a single location to use the respective build scripts.;3
XD-3166;As a developer I'd like to publish performance benchmarks along with the infrastructure specifics so the users can use it as a reference while setting up Spring XD cluster.;5
XD-3169;As a developer I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.;5
XD-3170;As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.  The documentation also needs some more information on `Reliable` receiver.;1
XD-3173;"As a user I'd like to be able to understand the root cause of an error on the {{http}} shell command.  When an exception occurs on an {{http}} shell command the user gets  {{""Failed to access http endpoint %s"" target}}  No information from the exception is conveyed to the user (nor is it logged by the admin).";1
XD-3192;As a user I'd like to have the module/app specific metrics consumed directly from Boot actuator [export()|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java] API so I can have insight on how it is performing being used and that it works etc.;5
XD-3193;As a developer I'd like to handle module options via pure boot property source management so I can leverage Boot's module [METADATA|http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core Spring XD runtime CP.;5
XD-3194;As a developer I'd like to have a central place to manage external properties for applications across all the environments so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers.;5
XD-3195;As a developer I'd like to troubleshoot the performance issues with Rabbit as message bus implementation so I can isolate the bottleneck and fix as appropriate.;5
XD-3196;As a developer I'd like to migrate the current MASTER branch CI builds to EC2 instances so I can manage them all in one-place reliably.;5
XD-3197;As a developer I'd like to add an option to support Apache Ambari installed Spring XD on YARN so I can easily establish the cluster up and running.;4
XD-3198;As a developer I'd like to use spring-cloud-config server for spring-bus modules so I can centrally manage external properties.;5
XD-3199;"As a developer I'd like to split up spring-xd dependencies to more fine-grained so I can get the ones ""below the line"" down to spring-bus-* instead of spring-xd-* bundle.";5
XD-3200;As a user I'm trying to delete the custom module using the {{module delete}} command via shell though the command is successfully I'm still seeing the associated artifact (_.jar file_) present in the custom_modules folder. Refer to [SO thread|http://stackoverflow.com/questions/30984922/springxd-module-delete-command-does-not-delete-the-uploaded-jar-file] for more details.;4
XD-3202;As a developer I'd like to investigate channel performance issues in SI 4.2 so I can determine the bottlenecks and take corrective actions to improve overall channel performance.;5
XD-3203;As a developer I'd like to measure the baseline serialization characteristics in XD so I can determine the areas of performance improvements.;4
XD-3204;As a spring-bus lead I'd like to review the current spring-bus architecture and the design specs so I can address any foundation level gaps.;4
XD-3205;As a user I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin so I can work on the latest release bits. I'd like to refer to the documentation to do so.;1
XD-3211;As a user I would like to use fsUri = file:// to use Hadoop LocalFileSystem instead of a running cluster. In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job. The quickest way to solve this was to change the fsUri to file://. and it should have just worked.   This will work alright for singlenode setups for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing.;1
XD-3215;As a user I'd like to have the option to specify system properties that will be passed in to the Sqoop job which runs in it's own Java process. This is needed for defining memory usage and also for defining some options for various connector implementations.;4
XD-3217;As a user I'm trying to connect to {{xd-admin}} server with basic security enabled however I'm unable to successfully connect to the server and I get the following error message.      {code:java}  server-unknown:>admin config server --uri http://localhost:9393 --username bob --password bobspwd  Unable to contact XD Admin Server at 'http://localhost:9393'.  {code};4
XD-3222;"As a user I would like to connect the Sqoop batch job to Teradata for import jobs.     I have tried the Teradata JDBC driver directly using:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}    but that results in an NPE.    The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz    That one allows me to use the following:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}";3
XD-3223;As a user I would like to be able to configure the logging directory to be outside of what is defined as xd.home. The logging directory is currently hard coded as {code}${xd.home}/logs{code}.    This would be useful for RPM installations where the logs really should be going to `/var/logs/spring-xd` instead of the current `/opt/pivotal/spring-xd/xd/logs` location.;3
XD-3224;As a developer I'd like to move message-bus from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;5
XD-3225;As a developer I'd like to move 'input/output type conversion' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;5
XD-3226;As a developer I'd like to move 'serialization codec' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;5
XD-3227;As a developer I'd like to develop a “singlenode�? (in a single JVM) implementation of XD Admin SPI (based on Module Launcher) so I can run data pipeline use-cases locally.;5
XD-3228;As a Spring XD user I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF Lattice/Diego.;5
XD-3229;As a s-c-s user I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.;5
XD-3230;As a developer I'd like to upgrade to Reactor 2.0.4 release so I could leverage the latest improvements and bug-fixes.;1
XD-3231;As a developer I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers so it is setup for HA.;4
XD-3233;As a developer I'd like to create an annotation ({{@EnableModule}}) driven programming model for modules so instead of explicitly defining I/O channels as beans on the module for classes annotated with {{@EnableModule}} the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.    The {{@Input}} and {{@Output}} annotations will be used to indicate the input and output channels of the module.;5
XD-3238;As a developer I'd like to complete the remaining Kryo optimization changes so I can polish and get the guidelines documented appropriately.;1
XD-3239;As a developer I'd like to move 1.2.x branch to EC2 infrastructure so I can reliably run CI test suites.;2
XD-3256;As a developer I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo so I could define the module {{artifactId}} from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.;5
XD-3260;As a developer I'd like to move 'serialization codec' from Spring XD repo into SI so I can update Spring XD to inherit the features/functionalities via maven dependency.;2
XD-3265;As a Spring XD user I'd like to use {{CloudController}} based implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF.    Relevant repos: [spring-cloud-data|https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers] | [spring-cloud-stream|https://github.com/spring-cloud/spring-cloud-stream]    Please refer to XD-3194 or XD-3229 as sample spike-deliverables (_google doc_) that were completed in the last sprint.;5
XD-3267;As a Spring XD on CF user I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics.    *Possible APIs:*  {code}    ModuleStatus getStatus(ModuleDescriptor descriptor)    Collection<ModuleDescriptor> listModules()    Map<ModuleDescriptor.Key ModuleStatus>    {code};4
XD-3268;As a Spring XD on CF user I'd like to use {{cloudController}} implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics.  *Possible APIs:* {code}  ModuleStatus getStatus(ModuleDescriptor descriptor)  Collection<ModuleDescriptor> listModules()  Map<ModuleDescriptor.Key ModuleStatus>  {code};5
XD-3269;As a Spring XD developer I'd like to have a permanent location of SPI implementations so I could use the common repo every time I contribute or enhance the test coverage.;3
XD-3270;As a Spring XD developer I'd like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.;4
XD-3271;As a Spring XD user I'd like to make SPI implementation profile aware so I can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.;3
XD-3273;As a s-c-s user I'd like to have the modules self-register itself with {{Eureka}} whenever they're installed so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines.;4
XD-3274;As a s-c-s user I'd like to search the modules by it's name aside from the default {{spring.application.name}} offered by boot so I can also fetch modules by it's name.;2
XD-3275;As a s-c-s user I'd like to store module metadata in {{Eureka}} so I can use the repository to determine the current state.;2
XD-3276;As a s-c-s user I'd like to have my modules add/update it's current state to Eureka so I can use the repository to discover the current sate of the module as needed.;2
XD-3277;As a Spring XD developer I'd like to refactor current controller with SPI calls so I can invoke the respective Admin SPI implementation based on the deployment.     *Controllers to Refactor*  * ContainersController  * StreamsController  * ModulesController  * JobsController;4
XD-3278;As a Spring XD user I'd like to capture module (aka: {{cf apps}}) metrics directly so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently there are two different ways we could consume this information from applications. SI's {{channel()}} and SBoot's {{actuator()}} APIs are the few to explore as part of this scope.;4
XD-3281;As a Spring XD developer I'd like to self-register {{xd-admin}} server with {{Eureka}} so I could have admin server exposed as discoverable endpoint.;3
XD-3282;As a s-c-s developer I'd like to setup CI builds for s-c-s builds so I can incrementally build and test code commits automatically.;3
XD-3283;As a Spring XD developer I'd like to port {{FTP/SFTP}} modules from XD to s-c-s repo so I can use them as {{source}} modules to build streaming pipeline.;2
XD-3284;As a Spring XD user I'd like to persist module (aka: {{cf apps}}) metrics directly so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently SBoot's {{export()}} API allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). This could be something to explore as part of this scope.;4
XD-3287;As a user I'm trying to setup HA cluster using Ambari installed Spring XD however I'm running into issues with the overrides. More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].;4
XD-3288;As a s-c-s developer I'd like to setup a CI workflow to build bundle and upload the {{module-launcher}} image to DockerHub so I don't have to worry about having a local-private docker registry for development/testing.    It could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] DockerHub location.;4
XD-3290;As a Spring XD user I'd like to have [IPython Notebook|http://ipython.org/notebook.html] integration so I can perform interactive data computations in real-time.;5
XD-3292;As a Azure user I'd like to read/write data from Azure Event Hubs. so I can leverage the pub-sub service to process and analyze large volumes of data.;5
XD-3293;As a Spring XD user I'd like to have IPython Notebook integration so I can perform interactive data computations in real-time.;5
XD-3303;As a user I'd like to refer to documentation while migrating to 1.3 release.;3
XD-3309;As a s-c-s user I'd like to have the option to direct bind _modules_ so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.;5
XD-3310;As a s-c-d developer I'd like to establish the foundation to expose REST-APIs to interact with the {{xd-admin}} and likewise perform CRUD operations to maneuver streaming and batch pipelines.;4
XD-3311;As a s-c-d developer I'd like to create {[ModuleRegistry}} stubs so I can create mock streams by interacting with the registry APIs.;3
XD-3312;As a s-c-s developer I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.;3
XD-3313;As a spring-cloud-data developer I'd like to use an in-memory stream definition repository so I don't have to spin up a store obviously this will not persist between application executions but it will be useful for a simplified development experience.;4
XD-3314;As a s-c-d developer I'd like to invoke REST APIs via shell so I can validate {{StreamController}} operations.;5
XD-3315;As a s-c-s developer I'd like to adapt redis {{counter}} from XD to s-c-s so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards.;3
XD-3316;As a s-c-d developer I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data] so I can build the project continuously on every commits.;4
XD-3317;As a s-c-s developer I'd like to investigate the right approach to include external library as dependency (ex: MySQL) so I can decide better handling of libraries which needs loaded and available in root CP at the runtime.;5
XD-3318;As a s-c-s developer I'd like to _bootify_ {{ModuleLauncher}} so I can use Spring Boot's support for property setting as well as adding options and new functionality in the future such as CP augmentation.;4
XD-3319;As a s-c-s developer I'd like to investigate the right approach to port {{PHD}} as the provider to support {{HDFS}} module from XD so I can decide better handling of HDFS dependencies which needs loaded and available in root CP at the runtime.;4
XD-3320;As a s-c-d user I'd like to add REST support for stream commands so I can maneuver streaming pipeline backed by StreamController.;4
XD-3322;As a s-c-s developer I'd like to setup CI infrastructure for {{spring-cloud-stream-modules}} (s-c-s-m) repo so I can build the project continuously on every commits.;3
XD-3337;As a s-c-d developer I'd like to investigate how to include/exclude msg bus/binding jars so I can decide the binding selection and fallback mechanism when there is none setup.;4
XD-3338;As a s-c-d developer I'd like to add as many jars via a bom (e.g. hadoop distro deps) so I don't have to explicitly worry about individual but related libraries.;2
XD-3339;As a s-c-d developer I'd like to add support for dependency resolution so when two or more modules use different version of jars (ex: direct binding of two modules that include different versions of spring data) I have the capability to resolve and include the right bits at runtime.;2
XD-3341;As a s-c-d developer I'd like to publish the s-c-d image to DockerHub so I can incrementally push the latest commits to the remote location.;1
XD-3343;As a s-c-s developer I'd like to create a public screencast of {{firehose| counter}} pipe so I can demonstrate s-c-s and the development experience.;3
XD-3344;As a s-c-d developer I'd like to implement _undeploy_ operation for {{singlenode}} (single JVM) so I can use this target to undeploy a running stream. More details in [this PR|https://github.com/spring-cloud/spring-cloud-data/pull/19].    *Note:* Its a prerequisite to determine consistent _undeploy_ strategy for both {{jobs}} and {{streams}}.;5
XD-3346;As a XD user I'm trying to access URI (- GET /jobs/executions//steps//progress => hasRole('ROLE_VIEW')) but it fails with 403 forbidden error for the role with view access. More details [here|https://issuetracker.springsource.com/browse/VESC-475].    Another URL with the same error: http://<HOST>:9393/streams/definitions.json?page=0&size=10;1
XD-3348;As a s-c-d developer I'd like to add support for _profiles_ to the core {{Admin}} application so I can back the stream repository with respective backend strategy. For example: {{local}} profile would use in-memory strategy to store the metadata.;3
XD-3350;As a s-c-d developer I'd like to add support to expose counter (metrics) endpoints so I can consume to feed the dashboards to demonstrate {{firehose | counter}} pipe.;3
XD-3353;As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.;4
XD-3355;As a s-c-d developer I'd like to collaborate with Boot engineering team and derive a strategy for module metadata via {{@ConfigurationProperties}} so I can implement the functionality to support {{shell}} {{autocompletion}} {{flo}} and {{ascii}} documentation in _spring-cloud-data_.     Eric's [gap analysis|https://docs.google.com/document/d/1A-9RpgSNL6SXD61q9eW2YRkrkn3tXk09rdkx7eCKlxY/edit#] document captures all the specifics in detail.;5
XD-3357;As a Spring XD user I'm trying to use a custom MongoDB Batch job however I'm getting an error running it against 1.2.0/1.2.1 release while the same works with older releases of Spring XD. More details in this [SO thread|http://stackoverflow.com/questions/31838720/mongodb-batch-job-broken-in-spring-xd-1-2-0].;3
XD-3362;As a Spring XD developer I'd like to port {{http}} module from XD to s-c-s repo so I can use it as {{source}} module in streaming pipeline.;2
XD-3363;As a Spring XD developer I'd like to port {{tcp}} module from XD to s-c-s repo so I can use it as {{source}} module to build streaming pipeline.;2
XD-3364;As a Spring XD developer I'd like to move {{twitterstream}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;2
XD-3365;As a Spring XD developer I'd like to move {{twittersearch}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;2
XD-3366;As a Spring XD developer I'd like to port {{filter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3367;As a Spring XD developer I'd like to port {{transform}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3368;As a Spring XD developer I'd like to port {{router}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3369;As a Spring XD developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3370;As a Spring XD developer I'd like to port {{FTP/SFTP}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.;2
XD-3374;As a Spring XD developer I'd like to move {{redis}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3375;As a Spring XD developer I'd like to move {{rabbit}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3376;As a Spring XD developer I'd like to move {{gemfire}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3378;As a Spring XD user I'd like to use the latest releases of {{HDP}}/{{PHD}} distros so I can leverage the latest features to create pipelines involving {{HDFS}}.;5
XD-3379;As a Spring XD developer I'd like to create a section on migration strategy from {{1.2}} to {{1.3}} releases so I can document new improvements and backward incompatibility specifics.;3
XD-3381;"As a module author I want to be able to test my code in ""next to real world"" conditions (ie Integration Testing but not really):  - I want all my module wiring to be testable  - I want all my module configuration (@ConfigurationProperties) to be in effect and I want to be able to test various combination of props  - I want to be able to send data to my module and assert what is coming at the other end  - I want an idiomatic way of asserting the above (eg integration with Hamcrest etc)  - I DONT want to have to send data to an actual bus (redis rabbit etc)";4
XD-3388;As a Spring XD developer I'd like to move {{trigger}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3389;As a Spring XD user I'd like to use redis/sentinel cluster as the 'message bus' so I could create streams and batch pipelines.;5
XD-3393;As a s-c-d developer I'd like to upgrade {{receptor-client}} to comply with latest {{Receptor}} API changes so I can sync-up and take advantage of the recent improvements.;3
XD-3397;As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.;2
XD-3398;As a s-c-s developer I'd like to create auto configuration for {{singlenode}} binder configuration/properties so I can automatically configure the Spring application based on the dependencies.;1
XD-3400;As a s-c-d user I'd like to have the option to support passing definition parameters into YARN container so I can effectively use those _params_ within the module running inside the container.;3
XD-3401;As a s-c-d developer I'd like to add support to deploy YARN App into HDFS automatically so I can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.;3
XD-3403;"As a s-c-d developer I'd like to support multiple app instances:  * This is simply to make controlling app instances more clever. Potentially we could use deployment properties to define different yarn app instances like:    {code}  cloud-data:>stream deploy --name ticktock --properties ""module.*.yarn.app.name=app""     cloud-data:>stream deploy --name ticktock --properties ""module.time.yarn.app.name=app""  {code}    * Motivation to this is that different yarn apps can have different queues and priorities. Yarn administrator can define that some app queues have higher priority to reserve resources from    * Using deployment properties like this allows to customize runtime parameters like how much we try to reserve mem/cpu for modules etc.";2
XD-3404;As a s-c-d developer I'd like to make the deployer work asynchronously so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.;2
XD-3405;As a s-c-d developer I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader so I have an approach to handle external libraries required by OOTB modules.;4
XD-3406;As a s-c-s developer I'd like to refactor the current {{ModuleLauncher}} contract with Boot's {{JarLauncher}} API so we don't have to maintain duplicate functionality.;1
XD-3407;As a s-c-d developer I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader so we could use this as a reference while porting modules with external dependencies.;3
XD-3408;As a s-c-d developer I'd like to add support to add external libraries so I can consume such dependencies for modules in an uniform way.;2
XD-3409;As a s-c-d developer I'd like to enforce external libraries from overriding any existing library in the uber-jar.;2
XD-3411;As a s-c-d developer I'd like to move the external library to its own project so we have a clear separation of functionalities in s-c-d repo.;3
XD-3412;As a Spring XD developer I'd like to port SFTP module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;4
XD-3414;"As a s-c-d developer I'd like to create a new project to contain all the rules associated {{@RedisRule}} contract so it is isolated from core functionalities and reusable by test coverage as needed.      Consider moving this coverage to SI ""commons"" or equivalent.";4
XD-3416;As a s-c-d developer I'd like to create foundation to support _processor_ as OOTB modules so I can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.;4
XD-3418;As a s-c-s developer I'd like to enable {{offline}} mode for {{AetherModuleResolver}} so I can pull the module artifacts from local instead of remote maven repo.;3
XD-3419;As a s-c-d developer I'd like to create {{ModuleRegistry}} implementation so I can use this infrastructure to lookup module coordinates by name.;5
XD-3425;As a s-c-d developer I'd like to have {{module info}} {{module list}} {{module register}} and {{module unregister}} commands so I can interact with {{ModuleRegistry}}.;5
XD-3426;As a s-c-d developer I'd like to have {{module info}} shell command so I can query each of the module specifics such as description and support options.;2
XD-3427;As a s-c-d developer I'd like to have {{module list}} shell command so I can query and list all the modules supported within the {{ModuleRegistry}}.;2
XD-3428;As a s-c-d developer I'd like to have {{module register}} shell command so I can register new modules in the {{ModuleRegistry}}.;2
XD-3429;As a s-c-d developer I'd like to have {{module unregister}} shell command so I can unregister an existing module from the {{ModuleRegistry}}.;2
XD-3430;As a s-c-d developer I'd like to provide optional key-value pairs as deployment properties so I could leverage them at the runtime to instruct how the modules will be deployed.   _The scope of this story is to specifically support {{count}} to represent {{N}} instances of modules that share the same environment variables._;5
XD-3444;As a s-c-d developer I'd like to setup {{gh_pages}} branch for s-c-d and s-c-s-m repos so I can start pushing documentation with PR commits.;4
XD-3445;As a s-c-s developer I'd like to fix the {{Kafka}} binder so I can create messaging microservices apps and successfully bind them to an operational Kafka broker.;3
XD-3447;As a s-c-d developer I'd like to produce ref. documentation for s-c-d architecture so I could define 1.x and 2.x deployment differences.;5
XD-3448;As a s-c-d developer I'd like to study [Concourse CI|http://concourse.ci/] so I can understand how to use it for s-c-d going forward.;3
XD-3454;As a module author I would like to apply RxJava processor module with spring cloud stream.;3
XD-3462;As a s-c-d user I'd like to create a new banner so I can embed and display the banner when the shell server boots-up.     Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?;1
XD-3463;As a s-c-d developer I'd like to document [Running on Cloud Foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in README so it can be publicly available as deployment guideline.;2
XD-3466;As a s-c-d developer I'd like to add _hdfs_ sink to module registry so I can use this module to build streaming pipeline and write to Hadoop.;1
XD-3467;As a s-c-d developer I'd like to add support for hadoop commands in shell so I can use it to query the hadoop file system.;3
XD-3478;"As a XD developer I'd like to explore repository options for ""composed jobs"" so I have the leverage to read/write composed job definitions.";4
XD-3479;As a XD user I'd like to orchestrate composed jobs so I can bring multiple jobs into single workflow and operationalize.;4
XD-3480;As a s-c-d developer I'd like to add test coverage to test {{shell}} commands in isolation so I don't have to run end-to-end full stream deployment based functional tests.    More details [here|https://docs.google.com/document/d/18uNqRAgVGO0BHdvDsVg3X78gDBeqXA_LN_C6jJ0YpKw/edit#].;4
XD-3481;As a s-c-s developer I'd like to support XD-like features where modules bind to incoming messages via expressions or other mechanism so I can bind message properties to every microservice modules.;4
XD-3482;As a s-c-s-m developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.   See also XD-2250;4
XD-3483;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{source}} to build streaming pipeline.;2
XD-3484;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3485;As a s-c-d developer I'd like to move {{rabbit}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2
XD-3486;As a s-c-d developer I'd like to add support for having different binder types for module's channels so I can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.;5
XD-3487;As a s-c-d developer I'd like to pass any overrides via external config file so I can influence and override the default module configurations. (ex: module resolution from a different maven coordinate).;3
XD-3488;As a s-c-d developer I'd like to refactor CC SPI deployer with CF java-client so I can improve the overall design and performance.;5
XD-3489;As a s-c-d user I'd like to have the option to choose Hadoop distribution of choice so I can load the right Hadoop libraries in the CP.;4
XD-3492;As a XD developer I'd like to move header-enricher from modules repo to XD proper.;1
XD-3493;As a XD developer I'd like to upgrade to SI 4.2 Spring 4.2.1 and AMQP 1.5 dependencies so I can take advantage of the latest improvements.;3
XD-3494;As a s-c-d developer I'd like to document the use of BOM templates so the general audience can use it as a reference to include external libraries dynamically.;1
XD-3496;As a s-c-d developer I'd like to enhance integration test coverage for {{Lattice}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3497;As a s-c-d developer I'd like to enhance integration test coverage for {{CC}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3498;As a s-c-d developer I'd like to enhance integration test coverage for {{YARN}} SPI so I can continuously evaluate functionalities via CI pipeline.;4
XD-3499;As a s-c-d developer I'd like to enhance unit test coverage for {{Lattice}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3500;As a s-c-d developer I'd like to enhance unit test coverage for {{YARN}} SPI so I can continuously evaluate functionalities via CI pipeline.;3
XD-3501;"As a user I'm not able to shutdown {{container}} from Admin UI with the following stream definition deployed.    {code}  stream create swagataTestIssue --definition ""jdbc --query='select employee_id employee_name employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy   {code}    More details [here|https://issuetracker.springsource.com/browse/VESC-504].";2
XD-3504;As a s-c-s user I'd like to have the option to use more than one binder connection factory so I can mix and match where I consume and publish data.     More details [here|https://github.com/spring-cloud/spring-cloud-stream/issues/140].;4
XD-3505;As a s-c-d user I'm unable to push admin app to CF due to SSL certification errors while bootstrapping.     Consider adding [CF trusted certificate|https://github.com/pivotal-cf/cloudfoundry-certificate-truster] as a CF SPI dependency.    Adding CF trusted certificate as dependency doesn't help either:    {code}  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.Validator.validate(Validator.java:260)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)  > Fri Sep 25 2015 12:55:32 GMT-...  {code};3
XD-3508;As a XD developer I'd like to refactor and replace {{codec}} code from XD with SI library so I don't have to maintain duplicate code.;3
XD-3512;As a s-c-s user I'd like to have {{Gemfire}} message-channel binder so I can use {{Gemfire}} as the messaging middleware for low latency use-cases.;5
XD-3513;As a s-c-d user I'd like to have the option of {{Gemfire}} SPI so I can use {{Gemfire}} and the infrastructure to orchestrate s-c-d data microservices.;5
XD-3514;As a s-c-d user I'd like to have the option of {{Gemfire}} as stream repository so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.;5
XD-3515;As a s-c-d user I'd like to have the option of {{Gemfire}} as module registry so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.;5
XD-3523;As a Spring XD developer I'd like to move {{jms}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3524;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3525;As a Spring XD developer I'd like to move {{mongo}} module from XD to s-c-s-m repo so I can use it as source to build streaming pipeline.;2
XD-3526;As a Spring XD developer I'd like to move {{mqtt}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3527;As a Spring XD developer I'd like to move {{reactor-ip}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3528;As a Spring XD developer I'd like to move {{stdout}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3529;As a Spring XD developer I'd like to move {{syslog}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3530;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3531;As a Spring XD developer I'd like to move {{tcp}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3532;As a Spring XD developer I'd like to move {{tcp-client}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3533;As a Spring XD developer I'd like to move {{gpfdist}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3534;As a Spring XD developer I'd like to move {{hdfs-dataset}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;4
XD-3535;As a Spring XD developer I'd like to move {{mail}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3536;As a Spring XD developer I'd like to move {{mongo}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3537;As a Spring XD developer I'd like to move {{mqtt}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3538;As a Spring XD developer I'd like to move {{null}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3539;As a Spring XD developer I'd like to move {{shell}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3540;As a Spring XD developer I'd like to move {{splunk}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3541;As a Spring XD developer I'd like to move {{tcp}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2
XD-3542;As a Spring XD developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2
XD-3543;As a Spring XD developer I'd like to port {{aggregator}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3544;As a Spring XD developer I'd like to port {{http-client}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3545;As a Spring XD developer I'd like to port {{json-to-tuple}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3546;As a Spring XD developer I'd like to port {{object-to-json}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3547;As a Spring XD developer I'd like to port {{script}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3548;As a Spring XD developer I'd like to port {{shell}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3549;As a Spring XD developer I'd like to port {{splitter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2
XD-3563;As a developer I want to have a {{BinderFactory}} abstraction so that I can support multiple binder types in the future.;4
XD-3564;As a developer I want to be able to connect to multiple types of transports in an application so that I can receive and send messages to different transport types.;4
XD-3565;As a developer I want to be able to connect to multiple external systems for the same binding type so that I can read data from a system and write it to another.;4
XD-3571;As a Spring XD developer I'd like to move {{cassandra}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;4
XD-3572;As a Spring XD developer I'd like to port {{analytic-pmml}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;4
XD-3580;As a s-c-d developer I'd like to explore options to bootstrap and setup Lattice based infrastructure for s-c-d's bare metal deployment.;4
XD-3581;As a spring-cloud-stream user I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.;3
XD-3590;As a XD developer I'd like to reproduce and fix anomalies as listed [here|https://github.com/spring-projects/spring-xd-admin-ui-client/issues/9].;1
XD-3593;As a SCDF user I want to be able to register artifacts as libraries so that I can reference them in include and exclude statements.;2
XD-3595;As a s-c-d developer I'd like to add test coverage for {{StreamController}} so I can verify API contracts at build time.;3
XD-3596;As a s-c-d user I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time.;1
XD-3599;As a s-c-s user I'd like to use {{kinesis}} module so I can use it as {{source}} module to build streaming pipeline.;2
XD-3600;As a s-c-s user I'd like to use {{kinesis}} module so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3602;As a developer I'd like to port {{Log}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.;2
XD-3605;As a developer I'd like to port {{field-value-counter}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3606;As a developer I'd like to port {{aggregate-counter}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3607;As a developer I'd like to port {{gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3608;As a developer I'd like to port {{rich-gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2
XD-3609;As a data scientist I'd like to have the option to process data using {{flink}} processor so I can take advantage of the streaming machine learning abstractions implemented on top of Flink.;4
XD-3618;As a s-c-d user I'd like to have {{runtime info}} as shell command so I can use this to list the details about the module such as {{host}} {{port}} and the like.;4
XD-3619;As a s-c-d user I'd like to deploy data flow on YARN so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.;2
XD-3622;As a developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{source}} module to build streaming pipeline.;3
XD-3624;As a s-c-d developer I'd like to break the build lifecycle to bundle SPI deployers individually so I don't have to build {{admin}} with all the deployer variations as one whole thing.;5
XD-3627;As a developer I'd like to get rid off {{XDRuntimeException}} from XD.;1
XD-3629;As a user I'd like to enable HA on {{namenode}} without having to enable custom configuration.     More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].;3
XD-3631;As a user I'd like to use the latest release of {{gemfire}} sink so I can create a streaming pipeline to land data in gemfire.;2
XD-3633;As a user I'd like to use SFTP source module so I can create streaming pipeline with it. However I cannot see SFTP as OOTB module listed on: {{module list}} and as well as the module bits are not available in [maven repo|http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/].;1
XD-3635;As a developer I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family so I can continuously evaluate functionalities on every commit.;5
XD-3636;As a Flo user I'd like to have {{timeout}} and {{pollInterval}} as global options at the DSL level so I can override the defaults at will.;1
XD-3637;As a developer I'd like to upgrade to SI 4.2.1 release so I can take advantage of the latest improvements.;1
XD-3641;As a developer I'd like to review and refactor {{JobLaunchingTasklet}} so I can improve performance characteristics.;3
XD-3644;As a developer I'd like to enhance test coverage to capture DSL and XML generation variants.;4
XD-3649;As a user I'd like to use SpEL expressions inline at the stream definition level so I can operate on the payload consistently while using any OOTB including the custom modules.;5
XD-3651;As a module developer I would like the JsonStringToTupleConverter in the Spring Cloud Streams project to maintain the types provided in the JSON string and not convert everything to a String representation.;1
XD-3653;As a user I cannot use {{admin-ui}} on the master build. It won't come up.;2
XD-3654;As a user I'd like to refer to 'job orchestration' documentation so I can use it as guideline for building batch workflows.;3
XD-3656;As a developer I'd like to add {{undeployed}} status for YARN SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3659;As a developer I'd like to split {{admin}} artifact packaged with hadoop distro specific libraries so I could avoid adding all variations of hadoop libraries under one project.;4
XD-3660;As a developer I'd like to create separate repo for YARN SPI so I don't have to bundle all SPI variants under one admin project.;4
XD-3661;As a developer I'd like to upgrade to {{0.6.0}} release of Lattice so I can demonstrate data flow on the latest Lattice improvements.;4
XD-3662;As a developer I'd like to replace all references of Spring XD with Spring Cloud Data Flow.;2
XD-3663;As a user I'm trying to load Job - Modules page in admin-ui but I'm seeing exceptions in console and the page wouldn't load.     {code}  Failed to convert value of type 'java.lang.String' to required type 'org.springframework.cloud.dataflow.core.ArtifactType' nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @org.springframework.web.bind.annotation.RequestParam org.springframework.cloud.dataflow.core.ArtifactType for value 'job' nested exception is java.lang.IllegalArgumentException: No enum constant org.springframework.cloud.dataflow.core.ArtifactType.job  {code};2
XD-3664;As a developer I'd like to replace all {{Job(s)}} references with {{Task(s)}}.;2
XD-3665;As a user I'm trying to load Task Task Deployment and Task Executions page but I'm seeing an error {{(Error fetching data. Is the XD server running?)}} instead.;1
XD-3666;As a user I'd like to use the admin-ui and flo with consistent look and feel.;1
XD-3667;"As a developer I'd like to troubleshoot and fix {{root}} level access over CF SPI REST calls they're broke at the moment.     Access for following calls fail:    {code}    href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/streams""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/tasks""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters/{name}""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/modules""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/completions/stream{?startdetailLevel}""  {code}";1
XD-3668;As a user I'd like to see the version and SPI type in the `about` section so I can confirm which build of {{admin-ui}} I'm currently using.;1
XD-3669;As a user I'd like Flo Graphs as screenshots while referring to the batch DSL so it will be easy for me to relate to concepts.;1
XD-3670;As a developer I'd like to revisit the existing design and identify known limitations and/or the gaps.;4
XD-3671;As a user I'd like to have direct shell commands to scale up/down a given module instance so I can avoid SPI specific CLI commands that needs run outside of data flow.;4
XD-3672;As a developer I'd like to submit a PR for existing work on Mesos SPI.;2
XD-3673;As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629] we would want to fix this experience for Kafka message bus.;4
XD-3674;As a developer I'd like to create separate repo for CF SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3675;As a developer I'd like to create separate repo for Lattice SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3676;As a developer I'd like to create separate repo for K8s SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3677;As a developer I'd like to create separate repo for Mesos SPI so I don't have to bundle all SPI variants under one admin project.;3
XD-3678;As a developer I'd like to add {{undeployed}} status for CF SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3679;As a developer I'd like to add {{undeployed}} status for Lattice SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3680;As a developer I'd like to add support for {{undeployed}} status consistently across all the deployers so I can present the correct status instead of the current {{unknown}}. This is applicable for existing streams without any deployment context associated with it.;1
XD-3681;As a developer I'd like to add {{undeployed}} status for k8s SPI so I can represent the correct status instead of the current {{unknown}} state.;1
XD-3682;As a developer I'd like to add {{undeployed}} status for Mesos SPI so I can represent the correct status instead of the current {{unknown}} state.;3
XD-3683;"As a user I'm trying to compose a job just with one definition however I'm getting the following error message which could be misinterpreted.    {code}  xd:>job create salsa --definition timestampfile  Successfully created job 'salsa'  xd:>job create foo --definition ""salsa || salsa""  Successfully created job 'foo'  xd:>job create foo222 --definition ""salsa""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'salsa' and type 'job'  {code}";1
XD-3684;As a user I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.;3
XD-3688;As a developer I'd like to be able to clean Rabbit binder broker artifacts using the REST API.    When the Rabbit Bus was ported from XD the bus cleaner was ported as {{RabbitBindingCleaner}} but the REST API to invoke it was not ported over.;2
XD-3692;As a developer I'd like to optimize YARN deployer so I can deploy stream and the modules part of the definition rapidly.;4
XD-3695;As a developer I'd like to upgrade to 2.2.1 GA release so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.;1
XD-3696;As a developer I'd like to upgrade to SI 4.2.2.GA release so I can leverage the latest improvements.;1
XD-3698;As a user I created a composed job with over 10 child jobs in the workflow I expected to see 'a' job in the execution list page without any pagination but instead I noticed empty pagination to skip to next page.;1
XD-3699;As a developer I'd like to remove the hardcoded buildpack reference since the latest 1.6.2 ER release includes all the features required by Data Flow.;1
XD-3702;As a developer I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module so that I can take advantage of the native Kafka partitioning and message ordering support.;3
XD-3705;As a developer I'd like to upgrade Boot and Spring Cloud Build revisions so I can leverage the latest updates.;4
XD-3706;As a user I'm trying to use {{counter}} sink with {SpEL}} expression but I'm not able to use them in combination. It [throws|https://github.com/spring-cloud/spring-cloud-stream-modules/blob/master/counter-sink/src/main/java/org/springframework/cloud/stream/module/metrics/CounterSinkProperties.java#L77] {{exactly one of 'name' and 'nameExpression' must be set}} as error message.;1
XD-3707;"As a user I'm trying to get all job definitions but the first 20 alone are returned.    Job samples:  {code}  job create aaa --definition ""hello"" --deploy  job create bbb --definition ""hello"" --deploy  job create ccc --definition ""hello"" --deploy  job create ddd --definition ""hello"" --deploy  job create eee --definition ""hello"" --deploy  job create fff --definition ""hello"" --deploy  job create ggg --definition ""hello"" --deploy  job create hhh --definition ""hello"" --deploy  job create iii --definition ""hello"" --deploy  job create jjj --definition ""hello"" --deploy  job create kkk --definition ""hello"" --deploy  job create lll --definition ""hello"" --deploy  job create mmm --definition ""hello"" --deploy  job create nnn --definition ""hello"" --deploy  job create ooo --definition ""hello"" --deploy  job create ppp --definition ""hello"" --deploy  job create qqq --definition ""hello"" --deploy  job create rrr --definition ""hello"" --deploy  job create sss --definition ""hello"" --deploy  job create ttt --definition ""hello"" --deploy  job create uuu --definition ""hello"" --deploy  job create vvv --definition ""hello"" --deploy  job create www --definition ""hello"" --deploy  job create xxx --definition ""hello"" --deploy  job create yyy --definition ""hello"" --deploy  job create zzz --definition ""hello"" --deploy  job create aaa1 --definition ""hello"" --deploy  job create bbb1 --definition ""hello"" --deploy  job create ccc1 --definition ""hello"" --deploy  job create ddd1 --definition ""hello"" --deploy  job create eee1 --definition ""hello"" --deploy  {code}    Request:  {{http://localhost:9393/jobs/definitions.json}} - returns top 20 the other experiments with page size of either 0 or -1 still brings the top 20.";1
XD-3708;As a developer I'd want to document the limitations of HSQL DB when using composed jobs.;1
XD-3714;As a developer I'd like to upgrade Spring XD's ambari plugin to 1.3 release.;3
XD-3715;As a developer I'd like to move k8s SPI to it's own repo.;4
XD-3718;As a user I want to be able to provide the partitioning logic for a named destination so that I can control the ordering of outbound messages.;1
XD-3732;As a developer I'm adding new overrides to {{server.yml}} file however the overridden properties do not reflect even after the restart of server.;2
XD-3741;As a Flo for Spring XD user I would like to be able to create a new stream using the graphicat UI.     This flow should be shown in a graphical way also in definition tab.  !http://example.com/image.png!  Right now it doesn't happen due to a javascript error.    {code}  TypeError: this.node.getTransformToElement is not a function      at Object.VElement.bbox (http://localhost:9393/admin-ui/lib/joint/src/vectorizer.js:323:36)      at joint.dia.ElementView.joint.dia.CellView.extend.positionRelative (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2740:51)      at null.<anonymous> (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2710:18)      at http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1177:23      at eval (eval at createIterator (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1:0) <anonymous>:10:9)      at Function.forEach (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:3645:9)      at joint.dia.ElementView.joint.dia.CellView.extend.update (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2700:11)      at bound [as update] (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1005:21)      at joint.dia.ElementView.joint.dia.CellView.extend.render (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2903:14)      at joint.dia.Paper.Backbone.View.extend.addCell (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:5004:14)(anonymous function) @ :9393/admin-ui/lib/angular/angular.js:11500  :9393!attachment-name.jpg|thumbnail!  {code};1
XD-434;As a user I'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics.    *Notes:*  * Spring-AMQP {{RabbitAdmin}} now has a {{getQueueProperties()}} method which returns the number of consumers so it may be possible to use it for this purpose.  * Consider the possibility of _producers_ and/or _queues_ still containing data  * Consider the scenario even after the topics/queues are cleaned-up what to do with fanout exchange?    *Some Further Thoughts*  * Consider using the upcoming Spring AMQP REST API {{RabbitManagementTemplate}} if the timing is not right we could temporarily invoke the rabbit REST API directly.  * Should be optional perhaps via {{stream destroy foo --clean}}  * Should this be done by the admin? Or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange since we undeploy left->right everything can be cleaned up on the consumer side.  * Third option would be new methods on the bus {{cleanConsumer}} etc invoked by the {{StreamPlugin}}  * Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so we'd need the admin url(s) for the cluster.;4
XD-923;As a user I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream/module.;5
XD-1;HDFS ItemWriter Base integration of core HDFS writer functionality with Spring Batch.;0
XD-10;Reactor based http ingestion When there is support for boostrapping a http server in the reactor project and inbound SI adapter and associated XD source module should be created.;0
XD-1000;User should be able to view the list of all the job definitions Create a tab view with tabs “Job Definitions�? “Runtime Jobs�? (Deployed Jobs? “Job Instances�? (Is Runtime Jobs a better name here?) and “Job Executions�?. On clicking “Job Definitions�? tab we can have a table view of job definitions. Since we bootstrap.js we can have a responsive table layout to list all the available job definitions. At the REST layer “/jobs�? provides the list of job definitions. We can expand the JobsController list()’s QueryOptions to add more criteria (especially to list JobDefinition’s status (Deployed/Undeployed).  Also this is the UI implementation for the shell command “job list�?;0
XD-1001;User should be able to view the list of all Deployed Jobs On clicking the “Deployed Jobs�? we can have a table view of all the deployed jobs.  This is again a responsive table layout with all the job definitions with status “deployed�?. The deployed XD job corresponds to a single batch Job Instance.     This story addresses the UI layout changes to display existing JobInstance information.;0
XD-1003;"UI: User should be able to launch a job from Deployed jobs page From the Deployed jobs page user should be able to click on the ""Launch"" button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request.";0
XD-1004;"UI: User should be able to schedule a job from Deployed jobs page From the Deployed jobs page by clicking the ""Schedule"" button on a specific deployed job row user should be able to schedule this job with:  1) Cron trigger (with cron expression) as a source to job launching named channel  2) Fixed rate/delay trigger as a source to job launching named channel";0
XD-1005;UI: User should be able to filter the list of executions on the execution tab On clicking the “Executions” tab user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by “Job name” “execution time” etc.;0
XD-1006;"UI: User should be able to view job detail from a specific job execution at Job Executions page On clicking ""details"" link on a job execution row user should see the job details.    Job detail page will show all the information about the job where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.";0
XD-1007;UI: User should be able to see step execution info in a table below job detail On clicking the job detail page we should display all the step executions associated with the specific job execution in a table view.;0
XD-1008;Jobs list REST endpoint should include deployed/undeployed status Currently the jobs definition list REST endpoint doesn't include deployed/undeployed status on a given job.;0
XD-101;Add gradle tasks that build and bundle the redis server;0
XD-1013;Add additional REST endpoint that return the XML definition of a job;0
XD-1015;Create a reusable responsive UI layout to render the XD PagedResoures in tabular view Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint.     As part of this try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.;0
XD-1016;Provide an option to pretty print JSON output Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally e.g. json.pretty.print=true.  This will require some refactoring of the ModuleTypeConversion plugin i.e. use DI in streams.xml;0
XD-1018;JobDeployer hides root exceptions on failure When deploying jobs the following code (line 103) hides the root cause of deployment failure:      if (exceptionClassName.equals(BEAN_CREATION_EXCEPTION) || exceptionClassName.equals(BEAN_DEFINITION_EXEPTION)) {      throw new MissingRequiredDefinitionException(definition.getName() cause.getMessage())    }    For example:    org.springframework.xd.dirt.stream.MissingRequiredDefinitionException: Error creating bean with name 'dataSourceInitializer' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Cannot resolve reference to bean 'databasePopulator' while setting bean property 'databasePopulator' nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'databasePopulator' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Initialization of bean failed nested exception is java.lang.NullPointerException    org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:103)    org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:67)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:242);0
XD-1019;Add Spring Retry to Rabbit Message Bus Log and purge bad messages;0
XD-1021;Fix undeploy of stream with a composed module Create a composed module  Create a stream that uses that module  Try to undeploy the stream.  Kaboom    The dispatch is not correctly implemented in ModuleDeployer;0
XD-1022;"Switch ""module list"" to horizontal display The module list command currently has a very simplistic two column display of (module name module type). The is not very readable.  Switch to a 4 column display: (Sources Processors Sinks Jobs)  Additionally mark composed module [e.g. ""myhttp (c)""]";0
XD-1023;Refactor job deploy to go through XDController.deploy(name) Job deployment currently goes through an overloaded version of deploy() that takes 4 parameters. This prohibits job handling code from benefiting from common behavior (and eg currently breaks deployAll)    Given that the 3 additional parameters are in fine handled as module parameters let's push them to the job definition known at creation time rather than at deployment time (as it does not really make sense to change those between deploys);0
XD-1025;UI: Implement Job Deploy/Undeploy from the Job Definitions page From XD-1023 the job status(deployed/undeployed) is available from JobInstance Repository and a job can be deployed/undeployed correctly.     Implement Job deploy/undeploy for a given job from JobDefinitions page and indicate status of the job definition (deployed/undeployed).;0
XD-1026;UI: Responsive layout for supported user agents(Mobile Tablet and Desktop) The current admin UI uses bootstrap 3.0.0 which provides responsive design. We need to expand our scope to support all supported user agents.  This requires changes to use user agent specific layout for the UI views.;0
XD-1027;Create script-based batch ItemProcessor This would be included in the OOTB batch jobs to optionally process the loaded Tuple with a configured script.;0
XD-1028;UI - Do not hard-code server url Specify the default URL as:    {code}  urlRoot: location.protocol+'//'+location.hostname+(location.port ? ':'+location.port: '')  {code};0
XD-1031;UI - Launch a job with parameters Use a modal dialog to specify runtime parameters. There should be a little text are that gives hints as to the spring batch parameter key/value conventions e.g. for type.  Might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number.  4 columns key value type identifying and an 'add parameter' button that adds a new row.  This would appear as a modal dialog box polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown.;0
XD-1032;"Convert hadoop module to isolated classloader scheme * rename spring-xd-extension-hdfs to something else as it seems it is all spring ""data"" stuff and is not coupled to xd. But leave it in extensions/ for now  * rename and move spring-xd-hadoop inside extensions (maybe to spring-xd-extension-hadoop (or hdfs))  * make hadoop related modules depend on the latter (which itself will depend on the former)";0
XD-1034;"Stream definitions should not be saved when auto-deploy results in an error This relates to XD-871 which provides a good scenario.     >stream create s1 --definition ""http | log --deploy""   >stream create s2 --definition ""http | log --deploy""    The second command results in an error message that the port is in use but the stream definition is still saved. Since create + deploy is a logical unit of work it should follow transactional semantics. In other words if the deploy fails the repository should be rolled back (or a compensating destroy should be performed).  Note this should not be handled the same way if create and deploy happen separately. In that case the stream definition should remain.";0
XD-1036;Support composed module deletion Provided it is not currently used in any stream:    V) Attempt to destroy a composed module  Should not be supported at all  Should not be supported if involved in at least one stream (EB? MF!)  Should be supported and have no other consequences whatsoever (see IV) (EB?)  Should be supported and invalidate/destroy streams involving it;0
XD-104;Add README to be included in root directory of distribution should explain basic layout of the distribution;0
XD-1042;Support short names for types in ModuleOptions The ModuleOptions PR currently uses FQN for types (eg java.lang.String)    Would be nice to have support for short names for common types both in the properties files and the annotation;0
XD-1045;Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase such as:  * RESTModuleType and ModuleType enums * ModuleOption and DetailedModuleDefinitionResource.Option;0
XD-1048;"Extend aggregate counter to dynamically aggregate by field values in addition to time. This would be a combination of the existing aggregate counter and field value counter functionality.  For example if the stream data was for car purchases some fields might be colour make and model.  When analysing the aggregate data I dont just want to know how many were sold on Monday but how many of each make or how many of each colour  or how many of a particular colour make AND model. This would allow a dashboard type client to 'drill down' into each dimension or combination of dimensions (in real time without executing batch queries against the raw data)  Ideally the aggregate counter would be specified as   stream create --name mytap --definition ""tap:mystream > aggregatecounter --name=mycount --fieldNames=colourmakemodel""  The keys would be dynamically created according to the field values in each record (ie in a similar way to the field value counter you would not need to predefine field values) and keys would be created for all combinations of the fields specified eg the record   { ""colour"":""silver""  ""make"":""VW""  ""model"" : ""Golf"" }   would increment the following key counters (in addtion to the existing time buckets)  <existing base counter - ie all fields for this time bucket> colour:black make:VW model:Golf colour:black.make:VW colour:black.model:Golf make:VW.model:Golf colour:black.make:VW.model:Golf  ie the actual keys would look something like  aggregatecounters.mycount.make:VW.model:Golf.201307 etc  This may seem like it would generate a lot of key combinations but in practice the data generated will still be massively less than the raw data and keys will only be created if that combination occurs in a time period.  Also some fields may be dependent on each other (such as make and model in the above example) so the amount of possibilites for those composite keys would be a lot less that the number of one times the number of the other.";0
XD-1049;Create documentation for composed modules;0
XD-1050;"Improve Module Options support note from PR #365 - which has been merged - providing the initial level of support...    Pending issues (to be addressed in another PR?):  - [x] complex case  - [x] default values for complex case when option is not surfaced back to the module (eg ""suffix"" in our canonical example)  - [ ] plugin provided options and values  - [ ] descriptive defaults instead of actual defaults (e.g. \<use stream name\>)  - [ ] JSR303 Validation";0
XD-1051;"Rename or reconsider the ""module display"" command note from PR #365:    {quote}  We should probably create a new story to (at least) rename ""module display"" to ""module showconfig"" or something but possibly even reconsider it altogether. In some sense it's even violating the encapsulation of ModuleRegistry. It wont work for java-config style modules or spring-integration Groovy DSL modules. Personally if anything I'd rather see those config files themselves exposed as part of an admin UI. What you are doing with the options here fits better with the encapsulation principle and the fact that typical usage should not require detailed knowledge of the actual underlying configuration of a Module.  {quote}";0
XD-1052;"Enforce consistent naming across CLI options and command/template/operations method names e.g. see comment on PR #390:  https://github.com/spring-projects/spring-xd/pull/390/files#r7563787    In that case it's ""delete"" in one place and ""destroy"" in another. There are other cases as well.";0
XD-1056;Empty parameter sent to job when launched from UI Job gets a empty key:value pair when launching the job from the admin-ui.;0
XD-1057;Colors on Job Definition tab are different than other tabs The table background color on the Job Definition Tab is green while the others tabs have a white background.  They should be consistent.;0
XD-1058;Remove unnecessary LESS files from XD UI styles Currently the bootstrap.less file has all the styles that the bootstrap supports. But we should only add/compile the LESS that are needed by XD UI.;0
XD-1059;Batch Job's step execution count is always '0' The batch job's step execution count is retrieved from org.springframework.batch.admin.web.JobExecutionInfo in batch job repository.    But the JobExecutionInfo always have the stepExecutionCount set to '0'.;0
XD-106;Container server does not log a message that it has started or stopped successfully $ ./xd-container  processing module 'Module [name=file type=sink]' from group 'tailtest' with index: 1 processing module 'Module [name=tail type=source]' from group 'tailtest' with index: 0   Logging of 'processing module' should have log level time..;0
XD-1060;Add support for Hortonworks Data Platform 2.0 (apologies if a ticket already exists for this but I didn't see one)    I spun up the Hortonworks Data Platform 2.0 sandbox but see it isn't supported by Spring XD yet.    How hard would it be to add these Distro's in?  Is it just a matter of dropping in a lib folder for hadoop22 and/or hdp20 and allowing those and options to be passed in via the --hadoopDistro option?    I'm currently trying to work through the following tutorial but using the HDP 2.0 sandbox instead of the 1.3 sandbox    http://hortonworks.com/hadoop-tutorial/using-spring-xd-to-stream-tweets-to-hadoop-for-sentiment-analysis/    Thanks!;0
XD-1062;User would like to see request/response details (headers URLs etc) in shell Add debug flag for logging globally maybe or else --trace per command?;0
XD-1063;Fix mqtt module properties Use of dot in property name prevents the user from specifying a value in stream definition  Also defaults are repeated at .xml and .properties level;0
XD-1064;"Update router sink logic to match new channel syntax for example the following should work:    {code}  xd:>stream create a1 --definition ""queue:a > transform --expression=payload+'-a' | log""  Created new stream 'a1'    xd:>stream create b1 --definition ""queue:b > transform --expression=payload+'-b' | log""  Created new stream 'b1'    xd:>stream create s1 --definition ""http | router --expression=payload.contains('a')?'queue:a':'queue:b'""  Created new stream 's1'    xd:>http post --data ""ha""  > POST (text/plainCharset=UTF-8) http://localhost:9000 ha  > 200 OK    // log shows: ""ha-a""    xd:>http post --data ""hi""  > POST (text/plainCharset=UTF-8) http://localhost:9000 hi  > 200 OK    // log shows: ""ha-b""  {code}    This needs to be tested against all transports (local redis and rabbit)";0
XD-107;Clean shutdown of redis in xd-admin A ctrl-c of xd-admin results in exception messages about disconnecting from redis.  14:16:07327 ERROR task-scheduler-1 handler.LoggingHandler:136 - org.springframework.data.redis.RedisSystemException: Redis command interrupted nested exception is com.lambdaworks.redis.RedisCommandInterruptedException: Command interrupted;0
XD-1070;"File to HDFS batch job fails due to ""/data"" directory not available in HDFS The batch job for File to HDFS will try to check for the default '/data/' directory even if the target directory in HDFS is something else.  If the /data directory isn't there the job will fail.    This should be fixed so there isn't a check on the directory that isn't the final HDFS target directory and the target directory should be created if it doesn't exist.";0
XD-1071;Close HDFS file when Batch job ends The File to HDFS batch job will not close the file being written to in HDFS when the job completes.  The ItemWriter for HDFS needs to incorporate functionality that is present in the standard FlatFileWriter perhaps inheriting from AbstractItemStreamItemWriter;0
XD-1074;Multiple SLF4J bindings on the classpath Summary says it all. When starting we now get {noformat} SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/Users/ebottard/.gradle/caches/artifacts-24/filestore/org.slf4j/slf4j-log4j12/1.7.5/jar/6edffc576ce104ec769d954618764f39f0f0f10d/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/Users/ebottard/.gradle/caches/artifacts-24/filestore/org.slf4j/slf4j-log4j12/1.6.1/jar/bd245d6746cdd4e6203e976e21d597a46f115802/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] {noformat}  Most certainly introduced by 1c4817ee60ae9325f6394dcc78aa803c47818546 or 72baec92f2e7bbe860b4a9dc6c994536c1670881;0
XD-1075;Restore XD Banner Migrating to boot dropped the XD banner and its info.  Can be restored using eg a boot Initializer and removing the default boot banner;0
XD-1078;"Add ""spring-xd-exec"" directory to Git repo Without the directory Spring XD cannot be imported into STS using its own Gradle support.";0
XD-108;Build script should not package 'spring-xd-dirt' scripts We are packaging separate scripts to start XDAdmin and XDContainer.  The Gradle application plugin will generate an unwanted 'spring-xd-dirt' scripts this should be removed from the bin directory when creating a distribution zip.;0
XD-1082;Create REST API for getting information on a job execution for a given execution id Adopted functionality from Spring Batch admin Should include springmvc test framework style tests  GET /batch/jobs/executions/{executionId} - Get information on all executions of a given job name.;0
XD-1086;Create REST API for stopping all job executions Adopted functionality from spring batch admin  Should include SpringMVC test framework style tests.    DELETE /batch/jobs/executions/ - stop all job executions;0
XD-1087;Create REST API for restarting a specific job instance Functionality adopted from spring-batch admin  Should include springmvc test framework style tests    POST /batch/jobs/{jobName}/{jobInstanceId}/executions - restart a specific job instance;0
XD-109;Documentation for starting Spring XD servers;0
XD-1090;Create shell command for restarting a specific job instance;0
XD-1091;Create shell command for getting information on the progress of a given step execution;0
XD-1093;Create shell command for getting information on a given step execution;0
XD-1101;"Create aggregator module that uses an embedded database stored in the local filesystem Similar to XD-1100.  SI has the jdbc based message store.    <int-jdbc:message-store id=""messageStore"" data-source=""dataSource""      table-prefix=""MY_INT_""/>    The configuration of this aggregator would be configured so that it uses an embedded database hsqldb or H2 depending if there is any real perf benefit to one or the other and store the data on the local file system.";0
XD-1102;Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options.  Redis can run on the same node as the benchmark.;0
XD-1103;"JDBC sink is broken - looks like some config options got booted The JDBC sink is broken. Simple ""time | jdbc"" results in:    org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback bad SQL grammar [insert into test (payload) values(?)] nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TEST    Looks like some config options got clobbered during bootification.";0
XD-1104;Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink as it becomes more prominent in XD.    Use of an in memory db where we expose eg a JdbcTemplate to assert state;0
XD-1109;Provide cmdline options validation Wherever they come from (cmd line args or ENV_VARS) options such as transport analytics etc should be validated and issues should be reported to users;0
XD-111;Create final distribution zip across multiple projects The final directory structure should look like    <install-dir>/xd  <install-dir>/redis  <install-dir>/gemfire    inside the XD directory     /xd/bin - which has xd-container and xd-admin scripts  /xd/lib    inside the gemfire directory  /gemfire/bin - has the gemfire-server script  /gemfire/lib     inside the redis directory is     /redis/redis-latest-v.x.y.z.tar  /redis/README  /readis/install-redis  - script that does the basic 4 commands to install redis.      There should be a gradle task that runs after the distZip task that will take the contents of different project directories script diretories and 'redis-binary' directories and creates the final layout for the distribution.;0
XD-1111;"Clear Redis after tests The following keys remain after running the test suite:  {code} redis 127.0.0.1:6379> keys * 1) ""containers"" 2) ""containers.application:9292"" {code}";0
XD-1117;Add bash based scripts of simple module create to src/main/scripts;0
XD-1118;Add starting of newly build XD server running of smoketest bash script and killing of XD server to CI test;0
XD-1120;Standardize Date/Time/TimeZone handling We should we centrally standardize on date/time formats so that we don't create inconsistencies and follow ISO 8601 internally. Internally we should only work with UTC (or make that the default config option).    Ultimately whatever the user sees is just a formatting concern.;0
XD-1123;Add profile activation on top of XD-953;0
XD-1125;"Provide ModuleOptionsMetadata using simple approach Following merge of XD-953 provide module options using the ""simple"" approach where applicable";0
XD-1126;Switch CAPITAL_LETTERS to system.property style in application config;0
XD-1130;Update the EC2 deployer EC2 Deployer   Needs to change its configuration behavior to use environment variables vs. the property files  * Remove ConfigureSystem class since we will use environment variables instead  * Allow users to set environment variables via the xd-ec2 properties.  * If properties are not present use those that are available in the application.yml  * Utilize JClouds environment variable setup features to implement this behavior.;0
XD-1131;Basic support for Plugin contributed Module Options Metadata Pending a better approach and extension point (see XD-1050) provide a way to factor out common recurring options for modules:  * inputType  * outputType  * job parameters;0
XD-1136;Failure in writing to HDFS when undeploying and redeploying a stream with numbers in directory and/or file name;0
XD-1138;Review and Optimize the Serialized JSON Nodes for Batch Objects For several Batch Job related JSON endpoints we serialize too much information.;0
XD-1139;Add TaskLet to Stream from (S)FTP to HDFS;0
XD-114;Add install script for Redis This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gz    The install script does the following:    - Check the platform OS & arch  - unzip the tar compile the sources;0
XD-1140;Add (S)FTP Gateway and Batch Partitioner to List/Process Remote Files;0
XD-1142;Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them.  The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group.  The project https://github.com/spring-projects/spring-data-grid is the start of this model.;0
XD-1145;Add --date option to the trigger module The TriggerSourceOptionsMetadata class should be able to use an actual Date object thanks to Spring binding conversion.  BUT the ${date} construct will receive a toString version of it. Make sure this works properly;0
XD-1148;Allow local data transport option for the container Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport i.e. --transport=local should fail.;0
XD-115;add SpEL 'transform' processor It should provide an 'expression' param for SpEL and have a default pass-thru of the payload.;0
XD-1152;"Step execution progress Shell command to use coherent Id (jobExecutionId:stepExecutionId) Instead of using jobExecutionId and stepExecutionId as two separate options for the ""job execution step progress"" command we can have a single option with id mentioned as (jobExecutionId:stepExecutionId)";0
XD-1155;The lib directory for hadoop12 contains mix of hadoop versions This causes issues depending on which version of the core/common jar gets loaded first - like:    xd:>hadoop fs ls  -ls: Fatal internal error  java.lang.UnsupportedOperationException: Not implemented by the DistributedFileSystem FileSystem implementation    at org.apache.hadoop.fs.FileSystem.getScheme(FileSystem.java:213)    at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:2401)    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2411)    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2428)    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:88)    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2467)    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2449)    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:367)    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:166)    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:351)    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:287)    at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:325)    at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)    at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)    at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)    at org.apache.hadoop.fs.shell.Command.run(Command.java:154)    at org.apache.hadoop.fs.FsShell.run(FsShell.java:255)    at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)    at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)    at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke(Method.java:606)    at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191)    at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)    at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)    at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)    at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:483)    at org.springframework.shell.core.JLineShell.run(JLineShell.java:157)    at java.lang.Thread.run(Thread.java:724);0
XD-1156;Refactor/Simplify JobPlugin Currently the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code (like it doesn't do anything with preProcessSharedContext()) in there.;0
XD-1158;Create integration test script for JMS & MQTT Create a script to sanity check JMS and MQTT;0
XD-116;add SpEL 'filter' processor It should provide an 'expression' param for SpEL and have a default value of true (accept everything).;0
XD-1160;Standardize naming and unit for options across modules We should standardize on the options between modules:  idleTimeout - timeout rolloverSize - rollover  Also need to standardize on unit used for timeout - should this be s or ms?;0
XD-1161;Re-deployment of hdfs sink reuses filename of first deployment Need to check for existing files with the same file counter;0
XD-1164;Update Spring Integration version to 4.0.M2;0
XD-1165;Enhancements to Gemfire CQ Source The Gemfire CQ source needs some enhancements:  * enable locator configuration * consider decoupling from JSON. Currently designed to work with gemfire-json-server to avoid dependence on specific domain objects on the client and server side. So produces json strings from PdxInstance(s) stored in the cache.;0
XD-1166;Create Gemfire Integration Test Scripts;0
XD-1167;Mail Source ModuleOptions (+ profiles);0
XD-1168;Tapping a stream with multiple labelled filters causes duplicate messages Test case is here:  https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/basic_stream_tests#L49  We would expect one message in the counter but get 3.;0
XD-1169;"Column name of JDBC sink module should not hard code to ""payload"". Current implementation of JDBC sink module insert data into ""payload"" column. But I can't just change the default column ""payload"" to something else using --columns option. Because JdbcMessagePayloadTransformer compare the columnName to ""payload"" and it hard coded.";0
XD-1173;"Duplicate messages on tap If I fiddle with the testTappingWithLabels method I can reproduce the same issue:    HttpSource source = newHttpSource()    FileSink sink = newFileSink().binary(true) FileSink tapsink1 = newFileSink().binary(true) stream().create(""myhttp"" ""%s | flibble: transform  --expression=payload.toUpperCase() | flibble2: transform  --expression=payload.toUpperCase() | %s"" source sink) stream().create(""mytap4"" ""tap:stream:myhttp.flibble > transform  --expression=payload.replaceAll('A''.') | %s"" tapsink1) source.ensureReady().postData(""Dracarys!"")    assertThat(sink eventually(hasContentsThat(equalTo(""DRACARYS!""))))    assertThat(tapsink1 eventually(hasContentsThat(equalTo(""DR.C.RYS!""))))      java.lang.AssertionError:  Expected: ""DR.C.RYS!"" trying at most 10 times        but: failed after 10*100=1000ms:  ""DR.C.RYS!DR.C.RYS!""";0
XD-1174;Update HDFS sink documentation to reflect new functionality introduced in XD-990 and XD-991;0
XD-1179;Nodes can not connect with Admin using Redis as transport This has happened more than once where a node fails for whatever reason and when it is restarted it does not receive requests from the admin server.  This could be file handle count based.  Since this is not Rabbit as a transport I'm not chasing this down yet.  But felt it needed to be recorded.;0
XD-1180;Enabling of JMX support is broken However this is triggered (depending on whether https://github.com/spring-projects/spring-xd/pull/477/files is merged yet or not) jmx seems to be broken because of duplicate beans / mbeans names;0
XD-1182;Update to spring-data-hadoop 2.0.0.M5 Update to spring-data-hadoop 2.0.0.M5 when it is released and remove the temporary DatasetTemplateAllowingNulls in spring-xd-hadoop  We should also review the supported hadoop distros - think we should support anything that is current/stable: - hadoop12 - hadoop22 - phd1 (PHD 1.1) - hdp13 - hdp20 - cdh4;0
XD-1183;topic in mqtt source was marked as topics Changed field back to topic;0
XD-1184;"Admin & Launcher startup fails when XD_JMX_ENABLED is set to true When exporting of MBeans are enabled via XD_JMX_ENABLED (also jmxEnabled as in application.yml) the Admin and Lancher server application fail to start.    Since the admin applications has the same 'integrationMbeanExporter' bean name for IntegrationMBeanExporter as that its ParentConfiguration there is a naming conflicts and the exception thrown as:    (Same is the case for launcher and its parent configuration)    Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mbeanExporter' defined in class org.springframework.context.annotation.MBeanExportConfiguration: Invocation of init method failed nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter' nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)    org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:124)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)    org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:60)    org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:42)  Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter' nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter    org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)    org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:535)    org.springframework.jmx.export.MBeanExporter.afterPropertiesSet(MBeanExporter.java:417)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549)  	... 15 more  Caused by: javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter    com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)    com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)    com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)    com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)    com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)    com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:513)    org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)    org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)    org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:600)  	... 19 more";0
XD-1185;Add redisConnectionFactory with connection pool We need to add a connection pool to the Redis connection factory used for the transport otherwise we'll see exceptions like these:    12:57:54842 ERROR inbound.tictoc.0-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:183 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.  org.springframework.data.redis.RedisSystemException: Redis exception nested exception is com.lambdaworks.redis.RedisException: Unable to connect    at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)    at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)    at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)    at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)    at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)    at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)    at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)    at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)    at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)    at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)    at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)    at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)    at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)    at java.lang.Thread.run(Thread.java:724)  Caused by: com.lambdaworks.redis.RedisException: Unable to connect    at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)    at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)    at org.springframework.data.redis.connection.lettuce.LettuceConnection.getAsyncDedicatedConnection(LettuceConnection.java:2924)    at org.springframework.data.redis.connection.lettuce.LettuceConnection.getDedicatedConnection(LettuceConnection.java:2932)    at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)    ... 11 more  Caused by: java.net.BindException: Cannot assign requested address    at sun.nio.ch.Net.connect0(Native Method)    at sun.nio.ch.Net.connect(Net.java:465)    at sun.nio.ch.Net.connect(Net.java:457)    at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)    at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)    at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)    at org.jboss.netty.channel.Channels.connect(Channels.java:634)    at org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:207)    at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:165)    ... 15 more;0
XD-1186;"Support use of application.yml fragments Since spring boot (by default) looks for property sources from file:./config/application.yml and file:./application.yml    In XD bundles the CLASSPATH of our XD startup scripts'(admin container singlenode startup scripts) set to use APP_HOME and APP_HOME/config.    But if we have an application.yml fragment on $APP_HOME/config then it is considered as classpath resource and the actual ""application.yml"" (from dirt lib/ classpath) is not loaded.     Also we need to separate out the properties files we have inside $APP_HOME/config as by default boot uses ""config"" directory as well.";0
XD-1187;xd-admin server to --transport as an option. --transport as an alias for --controlTransport;0
XD-119;HDFS sink should default to hdfs://localhost:8020 The current default is hdfs://localhost:9000 but most new distributions/installs use 8020;0
XD-1190;Setup precedence order for module properties' property resolver The PropertyResolver needs to follow the below precedence order on PropertySources when resolving the module properties:    From lowest to the highest order    0 application.yml  1 applicaiton.yml fragment  2 property placeholders  2a  property placeholder under 'shared' config directory   2b property placeholder under module/(source/sink/processor)/config directory  3. environment variables  4. system properties  5. command line;0
XD-1192;Add documentation for JDBC to HDFS batch job Add docs to section     https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#pre-packaged-batch-jobs;0
XD-1193;Update to Spring Batch 2.2.4;0
XD-1195;Add paging and sorting to Field Value Counter API see discussion at https://github.com/spring-projects/spring-xd/commit/2f0e80b5e337b71c9c70de510a44d2f050d10fa7;0
XD-1199;Fix filejdbc batch job filejdbc throws an exception:   {code}  java.lang.IllegalArgumentException: Could not resolve resource location pattern [/mycsvdir/*.csv]: class path resource [mycsvdir/] cannot be resolved to URL because it does not exist  {code}    This can be solved by using a file:// prefix    Maybe just update the docs?;0
XD-12;Jolokia based aggregator for cluster monitoring;0
XD-120;Find and eliminate package-level cycles across XD projects;0
XD-1200;"Fix hdfsjdbc batch job hdfsjdbc throws an exception:  {code}  org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'itemReader' defined in URL [file:/Users/trisberg/Projects/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Could not resolve placeholder 'columns' in string value ""${columns}""  {code}    The hdfsjdbc job uses 'columns' instead of 'names' as the parameter for the column-names. Should we make this usage consistent between jobs?    There is a comment in the docs - ""there is also a limitation in that the database table must be created manually. This is due to a bug in Spring Hadoop and will be fixed in the future."" Think this is this solved in Spring Hadoop now?    initializeDatabase should default to false now to be consistent with jdbc sink    Rename batch-jdbc/mongo-import.properties to batch-jdbc/mongo.properties since these aren't just for import";0
XD-1202;Update build script to use correct version of spring-data-hadoop based on distro;0
XD-1204;Update jdbchdfs properties and defaults to better match hdfs sink We should use fileName fileExtension properties and default to /xd/jobname as directory;0
XD-1207;Job Plugin - Notification Channel not correctly bound to MessageBus;0
XD-1210;Shell - 'makeUnique' Job Parameter is true by default Currently the shell assumes that the 'makeUnique'job parameter is by default *false*. That is not true. As a consequence the parameter has currently no impact/does not work.;0
XD-1211;"Update hadoop instructions in the xd-samples batchHashtagCount and batchWordCount  projects need ""hadoop fs ls"" instructions need to be updated.";0
XD-1216;Serialization of ChunkContext fails using Kryo;0
XD-1217;twittersearch and twitterstream should support compatible formats Currently twitterstream emits native twitter json whereas twittersearch uses SI/Spring Social and emits spring social Tweet types. This makes it difficult to replace twitter sources and reuse XD stream definitions.  This requires coordination with SS 1.1.0 and SI 4.0 GA releases. NOTE: I think it's a good idea to continue to support native twitter JSON keep as an option for twitterstream but the default should be Tweet types.;0
XD-1218;Base server implementation on Spring Boot Server startup is done using Spring  Boot as well as starting a module application context at runtime.;0
XD-1222;"Duplicate MBean server definition by MBeanExportingPlugin The MBeanServer is referred by XD admin/launcher when JMX is enabled (by setting --jmxEnabled option) and this is defined in xd-global-beans.xml.    The MBeans that are exposed by the modules also use the same MBeanServer define above and there is a duplicate MBeanServer definition (from jmx/common.xml) which the MBeanExportingPlugin adds as a component to the module which doesn't seem to be needed.    Also currently the flag ""jmxEnabled"" is generic and used by adminserver/launcher as well as the module MBeanExportingPlugin. If we have a separate flag to enable the JMX *only* for modules then a separate definition of MBeanServer could be necessary.";0
XD-1224;Add code coverage to gradle build Build should be able to generate code coverage reports.    After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle.    http://www.gradle.org/docs/current/userguide/jacoco_plugin.html;0
XD-1225;Integrate code coverage reports into the CI process Not sure if this is best done via Sonar our sonar build plan the nightly one or the frequent one off master...    Open question is if we want to fail a build do to code coverage levels.;0
XD-1226;Review abstract base classes used in test cases to ensure proper resource cleanup.;0
XD-1227;Investigate long running tests and create refactoring issues https://sonar.springsource.org/dashboard/index/7173?did=3    Shows which of our current tests take the most time to execute.    xd.dirt.stream and xd.shell.command are where the most time is spent.    In xd.dirt.stream it seems likely that time can be reduced by not restarting a new single node server per test but sharing it across tests e.g.     RabbitSingleNodeStreamDeploymentIntegrationTests 	   LocalSingleNodeStreamDeploymentIntegrationTests   RedisSingleNodeStreamDeploymentIntegrationTests 	    As a first pass the test that take longer than 15 seconds in that report should be investigated.;0
XD-1228;Provide a easy prescriptive means to perform unit and basic stream integration tests. AbstractSingleNodeStreamDeploymentIntegrationTests is the basis of 'state of the art' testing for a stream that allows you to get a reference to the input and output channel of the stream    http | filter | transform | file.    One can send messages to the channel after the http module but before filter and one can retrieve the messages that were sent to the channel after the transform module but before file.    The current implementation inside AbstractSingleNodeStreamDeploymentIntegrationTests can be improved in terms of ease of use for end-users.      The issue is to create as simple a way as possible for a user to test their processing modules/stream definitions without having to actually do a real integration test by sending data to the input module.    Either as a separate issue or as part of this one the documentation     https://github.com/spring-projects/spring-xd/wiki/Creating-a-Processor-Module    should be updated to explicitly show how to use this issue's test functionality.;0
XD-123;XD scripts lib path needs to be dynamic We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc. are dynamically updated.;0
XD-1231;Investigate if we should use RequreJS with Angular;0
XD-1232;Create EC2 AMI for single-node install of Apache Hadoop 1.2.1;0
XD-1234;Create EC2 AMI for single-node install of  Pivotal HD 1.1;0
XD-1236;Create EC2 AMI for single-node install of Hortonworks Data Platform 1.3;0
XD-1237;Add option to stop all running XD EC2 instances that match a given naming pattern This functionality should be added as a command line option to the main app in the spring-xd-ec2 project;0
XD-1238;Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments Add a stage to the plan that will stop any instances that the CI process may have started before and relaunch a 2 node install based on rabbit.    https://build.springsource.org/browse/XD-ATEC2 was created as an empty shell.    The running of across different transports will be handled in a separate story along with adding a stage to run a 'hello world' acceptance test.;0
XD-1239;Add stage to Acceptance Test EC2 build plan that runs a basic acceptance test application against the single-node deployment Run test application developed in XD-1245;0
XD-1241;"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements    ""Stages are comprised of one or more Jobs which run in parallel""    we would like the tests across the rabbit and redis transport to occur in parallel.";0
XD-1245;Develop basic acceptance test application to exercise based XD-EC2 deployment from CI Create a first pass at an acceptance test app for a stream definition of http | log.      This will involve creating two new projects in xd    1. spring-xd-integration-test  2. spring-xd-acceptance-tests    #1 will contain generally useful utility methods for acceptance test such as sending data over http obtaining and asserting JMX values of specific modules.  #2 will contain tests that use #1 to test the various out of the box modules provides in XD.;0
XD-1246;To be able to run the tests without conflicting with an existing XD admin server/launcher In line with what we address at https://jira.springsource.org/browse/XD-1223 there are cases where tests fail when there is an existing instance of hsqldb running.    Since hsqldb uses the same port and database it causes issues.;0
XD-1249;AbstractShellIntegrationTests should start and stop server once. e.g. make application static and check for initialization. Need to ensure each test restores the initial state of the server;0
XD-1251;Access-Control-Allow-Origin header should not be hard-coded See also XD-451 as reference.;0
XD-1252;"Allow processor script variables to be passed as module parameters Currently if we want to bind values to script variables we need to put them in a properties file like so:  xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log  Ideally it should be:  xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log";0
XD-1253;"RabbitMessageBus queue name prefix I see the topics/exchanges created for Redis/Rabbit message buses have the prefix ""topic."" Is there any reason why we didn't have the prefix ""queue."" for the name of the queue created in Rabbit message bus in compared with the queue created in Redis message bus which has prefix ""queue.""";0
XD-1254;Optimize AbstractSingleNodeStreamDeploymentIntegrationTests XD singlenode currenly initialized in @Before should be @BeforeClass. In this case must be re-initialized for each transport but not for each @Test.;0
XD-1255;"Create assertion to get count of messages processed by a specific module in a stream The modules are exposed via JMX and in turn exposed over http via jolokia.  See https://jira.springsource.org/browse/XD-343.  This issue is to develop a helper method that given a stream id and/or module name assert that the number of messages processed after sending stimulus messages is as expected. e.g.  int originalCount = getCount(""testStream"" ""file"")  //do stuff that generates 100 messages assertCount(""testStream"" ""file"" 100 originalCount)  For now we can assume we know the location of where the modules are located by assuming we have only one container deployed.";0
XD-126;Documentation for sources sinks modules should define which attributes are required and which optional This will eventually be supplied by the admin server but for now write it up by hand in the documentation;0
XD-1262;Provide a clean way to get a reference to the MessageBus running in SingleNodeApplication Currently the message bus is only obtained via Module.getComponent(MessageBus.class). Stream testing scenarios that depend on sending and receiving payloads via named channels do not require a deployed module instance per se but any stream flow control uses the MessageBus directly. Getting a deployed module instance in general is expensive e.g. you have to wait for the module to deploy asynchronously whereas the MessageBus implementation could be known a priori when the application starts. An improvement would be to ask the container for its MessageBus.;0
XD-1264;Update SI to latest 4.0 M3 and Spring AMQP to 1.3.0.M2 The Rabbit endpoint suffers from a problem similar to XD-1067.  Seems like spring-[rabbit/amqp] needs to be bumped to 1.3.0.M1 to fix it.  Sadly we get this error:  noformat  java.lang.NoSuchMethodError: org.springframework.amqp.core.MessageProperties.getContentLength()J  at org.springframework.integration.amqp.support.DefaultAmqpHeaderMapper.extractStandardHeaders(DefaultAmqpHeaderMapper.java:102)  at org.springframework.integration.amqp.support.DefaultAmqpHeaderMapper.extractStandardHeaders(DefaultAmqpHeaderMapper.java:53)  at org.springframework.integration.mapping.AbstractHeaderMapper.toHeaders(AbstractHeaderMapper.java:205)  at org.springframework.integration.mapping.AbstractHeaderMapper.toHeadersFromRequest(AbstractHeaderMapper.java:148)  at org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter$1.onMessage(AmqpInboundChannelAdapter.java:75)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:584)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:482)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:69)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:144)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:920)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:454)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:728)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:712)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$400(SimpleMessageListenerContainer.java:69)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:812)  at java.lang.Thread.run(Thread.java:724)  noformat  Updating to latest SI snapshot does not help (as of Jan 23rd);0
XD-1265;"Surface better exception information to client In trying to upgrade to latest SI I encountered a failing test because it expects an error message to contain something but SI changes make it disappear (the problem is an SI exception now has an explicit message and so does not expose its cause message anymore)  This however is the manifest of a deeper ""problem"". We currently expose the getMessage() of any generic Exception caught in the VndError REST construct. But this is not enough.  Things that we can consider are: 1) adding the whole stacktrace of the caught exception as a String. This is not very good at it leaks java specific details 2) unwrap the caught exception to get to the deepest cause. This may not be what we want everytime 3) construct a VndErrors (note the 's') made of each layered exception 4) similar to 1) but not using the stacktrace only the messages of each cause  etc";0
XD-1266;Twitterstream is broken;0
XD-1268;Remove unused code related to 'accepted media type' in MessageBus;0
XD-127;Create TCP source module Based off SI tcp inbound adapter.  This will allow for event forwarding that can select among the existing SI serialized/deserializer options.;0
XD-1271;Investigate missing boot's actuator endpoints in XD Currently few of the boot's actuator endpoints go missing in the EndpointHandler mapping.  They are: BeansEndpoint dumpEndpoint traceEndpoint healthEndpoint infoEndpoint.    Also the EndpointHandler mapping doesn't even happen in case of LauncherApplication.  I think this is because the LauncherApplication context starts with port '0' and the TomcatEmbeddedServletContainer sets the local port for it later. With port '0' the Endpointhandler mapping is disabled during the EndpointHandler mapping bean creation.;0
XD-1276;Out of the box batch jobs should add xdJobExecutionListener and xdStepExecutionListener To show best practice our batch jobs should include these listeners so that notifications can be sent.  In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move/delete the file;0
XD-1277;"Default option values broken for composed modules May want to fix ""properly"" when tackling the module options for composed modules but this is currently broken (and wasn't at some point):    module compose upperHttp --definition ""http | transform --expression=payload.toUpperCase()""  stream create foo --definition ""upperHttp | log""    This will fail saying that ${port} can't be resolved    This will work though:  module compose upperHttp --definition ""http --port=9000 | transform --expression=payload.toUpperCase()""  stream create foo --definition ""upperHttp | log""      Note that   stream create foo --definition ""upperHttp --port=xxx | log"" should work too wut won't but that's another bug (will create after this one)";0
XD-1279;The HDFS Sink should roll over based on the number of events.;0
XD-128;Create TCP sink module Based off SI tcp inbound adapter.  This will allow for event fowarding.;0
XD-1282;Add caching to ModuleOptionsMetadataResolver Will likely involve having the module identity (type+name) be part of the OptionsMetadata identity/cache key;0
XD-1285;Support shell completions for module names see CompletionProviderTests#testUnfinishedModuleNameShouldReturnCompletions()    Ideally would require a change in the parser so that it knows which kind of module was expected when it failed.;0
XD-1287;"Tap definitions should verify stream name xd:>stream create --name simple --definition ""http | transform | filter | transform | file"" Created new stream 'simple' xd:>stream create --name tapSimple --definition ""tap:stream:mystream.transform > file"" Created new stream 'tapSimple'  There isn't a stream named ""mystream""... I don't remember if we want to allow for this (set up taps before there is a stream) or if it should be an error.  Otherwise works as expected  xd:>stream create --name tapSimple2 --definition ""tap:stream:simple.transform > file"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD144E:(pos 11): Reference to 'transform' is not unique in the target stream 'http | transform | filter | transform | file' please label the relevant module and use the label or use a suffix index to indicate which occurrence of the module e.g. 'transform.0' tap:simple.transform";0
XD-1289;"Use descriptive texts for some module options defaults Need a way to tell the user that this option will be determined at runtimelate bindings.  In the module info command references to ${xd.stream.name} could read ""<use stream name>"" for example)";0
XD-129;Documenation for building/starting redis servers;0
XD-1290;Module context PropertyPlaceholderAutoConfiguration should have allowNulls = true The current configuration prevents modules to have default values that evaluate to null.  The workaround is to either:    - have the module have its own PPC (which allows nulls)  - rid the placeholders with ${foo:};0
XD-1294;Update spring-xd-extension-reactor dependency Currently the reactorEnv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project.     This enables boot's ReactorAutoConfiguration to initialize the reactor environment we have the reactor setup configured for both admin and container server applications.    Since reactor environment is not being used by container and only used by the reactor-syslog module we can move the reactorEnv bean definition in reactor-syslog module.    There is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed.;0
XD-1295;"Module message conversion fails to work if JMX is enabled If JMX is enabled for modules (enabling the IntegrationMBeanExporter) the ModuleTypeConversionPlugin fails to get the reference to input/output channel (for adding the ContentTypeHeaderInterceptor) and results in exception.    It seems like the IntegrationMBeanExporter (when JMX is enabled) creates JdkDynamicAopProxy for all the integration components and thereby the following check on ModuleTypeConversionPlugin to retrieve the AbstractMessageChannel fails.    AbstractMessageChannel channel = null  			if (isInput) {  				channel = module.getComponent(""input"" AbstractMessageChannel.class)  			}  			else {  				channel = module.getComponent(""output"" AbstractMessageChannel.class)  			}    I see the reason why AbstractMessageChannel is used here (to use some of the methods in the implementing class that didn't exist in the interfaces) but IntegrationMBeanExporter creating JdkDynamicAopProxy for the channel fails to resolve as AbstractMessageChannel here.    Following is the full stack trace:    To replicate    stream create testing --definition """"http --outputType=text/plain | log""  3:45238 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [moduleDeployer]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:601)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy62.handleMessage(Unknown Source)    org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:152)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:121)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:108)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:218)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:188)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:601)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy61.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:96)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:212)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    java.lang.Thread.run(Thread.java:722)  Caused by: org.springframework.xd.dirt.plugins.ModuleConfigurationException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel] but was actually of type [com.sun.proxy.$Proxy70]    org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:144)    org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.postProcessModule(ModuleTypeConversionPlugin.java:70)    org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:378)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:282)    org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:271)    org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:266)    org.springframework.xd.dirt.module.ModuleDeployer.handleSingleModuleMessage(ModuleDeployer.java:244)    org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:171)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  	... 42 more  Caused by: org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel] but was actually of type [com.sun.proxy.$Proxy70]    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:376)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:979)    org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:156)    org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:100)  	... 50 more";0
XD-1296;Few integration tests fail if JMX is enabled If JMX is enabled some of the integration tests fail.    This is similar to what we see in XD-1295.    One example of this case is the test classes that extend StreamTestSupport.    In StreamTestSupport the @BeforeClass has this line:    moduleDeployer = containerContext.getBean(ModuleDeployer.class)    When JMX is enable the IntegrationMBeanExporter creates JdkDynamicProxy for the ModuleDeployer (since it is of type MessageHandler) and thereby the above line to get bean by the implementing class type (ModuleDeployer) fails.    There are few other places where we use to refer the implementing classes on getBean().  Looks like we need to fix those as well.;0
XD-1297;Fix module type guessing heuristics Commit 96de9fcfaf32719413015a1a6bace1b30b6b9610 strengthened module type inference but some corner cases remain (marked as TODOs and commented out assertions in tests).    To be effective we need to look at the whole deployed stream (or composed module). Modify ParsinContext accordingly.;0
XD-13;Tail file channel adapters;0
XD-130;Remove container entry in Redis when the application context event to shutdown the container is fired;0
XD-1303;Create REST API for getting information on a given job instance;0
XD-1306;Move ftp support from .x package to spring-xd-dirt batch package Commit https://github.com/spring-projects/spring-xd/commit/761cd5e8250c055878caf3a789ab5b3254ba48e8 introduced support for FTP and added a bunch of .x classes.    These should not belong to DIRT proper though and should be added to an extension style project. The job(s) module would then depend on them;0
XD-1307;Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg /streams/{id} instead of using string concatenation;0
XD-1308;"Weird behavior of the transform module When trying some of the examples of XD-159 came up with weird behavior of the transform module.    This boils down to:  {noformat}  stream create foo --definition ""http |transform --expression='new java.lang.Integer(payload)' |  transform --expression=payload.getClass() | log""  http post --data 42   ==> Integer (OK)  http post --data WTH => WTH (!)  {noformat}    Seems that when the expression can not be evaluated the incoming payload is transmitted as is";0
XD-1309;JSR303 validation of options interferes with dsl completion When using a JSR303 annotated class for module options the binding failures should be bypassed as they interfere with completion proposals.;0
XD-131;Upgrade Lettuce to 2.3.2;0
XD-1310;Misleading error message when trying to restart a job exec Disregard the missing date that is caused by another problem.  Here is the setup:  {noformat}  xd:>job execution list    Id  Job Name  Start Time                        Step Execution Count  Status    --  --------  --------------------------------  --------------------  ---------    13  foo         Europe/Paris                    0                     STARTING    12  foo       2014-02-12 15:39:46 Europe/Paris  1                     FAILED    11  foo       2014-02-12 15:39:29 Europe/Paris  1                     COMPLETED    10  foo       2014-02-12 15:38:36 Europe/Paris  1                     COMPLETED    9   foo       2014-02-12 15:38:21 Europe/Paris  1                     COMPLETED    8   foo         Europe/Paris                    0                     STARTING    7   foo       2014-02-12 15:25:41 Europe/Paris  1                     COMPLETED    6   foo       2014-02-12 15:25:04 Europe/Paris  1                     FAILED    5   foo       2014-02-12 15:14:32 Europe/Paris  1                     FAILED    4   foo       2014-02-12 15:14:13 Europe/Paris  1                     FAILED    3   foo       2014-02-12 15:13:54 Europe/Paris  1                     FAILED    2   foo       2014-02-12 15:13:18 Europe/Paris  1                     FAILED    1   foo       2014-02-12 15:12:58 Europe/Paris  1                     FAILED    0   foo       2014-02-12 15:11:44 Europe/Paris  1                     FAILED    xd:>job execution restart --id 12  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Job Execution 12 is already running.  {noformat}    while the server exception is a bit better:  {noformat}  Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobInstance: id=11 version=0 Job=[foo]    org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:120)  {noformat}    I'd argue we should not speak in terms of execution ids if possible but rather in terms of job names;0
XD-1311;Job execution list should mention jobs that have been deleted Create a job execute it a couple of times destroy it and then invoke job execution list.    The job name column should mention that a job is defunct (even though a job with the same name could have been re-created in the interim);0
XD-1312;Job execution restart fails with NPE Create a job launch it but make it fail (eg filejdbc with missing file)  job execution list => it's there as FAILED. Good  job execution restart <theid> ==> Fails with NPE:  {noformat} 16:59:42160 ERROR http-nio-9393-exec-7 rest.RestControllerAdvice:191 - Caught exception while handling a request java.lang.NullPointerException   org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:351)   org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)   sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy39.run(Unknown Source)   org.springframework.batch.admin.service.SimpleJobService.restart(SimpleJobService.java:179)   org.springframework.xd.dirt.plugins.job.DistributedJobService.restart(DistributedJobService.java:77)   org.springframework.xd.dirt.rest.BatchJobExecutionsController.restartJobExecution(BatchJobExecutionsController.java:146)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springfram {noformat};0
XD-1316;"UI:Fix E2E test warning When running E2E tests the following warning may be observed:    {code}  Running ""karma:e2e"" (karma) task  INFO [karma]: Karma v0.10.9 server started at http://localhost:7070/_karma_/  INFO [launcher]: Starting browser PhantomJS  TypeError: Cannot read property 'verbose' of undefined      at enableWebsocket (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:101:18)      at Object.utils.proxyRequest [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:109:5)      at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)      at Object.livereload [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect-livereload/index.js:147:5)      at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)      at Function.app.handle (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:201:3)      at Server.app (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/connect.js:65:37)      at Server.EventEmitter.emit (events.js:98:17)      at HTTPParser.parser.onIncoming (http.js:2108:12)      at HTTPParser.parserOnHeadersComplete [as onHeadersComplete] (http.js:121:23)      at Socket.socket.ondata (http.js:1966:22)      at TCP.onread (net.js:525:27)  {code}";0
XD-1318;XD container can not be started before the admin server The job single partitioned step support (from singlestep-partitioner-support.xml) has the batch job DAOs (loaded from batch.xml).    During container startup when the jobExecutionDao bean is initialized it makes the db connection to the underlying batch database (which admin server initializes).     Here is the exception:    15:30:03600  INFO main xml.XmlBeanDefinitionReader:316 - Loading XML bean definitions from class path resource [META-INF/spring-xd/batch/batch.xml]  15:30:06154  WARN main annotation.ConfigurationClassEnhancer:318 - @Bean method StepScopeConfiguration.stepScope is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues see @Bean Javadoc for complete details  15:30:06705  INFO main support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:309 - Bean 'org.springframework.xd.dirt.server.ParentConfiguration$JmxConfiguration' of type [class org.springframework.xd.dirt.server.ParentConfiguration$JmxConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)  15:30:07266  INFO main annotation.AnnotationMBeanExporter:416 - Registering beans for JMX exposure on startup  15:30:07291  INFO main annotation.AnnotationMBeanExporter:896 - Bean with name 'XDParentConfigMBeanExporter' has been autodetected for JMX exposure  15:30:07299  INFO main annotation.AnnotationMBeanExporter:659 - Located managed bean 'XDParentConfigMBeanExporter': registering with JMX server as MBean [org.springframework.integration.monitor:name=XDParentConfigMBeanExportertype=IntegrationMBeanExporter]  15:30:09637  INFO main concurrent.ThreadPoolTaskScheduler:165 - Initializing ExecutorService  'scheduler'  15:56:08788  INFO main concurrent.ThreadPoolTaskScheduler:203 - Shutting down ExecutorService 'scheduler'  15:56:08806  INFO main annotation.AnnotationMBeanExporter:434 - Unregistering JMX-exposed beans on shutdown  15:56:08853  INFO main autoconfigure.AutoConfigurationReportLoggingInitializer:118 -     Error starting ApplicationContext. To display the auto-configuration report enabled debug logging (start with --debug)      15:56:08854  INFO main listener.ClasspathLoggingApplicationListener:54 - Application failed to start with classpath: [file:/Users/iperumal/workspace/spring-xd/modules/processor/scripts/ file:/Users/iperumal/workspace/spring-xd/spring-xd-dirt/bin/ file:/Users/iperumal/workspace/spring-xd/spring-xd-test/bin/ file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-test/4.0.0.M3/74e696bad60aab349c74f52839eb43ed0e1ce0e2/spring-integration-test-4.0.0.M3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-amqp/4.0.0.M3/32dd5001acffd82391d756cf3b5ba73ca4075aed/spring-integration-amqp-4.0.0.M3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-redis/4.0.0.M3/ed5e47b6844212bb88c112c559556b4cb3d6b087/spring-integration-redis-4.0.0.M3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop/2.0.0.M4/9f1acbf66f3a97d42a8f5b00eb0c0cad11562730/spring-data-hadoop-2.0.0.M4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-redis/1.1.1.RELEASE/e2d5e9cfdaaa3fbcc2a8d4bdbe06daf771cb4e39/spring-data-redis-1.1.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/4.0.1.RELEASE/cb996939c8d48ae55ec933041f17e7fba4d9e27d/spring-context-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context-support/4.0.1.RELEASE/94dc23c49a74f3f4b894b29416b08202e5976f49/spring-context-support-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/4.0.1.RELEASE/b93b2c39b09ff858a42db85a0a9a8ce232a6779/spring-tx-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/4.0.1.RELEASE/367212c3b84c63a48220efa0fe8e9a3a937fcf68/spring-test-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.lambdaworks/lettuce/2.3.3/1366615be02807a568c5f2d3a4475a3d27a879a6/lettuce-2.3.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hsqldb/hsqldb/2.3.0/93306187b1a782f2b929d12536022185487037d2/hsqldb-2.3.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-jdbc/7.0.42/3827da9ca05ff115f239a2372bd44cfd729c692d/tomcat-jdbc-7.0.42.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/junit/junit/4.11/4e031bb61df09069aeb2bffb4019e7a5034a4ee0/junit-4.11.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/2.4/b1b6ea3b7e4aa4f492509a4952029cd8e48019ad/commons-io-2.4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.groovy/groovy-all/2.1.0/a14306a090eec2fa91017b77ac079361f68e1830/groovy-all-2.1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.0/9b473564e792c2bdf1449da1f0b1b5bff9805704/objenesis-1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/1.9.5/c3264abeea62c4d2f367e21484fbb40c7e256393/mockito-core-1.9.5.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.1/5043bfebc3db072ed80fbd362e7caf00e885d8ae/commons-logging-1.1.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/4.0.1.RELEASE/e39774d97c9dadfe49e6dfd16e3868bc1e390554/spring-core-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/4.0.1.RELEASE/605582e95fb62b43fb4a843babdcf739f3497e92/spring-beans-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/aopalliance/aopalliance/1.0/235ba8b489512805ac13a8f9ea77a1ca5ebe3e8/aopalliance-1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/4.0.1.RELEASE/ff68e4cfdbb2be3e8d8a7f34e7cbacc1860dfe75/spring-aop-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/4.0.1.RELEASE/452cb22401e868a1e79677dd22b6a3097fc603fa/spring-expression-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.3.RELEASE/33b967f6abaa0a496318bff2ce96e6da6285a54d/spring-retry-1.0.3.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/4.0.1.RELEASE/829829afd9135368faa1e3a5261404f602a2e939/spring-messaging-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.integration/spring-integration-core/4.0.0.M3/12b445cfa896b906facd2be289adcdfe839f6104/spring-integration-core-4.0.0.M3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-all/1.3/63a21ebc981131004ad02e0434e799fd7f3a8d5a/hamcrest-all-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-amqp/1.3.0.M2/e668db16a4206e96531b978e5978868ba0ebf4e9/spring-amqp-1.3.0.M2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.rabbitmq/amqp-client/3.2.2/9e4485e734415e84ea3caea25650f8651f388a3a/amqp-client-3.2.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.amqp/spring-rabbit/1.3.0.M2/ceb54c437d2d00c3a22d59982922f24fbf78c8a/spring-rabbit-1.3.0.M2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.6.6/ce53b0a0e2cfbb27e8a59d38f79a18a5c6a8d2b0/slf4j-api-1.6.6.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.6.6/ec497945fdcaf7fd970ae9931b9bbfaf735d385e/jcl-over-slf4j-1.6.6.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jdbc/4.0.1.RELEASE/7d46d07d44f56af7cdcbba53ff671c5487f9547/spring-jdbc-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.2/2bf96b7aa8b611c177d329452af1dc933e14501c/commons-cli-1.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/xmlenc/xmlenc/0.52/d82554efbe65906d83b3d97bd7509289e9db561a/xmlenc-0.52.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.4/4216af16d38465bbab0f3dff8efa14204f7a399a/commons-codec-1.4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-httpclient/commons-httpclient/3.0.1/d6364bcc1b2b2aa69d008602d36a700453648560/commons-httpclient-3.0.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-math/2.1/b3c4bdc2778ddccceb8da2acec3e37bfa41303e9/commons-math-2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2.1/761ea405b9b37ced573d2df0d1e3a4e0f9edc668/commons-collections-3.2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.4/16313e02a793435009f1e458fa4af5d879f6fb11/commons-lang-2.4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils/1.7.0/5675fd96b29656504b86029551973d60fb41339b/commons-beanutils-1.7.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-digester/commons-digester/1.8/dc6a73fdbd1fa3f0944e8497c6c872fa21dca37e/commons-digester-1.8.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-beanutils/commons-beanutils-core/1.8.0/175dc721f87e4bc5cc0573f990e28c3cf9117508/commons-beanutils-core-1.8.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-configuration/commons-configuration/1.6/32cadde23955d7681b0d94a2715846d20b425235/commons-configuration-1.6.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/oro/oro/2.0.8/5592374f834645c4ae250f4c9fbb314c9369d698/oro-2.0.8.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-net/commons-net/1.4.1/abb932adb2c10790c1eaa4365d3ac2a1ac7cb700/commons-net-1.4.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-el/commons-el/1.0/1df2c042b3f2de0124750241ac6c886dbfa2cc2c/commons-el-1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.eclipse.jdt/core/3.1.1/88c83ce444cf46d02494da37c9fa1eebc9ce9cea/core-3.1.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-core/1.2.1/3e5874122a26a735162a380627210779b41bfd59/hadoop-core-1.2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-streaming/1.2.1/4baac190cf4cd4a6d085780cbcab1a89493f932b/hadoop-streaming-1.2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.hadoop/hadoop-tools/1.2.1/b08c16bd0448fbcadab67c4f8df837c094fdc91e/hadoop-tools-1.2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-core/2.0.0.M4/ff4cefb0870d61fdc9efe26d118310c02b5eafbb/spring-data-hadoop-core-2.0.0.M4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-batch/2.0.0.M4/47de250d5d9b48ed1319a747e3b06fdc46d939ef/spring-data-hadoop-batch-2.0.0.M4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.6.6.Final/e4e40738ce9bee0a92389cb739c94d7839778647/netty-3.6.6.Final.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.apache.tomcat/tomcat-juli/7.0.42/f0049ac94514d69231c41ed96238efb94ffdd9cf/tomcat-juli-7.0.42.jar file:/Users/iperumal/workspace/spring-xd/spring-xd-analytics/bin/ file:/Users/iperumal/workspace/spring-xd/spring-xd-tuple/bin/ file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.2.2/3c8f6018eaa72d43b261181e801e6f8676c16ef6/jackson-databind-2.2.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-infrastructure/3.0.0.BUILD-SNAPSHOT/cfaea737589c43c54ff338ae27e1bee477620176/spring-batch-infrastructure-3.0.0.BUILD-SNAPSHOT.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.eaio.uuid/uuid/3.2/77ba5105d949cd589aff75400d9f7d3676691a46/uuid-3.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.2.2/285cb9c666f0f0f3dd8a1be04e1f457eb7b15113/jackson-annotations-2.2.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.2.2/d20be6a5ddd6f8cfd36ebf6dea329873a1c41f1b/jackson-core-2.2.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-commons/1.6.2.RELEASE/e96a0458cdc3179ca70c880f42315bb75df4faf5/spring-data-commons-1.6.2.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.1/8f79e353ef77da6710e1f10d34fc3698eaaacbca/joda-time-2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/jcl-over-slf4j/1.7.5/cd5970bd13fa85f7bed41ca606d6daf7cbf1365/jcl-over-slf4j-1.7.5.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.5/6edffc576ce104ec769d954618764f39f0f0f10d/slf4j-log4j12-1.7.5.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/nl.jqno.equalsverifier/equalsverifier/1.1.3/60cd685f314a9cebfd0595d88fea45fba2f47918/equalsverifier-1.1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.5/6b262da268f8ad9eff941b25503a9198f0a0ac93/slf4j-api-1.7.5.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.1/63db1176f16448172611266154e4f6d39a0e1e68/objenesis-1.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/2.2/59afed7ab65e7ec6585d5bc60556c3cbd203532b/cglib-nodep-2.2.jar file:/Users/iperumal/workspace/spring-xd/spring-xd-rest-domain/bin/ file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.hateoas/spring-hateoas/0.8.0.RELEASE/819c25e1ff12b7fca483d76b4e7d20221f621fcd/spring-hateoas-0.8.0.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-manager/1.3.0.M1/5afc7442417af8c46ae51480ed2b83943283d449/spring-batch-admin-manager-1.3.0.M1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-core/3.0.0.BUILD-SNAPSHOT/8168f58716cd305040eaa87c82dc61822b03415c/spring-batch-core-3.0.0.BUILD-SNAPSHOT.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.13/3c304d70f42f832e0a86d45bd437f692129299a4/jackson-core-asl-1.9.13.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/4.0.1.RELEASE/2ace92025f042e1d3ddfdbba093172e3572ac130/spring-web-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/4.0.1.RELEASE/2dbc91a6413115f7ffbe94f0fa9bc9fda3281d90/spring-webmvc-4.0.1.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/1.3/dc13ae4faca6df981fc7aeb5a522d9db446d5d50/objenesis-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.2/81d61b7f33ebeab314e07de0cc596f8e858d97/slf4j-api-1.7.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjrt/1.6.6/ff58f520e1a304b8a02b8cea8b96b1b8e5b25b0/aspectjrt-1.6.6.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.aspectj/aspectjweaver/1.6.6/c0383be877cfa4ec6b62202c942a89a6264a2be6/aspectjweaver-1.6.6.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-pool/commons-pool/1.3/3231230c1d7631b66a74d1c4653cfd65a6f9ea0/commons-pool-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-dbcp/commons-dbcp/1.2.2/4fd4c6110e9bca3a655b717eb2e5920febb8403d/commons-dbcp-1.2.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-io/commons-io/1.4/a8762d07e76cfde2395257a5da47ba7c1dbd3dce/commons-io-1.4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.1/4763ecc9d78781c915c07eb03e90572c7ff04205/commons-lang-2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-fileupload/commons-fileupload/1.2.1/384faa82e193d4e4b0546059ca09572654bc3970/commons-fileupload-1.2.1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/net.sf.ehcache/ehcache-core/2.3.0/e59473c71a31e8e19da4fbc7028585c8ed51d69f/ehcache-core-2.3.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/commons-collections/commons-collections/3.2/f951934aa5ae5a88d7e6dfaa6d32307d834a88be/commons-collections-3.2.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.freemarker/freemarker/2.3.15/c8cfe522476fcec8da5c980d58bf62d6ab0cf27c/freemarker-2.3.15.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.batch/spring-batch-admin-resources/1.3.0.M1/bdf7d5afc02397385fce8731409f606e54d4d033/spring-batch-admin-resources-1.3.0.M1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.0.2.RELEASE/d673c90a9fd8f0de5f20d53d61047849f707f42b/spring-retry-1.0.2.RELEASE.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/javax.batch/javax.batch-api/1.0/65392d027a6eb369fd9fcd1b75cae150e25ac03c/javax.batch-api-1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.ibm.jbatch/com.ibm.jbatch-tck-spi/1.0/8ac869b0a60bff1a15eba0fb6398942410396938/com.ibm.jbatch-tck-spi-1.0.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/xpp3/xpp3_min/1.1.4c/19d4e90b43059058f6e056f794f0ea4030d60b86/xpp3_min-1.1.4c.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/com.thoughtworks.xstream/xstream/1.3/3f755b1a46744302712b1b962c4ab64de392f477/xstream-1.3.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.codehaus.jettison/jettison/1.1/1a01a2a1218fcf9faa2cc2a6ced025bdea687262/jettison-1.1.jar file:/Users/iperumal/workspace/spring-xd/spring-xd-module/bin/ file:/Users/iperumal/workspace/spring-xd/spring-xd-module-spi/bin/ file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/1.0.0.RC1/7830d0dd26f75841d8b5c2c72c42b864b1192ddb/spring-boot-autoconfigure-1.0.0.RC1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/1.0.0.GA/b6bd7f9d78f6fdaa3c37dae18a4bd298915f328e/validation-api-1.0.0.GA.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.hibernate/hibernate-validator/4.3.1.Final/49b31d8ea51fa21cc78a89e9d4ddb11d6bfb4669/hibernate-validator-4.3.1.Final.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/1.0.0.RC1/7e53b72a368c495a482d3a213ad6338f8f7afcfa/spring-boot-1.0.0.RC1.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.1.0.CR2/28725380c07f917ace4e511db21cc45e9ae5a72b/jboss-logging-3.1.0.CR2.jar file:/Users/iperumal/workspace/spring-xd/spring-xd-hadoop/bin/ file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.springframework.data/spring-data-hadoop-store/2.0.0.M4/1d3d691c0e6952ba26724339668e17040c368683/spring-data-hadoop-store-2.0.0.M4.jar file:/Users/iperumal/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.0/71c46e2313e9288...;0
XD-1319;"Allow mixins of ModuleOptionsMetadata A lot of modules have similar options. Moreover job modules often have options that belong to at least two domains (eg jdbc + hdfs).  I think that by using FlattenedCompositeModuleOptionsMetadata we could come up with a way to combine several options POJOs into one. Something like:  public class JdbcHdfsOptionsMetadata {    @OptionsMixin   private JdbcOptionsMetadata jdbc    @OptionsMixin   private HdfsOptionsMetadata hdfs }  this would expose eg ""driverClass"" as well as ""rolloverSize"" as top level options. Values could be actually injected into the fields so that eg custom validation could occur (default validation for the mixin class would occur by default)";0
XD-1322;Add way to provide module config options for XD on YARN There seems to be some intersection with the work for this issue and the rationalization of how module properties are handled.  There will be changes to configuration/property management support such that each module (source sink etc) will be able to also be overridden in spring-xd.yml (or wherever -Dspring.config.location points to.  The HDFS sink module for example will have default values based on it's OptionsMetadata and will be of the form <type>.<module>.<option>      That means in the configuration for hdfs.xml sink there would be a config section such as    {code:xml}      <configuration>        fs.default.name=${sink.hdfs.hd.fs}        mapred.job.tracker=${sink.hdfs.hd.jt}        yarn.resourcemanager.address=${sink.hdfs.hd.rm}        mapreduce.framework.name=${sink.hdfs.mr.fw}      </configuration>  {code}    With default values defined by a HdfsSinkOptionsMetadata class.  The hdfs.xml module file would not contain any references to a properties file.    A file specified by -Dspring.config.location could override the values in a config section such as    sink:    hdfs:      hd.fs : hdfs://foobarhost:8020      hd.jt : 10.123.123.123:9000    etc.;0
XD-1326;Provide xd-shell integration for deploying XD on YARN Command such as  yarn app list yarn deploy-xd --zipFile /tmp/myapp.zip --config /tmp/myconfig.yml;0
XD-1327;"Rabbit source module with outputType fails to deploy To replicate the issue:    Create stream:   stream create rabbittest --definition ""rabbit --queues=test --outputType=text/plain | log""    Stacktrace thrown:    17:59:56436 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:191 - Caught exception while handling a request  java.lang.IllegalArgumentException: Module option named outputType is already present    org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.<init>(FlattenedCompositeModuleOptionsMetadata.java:56)    org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:49)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:117)    org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:73)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:227)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:601)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)    org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)    javax.servlet.http.HttpServlet.service(HttpServlet.java:647)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)    javax.servlet.http.HttpServlet.service(HttpServlet.java:728)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:131)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)    org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:722)";0
XD-1328;Modularize XD UI From https://jira.springsource.org/browse/XD-1231 we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.;0
XD-133;Fail Sonar CI build if there are any package tangles violated. Similar to what would show up on structure101 reports.;0
XD-1330;Enhance HadoopFileSystemTestSupport to obtain resource for a specific hadoop distro It looks like the HadoopFileSystemTestSupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro.     Currently if the test is run against a version other than 1.2 the rule says:    15:47:34469 ERROR main hadoop.HadoopFileSystemTestSupport:95 - HADOOP_FS IS NOT AVAILABLE SKIPPING TESTS  org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4    org.apache.hadoop.ipc.Client.call(Client.java:1113)    org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)    com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:601)    org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)    org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)    com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)    org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)    org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)    org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)    org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)    org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)    org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)    org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)    org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)    org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)    org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)    org.springframework.xd.test.hadoop.HadoopFileSystemTestSupport.obtainResource(HadoopFileSystemTestSupport.java:49)    org.springframework.xd.test.AbstractExternalResourceTestSupport.apply(AbstractExternalResourceTestSupport.java:58)    org.junit.rules.RunRules.applyAll(RunRules.java:26)    org.junit.rules.RunRules.<init>(RunRules.java:15)    org.junit.runners.BlockJUnit4ClassRunner.withTestRules(BlockJUnit4ClassRunner.java:379)    org.junit.runners.BlockJUnit4ClassRunner.withRules(BlockJUnit4ClassRunner.java:340)    org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:256)    org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)    org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)    org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)    org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)    org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)    org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)    org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)    org.junit.runners.ParentRunner.run(ParentRunner.java:309)    org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)    org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)    org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)    org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)    org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)    org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197);0
XD-1331;Make Batch Job Restarts Work using Single Node See also XD-1320.;0
XD-1333;Add config file fragment support configuration in XD windows bat scripts The external configuration fragment file support by setting spring.config.location in the XD startup scripts are not updated in xd-admin xd-container and xd-singlenode .bat scripts.   Please refer: https://github.com/spring-projects/spring-xd/issues/582;0
XD-1334;Ensure XD Samples share common version dependencies Currently samples use separate build scripts so the XD versions etc. may all be different. There should be a top level build script or at least a way to ensure the same version dependencies;0
XD-1338;"Deployment manifest to support partitioning a stream We need a methodology for providing partitioning hints.    A current proposal uses message headers to provide:    * partition_key – the item to partition on  * destination_region – what to target    In the proposal the developer used ""partition_key"" to route the stream message to the node where data was stored in process.  This was done so downstream stream operations could work on the data with out suffering any network IO.    The ""destination_region"" was used to target the type of data the downstream streams were going to use in their stream processing.";0
XD-134;Investigate link checking tool for user guide Asciidoc/doctor might have one as part of it toolchain;0
XD-1341;Support oracle jdbc configuration for XD batch job repository Currently hsqldb postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.;0
XD-1342;Configuration for RabbitMQ message bus concurrent consumers By having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.;0
XD-1345;Use dot as the composed module option separator Following merge of https://github.com/spring-projects/spring-xd/pull/601 use dot as the separator for a composed module option.    Need change to the parser to accept dots;0
XD-1346;Add aliases concept to module options and use in composed modules Following merge of https://github.com/spring-projects/spring-xd/pull/601 allow a module option to be known by several names and elect a short name in composed module options when there is no ambiguity;0
XD-1353;Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn't had any update activity for several months. Jedis is actively maintained.    We might also want to investigate Redisson which is a fork of Lettuce - https://github.com/mrniko/redisson;0
XD-1354;Remove XDContainer and rename LauncherApplication Post-boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into LauncherApplication. Rename LauncherApplication to ContainerServerApplication (consistent with AdminServerApplication).;0
XD-1357;Container nodes should write attributes to ZooKeeper The /xd/containers node is the parent where each Container will write an ephemeral child node. The node name should be the Container's ID and the node data should be the Container's attributes (host pid and much more to be added later).    When a Container shuts down cleanly it should eagerly delete the ephemeral node so that watchers are notified immediately. For any other case (including a network partition) the ephemeral node will disappear after the timeout elapses.;0
XD-1360;"Json information returned by curl does not reflect deployed status correctly The Json information returned by curl does not reflect deployed status correctly.  To recreate:  1. Start xd-singlenode  2. start xd-shell  In the xd-shell      (i). stream create --definition ""time | log"" --name ticktock     (ii). stream list  Note the status of the ticktock stream is deployed  3. open a new command prompt & type curl http://localhost:9393/streams/ticktock  4. Note the returned json stream:    {""name"":""ticktock""""deployed"":null""definition"":""time | log""""links"":[{""rel"":""self""""href"":""http://localhost:9393/streams/ticktock""}]}  5. I would expect the json attribute ""deployed"" to be ""true"" but it is null.";0
XD-1361;"Classpath issue with homebrew version on MacOSX 10.9.1 I've installed spring xd for the first time today on my mac using the homebrew distribution.  I tried to create the following stream :  {{xd> stream create --definition ""http --port=6666 | log"" --name httptest}}  This produced the following error :   org.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)   org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:183)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:153)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:183)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:153)   org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)   org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:163)   org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:204)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)   org.springframework.xd.dirt.rest.XDController.save(XDController.java:229)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:931)   org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:833)   javax.servlet.http.HttpServlet.service(HttpServlet.java:647)   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:807)   javax.servlet.http.HttpServlet.service(HttpServlet.java:728)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:126)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)   org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)   org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)   org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)   org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)   org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)   org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)   org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)   org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)   org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)   org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Cannot find class [org.springframework.integration.x.http.NettyHttpInboundChannelAdapter] for bean with name 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0' defined in URL [file:/Users/philippe/springsource/spring-xd-1.0.0.M1/xd/modules/source/http.xml] nested exception is java.lang.ClassNotFoundException: org.springframework.integration.x.http.NettyHttpInboundChannelAdapter   org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1327)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:594)   org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1396)   org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:959)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:680)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:181)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:264)   org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:254)   org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:249)   org.springframework.xd.dirt.module.ModuleDeployer.handleSingleModuleMessage(ModuleDeployer.java:227)   org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:154)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73) 	... 79 more Caused by: java.lang.ClassNotFoundException: org.springframework.integration.x.http.NettyHttpInboundChannelAdapter   org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedWebappClassLoader.loadClass(TomcatEmbeddedWebappClassLoader.java:68)   org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)   org.springframework.util.ClassUtils.forName(ClassUtils.java:238)   org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:392)   org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1348)   org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1319) 	... 95 more  I managed to create the exact same stream successfully after installing the release manually from the zip file and setting up XD_HOME and my path as documented so I guess it's a problem specific to the homebrew installation.";0
XD-1362;Make Job notification channels subscribable Currently the job notification channels are direct channels. We need to make these pub/sub channels.    With XD-885 (allowing automatic job listeners registration)  this would allow us to create named channel syntax like:    topic:job:myjobname-jobExecution > log  topic:job:myjobname-stepExecution > log;0
XD-1364;Upgrade to SHDP 2.0 M6 The YARN support in M6 changes most of the config properties need to update XD to use new ones.;0
XD-1365;StreamDeployer.deleteAll() does not handle dependency tracking create a composed module use it in a stream delete ALL streams.  Try to delete the composed module => fails thinking that it's still used by the stream;0
XD-1366;"Unable to destroy stream when using http source When destroying a stream that contains an http source an exception is thrown.  Thus even though the stream is destroyed all resources are not released i.e. port 9000 is still in use.    NettyHttpInboundChannelAdapter is currently setup with child.tcpNoDelay set to true.  And when running on my system and on EC2 the http needs more time to release the port.    My recommendation is to set bootstrap.setOption(""child.tcpNoDelay"" false) instead of true.";0
XD-1367;Exclude commons-logging from final distro1 xd/lib includes jcl-over-slf4j so we don't need additional commons-logging jars in the modules or extensions:  https://github.com/spring-projects/spring-xd/pull/610;0
XD-1368;Refactor container to remove shared module context as a separate context The main container context becomes the shared context for modules.;0
XD-137;Release Spring XD 1.0 M1;0
XD-1371;"Clarify API or syntax for managing deployment parameters Suppose we have 3 environements of Spring XD : - Dev environment  - Test environment  - Prod environement (  Suppose whe develop the script bellow: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=/tmp/toto  stream2 = http | filter --expression=payload.contains('titi') | file --dir=/tmp/titi //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////  When we need to deploy the script in Test and Prod environements  we must modify ""dir"" option of ""file"" sink. This is very easy when there is not a lot of options and when we have a small factory team. But in a big factory environment this will be problematic.   In order to industrialize deployment it would be convenient to implement in DSL a directory interface API or something equivalent like below:  Suppose we call this directory interface XDDI ... like ""XD Directory Interface"" :-)  The script can be like that: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=XDDI('totoKey')  stream2 = http | filter --expression=payload.contains('titi') | file --dir=XDDI('titiKey')  //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////  The XDDI keys are defined in a centralized directory interface (admin console or XDDI.properties)  The XDDI keys/values in Dev environment: ///////////////////////////////////// totoKey=/tmp/toto titiKey=/tmp/titi /////////////////////////////////////  The XDDI keys/values in Test environment: ////////////////////////////////////////// totoKey=/tartempion/toto titiKey=/petaouchnok/titi /////////////////////////////////////////  The XDDI keys/values in Prod environment: ///////////////////////////////////////////////////// totoKey=/vavoirlabasijysuis/toto titiKey=/vavoirlabasijysuis/titi /////////////////////////////////////////////////////  When the script is deployed in Test or Prod environement if the script contain a key that is not defined in centralized directory the deployment fail.   This will reduce errors risks in a big factory environnement (several hundred parameters and signifiant team turnover).";0
XD-1374;Update to use spring-data-hadoop 2.0 M6;0
XD-1375;Create spike of web app that maps UI design docs to MVC components in Angluar;0
XD-1376;"XD Shell crashes when the stream DSL has ""!"" The XD shell crashes when the following command issued:    stream create test --definition ""http | filter --expression=!payload.contains('test') | log""    It looks like the JLine ConsoleReader's expandEvents is set to true by default and this causes the issue:    Exception in thread ""Spring Shell"" java.lang.IllegalArgumentException: !payload.contains('test') | log"": event not found    jline.console.ConsoleReader.expandEvents(ConsoleReader.java:734)    jline.console.ConsoleReader.finishBuffer(ConsoleReader.java:604)    jline.console.ConsoleReader.accept(ConsoleReader.java:1912)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2537)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)    org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:517)    org.springframework.shell.core.JLineShell.run(JLineShell.java:178)    java.lang.Thread.run(Thread.java:722)";0
XD-1377;"Rename ""node"" references to ""container"" This applies to a few places (when addressing the issue a search should be done to uncover any others) e.g.:    ContainerServerApplication:      public static final String NODE_PROFILE = ""node""    *Options classes:       ""The transport to use for data messages (from node to node)""       ""The transport to use for control messages (between admin and nodes)""";0
XD-1380;"Can't create http source while TCP is used as a source and sink on singlenode [Problem] Can't use tcp source sink and http together on Single Node.  While creating tests for CI I tried to create the following: [Steps to Reproduce] xd:>stream create fooOut --definition ""tcp|file"" Created new stream 'fooOut' xd:>stream create fooIn --definition ""http --port=9002|tcp"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Failed to bind to: 0.0.0.0/0.0.0.0:9000. Possibly the port is already in use. Even if I use different ports for the tcp I still get failures pointing to 9000. [Extra Notes] The stream below is works. xd:>stream create fooOut --definition ""tcp|file"" Created new stream 'fooOut' xd:>stream create fooIN --definition ""time|tcp""  *Stack Trace Attached*";0
XD-1382;tcp source requires a \r\n to suffix all inbound data When sending data to the TCP Source if the data is not terminated with a \r\n when the socket is closed by the client XD throws an exception.;0
XD-1385;Add JDBC Sink to acceptance tests;0
XD-1386;Add option to xd-admin and xd-container YARN scripts to allow copying ot HDFS and no execution.;0
XD-1387;Add documentation on how to deploy XD to YARN;0
XD-1388;Upgrade to Spring Batch 3.0.0 M3;0
XD-1394;Upgrade to Spring 4.0.2.RELEASE;0
XD-1396;Container fails to start if JMX is enabled and manage_port is set The container will not start with JMX enabled and the management_port set.  The stacktrace is attached and the settings for the container are enumerated below:      export endpoints_jmx_enabled=true     export endpoints_jmx_uniqueNames=true     export endpoints_jolokia_enabled=true     export XD_JMX_ENABLED=true     export management_port=15005;0
XD-1398;Admin servers should write streams to and delete them from ZooKeeper This should also enable removal of any StreamDefinitionRepository code.    The state should be written as a data node at the stream level (e.g. /xd/streams/mystream {state=...})    For now we at least need to support the boolean --deploy=true|false flag. If that is true then the leader Admin will deploy the modules of the stream across available containers (XD-1399);0
XD-1399;Admin leader should watch ZooKeeper for Stream deployment requests The Stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed.    When a Stream is deployed the leader will consult its Container cache and write the modules to the various /xd/deployments child nodes (see XD-1400).;0
XD-140;Parameterize syslog Source Add Support for TCP The syslog source currently is hard-coded to use udp on port 11111.    Need to parameterize the port and provide an option to use TCP.;0
XD-1400;Containers should listen for Module deployment requests and their deletions The Admin leader will write each Module deployment request to a child node of /xd/deployments for a selected Container (see XD-1399). That Container-specific (persistent) child node needs to be created by the Container at the same time as it creates its ephemeral node under /xd/containers.    The Container should then deploy the Module. If that same node is subsequently deleted the Container should undeploy the Module.;0
XD-1401;Add new reactor tcp module A reactor based TCP module that would support some basic CODECS.    Should evaluate if this new TCP module would subsume the current reactor-syslog module functionality or if the reactor-syslog module should be enhanced/upgradted.;0
XD-1403;Create benchmarking application to demonstrate high performance message processing The application should live in  in spring-xd-samples repository.    The stream created in https://jira.spring.io/browse/XD-1402 should be documented how to run a benchmark and made easy to execute.  Can use ruby/bash-awk-sed to generate traffic via sendfile in order to saturate the stream.;0
XD-1404;Test against Spring Boot Snapshot build;0
XD-1405;Version XD dependencies with Spring IO platform versioning All the XD artifacts dependencies need to be updated with the versions that in line with Spring IO platform's standard versioning.;0
XD-1412;"Composed options does not trigger profile activation I was in the process of rewriting transform using profiles (see ExpressionOrScriptMixin).  This broke eg ModuleCommandTests.testComposedModulesValuesInDefinition because basically composed module options activate no profile.  The problem is that there is no real way to know what to activate currently because when deploying a part of a composed module its metadata is actually a link to the *whole* metadata but does not really know which part.  Long story short something we may be able to do is to activate the union of all profiles but this breaks very easily : module compose foo --definition ""transform --expr=foo | transform --script=bar""  would try to activate both ""script"" and ""expression"" profiles for both modules.";0
XD-1418;Create subproject spring-xd-machine-learning-analytics This project contains core abstractions that will allow for multiple implementations of a machine learning algorithm to be implemented via integration with various existing libraries or custom code implementations.      The initial code for this has been developed in a separate github repo and is located here     https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics/src/main/java/org/springframework/xd/analytics/model    The model can assume its use in evaluation of the model inside a stream where the data structure is a Tuple.  Note it maybe useful to consider Message<Tuple> in case any metadata outside the core 'input data' is required to help guide the evaluation.    The build.gradle file should be updated such that there is a new build artifact spring-xd-machine-learning-analytics.jar along the lines of our other build artifacts.  Open to other naming suggestions.;0
XD-1423;Create documentation for how module properties are resolved. The ordering of the lookup should be described in particular detail on how environment variables can overrride properties.    Some details will necessarily change based on outcome of current discussion but the overall ordering is going to remain.;0
XD-1426;Minification of XD Admin UI JS files With requireJS r.js and ngmin we need to make sure the XD admin JS files are appropriately minified. Currently the JS files are not minified.;0
XD-1428;Log Hadoop Distro and ZK client connect info on Container startup It would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up.;0
XD-1432;Configure servers to use VanillaHealthEndpoint The standard SimpleHealthIndicator that boot performs a database test that fails in xd-container since it does not require the use of a database.;0
XD-1434;Improvements to Modules Tab 1. Get listing of job modules  2. Remove version and action column  3. Text to say creating definitions from available modules in the UI is forthcoming link to https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#creating-a-job for how to do this in the command line.     4. Hardcode an association between spring xd out of the box module names and a description.   5. Add button to display the XML file that defines the job module;0
XD-1439;Investigate module classloader leakage See report at https://github.com/spring-projects/spring-xd/issues/661    This should not happen as the module holds the classes that hold the classloader but who knows. An integration test that verifies this would be nice albeit tricky.;0
XD-1441;Implement XD_MODULE_CONFIG_LOCATION & NAME The description in the google doc     https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharing    describes the usage of XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME;0
XD-1444;Update to Spring Boot 1.0 GA;0
XD-1448;SpringXD logs error and large stack trace when metric can't be found. Distracting. When a REST client of SpringXD (i.e. a dashboard) attempts to query (GET) a metric (e.g. counter gauge etc.) that does not exist the admin sever logs an ERROR and a large stack trace (attached).  In usage of Spring XD we see this frequently because a dashboard is running but the streams and counters have not been created quite yet or initialized by messages flowing through the streams.  With a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues.      I would suggest logging a one line warning or info message instead of the error and stack trace.;0
XD-1452;http module leaks threads Attempts to create/use/undeploy a stream involving the http module will result in an OOME stating that VM could not create native thread.    Other modules should be checked as well.  {noformat}    java.lang.Thread.run(Thread.java:724)  Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0' nested exception is java.lang.OutOfMemoryError: unable to create new native thread    org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)    org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)    org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)    org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)    org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:91)    org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1180)    org.springframework.xd.module.core.SimpleModule.start(SimpleModule.java:273)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:251)    org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:239)    org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:179)    org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:150)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  	... 80 more  Caused by: java.lang.OutOfMemoryError: unable to create new native thread    java.lang.Thread.$$YJP$$start0(Native Method)    java.lang.Thread.start0(Thread.java)    java.lang.Thread.start(Thread.java:693)    java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)    java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1371)    org.jboss.netty.util.internal.DeadLockProofWorker.start(DeadLockProofWorker.java:38)    org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:343)    org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95)    org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:53)    org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)    org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:45)    org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:28)    org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(AbstractNioWorkerPool.java:99)    org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:69)    org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)    org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)    org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)    org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)    org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:115)    org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.doStart(NettyHttpInboundChannelAdapter.java:114)    org.springframework.integration.endpoint.AbstractEndpoint.start(AbstractEndpoint.java:84)    org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)  	... 91 more  {noformat};0
XD-1454;User should not be required to specify a control channel With the addition of zookeeper a user does not have to specify rabbit or redis for the control channel.   This story should allow a user to specify redis rabbit or no control channel.;0
XD-1455;Environment checkers in acceptance tests should use Asserts Replace tests and throws in the XdEc2Validation with asserts in the following methods:  verifyTestContent  verifyLogContent  verifySendCounts    VerifySendCounts should check for the exact number of Jmx events instead of >0.;0
XD-1456;Allow user to configure tests with DI With the addition of sinks and sources that require connections with external entities (hadoop JMS JDBC ...)  the environment setup is getting unwieldy.    * Integrate SpringJUnit4ClassRunner.class into acceptance tests.  * Retrieve environment variables via Dependency injection from application.properties.  * Utilize profiles for     --local single node    --local cluster    --ec2 single node    --ec2 cluster;0
XD-1467;Do not eagerly use repositories in completion's *Strategy;0
XD-1469;"Error in correlation strategy in aggregator.xml {noformat}  	correlation-strategy-expression=""${correlation:'${xd.stream.name}}'""  {noformat}  should be  {noformat}  	correlation-strategy-expression=""${correlation:'${xd.stream.name}'}""  {noformat}  Add a test to make sure correlation expressions here work.";0
XD-147;Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes 'java plugin' which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling.;0
XD-1471;Migrate repositories to ZooKeeper all state about the running system (containers streams and jobs) should be available via ZK and ultimately the --store option should not be needed    1. Refactor ModuleDefinitionRepository to use ZooKeeper     * remove RedisModuleDefinitionRepository     * remove InMemoryModuleDefinitionRepository    2. Refactor ModuleDependencyRepository to use ZooKeeper     * remove RedisModuleDependencyRepository     * remove InMemoryModuleDependencyRepository    3. Refactor RuntimeModuleInfoRepository to use ZooKeeper (rename ModuleMetadata...)     * remove RedisRuntimeModuleInfoRepository     * remove AbstractRedisRuntimeModuleInfoRepository     * remove InMemoryRuntimeModuleInfoRepository    4. Refactor RuntimeContainerModuleInfoRepository to use ZooKeeper (rename ContainerMetadata...)     * remove RedisRuntimeContainerModuleInfoRepository     * remove InMemoryRuntimeContainerModuleInfoRepository    5. Remove support for --store     * remove the memory-store.xml and the redis-store.xml     * instead include just one repositories.xml in shared server config     * remove the associated property key and the *Options properties    6. Remove the events and listeners that were being used;0
XD-1477;"Merge Container and ContainerMetadata as well as their ""repositories"" The two classes in question are:  * org.springframework.xd.dirt.cluster.Container  * org.springframework.xd.dirt.container.ContainerMetadata    The former is currently used by the Admin when making decisions about Module deployment. That latter was a replacement for RuntimeContainerInforEntity as we migrated the various Redis/InMemory Repositories to use the data that is now available in ZooKeeper instead.    The ContainerRepository is currently used by the Admin leader and the ContainerMetadataRepository is used by the REST endpoint that supports the xd-shell's 'runtime containers' command. Perhaps those can also be merged.    In any case if not addressed by a larger refactoring the ContainerRepository should probably support an Iterable return rather than an Iterator. Having finders (e.g. for attribute key/values such as ""group""==""foo"") might be convenient for various Module deployment strategies.";0
XD-1479;DefaultContainerMatcher should make a better attempt at round-robin distribution Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.;0
XD-148;"Improve User Experience when Redis is not running Redis is not running we get a nasty stacktrace:    {code}  ~/dev/git/spring-xd/dist/spring-xd/xd/bin (master)] ➔ ./xd-container   13/05/29 16:17:15 INFO support.ClassPathXmlApplicationContext: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@851052d: startup date [Wed May 29 16:17:15 EDT 2013] root of context hierarchy  13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/launcher.xml]  13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/redis.xml]  13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0redisConnectionFactoryorg.springframework.xd.dirt.launcher.RedisContainerLauncher#0] root of factory hierarchy  13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0redisConnectionFactoryorg.springframework.xd.dirt.launcher.RedisContainerLauncher#0] root of factory hierarchy  Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [META-INF/spring/redis.xml]: Invocation of init method failed nested exception is com.lambdaworks.redis.RedisException: Unable to connect    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1488)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:626)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)    org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)    org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)    org.springframework.xd.dirt.launcher.RedisContainerLauncher.main(RedisContainerLauncher.java:68)    org.springframework.xd.ContainerMain.main(ContainerMain.java:68)  Caused by: com.lambdaworks.redis.RedisException: Unable to connect    com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)    com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)    org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:108)    org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.afterPropertiesSet(LettuceConnectionFactory.java:86)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1547)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1485)  	... 13 more  Caused by: java.net.ConnectException: Connection refused: localhost/127.0.0.1:6379    sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)    sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)    org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150)    org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)    org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)    org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)    org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680)  {code}    I think it would be helpful to provide users with some helpful advice e.g.:    Redis does not seem to be running at 'localhost/127.0.0.1:6379'. Did you start or install Redis? Please see for further help http://foo/bar";0
XD-1486;eliminate package tangle see:  https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717;0
XD-1487;Test scripts on windows that use XD_MODULE_CONFIG_LOCATION/NAME;0
XD-149;Create asciidoc toolchain script to create a 'toc2' style html output Publishing an html version of the guide that uses the 'toc2' style format table of contents on the left.    Looks like a 'stylesheet factory' http://asciidoctor.org/docs/produce-custom-themes-using-asciidoctor-stylesheet-factory/  needs to be installed.    From the theme showcase http://themes.asciidoctor.org/preview/ the 'golo' theme has a toc2 style.    In the root of the git repo for the wiki is a build.gradle file that uses the asciidoctor gradle plugin but it doesn't support using a single file with import as input. (See See https://github.com/asciidoctor/asciidoctor-gradle-plugin/issues/15 )    The mvn plugin does support this so maybe using mvn is an option or just a bash script.;0
XD-1491;Allow users to set attribute values on a container Allow users to configure arbitrary key value pairs for a container instance that may be referenced in deployment descriptors to target specific container instances.;0
XD-1492;Support groups container attribute A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as xd.container.groups=<comma delimited string> or an environment variable or --groups command line argument.;0
XD-1493;"xd-shell tab completion missing for http post/get xd-shell tab completion missing for 'http post' and 'http get' cli commands.  Typing ""xd:>http post"" <tab> <tab> gives no suggestions event though --file or --data are required.";0
XD-1495;xd:>runtime modules gives error from CLI xd:>runtime modules  Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/TickTock.sink.log-1/metadata    This is on OSX running in distributed mode with --transport rabbit --hadoopDistro hadoop22 redis 2.8.8 rabbit 3.2.3 hadoop 2.2.0 and zookeeper 3.4.5.;0
XD-1499;change xd-config.yml and xd-modules-config.yml to servers.yml and modules.yml;0
XD-150;Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.;0
XD-1508;All jobs end up on the same container node The jobs aren't spread evenly across available container nodes as they are created/deployed. I had 3 nodes but only one has the job modules.    [zk: localhost:2181(CONNECTED) 56] ls /xd/deployments/modules/621230e0-a089-4fbe-afc8-611ae527fcbc  [myjob9.job.jdbchdfs-0 myjob5.job.jdbchdfs-0 myjob8.job.jdbchdfs-0 myjob4.job.jdbchdfs-0 myjob6.job.jdbchdfs-0 myjob7.job.jdbchdfs-0]  [zk: localhost:2181(CONNECTED) 57] ls /xd/deployments/modules/6969579c-0cf4-4cc1-8e21-e01d73a70965  []  [zk: localhost:2181(CONNECTED) 58] ls /xd/deployments/modules/d0667cd1-a57a-4279-b7fb-dd63e4dd40d4  [];0
XD-151;Add Redis binaries for Windows Presently Spring XD does not ship Windows binaries for Redis. However Microsoft is actively working [1] on supporting Redis on Windows. You can download Windows Redis binaries from:    https://github.com/MSOpenTech/redis/tree/2.6/bin/release     [1] http://blogs.msdn.com/b/interoperability/archive/2013/04/22/redis-on-windows-stable-and-reliable.aspx;0
XD-1511;Create documentation for ZK runtime;0
XD-1512;Create documentation for how to extend the XD containers https://jira.spring.io/browse/XD-1343 and related issues.;0
XD-1514;Create documentation for the deployment manifest;0
XD-1515;Allow the value of xd.module.number to be used as property placeholder value This will allow us to use multiple instances of  hdfs/file sinks and not have any filename/path collisions.;0
XD-1516;"Deploy ""orphaned"" jobs to new containers When a container joins the cluster the leader admin will assign modules to it that are unassigned. It needs to also check for job modules and deploy them if required.";0
XD-152;Create rich gauge module Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.;0
XD-1521;Create a dedicated plugin for ${xd.stream.name} and similar The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin etc  Moreover there is no strong String constant to reference it    Create a plugin dedicated to those matters (namely making bits of DeploymentMetadata available to the module environment);0
XD-1522;parser should only allow one label instance per module;0
XD-1523;"stream list should show ""undeployed"" rather than blank if a stream is not deployed";0
XD-1526;"Exception when accessing CDH4 namenode Get exception when accessing cdh4 from shell -    java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.    com.google.protobuf.GeneratedMessage.getUnknownFields    most likely due to protobuf-java-2.5.0.jar being on the main classpath now      Full stack trace:  {code}  trisberg@carbon:~/Test$ ./spring-xd-1.0.0.BUILD-SNAPSHOT/shell/bin/xd-shell --hadoopDistro cdh4  16:55:22680  WARN main conf.Configuration:824 - fs.default.name is deprecated. Instead use fs.defaultFS   _____                           __   _______  /  ___|          (-)             \ \ / /  _  \  \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |   `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |  /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /  \____/| .__/|_|  |_|_| |_|\__ | \/   \/___/        | |                  __/ |        |_|                 |___/  eXtreme Data  1.0.0.BUILD-SNAPSHOT | Admin Server Target: http://localhost:9393  Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".  xd:>hadoop config fs --namenode hdfs://cdh4:8020  xd:>hadoop fs ls /  Hadoop configuration changed re-initializing shell...  16:55:28853  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable  -ls: Fatal internal error  java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.    com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:30108)    com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49)    org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.constructRpcRequest(ProtobufRpcEngine.java:149)    org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:193)    com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164)    org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83)    com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:629)    org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1545)    org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:819)    org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1646)    org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1592)    org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1567)    org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:271)    org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)    org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)    org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)    org.apache.hadoop.fs.shell.Command.run(Command.java:154)    org.apache.hadoop.fs.FsShell.run(FsShell.java:254)    org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)    org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)    org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:196)    org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)    org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)    org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)    org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:530)    org.springframework.shell.core.JLineShell.run(JLineShell.java:178)    java.lang.Thread.run(Thread.java:744)  {code}";0
XD-1529;Correct hadoop classpath versions for the distros When using hdp13 the XdConfigLoggingInitializer throws this info:  12:02:06064  INFO main util.XdConfigLoggingInitializer:77 - Hadoop Distro: hdp13 12:02:06068  WARN main util.XdConfigLoggingInitializer:84 - Hadoop version detected from classpath: 1.2.0 but you provided '--hadoopDistro hdp13'. Did you mean '--hadoopDistro hdp20'? 12:02:06069  WARN main util.XdConfigLoggingInitializer:84 - Hadoop version detected from classpath: 1.2.0 but you provided '--hadoopDistro hdp13'. Did you mean '--hadoopDistro hadoop12'?  Since hdp13 uses hadoop 1.2.0 we need to fix that in the versions map ContainerOptions.getHadoopDistroVersions();0
XD-1530;Error when removing HDFS files in shell I get this:    {code}  xd:>hadoop fs rm /xd/test/time-3.log  Error: run HDFS shell failed. Message is: org.apache.hadoop.fs.FileStatus.isDirectory()Z  {code}    so far I have seen this with --hadoopDistro hdp13 and hadoop12    same command works fine using shell from M5 release;0
XD-1531;Rename xd-config.yml to servers.yml and add modules/modules.yml to spring-xd-yarn Make changes to XD on YARN config that correspond to XD-1499 changes;0
XD-1532;Clean up MBean registration for failed module deployments When a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a JMX exception:  {noformat} java.lang.RuntimeException: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output   org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:447)   org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:346)   org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:92)   org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:655)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   java.util.concurrent.FutureTask.run(FutureTask.java:266)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   java.util.concurrent.FutureTask.run(FutureTask.java:266)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output   org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)   org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)   org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)   org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)   org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112)   org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:485)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)   org.springframework.boot.SpringApplication.run(SpringApplication.java:311)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:240)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:184)   org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:174)   org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:164)   org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:227)   org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:429) 	... 18 more Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output   org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)   org.springframework.integration.monitor.IntegrationMBeanExporter.registerChannels(IntegrationMBeanExporter.java:837)   org.springframework.integration.monitor.IntegrationMBeanExporter.doStart(IntegrationMBeanExporter.java:459)   org.springframework.integration.monitor.IntegrationMBeanExporter.start(IntegrationMBeanExporter.java:410)   org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173) 	... 33 more Caused by: javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output   com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)   com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)   com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)   com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)   com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)   com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)   org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)   org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)   org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:606) 	... 37 more {noformat};0
XD-1533;Admin needs to clean up failed deployment attempts If a container fails to deploy a module the admin needs to clean up the {{/xd/deployments/modules/CONTAINER-ID/module}} path so that another attempt can be made to deploy that module to that container.;0
XD-1536;Add ability to inject delimiter on pre-packaged jobs that deal with files.;0
XD-1538;Update docs and samples now that deploy is false on job/stream creation;0
XD-1540;stack trace on xd-admin restart when redploying streams (the trace below occurs in the admin console but the Admin continues to handle subsequent deployment requests fine it seems)    To reproduce:    * start xd-admin and xd-container (just 1 of each)  * deploy 'time | log'  * kill both xd-admin and xd-container  * start xd-container by itself  * wait 10 seconds or so then start xd-admin    result:  {code}  21:35:01575 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 -  org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/f89e5fdc-7dc1-49fb-93cc-d536ab853f12/s.source.time-0    org.apache.zookeeper.KeeperException.create(KeeperException.java:119)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)    org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)    org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)    org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)    org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)    org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:411)    org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:319)    org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:255)    org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:272)    org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:152)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  {code};0
XD-1541;Batch Basic Fails to launch job when rabbit is data transport Deployed the batch basic as instructions prescribe.  Tests work for both singlenode and redis as a data transport.  However while the job does deploy using rabbit  it does not launch.;0
XD-1542;HdfsTextFileWriter incompatible with MaprFS Use of FsShell in AbstractHdfsWriter.initializeCounterIfNecessary() causes MaprFS to throw an unimplemented operation exception.  Replacing the FsShell code with FileSystem.listStatus allows it to be used with MaprFs.;0
XD-1545;Support deploying to multiple containers in EC2 acceptance tests need the ability to support the --group option.;0
XD-1549;"Proactively handle failed deployments When a deployment fails on a container due to a misconfiguration the container does not notify the admin. Instead the admin waits for the container to write out an ephemeral node to the definition path {{/xd/streams}} or {{/xd/jobs}} to indicate a successful deployment and if the path isn't written in 10 seconds the deployment is considered failed.    This ""timeout"" should be considered a heuristic failure meaning that the container was not able to write out a response of success or failure. If the deployment fails the container needs to indicate this by writing a node to ZK.";0
XD-1550;Fix 'cannot find MessageBuilderFactory' warning 5:27:47887 WARN DeploymentsPathChildrenCache-0 org.springframework.integration.context.IntegrationContextUtils:195 - No 'beanFactory' supplied cannot find MessageBuilderFactory using default.  a lot of those;0
XD-1551;Fix Startup Messages Started container : AdminServerApplication Documentation: https://github.com/SpringSource/spring-xd/wiki;0
XD-1552;Remove --transport option except for single node Since transport is now shared by Admin and Container a command line arg is not appropriate since it allows the user to set them to different values which would break XD. The recommend way to configure transport is in servers.yml.  The command line arg is still valid for single node;0
XD-1553;syslog source is not capturing log info. Keep in mind.  This could be pbkac on my part.  Please review and see if you can get it to work.;0
XD-1555;"transform processor with script option is broken Creating the following stream throws exception:    stream create s1 --definition ""http | transform --script=transform.groovy | log""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:      valid: the 'script' and 'expression' options are mutually exclusive    The ExpressionOrScriptMixin's assertions to check if script and expression options are mutually exclusive `always` fails.";0
XD-1556;Batch hashtag count throws exception when launched 1) Update Instructions to mention --hadoopDistro for both singlenode and shell.  Else demo will not work.  2) Pom needs to be updated to use 1.2.1 at the least.  3) I can see where hdfs is writing the results  4) throws NPE   Stacktrace is attached.;0
XD-156;Create config support for Redis We would like to have Redis driven from a config property file under XD_HOME.;0
XD-1561;"When using transform --script=foo.groovy shell displays error When trying to create the stream for the gemfire example: stream create hashtags --definition ""tap:stream:tweets  > transform --script=tweetSummary.groovy | gemfire-server --keyExpression=payload['id']"" --deploy  The shell displays:  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:     valid: the 'script' and 'expression' options are mutually exclusive  I get the following error";0
XD-1565;"Document append support else filepollhdfs writes empty file to hdfs When testing in both singlenode and cluster (redis) XD throws exception (stacktrace attached).  The file is created on hdfs but it is empty.    [Steps to recreate Using Hadoop12]  1) job create myjob --definition ""filepollhdfs --names=forenamesurnameaddress"" --deploy   2) stream create csvStream --definition ""file --ref=true --dir=/tmp/dug --pattern=*.csv > queue:job:myjob"" --deploy  3) use excel to create a 3 column spreadsheet and save as csv.   4) Copy csv to /tmp/dug directory";0
XD-1566;"Document append configuration else jdbchdfs writes empty file to hdfs Similar to XD-1565  so I'd link these 2 together.    [Steps to reproduce on Hadoop12]  1) Created Table People with columns forenamesurname and address (use the result from filejdbc)  2) job create myjob --definition ""jdbchdfs --sql='select col1col2col3 from some_table'""  3)job launch myjob  4) myjob is created on hdfs but with zero bytes  5) throws an exception stack trace attached.";0
XD-1568;Update documentation related to transport and controlTransport e.g. Need to update this section (maybe others):  https://github.com/spring-projects/spring-xd/wiki/Running-Distributed-Mode    Remove all mentions of Control Bus and replace any mentions of the --transport cmd line arg with the xd.transport property in yml.;0
XD-1569;Rename reactor-tcp module to reactor-ip since it also supports udp the --transport option allows 'udp' as well as 'tcp/;0
XD-1571;JLine 1 is brought up (and shows in IDE) through ZK/curator We don't want jline1 anymore.  This shows in IDE only (either run shell integration tests or run the shell as Gunnar mentioned);0
XD-1572;"Unable to delete composed module After creating a composed module I am unable to delete it.  [Steps to reproduce] xd:>module compose doo --definition ""filter --expression=payload.contains('doo') | file"" Successfully created module 'doo' with type sink xd:>module  module compose    module delete     module display    module info       module list        xd:>module delete --name doo --type sink java.lang.StringIndexOutOfBoundsException: Failed to convert 'doo' to type QualifiedModuleName for option 'name' String index out of range: -1 xd:>";0
XD-1574;JDBC Acceptance tests must jdbc props vs. configProps setting. In this case we will use environment variables to set the JDBC sink settings.  Thus we will just remove code.;0
XD-1575;Add UDP support to reactor-syslog source module Currently the reactor-syslog source module only supports TCP.    Once we add UDP support we can probably remove the existing syslog-tcp and syslog-udp modules.;0
XD-1576;Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove/update any documentation references to these files;0
XD-158;Expose shutdown operation over http This will allow for a simple way to shutdown the server via an HTTP call.  Support for security is a separate story. The end goal is to have some shell scripts distributed that can issue HTTP requests to shutdown the xd-admin and xd-container servers.    The newest version of Jolokia has the ability to boostrap itself inside an application context vs. requiring a java agent.  I suspect using the application context approach will provide us with more flexibility (e.g. property replacement etc) but not sure.;0
XD-1580;Undeploy modules when container disconnected from ZK Consider a module running in a container when it is disconnected from ZK:    {noformat}  12:30:13021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:13  12:30:14025  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:14  12:30:15029  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:15  12:30:16031  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:16  12:30:32590  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:32  12:37:42985  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:42  12:37:43398  INFO main-SendThread(fe80:0:0:0:0:0:0:1%1:2181) zookeeper.ClientCnxn:1096 - Client session timed out have not heard from server in 430809ms for sessionid 0x145662be03e0002 closing socket connection and attempting reconnect  12:37:43985  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:975 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)  12:37:43986  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:852 - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181 initiating session  12:37:43988  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:43  12:37:43989  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:1094 - Unable to reconnect to ZooKeeper service session 0x145662be03e0002 has expired closing socket connection  {noformat}    Currently the module for the disconnected container continues to execute:    {noformat}  12:37:45994  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:45  12:37:46997  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:46  12:37:48000  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:47  12:37:48094 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exception  org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /xd    org.apache.zookeeper.KeeperException.create(KeeperException.java:127)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)    org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)    org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)    org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)    org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)    org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:609)    org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)    org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)    org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)  12:37:48097  INFO main-EventThread state.ConnectionStateManager:194 - State change: SUSPENDED  12:37:48097  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:262 - >>> Curator disconnected event: SUSPENDED  12:37:48097  WARN ConnectionStateManager-0 server.ContainerRegistrar:325 - >>> disconnected container: 88ba115b-6190-497a-a67c-df1e295bf158  12:37:49001  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:49  12:37:50004  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:50  12:37:51008  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:51  12:37:52012  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:52  12:37:53016  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:53  12:37:54021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:54  12:37:55023  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:55  ...  {noformat}    This container should not continue executing the module because the leader admin will likely select another container to execute this module. If and when this container reconnects to ZK it can be (re)assigned modules for deployment.    This can be done via a simple undeployment or we may even consider closing and reopening the application context.;0
XD-1581;XD config home should use XD_CONFIG_LOCATION if this is set If XD_CONFIG_LOCATION is set then XD runtime's xd.config.home should use that. otherwise they point to two different paths.;0
XD-1582;"Temporary race condition between deployment and ""runtime modules"" command The ""runtime modules"" command can show a failure between the deployment command and the actual deployment on the container node especially if there is a network hop. This clears up once the module is fully deployed.    {code}  xd:>stream create --name trois3 --definition ""time | jdbc"" --deploy   Created and deployed new stream 'trois3'  xd:>runtime modules   Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/bc95653e-9da5-4738-beb2-f215e4003318/trois3.source.time-0/metadata    xd:>runtime modules     Module                Container Id                          Options    --------------------  ------------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    trois3.source.time-0  bc95653e-9da5-4738-beb2-f215e4003318  {format=yyyy-MM-dd HH:mm:ss fixedDelay=1}    wintu.sink.jdbc-1     bc95653e-9da5-4738-beb2-f215e4003318  {tableName=${xd.stream.name} url=jdbc:hsqldb:hsql://carbon:9102/xdjob columns=payload driverClassName=org.hsqldb.jdbc.JDBCDriver initializeDatabase=false initializerScript=init_db.sql username=sa}    trois3.sink.jdbc-1    d0ad8eda-be27-46ac-86be-e43b5d9921af  {tableName=${xd.stream.name} url=jdbc:hsqldb:hsql://carbon:9102/xdjob columns=payload driverClassName=org.hsqldb.jdbc.JDBCDriver initializeDatabase=false initializerScript=init_db.sql username=sa}    wintu.source.time-0   befa5f27-aac3-4d94-9171-77c07036ec75  {format=yyyy-MM-dd HH:mm:ss fixedDelay=1}  {code}";0
XD-1584;"Sample app that can process and analyze network packets Create an example application that demonstrates the processing / analysis from a stream of network packets.  A potential scenario could be the detection of ongoing cyber attacks by scanning for TLS packets that what to abuse a SSL vulnerability aka ""heart bleed"".  A library that could help with this is: http://jnetpcap.com/";0
XD-1586;"Stream should not be in deployed state following module failure. Run singlenode. Ensure twitterstream credentials are not valid. e.g.  no consumerKey property. This is the default state.    >stream create tweets --definition ""twitterstream | log"" --deploy  Created and deployed stream 'tweets'    Meanwhile Singlenode throws an exception the stacktrace below     xd:>stream list    Stream Name  Stream Definition    Status    -----------  -------------------  --------    tweets       twitterstream | log  deployed    {code}  15:54:07298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -  java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}"" nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""    org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)    org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)    org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)    org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}"" nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""  {/code}";0
XD-1587;Provide module configuration templates for twitter sources Provide module templates including required property keys but not values for  $XD_MODULE_CONFIG/source/twitter*/twitter*.properties. Also look for any other packaged modules that have required properties that should be statically configured and we cannot provide defaults.  The Source modules document should be more clear regarding the configuration of these properties.;0
XD-1588;PropertySource leakage between runtime and modules in EnvironmentAwareModuleOptionsMetadataResolver::loadPropertySources the call to merge(parentEnv) was added to inherit the active profiles of the runtime.    Sadly it added the parentEnv property sources by side effect.    Note that the jdbc module defaults rely on this bug;0
XD-1589;Support Groovy bean definitions as XD extensions Modify the PluginContextExtensionsInitializer to consume .groovy bean definitions as well as XML.;0
XD-159;Parameter parsing does not work if an argument contains '--'. Parameter parsing does not work if an argument contains '--'.    For example:    {code}  ... | transform --expression=42 | transform --expression=--payload |...  {code}    Also I was surprised that this worked..    {code}  | transform --expression=new StringBuilder(payload).reverse() |  {code}    ... but this didn't...    {code}  | transform --expression='new StringBuilder(payload).reverse()' |  {code}    I think we need to tokenize the argument (with ' if contains spaces) and remove any surrounding '...' from the result. This means if someone wants a SpEL literal they would have to use something like     {code}--expression=''Hello world!''{code}    resulting in a SpEL literal 'Hello world!';0
XD-1590;Move ephemeral nodes from /xd/streams to /xd/deployments/streams To have a clear separation of definition vs runtime information move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. Same for jobs.;0
XD-1592;"Make transport configuration extensible. Change message-bus.xml to read     <import resource=""classpath*:/META-INF/spring-xd/transports/${XD_TRANSPORT}-bus.xml""/>    So new transports may be configured in external jars";0
XD-1594;"Move resusable analytics repository classes to a new project. The analytics project has been used as a host for common repository classes because it was easily visible by both -dirt and other stuff (can't remember which)  This should be cleaned and a dedicated project for ""core"" ""utility"" ""re-usable"" ""whatever"" classes should be created";0
XD-1596;Rabbit Source Should Expose More Container Options acknowlege-more tx-size prefetch-count concurrency etc.;0
XD-1597;Update to Spring AMQP 1.3.2 If the rabbit source receives a message it can't convert a {{MessageConversionException}} is thrown and the message is rejected (and requeued) causing an endless loop.    Add an {{ErrorHandler}} to the inbound adapter to detect and convert {{MCE}} to {{AmqpRejectAndDontRequeueException}}.    Also consider adding a retry interceptor to do the same for exceptions in modules (when using local transport).;0
XD-1599;Change SpringSource references in pom.xml to Spring/spring.io This is currently in the M6 pom:      <organization>      <name>SpringSource</name>      <url>http://springsource.org</url>    </organization>;0
XD-1602;JMS Source on EC2 only uses localhost for activemq broker [Problem]  On a EC2 container jms-activemq.properties was configured to use a activemq broker on a different host it still referred to localhost.    On my local mac I was able to updated the jms-activemq.properties with an activemq on a different host and it worked.    [work-around]  While not recommended you can set the amq.url in the jms-activemq-infrastructure-context.xml.    [Steps to reproduce]  1) Deploy a single admin/container using xd-ec2.    2) create a jms-activemq.properties file in the spring-xd-1.0.0.BUILD-SNAPSHOT/xd/ where it refers to a broker on another machine (ec2-54-221-32-82.compute-1.amazonaws.com).    3) Create a stream with JMS as its source.;0
XD-1611;XD-EC2 will have to support the --hadoopDistro command line for xd-container;0
XD-1613;"Parser fails on + after literal within an expression This fails:  {code}  xd:>stream create s --definition ""http | transform --expression='hi'+payload | log""    Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 34): unexpected data in stream definition '+'  http | transform --expression='hi'+payload | log  {code}    But this works:  {code}  xd:>stream create s --definition ""http | transform --expression=payload+'hi' | log""    Created new stream 's'  {code}";0
XD-1614;Job display command handling null date value for execution endtime If the job display command is executed for JobExecution and StepExecution list it may be possible that the Job/Step execution's endTime still null (because the status is still unknown and not completed). In this case the display command throws assertion failure here:    Caused by: java.lang.IllegalArgumentException: The provided date must not be null.    org.springframework.util.Assert.notNull(Assert.java:112)    org.springframework.xd.shell.util.CommonUtils.getUtcTime(CommonUtils.java:144)    org.springframework.xd.shell.command.JobCommands.display(JobCommands.java:249);0
XD-1615;UI: The user can create a new job definition by selecting a job template and providing additional configuration properties;0
XD-1616;UI: The user should provide username/password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.;0
XD-162;Create design document for implementation strategy to support message conversion in ChannelRegistry The conversion should be based on content-type headers similar to the way Spring's HttpMessageConverters work (with mime types).    Also the map of available converters should be extensible while including the most common defaults (for JSON XML etc). We most likely want to add a few of our own content types also (e.g. for Tuples).    Most likely this logic and the configuration methods for extending the converter map belong in AbstractChannelRegistry since it should be common across all implementations (i.e. the logic should be the same regardless of the transport used after-serialization/before-deserialization).;0
XD-1620;Fix JobCommandTests' verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this:    String id = jobExecutions.getRows().get(0).getValue(1)  		displayJobExecution(id)    It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures.;0
XD-1621;UI: The user should be able to view the log file for a specific job execution Will require additional server-side Jiras;0
XD-1622;Add support for typed Batch Steps This may require additional support (Jiras) for Spring Batch;0
XD-1624;UI: The user should be able to view a graphical representation of the job This may be broken up into multiple Jira issues. Provide a generic approach to render Batch jobs graphically.   Second especially for Hadoop components - Provide step-type-dependent renderings of Batch components - see: XD-1622;0
XD-1626;UI: Improve the filtering capabilities of jobs that are executing/have executed * Show only the jobs that you have created vs. those of others. (Requires Security - e.g. XD-1616) - Probably a separate issue    * Show only jobs that are in a specific status/state  running vs. other states.  * Show only jobs for the past x number of days.  * Show only jobs whose name matches a simple string e.g. ‘userAnalysis’;0
XD-1628;UI: The user can view the job properties that were specified when the job definition was created as well as job parameters when it was launched/executed;0
XD-163;Enable grouping of modules for co-located deployment example:    {code}  a | (b | c) | d  {code}    ...where b and c modules are deployed together as a composite module.    There are 2 options (maybe more) for how we could handle that. One would be defining a CompositeModule type that simply bridges the channels (b's output to c's input in this example). The second option would be to deploy those together on the same node as modules but using the LocalChannelRegistry between them.;0
XD-1631;Update hdfs sink docs Options that are not covered:  --codec  --idleTimeout  --inUsePrefix  --inUseSuffix  --inputType  --overwrite    Options Renamed:  --filename is now --fileName;0
XD-1632;Use unique queue names in shell tests There seems to be some cross talk among the shell integration tests.   It looks like the same singlenode application might get shared among the test classes when they run in parallel.    Using unique queue names across the tests seem to fix the issue for now.;0
XD-1633;Fix cross-talk among the shell integration tests It looks like the singlenode application used by each of the shell integration test class is shared by other test classes as well. This causes some issues that are common to these tests. We need to avoid such scenarios.;0
XD-1634;Update Spring Integration Version to 4.0.0.RELEASE;0
XD-1636;servers.yaml's 'xd: -> transport: rabbit' overrides xd-singlenode's default of local transport When working w/ SXD xd-singlenode out of the box it defaults to using all embedded components (transport analytics hsqldb & zookeeper) which is easy and a great way to get going.  This is also great for development.    When I then started trying out the M6 distributed mode I set my transport to rabbit in servers.yaml (now that the --transport option is gone).  Rabbit is my preferred transport here.    I then went back to running the singlenode for simplicity and then got an exception saying that the singlenode couldn't contact RabbitMQ/AMQP (I was no longer running rabbit).  I then had to add the '--transport local' flag back to xd-singlenode.      Having the --transport option on xd-singlenode but not on xd-container is confusing.  Also I would expect xd-singlenode to default to local transport unless I specify another option in --transport.    -Derek;0
XD-1637;Re-enable JSHint during grunt build JSHint should be enabled in grunt build. There are few minor issues and needs to be fixed.;0
XD-1638;Add a 'rank' expression to be used by the container matcher following the HTCondor model for resource assignment the use of a 'rank' expression that evaluates to an integer is used to order the containers that match the current 'criteria' expression.  This allows you to setup ranks such as 'prefer the machine with the most free memory' or 'prefer a machine from groupa'  (higher rank values match first).  From HTCondor Presentation Rank * The rank expression is evaluated into a number for every potential matching machine. * A machine with a higher number will be preferred over a machine with a lower number.  Rank Examples  * Prefer machines with more Mips: ** Rank = Mips  * Prefer more memory but add 100 to the rank if the machine is Solaris 2.7: ** Rank = Memory + 100*(OpSys==“SOLARIS27)”  * Prefer machines with a high ratio of memory to cpu performance: ** Rank = Memory/Mips  * Prefer machines that will checkpoint in Bologna: ** Rank = (CkptServer==“ckpt.bo.infn.it”);0
XD-1643;"Use new Table classes provided by Spring Shell The classes:  * org.springframework.xd.shell.util.Table * org.springframework.xd.shell.util.TableHeader * org.springframework.xd.shell.util.TableRow  are now provided by *org.springframework.shell.support.table*.  Objectives:  * We should use those. (But wait for SHL-142 to be complete) * Improve all tests that use the table classes - Avoid accessing table data using numeric keys (row/column numbers) - Instead use ""business"" keys such as table header names etc.";0
XD-1645;Refactor Exception Handling and update JavaDocs for acceptance test [Add JavaDocs to]  * StreamUtils  * HttpTest  * MqttTest  * JmsSource    [Exception Handling]  StreamUtils stream method should throw  IllegalStateException instead of a checked exception.  XDEc2Validation assertReceived assertValid should throw IllegalStateException instead of a checked exception;0
XD-1646;CLI needs to be setup to use the updated acceptance test structure This change has to be facilitated because of the XD-1456 and XD-1455 stories.;0
XD-1649;Spring XD using Redis as data transport is failing to start in CI Acceptance Test.;0
XD-165;xd-container and xd-admin should log to a file out of the box We should have an externally editable log4j config file in a conf dir and the default should log to a file (presumably in a logs dir);0
XD-1651;Update HDFS sink to use unique id (GUID) as part of file name HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id (GUID) - like base-path/logfile-GUID-1.txt;0
XD-1656;The type StubDatasetOperations must implement the inherited abstract method DatasetOperations.getDatasetDescriptor(Class<T>) StubDatasetOperations class needs to be either declared asbtract or implemente inherited methods from DatasetOperations;0
XD-1659;Add HDFS (apache Hadoop 2.2 distro) acceptance tests;0
XD-166;"Create config support based on channel registry type We need to have the XD container & admin reading the registry specific property based on the registry type selected.   From Mark F on one of the code review comments:  Maybe rather than having redis rabbit etc. properties all within a container.properties we should rely upon naming conventions instead. Specifically we could have a single configurable property for the type of channel registry (""redis"" ""rabbit"" or ""local"" being possible values) and then we could use something like:  <import resource=""config/${registry.type}.xml""/>  <context:property-placeholder location=""config/${registry.type}.properties""/>";0
XD-1661;Fix package tangles Sonar build is currently failing.;0
XD-1666;Upgrade to Spring Shell 1.1 RC3;0
XD-1667;Add Steams page to show job triggers The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.;0
XD-1668;Modularize angular app modules based on the functionality When adding streams page to the UI (from XD-1667) it is necessary to modularize the angular app modules based on the functionality/components (job stream auth etc.).     As we expand into more components and use cases in the UI this definitely makes it easier to concentrate on specific modules based on the functionality.;0
XD-167;Script to generate reference documentation from wiki and include in .zip distribution;0
XD-1670;NPE when a container departs When a container departs the cluster the admin will try to redeploy any modules that container was running. If the stream was *destroyed* and the container exited before it had the chance to clean up its deployments under {{/xd/deployments/modules}} (for example with {{kill -9}}) the following NPE occurs:    {noformat}  java.lang.NullPointerException    org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:347)    org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)    org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:158)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:724)  {noformat}    If the stream was *undeployed* the following stack appears:  {noformat}  15:13:06002 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 -   java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0    org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:468)    org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)    java.util.concurrent.FutureTask.run(FutureTask.java:266)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)    java.util.concurrent.FutureTask.run(FutureTask.java:266)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:744)  Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0    org.apache.zookeeper.KeeperException.create(KeeperException.java:111)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)    org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)    org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)    org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)    org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)    org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:358)    org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:417)  	... 16 more  {noformat}    In short this logic makes the assumption that the stream is still present and deployed. It needs to take into account the fact that neither assumption can be made.;0
XD-1671;Set fetch size when reading from database in pre-packaged jobs When running a query against a large dataset JDBC will attempt to load the entire result set into memory by default.  If this isn't desired (which would be the case in the prepackaged jobs) you can set the fetchSize on the JdbcCursorItemReader to set the number of rows to return with each fetch.  It is good practice to make this match the commit interval.      If the fetch size is not set with large datasets the stack blows with an OutOfMemoryException.;0
XD-1672;Add filepollhdfs Acceptance Tests;0
XD-1673;filepollhdfs documentation needs to be updated with all of the options available. currently the documentation only shows the --name as an option.  Review the FilePollHdfsJobOptionsMetadata to find all the available options.;0
XD-1674;"Accessing non-existing module causes NullPointerException This source exists:  {code}  http://localhost:9393/modules/source/time  {code}  But trying to access a non-existing source such as:  {code}  http://localhost:9393/modules/source/time2  {code}  Triggers in the UI:   {code}  [{""links"":[]""logref"":""NullPointerException""""message"":""NullPointerException""}]  {code}  On the server-side:  {code}  6:03:45387 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:199 - Caught exception while handling a request  java.lang.NullPointerException    org.springframework.xd.dirt.rest.DetailedModuleDefinitionResourceAssembler.toResource(DetailedModuleDefinitionResourceAssembler.java:49)    org.springframework.xd.dirt.rest.ModulesController.info(ModulesController.java:104)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)    org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)    javax.servlet.http.HttpServlet.service(HttpServlet.java:621)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)    javax.servlet.http.HttpServlet.service(HttpServlet.java:728)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)    org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:744)  {code}    Accessing a non existing resource should probably result in a 404 status code.";0
XD-1675;"FilePollHdfs is not writing results to hdfs XD Deployment   Description:		XD Cluster (1 Container)  Environment:		EC2  Type Of Test:		Manual Test  Test Failed On		filepollhdfs (only test that was run)  Build Used		Built May 7 10:29 UTC    From the shell attempted to create filepollhdfs however no results were written to hdfs (hadoop22).      The commands executed were the following:  job create myjob --definition ""filepollhdfs  --names=forenamesurnameaddress"" --deploy  stream create mystream --definition ""file --dir=67fc27a6-224d-4c67-a02a-40730bcf8906 --pattern='*.out' > queue:job:myjob"" --deploy    No warnings nor exceptions were displayed till I changed the log4j.logger.org.springframework to INFO and restarted the container.   Then when I copied the sample file to the monitored directory the log reported:  21:30:07605  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer:118 - deployed SimpleModule [name=file type=source group=mystream index=0 @61612c7c]  Exception in thread ""inbound.job:myjob-redis:queue-inbound-channel-adapter1"" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)    org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)    org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)    java.lang.Thread.run(Thread.java:724)  Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined    org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)    org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)    When using the attached sample file you need to rename the file to try2.out.";0
XD-1677;"Add ""log-full-message"" Property to the Log Sink Allows looking at message headers without turning on debugging.";0
XD-1678;"XD does not reconnect to jobstore if connection is  lost leaving Jobs in inconsistent state. XD Deployment Description	XD Cluster (1 Container)  Environment	EC2  Type Of Test	Shell Command Line  Test Failed On	hdfs (only test that was run)  Build Used	Built May 7 10:29 PST    [Overall issue]  XD Admin and container lost connectivity to the the jobstore (MySql on RDS) and did not reconnect.    Exception Displayed in log.  Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was 54321927 milliseconds ago.  The last packet sent successfully to the server was 54321928 milliseconds ago. is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application increasing the server configured values for client timeouts or using the Connector/J connection property 'autoReconnect=true' to avoid this problem.    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)    java.lang.reflect.Constructor.newInstance(Constructor.java:526)    com.mysql.jdbc.Util.handleNewInstance(Util.java:411)    com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1117)    com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3871)    com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2484)    com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2664)    com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2788)    com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2738)    com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1617)    org.springframework.jdbc.core.JdbcTemplate$1QueryStatementCallback.doInStatement(JdbcTemplate.java:452)    org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:402)  	... 57 more    [Side Effects]  [Unable to create new Job with same name]  User executed a job list and then removed the jobs in the list.  When the user tried to create new jobs using the same names the application reported:  ""Command failed org.springframework.xd.rest.client.impl.SpringXDException: StatementCallback SQL [SELECT JOB_NAME FROM JOB_REGISTRY_NAMES] No operations allowed after connection closed. nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.""  The only way to resolve it completely was to:   1) shutdown the admin and the containers.    2) Clear the jobs from the Batch job tables by hand  3) restart XD admin and containers.";0
XD-1679;Remove %L from Log4j PatternLayout The xd-dirt log4j.properties includes the calling line number {{%L}} which is not recommended for production.    https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PatternLayout.html    {{WARNING Generating caller location information is extremely slow and should be avoided unless execution speed is not an issue.}};0
XD-1680;jdbchdfs Acceptance Test;0
XD-1681;Need to support XD_admin_host and xd_containers in test properties If a user wishes to run the acceptance tests from their local machine against an XD instance on EC2  the only way to establish container and admin server is via the artifact ec2servers.csv. And this has to be copied to the spring-xd-integration-test subdirectory.   The user should be able to set the xd_admin_host and xd_containers in the application-<profile>.properties file.;0
XD-1682;Syslog Acceptance Tests;0
XD-1683;"syslog-tcp throws exception when receiving syslog data XD Deployment   Description	XD Cluster (1 Container)  Environment	EC2  Type Of Test	Manual test via shell  Test Failed On	syslog-tcp (only test that was run)  Build Used	Built May 7 10:29 UTC    [Setting up the Environment]  * Used the wiki instructions to setup the syslog on the ec2 instance.   * Deploy the stream below:  stream create mystream --definition ""syslog-tcp | file --binary=true --mode=REPLACE"" --deploy   * On the EC2 Instance execute the line below:  logger -p local3.info -t TESTING ""Test Syslog Message""    [What occurred]  Stream fails to process inbound syslog information and throws the exception below:     Exception in thread ""inbound.mystream.0-redis:queue-inbound-channel-adapter17"" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)    org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)    org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)    java.lang.Thread.run(Thread.java:724)  Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined    org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)    org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)  	... 5 more";0
XD-1684;"Test integration with jboss queue message I am new to Spring XD I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e ""stream create --name TEST-LOG  --definition ""jms | file"" --deploy"". I am trying to configure the ""spring-xd-1.0.0.M6\xd\modules\common\jms-jbossmq-infrastructure-context.xml"" to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?";0
XD-1688;New libraries to experiment We would like to experiment with open source libraries to further enrich Spring XD’s service offerings and feature-set.  This epic remains the anchor point for following categories and the respective experimentation outcomes will be documented in the associated stories.  * Measure based alerts * Log analysis * Machine learning and graph computation;0
XD-169;XD should run offline Trying to run XD offline results in an error in redis.xml because the cloudfoundry schema file is missing.  We need to add the cf-runtime jar to the classpath to resolve this.;0
XD-1691;ELK - log analysis We would like to experiment with “ELK” stack. It’s the combination of Elasticsearch Logstash and Kibana to extract end-to-end real-time insights from structured and unstructured data source. Possibly provide integration endpoints to some of the components.  Features: * Search and analyze in real-time * Scrub parse and enrich data * Visualization  Website -> http://www.elasticsearch.org/overview/ GitHub -> http://www.elasticsearch.org/overview/elkdownloads/;0
XD-1697;hdfsjdbc Acceptance Test;0
XD-170;Home wiki page improvements Add more structure more easily find the reference guide.  The style that is here  https://github.com/snowplow/snowplow/wiki is nice.;0
XD-1706;"Add tab completion for named channels (i.e. queue:xyz >) Tab completion doesn't currently list/support ""queue"" as a source.  For example if typing the following stream: stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log"" --deploy  Tab completion doesn't recognize or suggest ""queue"" or anything after it until after the first bar ""|"".    The same applies to named channels ""queue"" as a sink.";0
XD-1707;"The Dynamic Router example in the docs throws an exception with Rabbit Transport The example in the M6 documentation for the Dynamic Router (here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#dynamic-router) for the SpEL-Based Routing throws an exception when processing the message (from the HTTP post) saying ""No bean named 'queue:foo' is defined"" when using RabbitMQ as the transport.  I do not know a workaround.    Steps to reproduce:  1) Run RabbitMQ locally  2) Run xd-singlenode --transport rabbit  3) xd:>stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log"" --deploy    xd:>stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log"" --deploy    xd:>stream create r --definition ""http | router --expression=payload.contains('a')?'queue:foo':'queue:bar'"" --deploy    4) xd:>http post --data ""a""    5) This should give a stacktrace:  Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'queue:foo' is defined    org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)    org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)    org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)  	... 83 more";0
XD-1708;Re-deployment of stream/job modules upon container departure doesn't choose appropriate container candidates Upon container departure the ContainerListener's onChildLeft() event triggers redeployment of stream/job modules that were deployed into the leaving container. During the redeployment it happens that the container candidates from the DefaultContainerMatcher *sometimes* (based on the subset from distributeForRequestedCount(List<Container> candidates int count))  includes the container which already have the module of the *same* stream/job definition deployed. This causes the re-deployment silently swallowing the NodeExistsException and the module being re-deployed doesn't actually get deployed.;0
XD-1709;"Handling JobExecution stop action if the JobExecution is COMPLETED Currently the flag ""stoppable"" on JobExecutionInfoResource is used to find if the jobExecution can be stopped.  Since this flag is set to true even if the JobExecution status is COMPLETED the jobExecution can still say it can be stopped.";0
XD-1710;ProcessorTest.testfailedSink needs to use http as its test source Also check the JMX output to see that the filter rejected the entry.;0
XD-1715;Create documentation section for the shell Create a new section in the docs regaring shell usage in particular how to represent single and double quotes.    Include some discussion of basic commands to manipulate streams jobs and list modules.  How to pass in a file that can be executed when the shell starts up.    Also point to spring-shell ref docs for extensibility in terms of adding custom commands.;0
XD-1717;Optimize JobService queries and batch domain object usages Based on the discussion from here:  https://github.com/spring-projects/spring-xd/pull/849#issuecomment-43215168  we need a better strategy to handle some of the queries and updates to the batch domain objects.;0
XD-1719;"ZooKeeper Job deployments path state is not updated after successful deployment After successful job deployment the Job deployments path in ZK doesn't get updated with the data {""state"": ""deployed""}    Though this data is not used for deployed instance repository (org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository) to check for the deployment status it may be better to have this state updated like stream deployment path.";0
XD-1723;"'--type=' not supported by module delete as shown in documentation examples In the Module Composition example here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#composing-modules on of the examples is ""module delete --name foo --type sink"" which fails as the '--type' argument is not supported by the CLI.      There are 3 other references to the '--type' argument in the documentation which may not be supported by the CLI anymore.";0
XD-1725;"Create tests for Stream/Job deployments path data verification Based on the discussion here:  https://github.com/spring-projects/spring-xd/pull/852#issuecomment-43356579  we would like to have tests created for verifying the Stream/Job deployments path ""data""";0
XD-1727;Add Stream/Job destroy option at the UI Add an option to destroy the stream/job definitions.  Also add confirm action that asks for user to confirm to proceed with destroy.;0
XD-1729;Update dependencies in Spring XD Sample Repository;0
XD-1731;Support for UUID suffix for hdfs file names in acceptance tests;0
XD-1733;Investigate fall through of server.yml values when running in YARN We don't support using @Configuration for modules ATM.  The current code was committed during the same time as improvements to handling module configuration.  We should switch the reactor-ip.xml to include all bean definitions and remove referencing @Configuration classes or see how to add support for @Configuration.      Another short term hack is to put the prefix 'sink.reactor-ip' in all @Value used in NetServerInboundChannelAdapterConfiguration.;0
XD-1735;FileJdbcTest & JdbcHdfsTest failing JdbcHdfsTest FileJdbcTest works for singlenode but not for admin & Container on the same machine.;0
XD-1738;Stream destroy fails to remove if the underlying modules have been removed. In short if you attempt to destroy a stream that has had its modules removed the destroy will fail.  1) So if I create my own processor:x and use the processor in a stream.  2) I then shutdown the admin and container.  3) Delete the processor:x from the $XD_HOME/modules directory  4) Restart the admin and container.  5) if you do a stream list the stream that used the processor.x is still present.  6) but you can not delete the stream because of the exception below.     [To Reproduce using Payload Conversion example]  1) Follow the instructions to install and use the myTupleProcessor module in a stream.  2) Now shutdown the admin and container  3) rm -rf $XD_HOME/modules/processor/myTupleProcessor.xml   4) rm -rf $XD_HOME/lib/payload-conversion.jar  5) Startup your admin and container  6) stream all destroy.  Then type 'y'<return>     6a) The shell will report ommand failed org.springframework.xd.rest.client.impl.SpringXDException: No content to map due to end-of-input at [Source: java.io.StringReader@5b8bd3d0 line: 1 column: 1]     6b) The Admin Server will report  11:59:43543 ERROR http-nio-9393-exec-1 rest.RestControllerAdvice:199 - Caught exception while handling a request  org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: No content to map due to end-of-input   at [Source: java.io.StringReader@648849d5 line: 1 column: 1]    org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:47)    org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:31)    org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapAndThrowIgnoring(ZooKeeperUtils.java:65)    org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:95)    org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:300)    org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:196)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:152)    org.springframework.xd.dirt.stream.StreamDeployer.beforeDelete(StreamDeployer.java:116)    org.springframework.xd.dirt.stream.StreamDeployer.beforeDelete(StreamDeployer.java:43)    org.springframework.xd.dirt.stream.AbstractDeployer.delete(AbstractDeployer.java:246)    org.springframework.xd.dirt.stream.AbstractDeployer.deleteAll(AbstractDeployer.java:169)    org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:100)    org.springframework.xd.dirt.rest.XDController.deleteAll(XDController.java:110)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)    org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:885)    javax.servlet.http.HttpServlet.service(HttpServlet.java:653)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)    javax.servlet.http.HttpServlet.service(HttpServlet.java:728)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)    org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:724)  Caused by: com.fasterxml.jackson.databind.JsonMappingException: No content to map due to end-of-input   at [Source: java.io.StringReader@648849d5 line: 1 column: 1]    com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:164)    com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3036)    com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:2978)    com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2098)    org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:82)  	... 61 more;0
XD-174;Document how to create a custom processor module. The use case is to write custom code that does processing on a specific domain class (perhaps from twitter adapter) or a tuple.  Need to package up this code so that it can be used inside XD.;0
XD-1743;"ClassNotFoundException: o.s.social.twitter.api.Tweet with Rabbit-transport Using Rabbit as a transport I get the below error when creating the following stream:  {code} stream create mytweets --definition ""twittersearch --query='spring' | log"" --deploy true {code}  In local mode the stream executes just fine. Of course it works with *--outputType=application/json*. Nevertheless I was not expecting that exception (see below)  Issue was also verified by [~grenfro].   {code} org.springframework.amqp.rabbit.listener.ListenerExecutionFailedException: Listener threw exception   org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.wrapToListenerExecutionFailedExceptionIfNeeded(AbstractMessageListenerContainer.java:758)   org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:653)   org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:576)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:75)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:154)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:69)   org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:255)   org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:162)   org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:87)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy102.invokeListener(Unknown Source)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:1111)   org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:559)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:904)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:888)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$500(SimpleMessageListenerContainer.java:75)   org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:989)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [se.0.convert.bridge]   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)   org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)   org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter.access$400(AmqpInboundChannelAdapter.java:44)   org.springframework.integration.amqp.inbound.AmqpInboundChannelAdapter$1.onMessage(AmqpInboundChannelAdapter.java:90)   org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:650) 	... 24 more Caused by: org.springframework.xd.dirt.integration.bus.serializer.SerializationException: unable to deserialize [null]. Class not found.   org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:381)   org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:363)   org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:346)   org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.access$500(RabbitMessageBus.java:70)   org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus$ReceivingHandler.handleRequestMessage(RabbitMessageBus.java:448)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) 	... 37 more Caused by: java.lang.ClassNotFoundException: org.springframework.social.twitter.api.Tweet   java.net.URLClassLoader$1.run(URLClassLoader.java:366)   java.net.URLClassLoader$1.run(URLClassLoader.java:355)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:354)   java.lang.ClassLoader.loadClass(ClassLoader.java:425)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)   java.lang.ClassLoader.loadClass(ClassLoader.java:358)   java.lang.Class.forName0(Native Method)   java.lang.Class.forName(Class.java:190)   org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:375) 	... 43 more {code}";0
XD-1748;Update to Spring Integration 4.0.1 Add messages store optimization to the `hdfs-dataset`;0
XD-1750;Exception handling at Module info command When not prefixing with appropriate module type module info command throws StringIndexOutOfBoundsException:      xd:>module info file  java.lang.StringIndexOutOfBoundsException: Failed to convert 'file' to type QualifiedModuleName for option 'name'  String index out of range: -1;0
XD-1751;Modules that use tomcat connection pool need to expose configurations filejdbc hdfsjdbc jdbchdfs & jdbc modules each support a tomcat connection  pool.  At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file.  We need to allow the user to configure them via yml property file and environment variables.;0
XD-1753;Change default date formats to be 'yyyy-MM-dd' We have some places where we us a default data format specified as 'yyyy/MM/dd'. In Spring for Apache Hadoop we use 'yyyy-MM-dd' for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.;0
XD-1754;"Assess if GemfireJsonServer & gemfireServer sinks should close the client cache * OS - Mac  * XD Deployment Type - Singlenode  * SHA - bb4dd58  * Required Software - XD Gemfire Sample Server    [Description]  After creating and destroying 3 streams with gemfireJsonServer sink the 4th will fail with this error:    * 44707 refused connection: The number of clients 4 exceeded the limit of 3 allowed by the default evaluation license.    [Steps to reproduce]  * From your shell execute the following 4 times:  ** stream create --name stocks --definition ""http --port=9090 | gemfire-json-server --regionName=Stocks --host=ec2-54-221-32-82.compute-1.amazonaws.com --port=40404 --keyExpression=payload.getField('symbol')"" --deploy  ** stream destroy stocks";0
XD-1755;gemfire source does not offer --host nor --port options;0
XD-1756;Update spring-data-hadoop version to 2.0.0.RC4 Update spring-data-hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.;0
XD-1758;JMS Source (ActiveMQ) failing to use jmsUrl environment variable Deployed on: SingleNode Ec2 SingleNode Mac  SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab    [Description]  JMS Source (Activemq) tried to access a broker on localhost.    The current deployment uses the following to set the JMS Broker:  * export amq_url=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616    [Analysis]  After reviewing the configuration of the jms-activemq-infrastructure-context.xml it was noted that the brokerUrl environment variable has been changed from amq.url to amqUrl.  While the jms-activemq.properties has not been changed (still amq.url).    After setting the following the test still failed:  * export amqUrl=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616    After going into the jms-activemq-infrastructure-context.xml and replacing the amqUrl with amq.url the jms source (activemq) returned to normal operation.      [Incident]  Acceptance tests reported a failure on Saturday Morning's build that the JMS Source failed.;0
XD-1760;Support in-memory transport for co-located modules We are looking to speed up the message passing from source to sink  and wondering if we could use a in-memory transport whenever we know that source and sink modules are co-located on the same container. Currently we do not see a straight forward way of doing it    Option 1 : Create a composite module and let users deploy a composite module by itself or in other words deploy a stream with one module    Option 2 : Let users define a transport as in-memory when defining a stream. This could be used along with the deployment manifest feature enforcing co-location of a source and sink module with in-memory transport    cc @adenissov;0
XD-1761;Documentation for data partitioning and all Rabbit Bus properties;0
XD-1762;Update data partitioning functionality to use murmur hash function https://github.com/addthis/stream-lib/blob/master/src/main/java/com/clearspring/analytics/hash/MurmurHash.java;0
XD-1764;Documentation for enhanced HDFS sink with paths based off date/time/message content;0
XD-1766;"Failing tcp to file in script tests build	22-May-2014 08:45:04	Creating stream tcptofile with definition 'tcp+--port%3D21234+--socketTimeout%3D2000+%7C+file+--dir%3D%2Ftmp%2Fxdtest%2Fbasic' ...  build	22-May-2014 08:45:04	{""name"":""tcptofile""""deployed"":null""definition"":""tcp --port=21234 --socketTimeout=2000 | file --dir=/tmp/xdtest/basic""""links"":[{""rel"":""self""""href"":""http://127.0.0.1:9393/streams/tcptofile""}]}  build	22-May-2014 08:45:04	  build	22-May-2014 08:45:11	Destroying stream tcptofile ...  build	22-May-2014 08:45:11	  build	22-May-2014 08:45:11	  build	22-May-2014 08:45:11	Expected blahblah does not match actual value (98108971049810897104)  simple	22-May-2014 08:45:11	Failing task since return code of [/bin/sh /tmp/XD-SCRIPTS-RS-513-ScriptBuildTask-7280766559152712153.sh] was 1 while expected 0  simple	22-May-2014 08:45:11	Finished task 'Run basic_stream_tests'    See https://build.spring.io/download/XD-SCRIPTS-RS/build_logs/XD-SCRIPTS-RS-513.log";0
XD-1768;User should be able to specify deploy properties for Jobs When clicking deploy from the job definitions page user should be able to specify the deployment manifest (module count module criteria etc.);0
XD-1769;User should be able to provide job deployment properties At the job definitions page user should be able to provide the job deployment manifest (module count criteria etc.);0
XD-177;Easily switch between a single process that performs all admin and processing tasks to one that has a dedicated admin processes and distributed processing containers.;0
XD-1771;Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test.  To support these changes:  1) Remove assertReceived.  Since the number of messages is indeterminate  2) Change file sink that captures the results to append mode.  Because each message will overwrite the previous messages result.;0
XD-1772;Do not allow a stream definition to contain ambiguous module references A stream definition such as http | transform | transform | file     will limit functionality such as taps since you can't reference which specific module to apply the tap.     Should be proactive in parsing the DSL and force the use of a label to disambiguate.;0
XD-1773;Upgrade Curator to 2.5.0;0
XD-1774;UI Automatically close notification messages * Automatically close notification messages * Polish UI;0
XD-1776;Need to support the ability to test Gemfire Locators Need to be able to setup a gemfire server that has locators enabled such that we can enable the gemfire modules locator features.  run tests for the use_server (default) and tests for locator.  They are enabled by activating the use-locator profile for the container(s) . For example: if you are running singlenode the profile would be: export spring_profiles_active=singlenodeuse-locator;0
XD-1777;Restore deployment properties for orphaned modules As part of XD-1338 we modified how module deployment works. Now module deployment requests include deployment properties as the data for the ZooKeeper node. This allows us to reuse those properties when a container exit the cluster and the module is redeployed to another container.    However if there are no other containers to handle the deployment the module deployment node is erased along with the properties. This mean no module will ever handle the partition that module was responsible for.    This condition needs to be handled so that partitioned streams continue to function in cases where the cluster temporarily doesn't have enough containers to support the stream.;0
XD-1781;Add HdfsMongoDb Acceptance Test. Create Acceptance Test  Add Mongo to Ec2 Acceptance Test Environment.;0
XD-1782;Exception thrown when all containers are shut down If all containers are shut down and there's a stream deployed this exception is thrown on the admin:  {noformat} java.util.NoSuchElementException   java.util.ArrayList$Itr.next(ArrayList.java:839)   org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:260)   org.springframework.xd.dirt.server.ContainerListener.redeployStreamModule(ContainerListener.java:432)   org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)   org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   java.util.concurrent.FutureTask.run(FutureTask.java:266)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   java.util.concurrent.FutureTask.run(FutureTask.java:266)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:744) {noformat}  This is a regression caused by the earlier code refactoring for stream deployment.;0
XD-1784;REST endpoint/command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules.    For example: 'runtime module foo.sink.bar-2';0
XD-1786;Support Partitioning/Bus Properties in the RedisMessageBus PR: https://github.com/spring-projects/spring-xd/pull/926;0
XD-1787;Detect Invalid Deployment Properties in the Bus Detect properties the bus doesn't support.;0
XD-1788;"Detect Module Properties for Non-existent Modules stream create foo --definition=""bar | baz""    stream deploy foo --properties=module.qux.fiz";0
XD-1789;"New job that executes SQL script using JDBC Create OOTB batch job that executes SQL script using JDBC - can be used for Hive2 jobs or HAWQ jobs etc.  Christian Tzolov provided the following baed on Dave Syers JdbcTasklte (https://src.springframework.org/svn/spring-batch-admin/sandbox/cloud-sample/src/main/java/org/springframework/batch/admin/sample/job/JdbcTasklet.java):  Attached is a simple job module that can run sql commands on Hawq or other DB over jdbc.  Just unzip it in <springxd>/xd/modules/job folder and create something like this: xd> job create analyticsJob  --definition ""     jdbc --driverClassName=org.postgresql.Driver             --url=jdbc:postgresql://<HAWQ master host>:5432/gpadmin             --username=gpadmin --password=''              --sql='CREATE TABLE fonecta_demo.analytics AS                              SELECT segmenttiluokka count(*) as cnt FROM fonecta_demo.segmenttiluokka                                    GROUP BY segmenttiluokka'"" --deploy";0
XD-179;Have three startup scripts xd-singlenode xd-admin and xd-container The xd-singlenode script will launch a main application that creates both the admin node (to process http admin requests) and the container node (to execute modules for data processing) within in the same process     the xd-admin script will launch a main application that creates only the admin node (remove current embeddedContainer options)    the xd-container script will launch a main application that creates only the container node (as it is now);0
XD-1790;"New job that executes a job on YARN Create OOTB batch job that executes a job on YARN  could be:  job create yarnJob --definition ""yarnjob --containerCount=4 --applicationDir=/apps/mystuff --archiveFile=yarn-job-0.1.0.jar --arguments=#{payload[value]}""";0
XD-1796;Create Acceptance tests for Container Groups * Create infrastructure to retrieve container data. * Create infrastructure to retrieve  Stream data and the associated container * Create tests that verify default behavior without group  * Create tests that verify behavior with sink belonging to specific group * Create tests that verify behavior with processor belonging to specific group  * Also generate tests for the scenarios above where the count >1;0
XD-1798;Rabbit Tests need to use another another account besides guest. Need to update the Rabbit & MQTT test to use the Acctest account instead of guest.  As of Rabbit 3.3 the guest account can only accept connections from localhost.  For now I've setup a loop back so that guest can be accessed from other manchines.;0
XD-1801;Encapsulate retrieval of module deployment metadata See comment here: https://github.com/spring-projects/spring-xd/pull/912/files#r13331190;0
XD-1802;Add @XmlRootElement to all REST resources Some REST resources lack an @XmlRootElement annotation.  This causes a JAXB marshalling error when trying to access the API with an Accept header of xml (which is the default in most browsers)  This is a preliminary to XD-1800 (which is much more involved) only to fix ugly exception;0
XD-1805;Support the ability to create module definitions in Groovy XML is currently required for module definitions. XD should also support Java @Config and Groovy bean definitions and potentially SI DSLs.;0
XD-1809;Improve E2E Test Coverage;0
XD-181;Update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location. launcher.xml can make use of the system property xd.pipeProtocol inside an import statement.  This determines which version of the XD infrastructure to load for example what ChannelRegistry implementation Local or Redis based or specific message listener containers.   File name conventions should be used so if the option passed in from the command line is --pipeProtocol localChannel  then the XML filename looked for has the 'Protocol' suffix applied e.g. localChannelProtocol and is loaded via the classpath.  Redis and Local will not be the only options other implementations will be provided in the future e.g. Rabbit and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).;0
XD-1810;Assess XD Fails to connect to remote Redis Instance Deployment: Admin/Container Redis as data transport  SHA: 45e1beb    [Description]  In the case that the Redis is not running locally XD cannot connect to the Redis instance even though the environment variable spring_redis_host has been set.      [Steps to reproduce]  * Shutdown local instance of Redis.  * For both the admin and container execute the command prior to running the instances:  ** export spring_redis_host=YourRedisHost  * Start admin and container instances  * deploy a simple stream   ** You will see the following error:  13:56:59647 ERROR task-scheduler-9 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter@6a1f1d12]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$SendingHandler.handleMessageInternal(RedisMessageBus.java:235)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy57.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:110)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool    org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:97)    org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:143)    org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:41)    org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:85)    org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:55)    org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169)    org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149)    org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)    org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:68)    org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:60)    org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter.handleMessageInternal(RedisQueueOutboundChannelAdapter.java:109)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  	... 43 more  Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool    redis.clients.util.Pool.getResource(Pool.java:42)    org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:90)  	... 54 more  Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused    redis.clients.jedis.Connection.connect(Connection.java:142)    redis.clients.jedis.BinaryClient.connect(BinaryClient.java:75)    redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1724)    redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)    org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:819)    org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:429)    org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:360)    redis.clients.util.Pool.getResource(Pool.java:40)  	... 55 more  Caused by: java.net.ConnectException: Connection refused    java.net.PlainSocketImpl.socketConnect(Native Method)    java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)    java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)    java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)    java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)    java.net.Socket.connect(Socket.java:579)    redis.clients.jedis.Connection.connect(Connection.java:137)  	... 62 more;0
XD-1812;Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}.    Disallow partitioning properties.;0
XD-1813;Upgrade to Spring Boot 1.1 SNAPSHOT;0
XD-1815;UI - Setup Sauce Labs Integration We should have a facility to easily test the E2E Protractor tests against a variety of common browsers including IE. Sauce Labs seems to be the service to use.;0
XD-1816;Generate asciidoc doc from module options Generate asciidoc fragments for each module's options this way it is always up to date.;0
XD-1817;ContainerListener to redeploy modules based on stream order. When redeploying in the case of a container failure the modules are now redeployed in a random order.  The list of modules in the failed container needs to be sorted based on its position in a given stream and then redeployed.;0
XD-1819;Investigate increased size of XD distribution.;0
XD-182;Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file.;0
XD-1825;Remove all javadoc warnings;0
XD-1826;"UI Suport ""Mandatory"" Module Parameters Spring XD should support mandatory module properties. In the UI when creating a definition from an existing Module mandatory definition properties should be visually highlighted and enforced.  I don't think the XD backend supports this though.";0
XD-1827;Modules utilizing Jdbc Data Source need to offer connection pool configurations externally. Currently JdbcSink HdfsJdbc&  FileJdbc offer only driverClassName url user name & password.  They need to offer a full range of configurations offered by the Tomcat Jdbc Connection pool.;0
XD-1828;"Update TwitterSearchTest to use #katyperry TwitterSearchTest is the only test that is dependent on an external system for its success.  As such there are times that the service is running slower than the test expects thus the test fails un-necessarily.   Once XD-1814 is merged we can utilize the ""waitForFile"" feature to wait for the result file from the stream to be written.  But the wait time for twitter will be extended to 1 min.   AAAAND make the the search string configurable.  Some tests fail because the #springio is not consistently present.";0
XD-183;Create localChannelProtocol.xml that will load all the SI specific implementations to suppor the XD container runtime and administration;0
XD-1830;"Support completion proposals of processors after a named channel Due to the way the heuristics for module type guessing work we can't currently support completions of the like: ""queue:foo > s<TAB>"" that would yield valid processor names  We need to add non-determinism (list of types instead of single type) to the type guessing heuristic";0
XD-1831;Mask Database Passwords in REST Controllers and Admin UI When deploying a batch job the UI displays the database password found in the server.yml in plain text to the user.  At the very least this should be displayed in a password field so it's masked out and have it masked out in the resulting definition at the bottom of the page.  Ideally we wouldn't provide the password on that page at all and only accept overriding options (if the user wants a password other than the configured one enter it…otherwise we'll use what we have).    I'm finding that this occurs in other places as well.  A full pass though of the UI should be done to mask out passwords (or eliminate their display all together).;0
XD-1833;Fix JMS Property Names The JMS Source/Sink has a pluggable provider (default {{activemq}}) but the URL property {{amqUrl}} implies activeMQ - the property name should be generic (found while testing XD-1149).;0
XD-1834;Add single threaded executor service to DeploymentSupervisor This will  eliminate any race conditions between deployments and containers  joining/leaving the cluster.;0
XD-1836;Remove unnecessary usage of module.getIndex() Following the merge of https://github.com/spring-projects/spring-xd/commit/03cf962845499610ad021d9e6689bccbf5e13cef  investigate calling sites of module.getIndex() or any similar API and remove it if needed;0
XD-1839;"Do not allow the use of named channels in composed modules This needs closer inspection but here are some things that currently do not work either at the parser level or at actual deployment time:    {noformat}  xd:>module compose foo --definition ""queue:bar > filter""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'filter' and type 'sink'    xd:>module compose foolog --definition ""queue:foo > log""   Successfully created module 'foolog' with type sink  ==> should fail (not a module but a full stream)    xd:>module compose foo --definition ""queue:bar > filter | transform""  Successfully created module 'foo' with type processor  ==> should be source  {noformat}";0
XD-184;Add unregistration support to the channel registry;0
XD-1840;Document and review REST API REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts;0
XD-1843;Write out initial stream deployment state Currently when a stream is deployed by {{DeploymentSupervisor}} the event thread blocks until all deployment requests have been answered or timed out. If there were any deployment errors we log a stack trace.    Instead (or in addition to) we need to write out the results of the deployment request. My initial thought is that it would go under:  {panel}  {{/xd/deployments/streams/<name>/state}}  {panel}  The data for {{state}} will be a JSON map with fields {{state}} and an optional {{errorDescription}}.;0
XD-1846;Improve DeploymentVerifier when stream state is complete As part of XD-1591 {{DeploymentVerifier}} was modified to take the node structure into account. As indicated in the review below the implementation does not take module properties (such as count) into account:    https://github.com/spring-projects/spring-xd/pull/939/files#r13730134    This means the implementation is incorrect. For now this won't affect us since all tests at the moment are single node. However this can be drastically improved (and simplified) once XD-1270 is completed. At that point we'll be able to simply read a single ZK node to determine if/when a deployment succeeded.;0
XD-1849;Consolidate REST endpoints for batch resources under /jobs currently we have /batch and /jobs. Everything should move to /jobs. See https://github.com/spring-projects/spring-xd/wiki/REST-API for details.;0
XD-1853;Tap Fixture refactoring The Tap fixture does not need to inherit from AbstractModuleFixture  Replace moduleName method with moduleToTap.    The current tap syntax is: tap:stream:<streamname>.<modulelabel>  and not  tap:stream:<streamname>.<modulelabel>.<modulename> as currently implemented by the label fixture.;0
XD-1856;Add option to specify fsUri to hdfs sinks We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs webhdfs);0
XD-1861;"Fix XD config initializer for ZK connection string Spring Boot 1.1.1 has the following change:    https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4    where an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external ""zk-properties"" property source always preceding over the application configuration properties.";0
XD-1862;Organize modules consistently using a dir per module Even if not strictly necessary for all modules use the one-dir-per-module scheme for all of them.  Care should be taken in case there are <import>;0
XD-1865;"Increase performance of query to determine Job restartability In BatchJobExecutionsController's list all job executions for each given job execution it needs to be evaluated against all the job executions of a given job instance to see if the job execution is restarted.  The rule is: for a given JobInstance there could be only one job execution that can be in ""COMPLETED"" state. If the job itself is restartable and if any of the job executions for this job instance are ""FAILED"" or ""STOPPED"" then that job execution can be restarted (based on the client request).  Hence if the job execution is complete then it will set the restartable flag to false for all the job executions on a given job instance.";0
XD-1866;Remove ability to do index-based tapping;0
XD-1868;Split DIRT project into common/admin/container/standalone This is a generalization of XD-1702;0
XD-187;Create XD script for xd-single node This script will launch XD admin along with the module container.    As part of this implementation we will also remove the embedded options for XD admin & container scripts.;0
XD-1870;Rabbit Sink & Source --host and --port are not updating module host/port. Acceptance Tests failed on the Rabbit Source and Sink Tests.  The test started failing when XD-1824 was introduced (Support RabbitMQ Cluster in source/sink).  This story added addresses to support rabbit cluster failover.    Currently if a user set --host --port to a remote Rabbit instance XD will use the default host=localhost and port=5672.  However using --addresses does work.;0
XD-1871;Create documentation for Batch DB migration Update documentation related to database migration with the changes from XD-1822;0
XD-1872;Tap lifecycle connection listener should close the tap path children cache upon ZK disconnect Currently TapLifecycleConnectionListener (which implements ZooKeeperConnectionListener) clears(but not closes) the taps (PathChildrenCache) upon ZK `onDisconnect` child event.  Since `onConnect` child event re-creates the tap PathChildrenCache the previously created PathChildrenCache is still hanging in there.  I would be better to close the cache upon disconnect.;0
XD-1873;"Investigate JobExecutions page list performance Investigate ""Job Executions"" list page load timing based on number of job executions to load.     The investigation can be of the following steps:    1) Return all the size restrictions to retrieve the number of job executions.  2) Setup 5 10 100 500 1000 number of job executions and measure the page load timings.    Based on this we can address the paging support mentioned in XD-1864.";0
XD-1877;Create gemfire test Port https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/gemfire_stream_tests    Need to consider how to start the server maybe use the jvm fork utilities?  Look into spring-data-gemfire as well.;0
XD-1878;Create low volume http stress test The test    https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/httpbash    is very simple it doesn't even check the results.  A small change to    https://github.com/spring-projects/spring-xd/blob/master/spring-xd-test-fixtures/src/main/java/org/springframework/xd/test/generator/SimpleHttpGenerator.java    so that number of messages to post is specified would be part of this work.;0
XD-1882;Add remote partitioning to filejdbc job h2. Narrative As a developer I need to be able to process the importing of files in parallel via the filejdbc batch job.  h2. Acceptance Criteria # Be able to provide a list of files to the job and have them be read in parallel based on the number of slaves deployed. # Use {{MultiResourcePartitioner}} to create on partition per incoming file.;0
XD-1883;Update dependencies to latest Spring IO platform versions https://github.com/spring-projects/gradle-plugins/tree/master/spring-io-plugin is the starting point to introduce the appropriate plugin to check for the correct dependencies.;0
XD-1884;"Module option validation not happening anymore It seems that no option validation (being Spring or jsr 303) is happening anymore at stream creation time.    eg  {noformat}  stream create foo --definition ""http --port=bar | log""  {noformat}";0
XD-1885;"Provide ability to disable tab completion for specific module options Not all module options are born equal. Some are more important/useful than others and having the more ""expert"" ones show up e.g. in TAB completion is very noisy (esp. given how JLine2 currently presents the whole stream definition typed so far when doing completion as opposed to just the last bit)";0
XD-1892;Update to Spring Platform 1.0.1;0
XD-1894;Create documentation section on best practices This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency.    It should also discuss the 'bypass' functionality - or reference another section that covers it.    We should probably include how to scale out http sources e.g. the need to use a load balancer.;0
XD-1897;Spring XD - Handling sink failures If a sink fails for whatever reason will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures?;0
XD-1898;"dist task failure - unable to access http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd The build task ""gradlew dist"" fails with the following error.  00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	... 52 more 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] Caused by: javax.xml.transform.TransformerException: Failure reading /Users/ixr303/spring-xd/build/reference-work/index.xml 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter]   com.icl.saxon.om.Builder.build(Builder.java:267) 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter]   com.icl.saxon.Controller.transform(Controller.java:936) 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter]   com.icl.saxon.Controller$transform.call(Unknown Source) 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter]   AbstractDocbookReferenceTask.transform(DocbookReferencePlugin.groovy:146) 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter]   org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:63) 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] 	... 59 more 00:20:16.976 [ERROR] [org.gradle.BuildExceptionReporter] Caused by: java.io.IOException: Server returned HTTP response code: 500 for URL: http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLEntityManager.setupCurrentEntity(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLEntityManager.startEntity(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLEntityManager.startDTDEntity(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLDTDScannerImpl.setInputSource(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLDocumentScannerImpl$DTDDispatcher.dispatch(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.parsers.XMLParser.parse(Unknown Source) 00:20:16.977 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source) 00:20:16.978 [ERROR] [org.gradle.BuildExceptionReporter]   org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source) 00:20:16.978 [ERROR] [org.gradle.BuildExceptionReporter]   com.icl.saxon.om.Builder.build(Builder.java:265)   The URL http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd returns 500 error most of the times.   Tried to circumvent the error by manually getting the did file locally and running again causes unintended relative path issues.  Help is very much appreciated.";0
XD-1904;Create AngularJS directive to render deployment statuses In order to minimize code duplication - Create an AngularJS directive to render deployment statuses. We could even color code the various statuses.  We should also create a 2nd directive for the status-help-popover. We should consider to possibly use the Angular Bootstrap UI popover support.;0
XD-1907;"Handle 'deploying' state at the Admin UI When the job is in ""deploying"" state until we decide whether the job is actually ""deployed"" or ""failed""/""incomplete"" there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue).   We could either disable both ""deploy""/""undeploy"" until the state changes from ""deploying""?";0
XD-1908;Remove Retry from TCP Sink Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.;0
XD-1910;Improve getting started docs for installation https://github.com/spring-guides/gs-spring-xd/issues/1;0
XD-1913;Enable FtpHdfsTest FtpHdfsTest was added in https://github.com/spring-projects/spring-xd/pull/1005 but excluded since it will require some changes to run on ec2 including setting up an ftpServer on ec2 with appropriate security etc.;0
XD-1914;"Stream/Job deployment state is always ""incomplete"" in case of module count zero In case of the deployment property module count for a specific module in a stream/job is zero the stream/job deployment status is calculated as ""zero"" even though the modules are deployed to all matching containers.  Currently the DefaultStateCalculator's 'calculate' method doesn't check if the expected count is zero.  Also we would need all the matching containers to determine the same module is deployed to all the matching containers (in case of module count = 0)";0
XD-1915;Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it;0
XD-1918;Update TypeConversion Page Need to update the examples in the TypeConversion doc re spring social Tweet which is no longer used.;0
XD-192;Update getting started documentation to use xd-singlenode start script. With the new option of starting without requiring redis the getting started documentation should reflect this easier way to start processing data.;0
XD-1921;TriggerSourceOptionsMetadata - Change DateFormat to be ISO 8601 compliant (with TimeZone) To bring in line with the rest of default date-formats change the date format to yyyy-MM-dd HH:mm:ss in TriggerSourceOptionsMetadata;0
XD-1922;"Make Cron-based Triggers TimeZone aware Currently specified Cron Expressions are executed in the Container's default TimeZone. In *Trigger.xml* we specify:  {code} 	<beans profile=""use-cron""> 		<int:inbound-channel-adapter channel=""output"" 			auto-startup=""false"" expression=""'${payload}'""> 			<int:poller cron=""${cron}"" /> 		</int:inbound-channel-adapter> 	</beans> {code}  This translates in *org.springframework.integration.config.xml.PollerParser* to  {code} BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(CronTrigger.class) builder.addConstructorArgValue(cronAttribute) {code}  Which will call *org.springframework.scheduling.support.CronTrigger*:  {code} 	/** 	 * Build a {@link CronTrigger} from the pattern provided in the default time zone. 	 * @param cronExpression a space-separated list of time fields 	 * following cron expression conventions 	 */ 	public CronTrigger(String cronExpression) { 		this.sequenceGenerator = new CronSequenceGenerator(cronExpression) 	} {code}  ""Build a {@link CronTrigger} from the pattern provided in the *default time zone*.""  We need to pass-in a timezone. *Should cron expressions as part of an XD *Definition* have a TimeZone parameter?* When creating the stream via the UI or the Shell the timezone can be inferred (if not specified) but should be mandatory for the REST API meaning being passed in as a mandatory parameter (OR alternatively if not passed in we assume the Cron expression is specified for UTC).  That way we could ensure that a (Stream/Job) Definition is globally valid.";0
XD-1924;Create RuntimeModuleDescriptor that represents runtime module instance See this for more info: https://github.com/spring-projects/spring-xd/pull/1021/files#r14611854;0
XD-1925;Rename ModuleDeployer For more info please see here:  https://github.com/spring-projects/spring-xd/pull/1021/files#r14617723;0
XD-1928;Provide JMS as a supported MessageBus implementation;0
XD-1929;Jolokia endpoints returning 404 http://localhost:9393/management/jolokia/search/xd.*:type=**    for singlenode in M7 returned a value..... on master it returns 404 error...;0
XD-1931;Verify platform compatibility versions with the XD dependencies We need to make sure there is no conflicting/missing dependency with build.gradle using spring IO platform dependencies.    https://jira.spring.io/browse/XD-1929 is one such scenario where jolokia dependency went missing.;0
XD-1933;Update http source to use netty 4 Platform version of netty is 4.0.18.Final.  Current http source is using 3.7.  Packages/classes have changed in netty4;0
XD-1934;Update Spring Integration Splunk Extension to 1.1 GA;0
XD-1936;Remove jars from .zip packaging whose license prevents distribution The work here is doing the research....    mysql client jar should be removed as it is GPL - http://dev.mysql.com/downloads/connector/j/5.0.html  (GPL)    postgresql is BSD so that is ok (another issue will handle license file inclusion.;0
XD-1938;"Shell completion crashes The XD shell completion crashes on:  job launch --name <TAB> gives  {noformat}  xd:>job launch --name Exception in thread ""Spring Shell"" java.lang.IllegalStateException: Could not determine kind: tab-completion-count-1 existing-job disable-string-converter    org.springframework.xd.shell.converter.CompletionConverter.determineKind(CompletionConverter.java:109)    org.springframework.xd.shell.converter.CompletionConverter.getAllPossibleValues(CompletionConverter.java:69)    org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)    org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)    jline.console.ConsoleReader.complete(ConsoleReader.java:3077)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)    org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)    org.springframework.shell.core.JLineShell.run(JLineShell.java:179)    java.lang.Thread.run(Thread.java:744)  {noformat}    Moreover seems completion generally crashes when the server is not up (which was taken care of previously if I'm not mistaken):    xd:>job destroy --name <TAB>  {noformat}  Exception in thread ""Spring Shell"" org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:9393/jobs/definitions?size=10000&deployments=true"":Connection refused nested exception is java.net.ConnectException: Connection refused    org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:561)    org.springframework.web.client.RestTemplate.execute(RestTemplate.java:506)    org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:243)    org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:121)    org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:40)    org.springframework.xd.shell.converter.ExistingXDEntityConverter.getAllPossibleValues(ExistingXDEntityConverter.java:72)    org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)    org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)    jline.console.ConsoleReader.complete(ConsoleReader.java:3077)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)    jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)    org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)    org.springframework.shell.core.JLineShell.run(JLineShell.java:179)    java.lang.Thread.run(Thread.java:744)  Caused by: java.net.ConnectException: Connection refused    java.net.PlainSocketImpl.socketConnect(Native Method)    java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)    java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)    java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)    java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)    java.net.Socket.connect(Socket.java:579)    java.net.Socket.connect(Socket.java:528)    sun.net.NetworkClient.doConnect(NetworkClient.java:180)    sun.net.www.http.HttpClient.openServer(HttpClient.java:432)    sun.net.www.http.HttpClient.openServer(HttpClient.java:527)    sun.net.www.http.HttpClient.<init>(HttpClient.java:211)    sun.net.www.http.HttpClient.New(HttpClient.java:308)    sun.net.www.http.HttpClient.New(HttpClient.java:326)    sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)    sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)    sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)    org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:78)    org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)    org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:52)  {noformat}";0
XD-1939;Update to Spring Batch Admin 1.3.0.RC1;0
XD-1940;Clean up duplicated dependencies from XD on YARN installation Remove unnecessary/duplicated jars from the lib directory in spring-xd-yarn zip distribution;0
XD-1942;Use guava 15.0 for spring-xd-integration-test jclouds is not compatible with versions of guava higher than 15.;0
XD-1946;Add stream state tests Test to verify stream state is correct after starting/stopping containers.;0
XD-1947;Fix support for @CliAvailabilityIndicator See PR https://github.com/spring-projects/spring-xd/pull/1043/;0
XD-1949;Ensure DSM matrix is diagonal;0
XD-195;The {{time}} Source Should Emit String by Default When running in local mode (no Redis) {{time | tcp}} no longer works.    Change the {{time}} source to emit the date as a String while allowing an option to emit a {{Date}} object.;0
XD-1950;Single step partition support on filejdbc module uses module's datasource The filejdbc module's single step partition support configures to use jdbc module's datasource rather than XD's batch datasource.    ```  org.springframework.messaging.MessageHandlingException: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID START_TIME END_TIME STATUS EXIT_CODE EXIT_MESSAGE CREATE_TIME LAST_UPDATED VERSION JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?] SQL state [null] error code [0] [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION) nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy117.handleMessage(Unknown Source)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)    sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy115.send(Unknown Source)    org.springframework.xd.dirt.integration.bus.LocalMessageBus$3.handleMessage(LocalMessageBus.java:188)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.access$000(UnicastingDispatcher.java:48)    org.springframework.integration.dispatcher.UnicastingDispatcher$1.run(UnicastingDispatcher.java:92)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  Caused by: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID START_TIME END_TIME STATUS EXIT_CODE EXIT_MESSAGE CREATE_TIME LAST_UPDATED VERSION JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?] SQL state [null] error code [0] [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION) nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)    org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)    org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)    org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)    org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:660)    org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:695)    org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:727)    org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:737)    org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:811)    org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.getJobExecution(JdbcJobExecutionDao.java:267)    org.springframework.batch.core.explore.support.SimpleJobExplorer.getStepExecution(SimpleJobExplorer.java:142)    org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:52)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  	... 41 more  Caused by: java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)    org.sqlite.DB.newSQLException(DB.java:383)    org.sqlite.DB.newSQLException(DB.java:387)    org.sqlite.DB.throwex(DB.java:374)    org.sqlite.NestedDB.prepare(NestedDB.java:134)    org.sqlite.DB.prepare(DB.java:123)    org.sqlite.PrepStmt.<init>(PrepStmt.java:42)    org.sqlite.Conn.prepareStatement(Conn.java:404)    org.sqlite.Conn.prepareStatement(Conn.java:399)    org.sqlite.Conn.prepareStatement(Conn.java:383)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)    org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:109)    org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:80)    com.sun.proxy.$Proxy109.prepareStatement(Unknown Source)    org.springframework.jdbc.core.JdbcTemplate$SimplePreparedStatementCreator.createPreparedStatement(JdbcTemplate.java:1557)    org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)  	... 63 more  12:23:37941  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@d192973 moduleName = 'filejdbc' moduleLabel = 'filejdbc' group = 'csvjdbcjob0' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv' 'initializeDatabase' -> 'true' 'names' -> 'col1col2col3' 'deleteFiles' -> 'true' 'driverClassName' -> 'org.sqlite.JDBC' 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'] children = list[[empty]]]  12:23:37941  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=filejdbc type=job group=csvjdbcjob0 index=0 @73cc35b5]  12:23:37944 ERROR task-scheduler-1 step.AbstractStep:225 - Encountered an error executing step step1-master in job csvjdbcjob0  org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned    org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)    org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy44.run(Unknown Source)    org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy117.handleMessage(Unknown Source)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)    sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy115.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy117.handleMessage(Unknown Source)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:...;0
XD-1952;"Automate execution of gradle pushGeneratedDocs Should be part of the daily build. One ""easy"" way to do it would be to use the ""hardcoded"" authentication scheme as described here (bamboo should mask a property whose name contains password) We may want to create a dedicated github user though";0
XD-1953;Stacktrace on container with deployed modules is shutdown When the container that has deployed module is shutdown following stacktrace is thrown:  10:10:27560  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@3a615460 moduleName = 'job' moduleLabel = 'job' group = 'j4' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]] 10:10:27560  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=job type=job group=j4 index=0 @7df1aff2] 10:10:27561 ERROR main-EventThread imps.CuratorFrameworkImpl:555 - Watcher exception java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@422fd7b7 has been closed already   org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)   org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)   org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:164)   org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:219)   org.springframework.xd.dirt.plugins.job.JobPlugin.removeModule(JobPlugin.java:70)   org.springframework.xd.dirt.module.ModuleDeployer.removeModule(ModuleDeployer.java:204)   org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:162)   org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:140)   org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:112)   org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:256)   org.springframework.xd.dirt.server.ContainerRegistrar$JobModuleWatcher.process(ContainerRegistrar.java:753)   org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)   org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)   org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) 10:10:27561  INFO main-EventThread zookeeper.ClientCnxn:512 - EventThread shut down 10:10:27564  INFO Thread-2 jmx.EndpointMBeanExporter:433 - Unregistering JMX-exposed beans on shutdown;0
XD-1957;Remove footer from admin UI Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1052#issuecomment-48761686;0
XD-196;replace the hacky parser with a good one Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL.  This will provide a stable base on which to quickly iterate on syntax.;0
XD-1961;Module info for jdbc sink and jobs are unreadable The 'module info' command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does 'fairQueue' have to do with filejdbc jobs?;0
XD-1962;Acceptance Tests fail to map some EC2 internal IPs to External IPs The acceptance tests interrogate the XD-Admin for the containers that are available.  When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal.     [Defect] The acceptance tests only handled the most common suffix of .ec2.internal.  Thus some CI Acceptance tests will fail because because the container's IPs were not properly mapped.  Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues.  FYI EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal.  The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.;0
XD-1964;Servers not finding logging file 12:30:43930  WARN main logging.LoggingApplicationListener - Logging environment value 'file:/data/projects/spring-xd/build/dist/spring-xd/xd/config///xd-container-logger.properties' cannot be opened and will be ignored    There are extra slashes in there.... probably due to some recent changes related to xd/config location in the scripts.;0
XD-1965;StepExecutionInfo can not be retrieved in distributed mode When constructing StepExecutionInfo the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.    Following exception is thrown:    SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root cause  java.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTasklet    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:425)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:358)    org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)    org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)    org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215);0
XD-1967;Dependendcies for Hadoop distros are broken We used to have distro specific jars i the lib/[distro] directory. That is no longer working and all distros seem to contain mostly the same version (hadoop 2.2.0 dependencies)  This is the list for phd1 now:  avro-1.7.5.jar hadoop-annotations-2.2.0.jar hadoop-auth-2.2.0.jar hadoop-client-2.0.5-alpha-gphd-2.1.0.0.jar hadoop-common-2.2.0.jar hadoop-distcp-2.2.0.jar hadoop-hdfs-2.2.0.jar hadoop-mapreduce-client-app-2.2.0.jar hadoop-mapreduce-client-common-2.2.0.jar hadoop-mapreduce-client-core-2.2.0.jar hadoop-mapreduce-client-jobclient-2.2.0.jar hadoop-mapreduce-client-shuffle-2.2.0.jar hadoop-streaming-2.2.0.jar hadoop-yarn-api-2.2.0.jar hadoop-yarn-client-2.2.0.jar hadoop-yarn-common-2.2.0.jar hadoop-yarn-server-common-2.2.0.jar hadoop-yarn-server-nodemanager-2.2.0.jar jersey-core-1.9.jar jersey-server-1.9.jar jetty-util-6.1.26.jar protobuf-java-2.5.0.jar spring-data-hadoop-2.0.1.RELEASE.jar spring-data-hadoop-batch-2.0.1.RELEASE.jar spring-data-hadoop-core-2.0.1.RELEASE.jar spring-data-hadoop-store-2.0.1.RELEASE.jar;0
XD-1968;HdfsTest in Acceptance test fails sporadically (uses trigger as a source) HdfsTest uses the following stream to test the hdfs sink.  trigger --payload='foobar' | hdfs.  In the test failure the test reported that no file was created on the hdfs.    I'm wondering if the trigger fired before the hdfs was fully deployed.   I would say that we set the phase to the maximum but the problem is that by default it is MAX_INT.  Thoughts?;0
XD-1969;"Send count check occasionally fails on Acceptance tests. Acceptance tests check the number of ""sends"" for each module after a single event is triggered.  This should entail that each module in the stream should have a send count of ""1"".   Sporadically this test will fail on a sink where the send count will be 2.    The stacktrace below occurred on a singleAdmin/2 container deployment with rabbit as its transport and this stream was used: ""tcp --port=1234 |file --binary=true --mode=REPLACE""  java.lang.AssertionError: java.lang.AssertionError: Module file.1 for channel input did not have expected count  expected:<1> but was:<2> java.lang.AssertionError: Module file.1 for channel input did not have expected count  expected:<1> but was:<2>   org.junit.Assert.fail(Assert.java:88)   org.junit.Assert.failNotEquals(Assert.java:743)   org.junit.Assert.assertEquals(Assert.java:118)   org.junit.Assert.assertEquals(Assert.java:555)   org.springframework.xd.integration.util.XdEc2Validation.verifySendCounts(XdEc2Validation.java:349)   org.springframework.xd.integration.util.XdEc2Validation.verifySendCounts(XdEc2Validation.java:323)   org.springframework.xd.integration.util.XdEc2Validation.assertReceived(XdEc2Validation.java:140)   org.springframework.xd.integration.test.AbstractIntegrationTest.assertReceived(AbstractIntegrationTest.java:490)   org.springframework.xd.integration.test.TcpTest.testTCPSourceCRLF(TcpTest.java:41)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)   org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:233)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:87)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)   org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)   org.junit.runners.ParentRunner.run(ParentRunner.java:309)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:176)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:724)";0
XD-1975;"Undeploying twitterstream logs warning - MessageDeliveryException To reproduce -     Download recent snapshot - http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/spring-xd-1.0.0.BUILD-20140715.101224-1-dist.zip    Start XD and shell -  xd:>stream create --name tweets --definition ""twitterstream | file"" --deploy   xd:>stream undeploy --name tweets     (Note: the IllegalStateException has been fixed for RC1 still need to fix the MessageDeliveryException)    There is an error logged in the logs:    {code}  08:37:57022  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]  08:38:02685  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@4807f3e2 moduleName = 'twitterstream' moduleLabel = 'twitterstream' group = 'tweets' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map[[empty]] children = list[[empty]]]  08:38:02687  INFO main-EventThread module.ModuleDeployer - removed SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]  08:38:02705  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar - Path cache event: /deployments/modules/allocated/fa40cb45-3c16-4b19-81e9-eb6d357d186d/tweets.source.twitterstream.1 type: CHILD_REMOVED  08:38:02779  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream.  org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]:defaultcontainer:0.to.discardDeletes'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)    sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy81.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)    org.springframework.integration.x.twitter.TwitterStreamChannelAdapter.doSendLine(TwitterStreamChannelAdapter.java:154)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)    org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:553)    org.springframework.web.client.RestTemplate.execute(RestTemplate.java:521)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 33 more  08:38:02780  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream waiting for 250 ms before restarting  08:38:02781 ERROR task-scheduler-4 handler.LoggingHandler - java.lang.IllegalStateException: java.lang.InterruptedException: sleep interrupted    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:258)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.waitLinearBackoff(AbstractTwitterInboundChannelAdapter.java:232)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.access$600(AbstractTwitterInboundChannelAdapter.java:54)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:174)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:744)  Caused by: java.lang.InterruptedException: sleep interrupted    java.lang.Thread.sleep(Native Method)    org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:254)  	... 11 more  {code}";0
XD-1976;Unable to deploy job in UI This only happens when creating jobs via the CLI and deploying using the UI    On the job page:  http://localhost:9393/admin-ui/#/jobs/definitions    I click [Deploy] for a Job and get a screen asking for Container Match Criteria and Job Module Count - clicking on the [Deploy] button on that screen does nothing - I see this error reported:    Deploying Job Definition undefined angular.js:9778  TypeError: Cannot read property 'jobDefinition' of undefined      at Scope.$scope.deployDefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78)      at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21      at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17      at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)      at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23)      at HTMLButtonElement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21)      at HTMLButtonElement.jQuery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9)      at HTMLButtonElement.elemData.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778;0
XD-1978;SSL Support For RabbitMQ (Bus and Modules);0
XD-1979;Change xd.sink logging level to INFO The log sink is not writing information to the log.  Not the solution but when log4j.rootLogger is set to INFO the log sink information is written to the log.;0
XD-1982;Add Https Support to the HTTP Source;0
XD-1983;NodeExists Exception upon container disconnect/reconnect without admin leader When the container which has modules deployed disconnects/reconnects to the cluster while the admin leader isn't available following exception is thrown:  This is more likely to happen in single-node scenario as there is no admin leader re-election there. In distributed mode we can always setup HA on admins so that the leadership re-election happens.    20:03:16307 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache -   org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/allocated/53f41042-8abd-443b-abfb-ba42a24fb9fb/foo.sink.log.1/metadata    org.apache.zookeeper.KeeperException.create(KeeperException.java:119)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)    org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)    org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)    org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)    org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)    org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)    org.springframework.xd.dirt.server.ContainerRegistrar.writeModuleMetadata(ContainerRegistrar.java:486)    org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:461)    org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:426)    org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:807)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92);0
XD-1984;Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period reset the clock. When the wait period expires start deploying modules.;0
XD-199;Ensure the DELETE Operation can Delete a Tap While deleting a stream doesn't remove any taps right now we should be able to explicitly delete a tap.    Determine whether the current DELETE works and if not make it so.;0
XD-1990;Add Docs (or Reference) For Standard Shell Commands (e.g. script) http://stackoverflow.com/questions/24819401/how-to-get-spring-xd-to-deploy-a-predefined-set-of-streams-and-taps-on-startup    It is documented here https://github.com/spring-projects/spring-xd/wiki/Shell#executing-a-script    But maybe it should also be at the top of the appendix?    https://github.com/spring-projects/spring-xd/wiki/ShellReference;0
XD-1991;Error message about memory leak when ctrl-c xd-container and xd-admin e.g.     ^C09:42:00882 ERROR localhost-startStop-2 loader.WebappClassLoader - The web application [] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak.    The thread name may be different...;0
XD-1992;Release 1.0 RC1;0
XD-1993;Update rpm and brew recipes;0
XD-1995;Step execution count is zero for the job execution list result For the Job execution list the step execution count for each job execution is always set to zero.    For a single job execution display command the step execution count is set correctly.;0
XD-1998;Remove jersey test framework for xd/lib distribution The jars     jersey-test-framework-core-1.9.jar   jersey-test-framework-grizzly2-1.9.jar    are incorrectly classified as compile time deps in hadoop vs. testCompile.;0
XD-1999;Remove unused post module references;0
XD-2;HDFS Core writing helper classes Simple file writer that has existed in the spring hadoop samples.;0
XD-20;DIRT Runtime that deploys an application context across multiple nodes using redis.;0
XD-200;Creating a tap throws an exception Creating a tap throws an exception. In local mode: Cannot resolve reference to bean 'redisConnectionFactory' while setting constructor argument nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'redisConnectionFactory' is defined  But also fails when using redis.;0
XD-2000;Consider usage of jackson afterburner see https://github.com/FasterXML/jackson-module-afterburner;0
XD-2001;"REST API for DSL completion should allow extension The REST API for DSL completion currently returns a List<String>.  This prevents future backwards compatible extension. Should change to List<Completion> where Completion has e.g. a ""text"" property.";0
XD-2002;Rename packages that is applicable for both stream/job Determine a better package name for the following packages once we have a common model that applies to both stream/job:  `org.springframework.xd.dirt.stream`   `org.springframework.xd.dirt.stream.zookeeper`;0
XD-2004;Containers stopped responding to Admin SHA = a205d43f0b59e1984bf55c3368b031a373a03712  Environment: Rabbit Transport Test 1 admin 2 containers.    [Initial Event]  During the run of FileJdbcTest.testPartitionedFileJdbcJob the containers quit responding to the admin server.   After the initial failure at 12:26:46 no other streams can be deployed.      [Secondary Event]  When shutting down one of the container 1 the following exception occurs on the admin server:  12:51:12004  INFO DeploymentSupervisorCacheListener-0 server.DepartingContainerModuleRedeployer - Container departed: Container{name='5353dc4b-6068-49a0-8981-fa175869edf0' attributes={id=5353dc4b-6068-49a0-8981-fa175869edf0 host=domU-12-31-39-07-81-02 pid=1270 groups= ip=10.209.130.240}}  12:51:12004 ERROR DeploymentSupervisorCacheListener-0 cache.PathChildrenCache -   org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/5353dc4b-6068-49a0-8981-fa175869edf0    org.apache.zookeeper.KeeperException.create(KeeperException.java:111)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)    org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)    org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)    org.springframework.xd.dirt.server.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:101)    org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:104)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)    The attached container logs are only partial because they have rolled over.  The attached admin log is fairly complete.;0
XD-2005;IllegalStateException when shutting down container {noformat}  13:23:57643  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log' moduleLabel = 'log' group = 'paymenttap' sourceChannelName = 'tap:job:payment' sinkChannelName = [null] sinkChannelName = [null] index = 0 type = sink parameters = map[[empty]] children = list[[empty]]]  13:23:57643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exception  java.lang.IllegalStateException: instance must be started before calling this method  at com.google.common.base.Preconditions.checkState(Preconditions.java:176)  at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344)  at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292)  at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257)  at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711)  at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)  at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)  at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)  {noformat}    Sequence of events:  * Stream module ZK path is removed  * Event is raised  * ZK connection is closed  * Event handler causes module undeployment which includes unregistration of tap  * Since connection is closed exception is thrown;0
XD-2007;Acceptance test must be able to handle log names with PID suffix Introduced by XD-2006 admin and container logs will have a pid suffix appended to their filename.  The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the xd_container_log_dir.;0
XD-2009;Cleanup Module Deployer Container's module deployer (org.springframework.xd.dirt.module.ModuleDeployer) has some unused code and container-server.xml has listeners.xml which is no longer used. Also all the extension code is moved to SharedContextConfiguration.;0
XD-2013;Build scripts can refer hadoop distro sub projects in a unique place Based on this change https://github.com/spring-projects/spring-xd/commit/87b97a0b4651f862e8a639697745ad232bb42e6a The gradle build scripts now refer to two different places to check for the list of hadoop distro sub projects. We can simplify this to make it available in one place so that maintenance will be easier.;0
XD-2014;Investigate throwing of exception in BatchJobRegistryBeanPostProcessor The condition that leads to this exception does not seem like it would ever occur namely the BPP processing a job deployment for a job that was already deployed to the same container.;0
XD-2016;Reorganize TOC for manual Here is a strawman {noformat} Getting Started  (rather meaty compared to other top level sections maybe have a section - running in SingleNode) * Running in Distributed Mode * Running on YARN *Application Configuration Message Bus Configuration Monitoring and Management  Technical Documentation    Architecture Distributed Runtime  (remove 'XD' prefix) Interactive Shell Batch Jobs Streams Modules Tuples Sources Processors Analytics Sinks Taps Type Conversion Deployment  (better name?) Best Practices (new section)  Admin UI DSL Reference REST API  Samples  {noformat};0
XD-2018;Fix images alignment in reference pdf doc The reference pdf doc has some of the images not aligned well within the document.    For the latest doc from snapshot build please refer here:    http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/;0
XD-202;Update twittersearch module for Twitter 1.0 API retirement;0
XD-2020;Replace jps calls to get the PIDs for the container log with listRuntimeContainers Replace the execution of JPS to retrieve PID for the containers in the acceptance tests with runtimeOperations().listRuntimeContainers().;0
XD-2022;0xData - investigate embedding 0xData is a rich JVM based machine learning and scoring engine.;0
XD-2023;Update to Spring Hadoop 2.0.2 A bug in the HDFS Store was discovered that should be fixed.;0
XD-2026;Handle random available http port for admin server If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to '0' the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port.    We also need to persist the admin servers' ports into ZK so that this repo can be accessed by the client.;0
XD-2027;"Add docs for ""Creating a job Item Processor"" https://github.com/spring-projects/spring-xd/wiki/Creating-a-Job-Item-Processor    should be very brief introduction to this topic before linking to relevant spring batch documentation.";0
XD-2028;Add docs for creating a Job Module There are a few places in the doc we can reference regarding overall lifecycle of jobs but this should provide a basic recipe for a single step job.    The focus should be on creating a job item processor.    In particular how List<Message<Tuple>> as the payload.    this should link back to a new section in the aggregator that also mentions List<Message<Tuple>>    Change title from  Creating a Job Item Processor to Creating a Job Module;0
XD-203;Provided modules should be integration tested I don't see that we have automated tests for the modules we provide out-of-the-box.  We could make the modules folder an Eclipse project (which would also help solve XD-198) and add some integration tests similar to those documented here:    https://github.com/SpringSource/spring-xd/wiki/Creating-Custom-Modules;0
XD-2031;Improvements to Tuple project Removed  various TODO comments in code and put here for proper triage.    DefaultTuple    * Error handling.  When delegating to the conversion service the ConversionFailedException does not have the context of which key caused the failure.  Need to wrap ConversionFailedException with IllegalArgumentException and add that context back in.  (see method convert)   * Ctor visibility.  Consider making ctor final and package protect the ctor so as to always use TupleBuilder   * check for no duplicate values when initializing names/values list    tuple.  * top level methods to add.      String getComponentName... somethign that would indicate which stream or job this tuple is being processed in....    * TupleFieldSetMapper    Only one date format?    * JsonStringtoTupleConverter/JsonNodetoTupleConverter   * do we want to not map id and timestamp (believe the answer is don't map preserve original);0
XD-2032;Fix misc doc formatting issues Noticed a few issues while reviewing the documentation    * The sidebar for TOC is no longer there :(  That was really nice.  * Somehow the 'Using-MQTT-on-XD' section is giving an error.    {quote}  asciidoctor: WARNING: index.adoc: line 167: invalid style for paragraph: appendix  asciidoctor: WARNING: index.adoc: line 169: include file not found: /data/projects/spring-xd/build/asciidoc/guide/Using-MQTT-on-XD.asciidoc  :distZip  {quote}    but I don't notice anything different between that appendix and the others in index.adoc.;0
XD-2033;Connection pool settings need to be in their own section in server.yml The   #ConnectionPoolSettings    define this in the beginning -     {code}  #spring:  #  datasource:  {code}    uncommenting this will override/invalidate any changes made earlier in the section since it defines spring:datasource again    should either be removed or in separate section;0
XD-2034;"Custom location for modules.yml not working tried local xd-admin/xd-container after setting    {code}  export XD_MODULE_CONFIG_LOCATION=file:./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/config/  {code}    have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module    Also not working for me deploying on YARN this used to work at some point not sure how long ago I actually tested this part - M6/M7?    The setting used for YARN deployment:    {code}  -Dxd.module.config.location: ""file:./""  {code}";0
XD-204;Document processor modules Fill in https://github.com/SpringSource/spring-xd/wiki/Processors;0
XD-2040;Release 1.0 GA;0
XD-2041;Fix anchor links so that they work in both the wiki and generated docs Part of the issue is likely with the build script https://github.com/spring-projects/spring-xd/blob/master/build.gradle#L1859  We should also add a link checker to the CI build.;0
XD-2042;Update XD-EC2 & Acceptance Test Configs to use 1.0.1 repo * Update XD-EC2 configs to Pull from 1.0.1 Repo * Update XD-EC2 Configs to use spring-xd-1.0.1.BUILD-SNAPSHOT dir  * Update test configs XD_HOME to spring-xd-1.0.1.BUILD-SNAPSHOT instead of spring-xd-1.0.0.BUILD-SNAPSHOT;0
XD-2045;DeployUndeployDeploy Acceptance tests run back to back causes exception. SHA: 33de93797106c8dd413dfb08f2fdbbb4931b528c Deployment: 1 Admin 1 Container DataStore: MySQL  A SpringXDException is thrown when running the  testJobDeployUndeployFlow test in Acceptance tests back to back.  # Ran the test once.  Success # Ran the test a second time. ## The following exception is thrown: SpringXDException: Batch Job with the name deployundeployjob already exists  ## The XD_JOB_REGISTRY_STEP_NAMES & XD_JOB_REGISTRY still have job_name deployunderployjob still stored. ## The following Exception is seen on the admin server ### 20:45:59214  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob type: CHILD_ADDED 20:46:04741  INFO Deployer server.JobDeploymentListener - Deployment status for job 'deployundeployjob': DeploymentStatus{state=deployed} 20:46:05436  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob type: CHILD_REMOVED 20:46:12471  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob type: CHILD_ADDED 20:46:16330  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob type: CHILD_REMOVED 20:46:17819  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/deployundeployjob type: CHILD_ADDED 20:46:17832  INFO Deployer server.JobDeploymentListener - Deployment status for job 'deployundeployjob': DeploymentStatus{state=deployed} 20:46:17834 ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status   org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)   org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)   org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)   org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)   org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)   org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status   org.apache.zookeeper.KeeperException.create(KeeperException.java:111)   org.apache.zookeeper.KeeperException.create(KeeperException.java:51)   org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)   org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)   org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)   org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)   org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)   org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)   org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)   org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165) 	... 7 more  # Clear  XD_JOB_REGISTRY_STEP_NAMES & XD_JOB_REGISTRY tables and run the test a third time  # Ran the test a third time. ## The following exception is thrown: SpringXDException: The job named 'deployundeployjob' is already deployed ## The following Exception was reported by the admin server. ### 21:18:29355  WARN http-nio-9393-exec-4 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'deployundeployjob' state to undeploying org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/deployundeployjob/status   org.apache.zookeeper.KeeperException.create(KeeperException.java:111)   org.apache.zookeeper.KeeperException.create(KeeperException.java:51)   org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)   org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)   org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)   org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)   org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)   org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)   org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)   org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:174)   org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:196)   org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:54)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:77)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:103)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:111)   org.springframework.xd.dirt.rest.XDController.deleteAll(XDController.java:114)   sun.reflect.GeneratedMethodAccessor161.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)   org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:885)   javax.servlet.http.HttpServlet.service(HttpServlet.java:652)   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)   javax.servlet.http.HttpServlet.service(HttpServlet.java:727)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:257)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)   org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)   org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)   org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:683)   org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)   org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)   org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)   org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)   org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1040)   org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:607)   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1720)   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1679)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)   java.lang.Thread.run(Thread.java:745) # Ran the test a fourth time.  Success;0
XD-2047;Easier Customization of Headers Passed by RedisMessageBus http://stackoverflow.com/questions/25072967/spring-xd-redis-message-bus-removing-headers-from-the-message/25081538#25081538    Currently you have to modify {{redis-bus.xml}} in the dirt jar.;0
XD-2048;Do you have plan to support Spark? Do you have plans to support Spark? In version 1.0 GA Spring XD has supported Hadoop But it has not supported the brand new big data calculation platform Spark. do you have plans to support Spark in the future?;0
XD-2050;"HDFS sink Partition Path causing writes to be slower in certain cases I have not tested this on M7 but I believe it is the case with latest release as well.    Stream definition 1:  stream create logIngestion --definition ""rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10M --idleTimeout=10000 --fileUuid=true --directory=/data/loganalysis --partitionPath=path(payload.split('\u0001')[1]dateFormat('yyyy/MM/dd/HH'payload.split('\u0001')[0]'yyyyMMddHHmmss'))""    we noticed this was causing writes to be slower    Stream definition 2:  stream create logIngestion --definition ""rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10M --idleTimeout=10000 --fileUuid=true --directory=/data/loganalysis ""    but this definition caused the writes to be much faster.    Please note this was just a one time test I did and not reproduced multiple times.     Janne also seems to have reproduced this in another use case.    Thanks  Girish";0
XD-2051;Add ability to copy job from http site to containers Download zipped Job Modules from a HTTP Site and deploy them to modules on the admin & containers before container is started.;0
XD-2052;"Add new source modules As an user I'd like to have OOTB source modules to integrate with various data sources to ingest data using Spring XD.   Note: The OOTB support however is limited to currently available Spring Integration adapters.   Acceptance Criteria: - User should be able to list the 'new source' through DSL commands  - User should be able to optionally choose the ""new source"" adapters for stream creation using XD shell - User should see appropriate error messages if the required attributes are missing while creating a stream with the 'new source' module - After successful stream creation with the 'new source' module the definition should be included in stream listing - REST endpoints should include 'new source' definitions - Data ingested using the 'new source' should be validated for accurateness - Appropriate error/exception message needs logged if there's any problem ingesting data using 'new source' module";0
XD-2054;Add infrastructure support for Admin UI As an user I'd like to have the ability to setup infrastructure to develop/enhance UI functionality.  This is including but not limited to: - UI designs (mockup's) - Unit testing - CI - JS 'minification';0
XD-2057;Investigate Travis issues We are currently facing issues with Travis. Determine the root cause isolate the bottleneck and resolve the issues.;0
XD-2058;Investigate long running tests The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations.;0
XD-206;XD AdminMain & ContainerMain should check xd.home property from scripts Currently the system property xd.home is set as JVM_OPTS (via SPRING_XD_ADMIN_OPTS) into xd-admin & xd-container scripts.    Inside the ContainerMain & AdminMain we need to check if this system property is set and use it. It seems like this check is missing now.;0
XD-2063;Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput HA and scalability for various payload sizes.    Depends on testing infrastructure setup configuration and availability.;0
XD-2064;Update JClouds to 1.8 Have to update the code because of deprecation and to get ready for 2.0.;0
XD-2066;Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail.  This is because sometimes it takes 2 or more sends to get the data transmitted between modules.  With the current test structure this is considered a failure.  Is this the correct behavior?;0
XD-2067;Upgrade asciidoctor toolchain This will in turn allow us to get rid of the custom logic for handling crossref links between documents;0
XD-2068;Add support for specifying an undeploy-condition for stream definitions In some scenarios like when performing exploratory data-analysis on streaming data one often create a stream keep it running for some time (or until some condition is met) and then stop the stream and start to investigate the collected data.  It would be cool to be able to specify some undeploy condition like e.g. a timeout after x minutes no. of events collected a specific counter past a given threshold file-size greater then x etc.;0
XD-2069;Provide a way to debug the http source The http source does not provide debug logging to see information such as http headers and requests in particular if a non OK response is returned.    I updated the log4j config for org.jboss.netty but it had no effect.  I suspect this is due to the need to configure the netty logging system via InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory()).;0
XD-2070;Get rid of custom asciidoctor link: transformations Remove   {noformat}  		filter { line ->  			// TODO: refine regex to only match local documents  			def match = (line =~ /link:(.*?)#(.*?)\[(.*?)\]/)  			if (match) match.replaceAll('xref:$2[$3]') else line  		}    {noformat}    and replace link:Foo#bar by xref:Foo#bar;0
XD-2071;Modularize gradle build split out build.gradle into multiple files.;0
XD-2073;Create a Sink and Source for Riak;0
XD-2075;Add --binary Option to MQTT Source See http://stackoverflow.com/questions/25226527/mqtt-source-spring-xd/25227531#25227531;0
XD-2076;"Ability to send files as attachment (mail sink) I'd be very pratical if the mail sink has the ability to send files as attachment. I.e. add the attribute ""attachment-filename"" to header-enricher.";0
XD-2077;"Problem using twittersearch when system where container is running has two network interfaces. Problem using twittersearch when the system where the XD container is running has two network interfaces.  With the following config:  eth0      local network resolves `hostname`  eth1      internet network  I get an error deploying the stream:  {code} 12:08:22965  WARN twitterSource-1-1 client.RestTemplate - GET request for ""https://stream.twitter.com/1.1/statuses/sample.json"" resulted in 401 (Authorization Required) invoking error handler 12:08:22972 ERROR twitterSource-1-1 twitter.TwitterStreamChannelAdapter - Twitter authentication failed: 401 Authorization Required {code}  If I flip the network interfaces to be:  eth0      internet network resolves `hostname` eth1      local network    then it seems to work.";0
XD-2079;Add a Retry/Dead Letter Interceptor to the RabbitMQ Source Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus).;0
XD-208;Document the file sink;0
XD-2080;"Modules do not redeploy properly when Zookeeper node is lost. * SHA baddfc24b08286a78392d5f565742c9bab5adfea * EC2 Environment ** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology  h2. The test scenario  # Bring up a up a 5 container 2 admin XD Cluster up using 3 ZK Server ensemble. # Create ticktock  stream ""time|log"" # Deploy with --properties ""module.log.count=5"" # Kill one of the ZK Servers in the ensemble  h2. Observed Behavior.  # In this particular scenario 3 containers were affected by killing (sudo kill <pid>) Zookeeper 2 # 2 Containers did not come back online even though they did show up in the runtime containers   h2. Timeline # 14:08:21 deployed stream # 14:09:10 kill server in ZK Ensemble # After waiting a few seconds ran runtime Modules (*Note:* log2 is undeployed and log5 is then deployed)  :  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo expression=payload level=INFO}  {count=5 sequence=1}   foo.sink.log.2     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo expression=payload level=INFO}  {count=5 sequence=2}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1 format=yyyy-MM-dd HH:mm:ss}  {count=1 sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo expression=payload level=INFO}  {count=5 sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo expression=payload level=INFO}  {count=5 sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1 format=yyyy-MM-dd HH:mm:ss}  {count=1 sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo expression=payload level=INFO}  {count=5 sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo expression=payload level=INFO}  {count=5 sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1 format=yyyy-MM-dd HH:mm:ss}  {count=1 sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0   h2.  Undeploy and redeploy stream   # 14:16:42 Undeploy and redploy with module.log.count=5 xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo expression=payload level=INFO}  {count=5 sequence=1}   foo.sink.log.2     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo expression=payload level=INFO}  {count=5 sequence=2}   foo.sink.log.5     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo expression=payload level=INFO}  {count=5 sequence=5}   foo.source.time.1  98a32c62-302a-484b-af9c-d670f2a3cfc2  {fixedDelay=1 format=yyyy-MM-dd HH:mm:ss}  {count=1 sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0    # 14:21:06 undeploy foo";0
XD-2081;"Container does not fail if sharing same ports on same machine with another container. * SHA baddfc24b08286a78392d5f565742c9bab5adfea * EC2 Environment ** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology  h2. The test scenario  # Can be duplicated with single server ZK ensemble # Start Container on a EC2 instance.  Wait till it joins cluster # Start 2nd container on same EC2 instance.  h2. Observed Behavior.  # Container 1 starts normally # Container 2 reports that failed to bind to address.  (shown in attached stack trace) ## But does not terminate  ## Shown as valid container when executing ""runtime containers"" command. xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes    0c88a300-9469-4f21-a256-7733259b13c7  ip-10-70-11-185   10.70.11.185   2061   256c35b7-c9f4-43ba-81dd-e1bfff0fb7c1  ip-10-70-9-57     10.70.9.57     3604   31fedc48-2762-4c45-8075-1dce64af5391  ip-10-110-186-48  *10.110.186.48*  2396  GROUPA   524bb933-a8b5-4014-a0b5-06d4fa8b30c2  ip-10-2-209-174   10.2.209.174   2123   e993026e-e2ac-4d16-9890-0786149d7b75  ip-10-110-186-48  *10.110.186.48*  2524  GROUPA   f9437b15-1ee2-4827-99d4-e7957f9abdf2  ip-10-70-9-153    10.70.9.153    2366  GROUP0";0
XD-2082;Investigate how to provide a means to share bean defintions across module instances In some cases it maybe useful to share a specific bean instance contributed by a user across multiple module instances.  This story is a placeholder to collect requirements and discuss.;0
XD-2083;singlestep-partition-support needs to allow grid size to be configurable h3.  Narrative As a developer I need to be able to configure a partitioned job's grid size so that the correct number of partitions are created (the current code is hard coded to 1 for the grid size).  h3.  Acceptance Criteria # Expose the gridSize attribute of the {{MessageChannelPartitionHandler}} as an option.  h3.  Assumptions # Existing OOTB jobs should not be impacted by this given they don't use the grid size.;0
XD-2086;Research how to handle data encryption within pipeline Design Spike: Investigate best approach to encrypt data pipeline. Consider all moving parts within the topology including the scenarios where data is at rest and as well as in transit.;0
XD-209;Create or document existing project template for custom module creation The wiki docs on creating custom modules have entire build.gradle files in them. Would be good to explore existing STS templates maven archetypes etc or create new ones for authoring custom modules.;0
XD-2091;Research approach to bootstrap custom modules Design Spike: Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?;0
XD-2093;"List Streams/Jobs based with deployed modules Currently there is a ""stream list""/""job list"" which shows the status of a given stream/job along with the DSL. and there is ""runtime modules"" which shows all the deployed modules with their container info.    We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status.";0
XD-2099;Remove unavailable jobs If a job is deployed an the singlenode job is canceled the job name cannot neither be reused nor destroyed. See screenshots.;0
XD-2100;Create XD source from POJO annotated @Source XD Module configured for component scanning classes (or methods?) annotated with @Source (consider @Processor and @Sink as well) and simply provide the POJOs and dependent jars in the module /lib directory. Custom processor is fairly straightforward currently but still requires an XML module definition to wire up the POJO as a service activator or transformer to the input and output channel. A service activator works for a POJO backed sink. Writing a source that is not backed by an existing inbound channel adapter is a bit more involved and requires more than basic familiarity with SI. It should be possible for XD to automatically create a polling source by wiring a Java method to an inbound adapter configured with a poller. Ideally we would require no XML even to enable component scanning- this will require some changes to the module registry/module initializer.;0
XD-2107;Allow aggregate-counter to increment by some value of the message Currently the aggregate counter only adds +1 to the individual values even though support is there to add any increment.    This ticket is about surfacing a SpEL expression on the message to choose the increment;0
XD-2108;Show Stream / Tap relationship in Admin UI It would be nice if the admin ui would sort the streams in such a way that the taps that are created for a particular stream are somehow placed UNDER the tapped stream... {code} Stream A ...  +-Tap A.foo ...  +-Tap A.bar ... {code}  Same goes for the list command in the XD-Shell;0
XD-211;Document the log sink;0
XD-2110;XD-EC2 needs to provide ability to use a preinstalled zip vs downloading from s3 [Current Behavior] Currently XD-EC2 downloads an XD zip file from the location specified by the xd-dist-url after verifying that the file is accessible..;0
XD-2112;User wants to select the ec2 zone when deploying XD Currently the application allows AWS select which zone in the region to create an instance.;0
XD-2117;Spring XD very poor performance when using redis as transport When using redis as transport bus there is a problem when using many streams and taps. Basically the maxTotal parameter of org.apache.commons.pool2.GenericObjectPool default is 8. After some streams are deployed it starts to occur concurrency problems hence the number of inbound redis channel adapters is larger than that number.    A more detailed explanation is in stackoverflow:    http://stackoverflow.com/questions/25851660/spring-xd-very-poor-performance-when-using-redis-as-transport;0
XD-212;Add http port command line option to AdminMain Currently StreamServer has setPort but no way for end user to set it.;0
XD-2139;Add ftp sink to default sink modules It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.;0
XD-214;Create documentation on the general DSL syntax The asciidoc wiki should have a section (included in the _Sidebar.asciidoc as well) that describes the general usage of the DSL syntax.;0
XD-2140;"Deployment properties should use label instead of name stream create foo --definition ""label: bar | xxxx""  stream deploy foo --properties ""module.label.yyy=zzz"" seems to work but it does not. The pre-validation is correct but downstream deployment logic still looks for module.bar (instead of module.label)";0
XD-2141;XD Cluster view: improve hover over capabilities Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1183#issuecomment-55917701;0
XD-2142;XD Cluster view: create container details page Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1183#issuecomment-55917701;0
XD-2149;Remove un-necessary libs from shell Shell currently adds all jars from xd/lib to its classpath.  Remove jars that are not needed to run shell.;0
XD-2152;Support XD as a service on PCF;0
XD-2156;Support XD Runtime on Docker;0
XD-216;Add support for tap foo.bar syntax in the DSL;0
XD-2167;Provide support for XD Runtime on Vagrant;0
XD-2170;NoNodeException for job creation The following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398    {noformat}  ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/NNNN/modules    org.apache.zookeeper.KeeperException.create(KeeperException.java:111)    org.apache.zookeeper.KeeperException.create(KeeperException.java:51)    org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1586)    org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)    org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)    org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)    org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)    org.springframework.xd.dirt.server.JobDeploymentListener.recalculateJobStates(JobDeploymentListener.java:197)    org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:389)    org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)    org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)    org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)    org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)    org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)    org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)    java.util.concurrent.FutureTask.run(FutureTask.java:266)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)    java.util.concurrent.FutureTask.run(FutureTask.java:266)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)  {noformat}    No specific details on reproducing yet although the Socialcast thread indicates:    {quote}  I only hit this when I have tried to deploy a job that fails deployment the first time  {quote};0
XD-2171;Document Kafka source;0
XD-2172;Provide a way to customize the isolation level of the JobRepository The Gemfire XD database cannot be used to store the Spring XD metadata because the former doesn't support the default Spring Batch transaction isolation level ISOLATION_SERIALIZABLE.  There looks to be no way to configure the Spring XD's internal Spring Batch JobRepository with another isolation level.  The JobRepository instance is getting created with default settings by the Spring Batch'es {{SimpleBatchConfiguration}} and there are no custom {{BatchConfigurer}}s available to change the default settings of the JobRepository.;0
XD-2173;"Shell does not report failed deploy attempt During the slow network tests the user undeployed a stream and then immediately redeployed the same stream to get the modules on different containers.  The deployment failed as reflected in the stacktrace below from the admin server however the the shell did not report an error and the user could not deploy the stream.   * The stream in question is ""http|log""  * The Shell did not report any error.   * Stream list does show the state of the stream as failed.  * executing a stream deploy fails with the following error:     ** Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'foo' is already deployed  * Undeploy and deploy of the stream worked.   17:54:39487  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failederror(s)=org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/73f0a93d-e213-414d-8337-6c04409ec210/foo.source.http.1/status   org.apache.zookeeper.KeeperException.create(KeeperException.java:111)   org.apache.zookeeper.KeeperException.create(KeeperException.java:51)   org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)   org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)   org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)   org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)   org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)   org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)   org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)   org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:205)   org.springframework.xd.dirt.server.ModuleDeploymentWriter.writeDeployment(ModuleDeploymentWriter.java:163)   org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:166)   org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)   org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)   org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) } 17:54:39496  INFO Deployer server.StreamDeploymentListener - Stream Stream{name='foo'} deployment attempt complete";0
XD-2175;"Throughput in a stream with any processor One of the goal for a micro benchmark is to compare throughput difference  between two types of streams: 1. source | sink 2. source | processor | sink  For this test I used reactor-tcp source throughput-sampler as sink and created a NoOp processor. Tests were performed on a single node container with direct binding turned on for all streams.  1. Throughput for ""source|sink""  {noformat} stream create reactortcp --definition ""reactor-ip --transport=tcp --port=4000 | throughput-sampler"" stream deploy reactortcp --properties module.*.count=0 {noformat}  On my system I get following numbers: Throughput sampled for 5000000 items: 345423/s in 14475ms elapsed time  2. Throughput for ""source|processor|sink""  Code for NoOpProcessor is available here: https://github.com/parikhkc/xd-noop-processor  {noformat} stream create reactornoop --definition ""reactor-ip --transport=tcp --port=5000 | noopprocessor | throughput-sampler"" stream deploy reactornoop --properties module.*.count=0 {noformat}  On the same system the throughput reduces to less then 70K/sec. Throughput sampled for 5000000 items: 67250/s in 74349ms elapsed time  Yourkit shows 50% of CPU time on following thread:  {noformat} * ringBuffer-17 [RUNNABLE] [DAEMON] java.lang.reflect.Method.getParameterAnnotations() Method.java:770 org.springframework.xd.integration.reactor.net.NetServerInboundChannelAdapter$1.accept(Object) NetServerInboundChannelAdapter.java:53 reactor.net.AbstractNetChannel$3.accept(Event) AbstractNetChannel.java:131 reactor.net.AbstractNetChannel$3.accept(Object) AbstractNetChannel.java:128 reactor.event.routing.ArgumentConvertingConsumerInvoker.invoke(Consumer Class Object) ArgumentConvertingConsumerInvoker.java:73 reactor.event.routing.ConsumerFilteringEventRouter.route(Object Event List Consumer Consumer) ConsumerFilteringEventRouter.java:78 reactor.event.dispatch.AbstractLifecycleDispatcher.route(AbstractLifecycleDispatcher$Task) AbstractLifecycleDispatcher.java:64 reactor.event.dispatch.AbstractSingleThreadDispatcher$SingleThreadTask.run() AbstractSingleThreadDispatcher.java:50 reactor.event.dispatch.RingBufferDispatcher$3.onEvent(RingBufferDispatcher$RingBufferTask long boolean) RingBufferDispatcher.java:115 reactor.event.dispatch.RingBufferDispatcher$3.onEvent(Object long boolean) RingBufferDispatcher.java:112 com.lmax.disruptor.BatchEventProcessor.run() BatchEventProcessor.java:128 java.lang.Thread.run() Thread.java:745  {noformat}";0
XD-2176;"Module (re) deployment failed after ZK Cluster Ensemble lost quorum When simulating a slow network by deploying a Zookeeper with 3 nodes. * Zookeeper 1 (follower)was located at US-East-1 * Zookeeper 2 (follower) was in Sydney  * Zookeeper 3 (Leader) was in Sydney XD Admin and containers were running in US-East-1 Zone  In this case we simulated a loss of quorum by killing the zookeeper 2 (follower in Sydney).  All modules were undeployed.  When I restarted the zookeeper 2 all containers and admin recognized the ensemble was up and tried to redeploy the modules but the stream was left in a ""Failed"" state.  Steps to reproduce:  * Deploy Stream ""http|file"" * Start Data Flow to stream from JMeter * Terminate ZK Follower in AU * Restart ZK Follower in AU  The workaround is to undeploy and deploy the stream.";0
XD-2177;Add support for Pivotal HD 2.1 (XD 1.0.2 Release) *XD 1.0.2 Release + PHD 2.1 Upgrade - Action Items:*    * Update to SHDP 2.0.3  * Add Hadoop 2.5 (hadoop25)  * Change PHD 2.x from phd20 to phd21  * Test PHD 2.0 with phd21   * Document that both PHD 2.1 and PHD 2.0 is supported with phd21;0
XD-218;Add support to load a twitter.properties file in the source;0
XD-2183;Fix 'cluster/containers' REST endpoint with security enabled Once the container's management server is secured the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.;0
XD-2185;Fix 'cluster/containers' REST endpoint with security enabled Once the container's management server is secured the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.;0
XD-2186;Fix 'cluster/containers' REST endpoint with security enabled Once the container's management server is secured the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.;0
XD-2187;"testHdfsSink  sporadically fails because twitter data is written to file. The hdfs sink needs to have a unique stream name.  Because the twitterSearch test uses the ""defaultName"" and it may broadcast more than one message to the sink for the search.  So when the stream is destroyed the message is abandoned until hdfsTest starts up using the same  ""defaultName"" and the message is delivered to hdfs sink and thus the twitter data is written to the file.";0
XD-2189;Fix 'cluster/containers' REST endpoint if security is enabled If the security is enabled for the container then admin server won't be able to fetch the message rates for the deployed modules in that container.  The REST endpoint 'cluster/containers' needs to be fixed.;0
XD-2193;Add authentication support to the mongo sink;0
XD-2195;Have counters use Double arithmetic instead of Long Now that we have --incrementExpression we often want to increment by some domain specific value that may not be integral (e.g. Watts in smartgrid demo);0
XD-2196;Refactor ContainerRegistrar Decouple from DeploymentListener. Make DL a public class to handle deployment related events.  Remove createSimpleModule() and createComposedModule() from DL.  This will be delegated to ModuleDeployer which will eventually be further refactored to use the proposed ModuleFactory.;0
XD-2198;Create CompositeModuleRegistry Currently there is no ModuleRegistry contract for composite modules. The composed module definition is maintained in ZooKeeperModuleDefinitionRepository which delegates to the ModuleRegistry to define and validate component modules. The repository should be converted to a ModuleRegistry.;0
XD-2199;Simplify ModuleRegistry MR is responsible for looking up existing module definitions by name and type.  ModuleDefinition should contain name type and resource where resource is a springframework.core.io.Resource containing the root path of the module definition. This could be file classpath http hdfs or something else but the contents under this path will not be inspected or processed by MR. The exception is for composite modules which should contain a list of corresponding Resources.    Simplify ModuleDefinition - remove classpath. Provide support for CompositeModuleDefinition - requires a list of resources (possibly a subclass)    Also retire RedisModuleRegistry;0
XD-220;Add twitter oauth properties file to config dir Those property keys should then be provided as defaults for the placeholders in source/twittersearch.xml;0
XD-2201;"Exception in a tap will stop the tapped stream from sinking data Exception in a tap will stop the tapped stream from sinking data.  h2. Background Running xd-singlenode. We experienced this when streaming data from a rabbit queue to hdfs. The stream was tapped and we had a groovy processor on the tap stream. Any exceptions in the processor stopped the main stream from writing data to the hdfs sink.  h2. Steps to reproduce. 1: Create a groovy script that throws an exception in  modules/processor/scripts/exceptionthrower.groovy. Code below {code} /**  * Custom processor to be wired into a tap to throw an exception.  */  throw new RuntimeException(""Error from processor"") {code} 2: Create a sample main stream {code} xd:>stream create --name ticktock --definition ""time | log"" --deploy {code} 3: Tail the log to confirm the data is going to the sink. We see  'sink.ticktock' appearing in the log as expected. 4: Add a tap to the stream that will throw an exception. {code} xd:>stream create --name exTap --definition ""tap:stream:ticktock > script --location=exceptionthrower.groovy | log"" --deploy {code} 5: Tail the log and we see that there are no more 'sink.ticktock' strings being logged. Looks like the main stream is no longer sending messages to the sink.";0
XD-2209;Add acceptance test to include Gemfire use case To enrich acceptance test I'd like to have basic coverage to evaluate Gemfire use cases.     An example would be to ingest data from HTTP source and write it to Gemfire server.;0
XD-221;"Links in asciidoctor generated HTML+docbook documentation are broken The issue arises because the link:document[Label] asciidoc macro is meant for ""external documents"" and creates {{<ulink>}} in docbook / {{<a href=""document"">}} in html whereas we want {{<link linkend=""anchor"">}} / {{<a href=""doc#anchor>}} resp. We also want it to continue working in github live view.    I guess what could work is to have the macro (either override the link macro or create our own if github supports that) that looks like :  {{link:document#anchor[Label]}}  (the #anchor works out of the box in asciidoc and should work in github) but override it for the html and docbook backends to render to the correct form.    The thing is there are several ways to create/override macros (and templates they render to) some of which make sense to our setup:  - having asciidoc.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)  - having docbook.conf/html.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)  - defining macros using attributes (http://asciidoc.org/userguide.html#_setting_configuration_entries)    I tried all of those but to no avail. These DO WORK with plain asciidoc but not with our toolchain. Don't know if the problem is with asciidocTOR or with the gradle wrapper though.";0
XD-2210;Enhance JDBC sink test to include more options To enrich acceptance test I'd like to add coverage to JDBC sink by including *-- driverclass* and *-- url* options.;0
XD-2217;Generated pom does not include spring boot 1.1. dependency The change in XD 1.0.1 to use Spring Boot 1.1.7 meant that we can't pickup the boot dependency by importing the platform-bom.  Andy W's suggestion is to change the generated pom to refer to the platform-bom as a parent (not import) and then declare the explicit dependency on Boot 1.1.7;0
XD-222;Add docs for Deleting a simple stream. curl -X DELETE http://localhost:8080/streams/ticktock;0
XD-2224;REST: Make the Configurations REST endpoint pagination-aware Add pagination for:    http://localhost:9393/jobs/configurations    Related to XD-1864;0
XD-2225;REST: Make the Job Execution REST endpoint pagination-aware Implement pagination for:    http://localhost:9393/jobs/executions;0
XD-2227;Need to set small commit level for Acceptance tests. XD-2180 introduced a default commit level for jobs to be 1000 vs the original 100.  Now tests sporadically fail.  Need to set the --commitInterval for the tests to a small value.;0
XD-223;Update Creating a Custom Source Module doc with a different SI adapter due to Twitter issues https://github.com/SpringSource/spring-xd/wiki/Creating-a-Source-Module uses the SI twittersearch inbound channel adapter which is no longer going to work once Twitter disallows anonymous searches.     Ideally we update the example to use a new version of SI-twitter that adds support for this (as opposed to the XD workaround.);0
XD-2233;"REST representation of an aggregate-counter can lead to mixed up output The current representation of REST resources of time-series data (e.g. aggregate counter) can lead to problems in consuming applications.  Despite the time series data provided by the ""counts"" data structure is logically ordered by key (timestamps) it doesn't guarantee an ordering since many consuming applications interpret JSON data as an unordered map like data structure.  Because of this consuming applications have to apply special ordering / transformation logic to get the data in an chronologically ordered fashion. It would be helpful if one could configure the rendering of the time series data e.g. as a list of json object like: {code:json} {  ""ts"":""Sun Oct 12 23:10:23 CEST 2014""  ""value"": 42 }  {code} Where {{ts}} denotes the timestamp and {{value}} denotes the value. It would also be helpful if one could adjust the date format either with a pattern or a well known date format like c.f.  {{ISO 8601}}.  I attached a python example for this that demonstrates the problem.  Steps to reproduce: Create stream {code} xd:>stream create test --definition ""http | filter --expression=payload.contains('pivotal') | log"" {code}  Create tap on stream with aggregate-counter {code} xd:>stream create test_tap --definition ""tap:stream:test.filter > aggregate-counter"" {code}  Post some http data {code} xd:>http post --data ""Hello pivotal data labs"" #...some more data... {code}  Display aggregate counter {code} xd:>aggregate-counter display test_tap --resolution minute   AggregateCounter=test_tap   -----------------------------  -  -----   TIME                           -  COUNT   Sun Oct 12 23:10:23 CEST 2014  |  0   Sun Oct 12 23:11:23 CEST 2014  |  0   Sun Oct 12 23:12:23 CEST 2014  |  0   Sun Oct 12 23:13:23 CEST 2014  |  0   ...   Mon Oct 13 00:02:23 CEST 2014  |  0   Mon Oct 13 00:03:23 CEST 2014  |  0   Mon Oct 13 00:04:23 CEST 2014  |  0   Mon Oct 13 00:05:23 CEST 2014  |  0   Mon Oct 13 00:06:23 CEST 2014  |  0   Mon Oct 13 00:07:23 CEST 2014  |  0   Mon Oct 13 00:08:23 CEST 2014  |  3   Mon Oct 13 00:09:23 CEST 2014  |  1 {code}  Install python Requests library (REST support) {code} pip install Requests {code}  Start a python console (or IPythonNotebook) and run the following program: {code:python} import requests import json  res = requests.get(""http://localhost:9393/metrics/aggregate-counters/test_tap?resolution=minute"") status_object = json.loads(res.content) print(json.dumps(status_object indent=4)) {code}  The above program should result in a similar output but as one can see due to pythons interpretation of the JSON object as a dict the order of the keys in the output got mixed up.   Instead of showing the counts ....3 and then 1 ... as in the example above. This is just one example of how the current representation of the rest resource could lead to problems in consuming applications.   {code:json} {     ""counts"": {         ""2014-10-12T21:26:28.553Z"": 0         ""2014-10-12T22:15:28.553Z"": 0         ""2014-10-12T22:22:28.553Z"": 0         ""2014-10-12T21:49:28.553Z"": 0         ""2014-10-12T21:35:28.553Z"": 0         ""2014-10-12T21:47:28.553Z"": 0         ""2014-10-12T22:18:28.553Z"": 0         ""2014-10-12T22:12:28.553Z"": 0         ""2014-10-12T22:16:28.553Z"": 0         ""2014-10-12T21:57:28.553Z"": 0         ""2014-10-12T21:28:28.553Z"": 0         ""2014-10-12T22:08:28.553Z"": 3         ""2014-10-12T21:40:28.553Z"": 0         ""2014-10-12T22:06:28.553Z"": 0         ""2014-10-12T21:27:28.553Z"": 0         ""2014-10-12T21:52:28.553Z"": 0         ""2014-10-12T22:11:28.553Z"": 0         ""2014-10-12T22:05:28.553Z"": 0         ""2014-10-12T21:29:28.553Z"": 0         ""2014-10-12T21:24:28.553Z"": 0         ""2014-10-12T21:56:28.553Z"": 0         ""2014-10-12T21:43:28.553Z"": 0         ""2014-10-12T22:00:28.553Z"": 0         ""2014-10-12T22:10:28.553Z"": 0         ""2014-10-12T21:58:28.553Z"": 0         ""2014-10-12T22:21:28.553Z"": 0         ""2014-10-12T21:32:28.553Z"": 0         ""2014-10-12T21:46:28.553Z"": 0         ""2014-10-12T22:04:28.553Z"": 0         ""2014-10-12T22:02:28.553Z"": 0         ""2014-10-12T21:51:28.553Z"": 0         ""2014-10-12T21:38:28.553Z"": 0         ""2014-10-12T21:31:28.553Z"": 0         ""2014-10-12T22:20:28.553Z"": 0         ""2014-10-12T21:54:28.553Z"": 0         ""2014-10-12T22:07:28.553Z"": 0         ""2014-10-12T22:03:28.553Z"": 0         ""2014-10-12T21:34:28.553Z"": 0         ""2014-10-12T22:09:28.553Z"": 1         ""2014-10-12T21:44:28.553Z"": 0         ""2014-10-12T22:17:28.553Z"": 0         ""2014-10-12T21:53:28.553Z"": 0         ""2014-10-12T22:19:28.553Z"": 0         ""2014-10-12T21:30:28.553Z"": 0         ""2014-10-12T22:23:28.553Z"": 0         ""2014-10-12T21:36:28.553Z"": 0         ""2014-10-12T21:41:28.553Z"": 0         ""2014-10-12T22:13:28.553Z"": 0         ""2014-10-12T21:59:28.553Z"": 0         ""2014-10-12T22:01:28.553Z"": 0         ""2014-10-12T21:33:28.553Z"": 0         ""2014-10-12T21:45:28.553Z"": 0         ""2014-10-12T21:39:28.553Z"": 0         ""2014-10-12T21:50:28.553Z"": 0         ""2014-10-12T21:37:28.553Z"": 0         ""2014-10-12T22:14:28.553Z"": 0         ""2014-10-12T21:25:28.553Z"": 0         ""2014-10-12T21:55:28.553Z"": 0         ""2014-10-12T21:42:28.553Z"": 0         ""2014-10-12T21:48:28.553Z"": 0     }     ""name"": ""test_tap""     ""links"": [         {             ""href"": ""http://localhost:9393/metrics/aggregate-counters/test_tap""             ""rel"": ""self""         }     ] } {code}";0
XD-2235;Basic authentication realm is always 'null' Besides the Basic authentication realm being always {{null}} {{security.basic.realm}} is always ignored.;0
XD-2237;Provide Python module to handle I/O for implementing a Python shell processor;0
XD-2238;"Improve module deployment distribution When a container joins the XD cluster (via ZooKeeper) it triggers stream/job module deployments for modules that need to be deployed. If multiple containers are being started at around the same time this can result in the first few containers taking all of the deployments while leaving the rest without any deployments.    To solve this we will introduce a ""quiet period"" where no deployments will be triggered within _n_ seconds of a container joining where _n_ will have a default value (perhaps 5 to 10 seconds). This value will be configurable.";0
XD-224;Reduce necessity for quoting in parameter values in DSL expressions parameter values that include spaces need to be quoted but this becomes overly complex in this kind of case.  Here is what you want to say:    {code}  http --port=9995 | filter --expression=payload.matches('hello world')  {code}    With the rule 'parameter values that contain spaces must be quoted' it would be this:    {code}  http --port=9995 | filter --expression='payload.matches('hello world')'  {code}    But then to include single quotes within a single quoted string you need to use two of them: '' - so it becomes    {code}  http --port=9995 | filter --expression='payload.matches(''hello world'')'  {code}    Less than ideal.;0
XD-2240;Redis sink: better handling of module options/profile activation Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1188#discussion_r18788216;0
XD-2241;"NoNode Exception in SpringXD Admin Sorry to set it ""Blocker"" but the problem makes SpringXD unusable. We are getting this weird NoNode exception on the status ZNode. Example and Log given below. Once this happens both streams and jobs cannot be deployed. For whatever reason the ""status"" znode goes missing.    The only way for us to get the cluster back to working state is to clear the zk znode /xd tree and restart spring-xd. At which point we have to recreate all our streams and jobs back again..   /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status  NoNode Exception:  13 Oct 2014 14:16:16044   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testDestroyStream1413234903170 type: CHILD_REMOVED 13 Oct 2014 14:16:16705   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170 type: CHILD_ADDED 13 Oct 2014 14:16:22818   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170 type: CHILD_REMOVED 13 Oct 2014 14:16:23585   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170 type: CHILD_ADDED 13 Oct 2014 14:16:37694   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001 type: CHILD_ADDED 13 Oct 2014 14:16:49950   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170 type: CHILD_REMOVED 13 Oct 2014 14:16:54490   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'testCreateStream_SrcHttp_SinkFile1413234903170': DeploymentStatus{state=failederror(s)=Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170' type=sink label='file'}' to container 'd03bccd6-524b-4ff8-84d2-88f3f6daac42' timed out after 30000 ms Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170' type=source label='http'}' to container '52abf1c8-ba45-4994-8324-6079b03c670c' timed out after 30000 ms} 13 Oct 2014 14:16:54493  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:185)         at org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:179)         ... 7 more 13 Oct 2014 14:16:56251   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001 type: CHILD_REMOVED 13 Oct 2014 14:17:08179   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-newjob001': DeploymentStatus{state=failederror(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-newjob001' type=job label='filepolltimeseries'}' to container '244d5076-f69d-42a4-8110-3b046cea2667' timed out after 30000 ms} 13 Oct 2014 14:17:08181  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)         at org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165)         ... 7 more 13 Oct 2014 14:17:10553   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001 type: CHILD_ADDED";0
XD-2242;NullPointerException while fetching runtime containers In SpringXD ver 1.0.1 runtime/containers fetches additional runtime modules information for each container.  When a user queries the runtime containers while a stream is being deploy it throws a NullPointerException.  See below:  15:56:02829  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: path=/deployments/streams/testCreateHTTPStream_postData1413327352991 type=CHILD_ADDED 15:56:02935  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='testCreateHTTPStream_postData1413327352991'} 15:56:05069 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request java.lang.NullPointerException   org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)   org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)   org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)   org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)   sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)   org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)   javax.servlet.http.HttpServlet.service(HttpServlet.java:620)   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)   javax.servlet.http.HttpServlet.service(HttpServlet.java:727)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)   org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)   org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)   org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)   org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)   org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)   org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)   org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)   org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)   org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)   org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)   java.lang.Thread.run(Thread.java:724);0
XD-2244;"Streams sending to Job Queue issue Look at the below Stream definition. This gets to ""deployed"" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state.     Here is an example of the Stream definition:    stream create --name jobName --definition ""file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"" --deploy";0
XD-2247;Log version number in log files When answering support questions the first step is to determine what version of the software the customer is using. This question can be easily answered if we log the version as one of the fields in the log file. For example:    {noformat}  10:44:21212 1.0.2.BUILD-SNAPSHOT  INFO DeploymentSupervisorCacheListener-0 server.ContainerListener - Container arrived: Container{name='431baa56-b23b-48fc-b37d-18b52231e799' attributes={ip=192.168.25.177 host=Patrick-Peralta-MacBook-Pro.local groups= pid=38004 id=431baa56-b23b-48fc-b37d-18b52231e799}}  {noformat}    This way when we receive log snippets (initial support inquires rarely include the entire log file) we can immediately determine if the issue has already been fixed in a later release.;0
XD-2249;"Automatically disable autostartup in module SmartLifeCycle components Provide a BPP to do this in the StreamPlugin.  (Possibly JobPlugin as well). Remove auto-startup=""false"" in existing module configs.";0
XD-2251;The HTTP Source creates the ChannelPipeline inefficiently The ChannelPipelineFactory used by the HTTP source should cache expensive objects used by the ChannelPipeline between requests because creating them every time is inefficient (and in the case of HTTPS it can become even more expensive).;0
XD-2252;Measure baseline performance of RabbitMQ using PerfTest (In-house);0
XD-2254;Vary message size (DB-2) Use a single producer single consumer prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.    Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.    *Message Sizes:*  100 bytes  1000  10000  100000     During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.;0
XD-2256;Vary consumers size (DB-4) Using a single producer message size of 1000 bytes Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.    Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.    *Number of consumers:*  * 1  * 2  * 4  * 6  * 10  * 50    During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.;0
XD-2259;Infrastructure for RabbitMQ Cluster (DB) Pre-requisite for Rabbit MQ Benchmarks:    * Infrastructure setup  * Configuration changes  * Tool-chain setup;0
XD-226;"Cleanup and Optimize gradle tasks to bundle spring-xd distribution We need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions.     Currently distXD does the copy of distributions from ""spring-xd-dirt"" ""redis"" and ""spring-xd-gemfire-server"" projects into ""$rootDir/dist/spring-xd"".    And the task ""zipXD"" makes the zip archive.    These tasks should be combined with the ""distZip"" & ""docZip"" tasks.    We also need to remove the duplicate artifacts configuration from these tasks.";0
XD-2262;Document 'idleTimeout' setting Document --idleTimeout setting to not exceed the HDFS timeout value.;0
XD-227;Add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the XD classpath This is needed for the use of the webhdfs:// scheme to talk to HDFS over http.;0
XD-2271;Upgrade to Spring Integration 4.1.0 As to prepare for 1.1 release we would like to upgrade to Spring Integration 4.1.0 (RC) so that we can leverage the new features enhancement and bug fixes.;0
XD-2274;Intermittent TcpModulesTests.testTcpSink test failure {noformat}  org.junit.ComparisonFailure: org.junit.ComparisonFailure: expected:<[Hi there!  ]> but was:<[]>  org.junit.ComparisonFailure: expected:<[Hi there!  ]> but was:<[]>    org.junit.Assert.assertEquals(Assert.java:115)    org.junit.Assert.assertEquals(Assert.java:144)    org.springframework.xd.shell.command.TcpModulesTests.testTcpSink(TcpModulesTests.java:63)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  (60 more lines...)  {noformat}    https://build.spring.io/browse/XD-JDK8-JOB1-1162/test;0
XD-2278;Vary queue number (ECB-7) Based on the the results from B-6 select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ‘top’ for the broker and PerfTest processes.      Test 1 (2 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 2 (3 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  Test 3 (4 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500  Test 4 (5 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500  etc.;0
XD-2281;Vary Producer and Consumer in combination using 2 Queues (B-6) The results from EC2 testing show that once prefetch and message size are set varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies.     Using 500 prefetch 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.    Test 1 (one producer / one consumer):  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 2 (one producer / two consumers):  * -a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500    Test 3 (two producers / one consumer):  * -a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500  * -a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500    Test 4 (two producers / two consumers):  * -a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500;0
XD-2283;Vary queue number on 32 core machine (ECB-8) Rerun test XD-2278 on a EC2 32 core machine and see when we max out.;0
XD-2285;"Change composed module behavior to ""black box"" Composed Module currently behave as ""white boxes"". As soon as a module is composed (say ""http | filter"") then all options of the children modules are available (as e.g. http.port and filter.expression in the example above).  Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable).  Possible syntaxes : 1) {code} module compose foo --definition ""http --port=${myport:1234} | filter"" {code}  2) {code} module compose foo --definition ""http | filter"" --expose port {code}  2.1) in case of ambiguity (simulated in this particular example): {code} module compose foo --definition ""http | filter"" --expose http.port {code}  2.2) for specifying a default: {code} module compose foo --definition ""http | filter"" --expose port=1234 {code}  3) allow both 1) and 2) using 1) mainly for cases where we don't map 1 to 1 with the underlying option e.g.: {code} filter --expression=${expr}+'foo' {code}";0
XD-2286;Simple OOTB job for testing Similar to {{time | log}} we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality especially in automated tests.;0
XD-2287;Have ResourceModuleRegistry transparently proxy a remote root thru filesystem ArchiveModuleRegistry and the use of Boot Archives inherently relies on java.io.File  Have ResourceModuleRegistry extend/compose ArchiveMR to transparently download and cache (remote) jars that may be located in a (non-file:) location.    The staging area should be customizable but some subdir of java.io.tmpdir sounds like a sensible default;0
XD-2289;Redis backed aggregate counters should return results inclusive of startend time interval An aggregate counter query should return results inclusive of start and end time [startend] for time resolutions minute hour day month.;0
XD-229;Add RabbitMQ-based implementation of ChannelRegistry;0
XD-2290;Documentation for aggregate counter REST API should include query parameters Query parameters for resolution from and to should be documented along with how to specify the time string (yyyy-MM-dd HH:mm:ss).;0
XD-2291;Shell - Handle Pagination This may be broken down into 2 issues. First of all we need to define the proper UI interaction for the CLI to deal with pagination and then of course the actual implementation.;0
XD-23;add file source and sink modules;0
XD-230;Add RabbitMQ source module configurable parameters should include the queue-name(s) and optional binding key pattern    connection info such as host and port should also be configurable but with defaults (localhost and default port) and that should likely fallback to a rabbit.properties file in the $XD_HOME/config directory;0
XD-2301;Research Spark integration options *Spike scope:*  * Brainstorm * Identify options * Document;0
XD-2305;POC for Spark Integration *Spike Scope:*    * Experiment with identified options  * POC with the logical integration choice;0
XD-2307;Add support for PHD 2.1 (XD 1.1 M1 Release) *XD 1.1 M1 Release + PHD 2.1 Upgrade - Action Items:*    * Update to SHDP 2.1.M2   * Add Hadoop 2.5 (hadoop25)  * Remove hadoop22  * Remove PHD 1.0 (phd1)   * Change PHD 2.x from phd20 to phd21  * Test PHD 2.0 with phd21;0
XD-2309;"Incremental data import with jdbchdfs job Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load.     The jdbchdfs job definition could take the following 2 new options.     h5. checkColumn   optional  Specifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp.  h5. lastValue   optional  If specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.    Sqoop provides 2 modes of operation for incremental load 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.    Example: To import data from the database table some_table which has a last update column called lastUpdated you could use.  {code}  xd:> job create myjob --definition ""jdbchdfs --sql='select col1col2col3 from some_table' --checkColumn=lastUpdated"" --deploy  {code}    The batch job should also be capable of being partitioned to run in parallel across multiple containers";0
XD-2310;"Parsing issues with kafka-bus.xml Using Kafka as a transport option yields:    [2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed  org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml]  Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml] nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)    org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)    org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)    org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)    org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)    org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:320)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)    org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)  	... 31 more  Caused by: org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)    com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)  	... 36 more";0
XD-2314;Vary producer threads (XD-B-2) Send 1M messages of 1000 bytes via the generator vary the number of producer threads.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of threads* * 2 * 4 * 8;0
XD-2316;"REST: ""jobs/configurations"" returns 404 if one job has error There is a bug in the deployments rest end-point.     *How to reproduce:*     * Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a “java.lang.ClassNotFoundException�?    *Result:*    You cannot retrieve the list of deployments list anymore using:    * http://localhost:9393/jobs/configurations    The rest endpoint will now report:    [{""links"":[]""logref"":""NoSuchBatchJobException""""message"":""Batch Job with the name myJob doesn't exist""}]    This message is not entirely wrong…but extremely misleading. I think we should still return the entire list and rather mark the job as having an error.    Also returning an “404 Not Found�? is misleading as well.";0
XD-2318;Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source processor sink and job and ideally different options for each. For example a processor configured with XML SI Java DSL or SI Java DSL with lambdas.;0
XD-2320;UI: Create a dedicated Launch Page for Jobs Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.;0
XD-2321;UI: Create a dedicated scheduling page for Jobs Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.    Similar to XD-2320;0
XD-2322;Enable configuration of replication factor on the Kafka message bus The field exists and it is referred to in application.yml but it does not have a setter and the bus will always use the configured default which is 1.;0
XD-2324;Add Partitioned Job Integration Tests Using Other Bus Implementations {{JobCommandTests}} in xd-shell only uses a {{LocalMessageBus}} so the problem in XD-2323 was not discovered until a manual integration test was executed.  At a minimum {{JobCommandTests.testLaunchPartitionedJob()}} should be run with all bus implementations.;0
XD-2325;Set 'auto-startup' to false in Kafka source We have to explicitly set it to false in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.;0
XD-2326;"Can't create stream running on Windows Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition ""time | log'    {code}  09:34:20789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..  09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//  09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication  09:34:20793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo  dules/  09:34:20794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  09:34:20795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui  09:34:20797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424  09:34:20798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  09:34:20799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  09:34:20913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:defaultadminsinglenodehsqldbServer:9393 is watching for  stream/job deployment requests.  09:34:21013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED  09:34:21070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031)  09:34:22593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120 host=Seattle groups= pid=1108 id=08c72e88-66d4-4b47-bd4a-8f5e5849  099f} joined cluster  09:34:22594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..  09:34:22594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  09:34:22595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo  dules/  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.120  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle  09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop22  09:34:22597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f type=CH  ILD_ADDED  09:34:22600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED  09:34:22607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f' attrib  utes={ip=192.168.0.120 host=Seattle groups= pid=1108 id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}}  09:34:22609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms  09:34:22611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.0  09:34:22612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424  09:34:22613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  09:34:22615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  09:34:22616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576)  09:36:15837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.StringIndexOutOfBoundsException: String index out of range: -1          at java.lang.String.substring(String.java:1954)          at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)          at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)          at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)          at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)          at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)          at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)          at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)          at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)          at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)          at java.lang.reflect.Method.invoke(Method.java:483)          at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)          at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)          at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)          at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)          at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)          at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)          at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)          at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)          at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)          at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)          at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)          at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)          at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf  iguration.java:280)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)          at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)          at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)          at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)          at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)          at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)          at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)          at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)          at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)          at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)          at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)          at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)          at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)          at java.lang.Thread.run(Thread.java:745)  {code}";0
XD-233;Create an shell to control all aspect of stream/job management;0
XD-2330;Zip created by Publish 1.1 only contains the shell. XD gemfire directories in the zip file are missing.;0
XD-2331;"Job deployment list returns 404 after Laptop wakes up *Version:*  XD 1.0.1  Mac OSX 10.9.5    *Problem:*  - Deployed a simple batch job in 'singlenode'  - Laptop put to sleep mode  - After login: notice that ZK is establishing connection   - Continues to clean-up prior to redeployment but never goes through successfully  - Listing job both in UI and Shell states it is ""undeployed""    *Gunnar's experiment:*  - System is running in Single Node  - Laptop goes to sleep  - After waking up your laptop from sleep you cannot retrieve the list of deployed jobs anymore (in AdminUI)    *Error:*  Only getting back a *404* - ""NoSuchBatchJobException"" ""Batch Job with the name abcd doesn't exist""";0
XD-2332;AdminUI - Provide Server-Side Cron Expression Validation It is easy to get a cron expression wrong.     Provide validation of the cron expression on the Schedule Job page using async validation.     * Submit the cron expression to the server-side - and validate that the expression is valid.  * Send a success message back (we may even send back some meta data … e.g. when is the next execution going to take place);0
XD-2338;Upgrade to Gradle 2.2 Looks like upgrade to Gradle 2.2 is not a simple version change e.g. I see:   {code} FAILURE: Build failed with an exception.  * Where: Build file '/Users/hillert/dev/git/spring-xd/build.gradle' line: 219  * What went wrong: A problem occurred evaluating root project 'spring-xd'. > Could not find method forceDependencyVersions() for arguments [project ':documentation-toolchain'] on root project 'spring-xd'. {code};0
XD-2339;Remove external config properties for modules There are some modules that use external config properties (kafka producer/consumer hadoop properties etc.). We need to avoid using such properties and have them configured inside module so that module and its properties are self contained.;0
XD-234;Support various output format e.g. Avro SequenceFile more advanced rollover options.;0
XD-2340;Ensure that branch-specific documentation is pulled and generated;0
XD-2344;"UI should quote parameters containing a space Trying to deploy the `timestampfile` job using the UI.    Seems the UI doesn't quote string parameters that contains a space so the job creation fails.    Keeping all the defaults I get the following ""Resulting Definition"" in the UI:    timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true    (note: the --format parameter has a space)    which causes:    XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^";0
XD-2345;XD UI not usable with IE 11 Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.;0
XD-235;Modules (sinks processors sources) should be able to be easily tested inside the IDE using JUnit;0
XD-2351;POM generation creates the correct dependency list We are referencing Spring.IO deps when we shouldn't (since we moved to a different version of boot than in in the platform).;0
XD-2354;EC2 Integration Tests fail after Boot 1.2 upgrade Many of the tests fail with:    {code}  java.lang.IllegalStateException: Cannot find template location: class path resource [templates/] (please add some templates check your Groovy configuration or set spring.groovy.template.check-template-location=false)  {code}    Somehow we need to disable this check using the property suggested.;0
XD-2355;xd-singlenode --verbose prints configuration information twice If you start xd-singlenode with the --verbose flag the configuration information is printed twice.    Steps to reproduce   1) run {{xd-singlenode --verbose}}    Example output:  {code}     _____                           __   _______  /  ___|          (-)             \ \ / /  _  \  \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |   `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |  /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /  \____/| .__/|_|  |_|_| |_|\__ | \/   \/___/        | |                  __/ |        |_|                 |___/  1.1.0.BUILD-SNAPSHOT             eXtreme Data      Started : SingleNodeApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    20:40:43098 1.1.0.SNAP  INFO main server.SingleNodeApplication - Starting SingleNodeApplication v1.1.0.BUILD-SNAPSHOT on gauss with PID 79926 (/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar started by tom in /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd)  20:40:43512 1.1.0.SNAP  INFO main server.SingleNodeApplication - Started SingleNodeApplication in 0.993 seconds (JVM running for 1.374)  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  20:40:56218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  20:40:56219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://gauss:9393/admin-ui  20:40:56219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225  20:40:56219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  20:40:56219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  20:40:56226 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer -   	Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render  	BROWSER=open  	CRASH_HOME=/Users/tom/.gvm/crash/current  	DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0  	EDITOR=vim  	GAIDEN_HOME=/Users/tom/.gvm/gaiden/current  	GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484  	GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global  	GLIDE_HOME=/Users/tom/.gvm/glide/current  	GRADLE_HOME=/Users/tom/.gvm/gradle/current  	GRAILS_HOME=/Users/tom/.gvm/grails/current  	GREP_COLOR=133  	GREP_OPTIONS=--color=auto  	GRIFFON_HOME=/Users/tom/.gvm/griffon/current  	GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current  	GROOVY_HOME=/Users/tom/.gvm/groovy/current  	GVM_BROADCAST_SERVICE=http://cast.gvm.io  	GVM_BROKER_SERVICE=http://release.gvm.io  	GVM_DIR=/Users/tom/.gvm  	GVM_INIT=true  	GVM_PLATFORM=Darwin  	GVM_SERVICE=http://api.gvmtool.net  	GVM_VERSION=2.2.0  	HADOOP_DISTRO=hadoop25  	HOME=/Users/tom  	IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc  	JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home  	JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication  	JBAKE_HOME=/Users/tom/.gvm/jbake/current  	LANG=en_US.UTF-8  	LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current  	LC_ALL=en_US.UTF-8  	LC_CTYPE=UTF-8  	LESS=-F -g -i -M -R -S -w -X -z-4  	LESS_TERMCAP_mb=[0131m  	LESS_TERMCAP_md=[0131m  	LESS_TERMCAP_me=[0m  	LESS_TERMCAP_se=[0m  	LESS_TERMCAP_so=[004730m  	LESS_TERMCAP_ue=[0m  	LESS_TERMCAP_us=[0132m  	LOGNAME=tom  	LSCOLORS=exfxcxdxbxGxDxabagacad  	LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=3601:cd=3301:su=314007:sg=364007:tw=324007:ow=334007:  	MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1  	MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484  	OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  	PAGER=less  	PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin  	PID=79926  	PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_  	PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  	SCREEN_NO=  	SECURITYSESSIONID=186a4  	SHELL=/bin/zsh  	SHLVL=1  	SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current  	SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners  	TERM=xterm-256color  	TERM_PROGRAM=Apple_Terminal  	TERM_PROGRAM_VERSION=326  	TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE  	TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7  	TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  	USER=tom  	VERTX_HOME=/Users/tom/.gvm/vertx/current  	VISUAL=vim  	XD_ANALYTICS=memory  	XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  	XD_CONFIG_NAME=serversapplication  	XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  	XD_JMX_ENABLED=true  	XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  	XD_MODULE_CONFIG_NAME=modules  	XD_TRANSPORT=local  	__CF_USER_TEXT_ENCODING=0x1F5:0:0  	__CHECKFIX1436934=1  	_system_arch=x86_64  	_system_name=OSX  	_system_type=Darwin  	_system_version=10.9  	analytics=memory  	awt.toolkit=sun.lwawt.macosx.LWCToolkit  	catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  	catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  	catalina.useNaming=false  	document=--  	embeddedHsql=true  	endpoints.jmx.enabled=true  	endpoints.jmx.uniqueNames=true  	endpoints.jolokia.enabled=true  	file.encoding=UTF-8  	file.encoding.pkg=sun.io  	file.separator=/  	ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  	gopherProxySet=false  	http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  	java.awt.graphicsenv=sun.awt.CGraphicsEnvironment  	java.awt.headless=true  	java.awt.printerjob=sun.lwawt.macosx.CPrinterJob  	java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring...;0
XD-2364;Remove usage of <context:property-placeholder location=.../> in module defitions This doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc.  This is in HDFS and some others.;0
XD-2366;Doc generation accesses http://docbook.sourceforge.net When generating docs the build tries to access    http://docbook.sourceforge.net/release/images/draft.png    You will observe output like:    {code}  Error with opening URL 'http://docbook.sourceforge.net/release/images/draft.png': docbook.sourceforge.net  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  {code};0
XD-2367;Investigate TypeConvertingStreamTests.testBasicTypeConversionWithTap test failure in CI builds TypeConvertingStreamTests.testBasicTypeConversionWithTap() is failing intermittently. Why?;0
XD-2370;Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.;0
XD-2371;Allow registering default SpEL functions to simplify expressions Often one has to perform some basic conversion / parsings in Stream definitions. It would be helpful if one could provide some helper functions to simplify SpEL expressions.  E.g. instead of: {code} transform --expression=T(java.lang.Long).parseLong(payload.value.toString()) {code} it would be nice to be able to write: {code} transform --expression=parseLong(payload.value) {code}  I'm thinking of support for: * parseByte * parseInt * parseShort * parseLong * parseFloat * parseDouble * parseBoolean * parseTuple  (I don't think we'd need support for parseCharacter)  This issue is about: 1) providing the centralised infrastructure for defining the SpEL expressions 2) Add support for the above listed predefined SpEL expressions  Those functions should be able to work with String based as well as {{JsonToStringFriendlyNode}} as input.;0
XD-238;Deploying Custom Code When a module is deployed it should run in its own isolated classpath.  The current code has all dependencies in a single classpath taken from the lib directory at startup.  This has a number of drawbacks one of the most important is the batch jobs can not be contributed to the system at runtime.  The work for this epic is decoupled from any module deployment story.  The assumption is that there will be a directory layout as shown below.  Current layout  ./modules/. |-- common |-- job |-- processor |-- sink |-- source |-- trigger  And inside source |-- source |   |-- file.xml |   |-- gemfire-cq.xml |   |-- gemfire.xml |   |-- http.xml |   |-- jms.xml |   |-- mqtt.xml |   |-- rabbit.xml |   |-- syslog-tcp.xml |   |-- syslog-udp.xml |   |-- tail.xml |   |-- tap.xml |   |-- tcp.xml |   |-- time.xml |   |-- twittersearch.xml |   |-- twitterstream.xml   Using an example of the source directory from the current layout.e.g ./modules/source/file the new layout would be  ./modules/source/file/lib/spring-integration-file.jar ./modules/source/file/config/file.xml   We should support both the new and old layout styles simultaneously.  There what is under 'file' directory is the 'package'  No .zip war is required.;0
XD-2380;"New sink for REST resources A new sink that would POST the message payload to a REST service over http.  Could be created with code something like this except without hardcoded user and password for basic auth...  rest-store.xml {code} <?xml version=""1.0"" encoding=""UTF-8""?> <beans xmlns=""http://www.springframework.org/schema/beans""        xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:int=""http://www.springframework.org/schema/integration""        xmlns:http=""http://www.springframework.org/schema/integration/http""        xsi:schemaLocation=""http://www.springframework.org/schema/beans 		http://www.springframework.org/schema/beans/spring-beans.xsd 		http://www.springframework.org/schema/integration 		http://www.springframework.org/schema/integration/spring-integration.xsd 		http://www.springframework.org/schema/integration/http 		http://www.springframework.org/schema/integration/http/spring-integration-http.xsd"">  	<int:channel id=""input"" /> 	<int:channel id=""restout"" /> 	<int:header-enricher input-channel=""input"" output-channel=""restout""> 		<int:header name=""Content-Type"" value=""${contenttype:application/json}""/> 	</int:header-enricher>  	<http:outbound-channel-adapter url=""${url}""                                        request-factory=""clientHttpRequestFactory""                                                                           channel=""restout""                                                                                                              http-method=""${method:POST}""                                                                                                                          header-mapper=""""/>  	<bean id=""httpComponentsMessageSender"" class=""org.springframework.ws.transport.http.HttpComponentsMessageSender""> 		<property name=""credentials""> 			<bean class=""org.apache.http.auth.UsernamePasswordCredentials""> 				<constructor-arg value=""myuser""/> 				<constructor-arg value=""mypassword""/> 			</bean> 		</property> 	</bean>  	<bean id=""clientHttpRequestFactory"" class=""org.springframework.http.client.HttpComponentsClientHttpRequestFactory""> 		<property name=""httpClient"" value=""#{httpComponentsMessageSender.httpClient}""/> 	</bean> </beans>			 {code}  rest-store.properties {code} options.url.description = The URL to send data to options.url.type = String  options.method.description = HTTP method. Default POST options.method.type = String  options.contenttype.description = Content-Type header to set. Default application/json options.contenttype.type = String {code}";0
XD-2381;Decouple messagebus dependencies *Refactoring scope:* (_spring-xd-dirt_)  * Message bus dependencies      The goal is to decouple them from startup phase to further enhance initialization time.;0
XD-2386;Need TCP-Client Source Acceptance test;0
XD-2389;Streams section of doc should explicitly mention that labels are required for ambiguous modules Currently I believe we only mention labels in this section of the doc:  https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labels    And it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.    We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module we should add one to illustrate this point.;0
XD-2390;Add regression test Verify that network interruptions will not negatively affect the XD cluster.    Verify that a container that looses connectivity will be able to rejoin the cluster cleanly.  Modules will redploy when the network is back up.;0
XD-2394;incremental jdbcfile process for loading data into Isilon cluster Users should have the ability to load data from a jdbc source to a file sink pointing to a file location (NFS mount to an Isilon cluster) in a particular directory structure.  Isilon support multiple protocols including NFS and HDFS. by storing data directly into an NFS mount we would eliminate the HDFS overhead.  This functionality should be similar to the jdbchdfs job that is currently available in SpringXD. See Jira issue 'XD-2309' for more details.;0
XD-2397;"TCP-Client source module throws ClassNotFoundException *Version:*  XD: 1.1 M1    *Problem:*  Trying to use tcp-client source module and observing an exception while deploying the stream.    *Stream Definition:*  {code:xml}   curl --data name=dummy-firehose --data definition='tcp-client --decoder=LF --port=8080 | log' --data deploy=true http://localhost:9393/streams/definitions  {""name"":""dummy-firehose""""status"":null""definition"":""tcp-client --decoder=LF --port=8080 | log""""_links"":{""self"":{""href"":""http://localhost:9393/streams/dummy-firehose""}}}  {code}    The same curl command works fine against XD 1.0.1 release.";0
XD-240;Throughput optimized TCP based adapters based on Reactor TCP project;0
XD-2404;Provide an XD Starter POM for module projects Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided configure the boot plugin for 'MODULE' layout and other boilerplate build configuration. This should include a similar feature for gradle.;0
XD-2405;Provide XD module build plugins to upload a module Provide maven and gradle plugins to execute module upload via REST to upload and install a module to Spring XD.  e.g. mvn xd:upload-module ...;0
XD-2406;Create Sample Module projects Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to https://github.com/dturanski/siDslModule these should include unit and single node integration tests and demonstrate the use of Spring XD build and packaging tools and other module development support. This may be split out into separate tasks but should include a sample for source processor sink and job using @Configuration or XML configuration (either as separate samples or using build profiles).;0
XD-2408;When a tap is re-deployed after undeploy it doesn't work When a tap on a stream is undeployed and re-deployed it stops working.  To make it work the main stream associated with the tap needs to be undeployed and re-deployed.;0
XD-2410;"Rename metrics repositories setValue(x y z) to something less ""javabean""";0
XD-2414;"Incorrect ""directory"" option described in hdfs-dataset docs Please see [hdfs-dataset 1.0.2.RELEASE docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.2.RELEASE/reference/html/#hdfs-dataset-avroparquet].    According to docs there should be ""directory"" option in this sink but in code ""basePath"" is used.";0
XD-2415;Using custom classes for module properties leads to ClassNotFoundException Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.    Following exception is thrown:  {code}6:26:03064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154)    org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)    org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173)    org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)    org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)    javax.servlet.http.HttpServlet.service(HttpServlet.java:646)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)    javax.servlet.http.HttpServlet.service(HttpServlet.java:727)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)    org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)    java.lang.Thread.run(Thread.java:745){code}    Please see attached patch file this seems to be enough to resolve the problem.;0
XD-2416;"SpelParseException is thrown when using empty string ("""") inside of an expression I can only reproduce this when using single quotes around the expression:    {code}  stream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \""\"")' | log"" --deploy true  {code}    The following two alternatives work fine though:  {code}  # Using trim on a single space  stream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \"" \"".trim())' | log"" --deploy true    # Not using single quotes or spaces in the expression  stream create test --definition ""http | transform --expression=payload.replace(\""abc\""\""\"") | log"" --deploy true  {code}";0
XD-2418;"Kafka Sink: Support async Producer The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).    Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element    {{async=""$\{async\}""}}";0
XD-242;Add JMS source module;0
XD-2423;WireTap is Applied to OutputChannel Before the Tap Channel has been Bound To The Bus When establishing the tap we create the tap channel and add the WireTap before the tap channel has been bound to the bus.    {quote}  17:00:23918 ERROR task-scheduler-8 handler.LoggingHandler - org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'tap:stream:foo.time.0.tap.bridge'. nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:129)  {quote};0
XD-2427;Use repo.spring.io as NPM repository In order to improve the build reliability we should be using the NPM repo provided by *repo.spring.io*     See *spring-xd-ui/README.md* for further details.;0
XD-2429;Bind Producer Before Consumer {quote}  		Here is the full exception:  		org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'ResourceConfiguredModule [name=filter type=processor group=request-rate index=0 @58b0f318]:use-expressiondefaultadminsinglenodehsqldbServer:9393.output'. nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers  		and here is that stream:  		topic:httpstartstop > filter --expression=payload.getHttpStartStop().getPeerType().name().equals('Client') | requestRateAggregator | appMetricsSplitter | router --expression='topic:app-request-rate-'+#jsonPath(payload'$.appId')  [2:59 PM] Gary Russell: @MarkFisher  @IlayaperumalGopinathan @PatrickPeralta  This looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. The tap is started before the tap stream is deployed. But it's not clear to me how the filter module could be deployed/bound as a consumer before the requestRateAggregator  [3:08 PM] Gary Russell: I see the problem: AbstractMessageBusBinderPlugin.bindConsumerAndProducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @DavidTuranski  {quote};0
XD-2430;Create a Sqoop job and required batch tasklet integration code Based on the POC from XD-2124 we should create the actual implementation.    Things to consider to store in step context:  - capture Log output/MapReduce job counters  - capture last-value from incremental imports;0
XD-2433;Implement a Spark Streaming Receiver that binds to the MessageBus;0
XD-2459;Update XD-EC2 to use placement groups;0
XD-2460;Update to use Compute optimized and standard machine types;0
XD-2463;Test with Java8 runtime;0
XD-2466;Implement a dirt plugin for Spark Streaming support;0
XD-2467;Implement a Spark Streaming Driver application that can be controlled as an XD module instance This should include lifecycle management so that when the module's stream is undeployed the Spark Streaming application should be stopped etc.    Deploying a number of module instances should result in multiple receiver tasks and those should bind to the bus using the consumer side partitioning metadata.;0
XD-247;Need to be able to specify password for Redis Running on Cloud Foundry (and other managed environments) we need to be able to specify a Redis password in addition to host and port.;0
XD-2481;Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor's Stream API.   Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.;0
XD-2482;"Add ""initialDelay"" to ""source:trigger"" Currently the {{source:trigger}} module is based on 3 profiles: {{date}} {{cron}} or {{fixedDelay}} where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:    {code:java}  @Override  public String[] profilesToActivate() {      if (cron != null) {          return new String[] { ""use-cron"" }      }      else if (fixedDelay != null) {          return new String[] { ""use-delay"" }      }      else {          return new String[] { ""use-date"" }      }  }  {code}    Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time and then repeat every X seconds.    This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour.";0
XD-2485;Update spring-data-hadoop version to 2.0.4 for XD 1.0.3;0
XD-2486;Context Deserialize Doesn't Use Parent First Classloader If a class is added to a batch execution context that is located in an isolated context an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization.;0
XD-2487;Create ReactorMessageHandler for Reactor based XD processor/sink modules The module should be flexible to act as a sink as well as a processor.  ErrorHandling will be considered as part of another JIRA;0
XD-2488;Create sample module in spring-xd-modules for a Reactor Stream processor A sample perhaps taken from Pivotal Labs use-case in Denver that would calculate some time window averages for a many individual senor values .;0
XD-2489;Reference documentation on creating Reactive Stream processor/sink;0
XD-2491;JDBCHDFS Master Process Timeout error The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.  The error message on the error message on the master process is:  org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned   org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)   org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)   org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)   org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)   org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)   org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)   org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)   org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)   org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)   org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)   org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy47.run(Unknown Source)   org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)   sun.reflect.NativeMethodAccessorImpl;0
XD-2494;Make trigger options explicitly exclusive see problem reported at http://stackoverflow.com/questions/27368351/spring-xd-module-sourcetrigger-does-not-work-as-expected;0
XD-2495;"Add Request/Reply support to Kafka message bus * Environment: ** Can be reproduced on local machine with Admin and a single container. * create the following job ** job create ogg --definition ""filejdbc --resources=file:filejdbctest//filejdbctestpartition* --names=data --tableName=filejdbctest --initializeDatabase=true "" --deploy * note: this works on Rabbit and Redis as a message bus * The following exception is thrown on the admin: 6:54:22856 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.JobDeploymentListener - Deployment status for job 'ogg': DeploymentStatus{state=failederror(s)=java.lang.UnsupportedOperationException: Auto-generated method stub   org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)   org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) }  * The following exception is thrown on the container 21:08:14721 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 config.ReleaseStrategyFactoryBean - No annotated method found falling back to SequenceSizeReleaseStrategy target:org.springframework.batch.integration.partition.MessageChannelPartitionHandler@692ee39f methodName:null 21:08:15946 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module java.lang.UnsupportedOperationException: Auto-generated method stub   org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)   org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745)";0
XD-2496;Refactor use of getContainerHostForSource in integration tests Some cleanup to make the tests a bit easer to read.;0
XD-2502;KafkaSourceSinkTests to use embedded Kafka server Test is failing since Kafka isn't installed on the CI server.  Using an embedded server will make the testing more robust vs. needing an external server.;0
XD-2504;Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI  Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.;0
XD-2505;Undeploying HDFS module closes filesystem When using the hadoop namespace to create a hadoop configuration and filesystem the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed;0
XD-2506;"""script"" processor options incorrect on docs The EXAMPLE in the documentation (and the paragraph preceding the example) for the ""script"" processor uses both ""location"" and ""properties-location"" options but these are in actuality ""script"" and ""locationProperties"" according to ""module info processor:script"" and the text of the documentation.  See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script   {quote}To use the module pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.  {code}xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log"" --deploy{code} {quote}";0
XD-251;Add support for stream creation For stream creation we need to be able to specify:  source sink processor  - filter  - transformer  - script  etc.;0
XD-2510;Fix classpath issues for RabbitMQ source/sink RabbitMQ Sink is throwing:  {quote}  09:44:16031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 19 columnNumber: 53 cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)      at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)      at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)      at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)      at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)      at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)      at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)      at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)      at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)      at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)      at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)      at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)      at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)      at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)      at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)      at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException lineNumber: 19 columnNumber: 53 cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)      at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)      at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)      at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)      at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)      ... 30 more  09:44:16036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 19 columnNumber: 53 cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)      at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)      at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)      at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)      at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)      at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)      at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)      at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)      at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)      at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)      at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)      at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)      at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)      at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)      at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)      at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException lineNumber: 19 columnNumber: 53 cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)      at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)      at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)      at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)      at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  {quote};0
XD-2512;Byte[] to String conversion should support application/json See http://stackoverflow.com/questions/27491237/spring-xd-tcp-source-outputs-byte-array-instead-of-string-how-to-output-regu.   Same behavior as --outputType text/plain but more intuitive to use application/json if the stream author expects the source to emit json. No content validation will be done.;0
XD-2517;Clean up spring-xd-batch sub-project We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project;0
XD-2518;Upgrade to Gradle 2.2;0
XD-2520;Add integration tests for Sqoop job We need to add some integration tests for the Sqoop job introduced in XD-2430;0
XD-2521;Add options for supporting compression on the message bus with RabbitMQ https://jira.spring.io/browse/AMQP-453 Added support for compression with RabbitMQ.  XD should expose configuration options to enable and configure compression on the message bus.  Note some options may be specific for brokers or require additional functionality in XD.      This issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations but expose what makes sense with the current code base for rabbitmq   As an example Kafka supports compressed.topics which lets you pick a subset of topics to be compressed.;0
XD-2522;Further decouple message bus deps (test scope) Commit https://github.com/spring-projects/spring-xd/commit/8d28b2786acbdea1617d7e903b805e5af5369b90 removed MessageBus implementations from the main dirt classpath but used a trick to have tests working (basically MB classes *are* on the CP when in test scope).  This story is about adding more gradle projects that support classpath isolation when running tests (and also when authoring a MB implementation).  This would avoid false positives such as https://github.com/spring-projects/spring-xd/pull/1340 were lacking jars go unnoticed;0
XD-2525;In XD shell an incomplete command will be executed as the full command When using the XD shell a user can enter the first character of a command and it will be accepted as the full command.  for example  e <return/>  will exit the shell The following commands below show how a user can target a new cluster and then get a job execution list by using the first character of the command.  server-unknown:>a c s http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 Successfully targeted http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 xd:>j e l   Id  Job Name                                   Start Time               Step Execution Count  Execution Status  Deployment Status  Definition Status   --  -----------------------------------------  -----------------------  --------------------  ----------------  -----------------  -----------------   28  tsle2145f21d-5b0b-49df-b9cc-a3fe65c49ecc   2014-12-18 11:08:47000  2                     COMPLETED         Undeployed         Destroyed   27  ec2Job3                                    2014-12-18 11:07:13000  2                     COMPLETED         Undeployed         Destroyed   26  ec2Job3;0
XD-2533;Upgrade to Reactor 2.0 M2;0
XD-2536;Provide IP binding to the spring-xd instance. We wanted to bind the spring-xd to the public IP but am not able to do so.  I scanned at the code here and could make there is not way to bind the IP address  https://github.com/spring-projects/spring-xd/blob/master/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/AdminServerApplication.java   This one looks a simple change I can fix it and push the pull request.;0
XD-2537;BackPort script.xml Bug Fix An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master it needs to be backported to 1.0.x.  {{s/$\{location\}/$\{script\}/}}   https://gopivotal-com.socialcast.com/messages/22909482;0
XD-2539;XD 1.1.0.M2 Won't Run on Windows See http://stackoverflow.com/questions/27725905/spring-xd-1-1-0-m2-fails-to-start    With {{XD_HOME}} set with back-whacks it fails on {{\U...}} with {{XD_HOME}} set with whacks it fails with {{/xd\...}}. The StackOverflow failure is similar.    1.0.3 works fine.    {noformat}  set XD_HOME=C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd    Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 5  .*C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd\lib\messagebus\([^/]*).*    set XD_HOME=C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd      Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 71  .*C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd\lib\messagebus\([^/]*).*  {noformat};0
XD-2544;Create a loadGenerator source module Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.;0
XD-2546;Create AMI for Spark Server installed;0
XD-2555;Create plugin module for reactor based processors As an developer I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava.  A plugin should allow a reactor processor module to specify the bare minimum to work e.g. the processor class.    Explore how additional configuration can be achieved with well known module option commands.;0
XD-2556;Reference documentation on RxJava Stream processor;0
XD-2563;"XD on YARN broken due to missing messagebus libs Admin on YARN simply fails because messagebus libs are not copied in place during a build.    Already tried and simple fix is for gradle/build-dist.gradle:    {code}  task copyYarnMessageBusLibs(type: Copy) {    from ""$rootDir/lib/messagebus""    into ""$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus""  }  {code}    and execute it together with copyMessageBusLibs task.";0
XD-2565;Remove MongoDB from main DIRT classpath MongoDb driver is present on DIRT's classpath while it should not (should be present on mongo-related modules though).  This is blocked by the shortcoming described here: https://github.com/spring-projects/spring-xd/pull/1116;0
XD-2570;Create a new Broadcast stream per thread The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation.  The current handler shares a single broadcast stream.  Change to create a new one per thread usage.;0
XD-2572;Set fixed NPM version for Grunt Gradle Plugin Ensure build works in Windows environments;0
XD-2573;"Full build with tests fail on Ubuntu On Ubuntu 14.04 LTS using OpenJDK version  ""1.7.0_65""    OpenJDK Runtime Environment (IcedTea 2.5.3) (7u71-2.5.3-0ubuntu0.14.04.1)  OpenJDK 64-Bit Server VM (build 24.65-b04 mixed mode)    I see the following failures:    :spring-xd-dirt:test    org.springframework.xd.dirt.security.SingleNodeApplicationWithUserBasedSecurityTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSimpleBindTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithDefaultSecurityTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithSslTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithUsersFileTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSearchAndBindTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    595 tests completed 6 failed 2 skipped  :spring-xd-dirt:test FAILED    The test reports has this:    Caused by: java.lang.IllegalStateException: HSQLDB could not be started on 0.0.0.0:7714 state: SHUTDOWN    org.springframework.xd.batch.hsqldb.server.HSQLServerBean.startServer(HSQLServerBean.java:162)    org.springframework.xd.batch.hsqldb.server.HSQLServerBean.afterPropertiesSet(HSQLServerBean.java:82)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 42 more  Caused by: java.net.BindException: Address already in use    java.net.PlainSocketImpl.socketBind(Native Method)    java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)    java.net.ServerSocket.bind(ServerSocket.java:376)    java.net.ServerSocket.<init>(ServerSocket.java:237)    java.net.ServerSocket.<init>(ServerSocket.java:128)    org.hsqldb.server.HsqlSocketFactory.createServerSocket(Unknown Source)    org.hsqldb.server.Server.openServerSocket(Unknown Source)    org.hsqldb.server.Server.run(Unknown Source)    org.hsqldb.server.Server.access$000(Unknown Source)    org.hsqldb.server.Server$ServerThread.run(Unknown Source)    So I assume I see this due HSQL running from another test.";0
XD-2575;HDFS sink should provide rolloverTime option not only idleTiemout When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.    Proposed option:  rolloverTimeout  timeout after file will be automatically closed    Link: #XD-2413;0
XD-2579;Spring XD shell should maintain single log file (per user?) Currently xd-shell script packaged in Spring XD dist creates spring-shell.log file in invocation directory.   When xd-shell is added to $PATH user will usually invoke the script from many directories leaving log files all over the file system.  Would it be possible to keep the log files in one predefined location (e.g. $HOME/.spring-shell.log or $DIST/shell/logs/spring-shell.log)?;0
XD-258;Add command for stream creation;0
XD-2581;JDBC sink doesn't deserialize JSON types correctly *Expected*   1. Create MYTABLE table with DATE or TIMESTAMP column MYTIME 2. Create a stream ending with {code}... | object-to-json | jdbc --tableName=MYTABLE ...{code} 3. Send a message with payload being a Java object that has a property myTime of type java.util.Date 4. Message payload is inserted into MYTABLE table date is correctly stored in MYTIME column.  *Actual*  4. Exception is thrown from JDBC sink which attempts to bind a long into MYTIME column.  *Root cause*  JDBC sink uses *org.springframework.xd.jdbc.JdbcMessagePayloadTransformer* class to deserialize JSON payload into Map which will later be used to bind parameters into java.sql.PreparedStatement.  Unfortunately JdbcMessagePayloadTransformer and MessageTransformingHandler which is calling it doesn't respect *json\_\_TypeId\_\_* message header so information about Java types is lost. Other Spring XD components serialize java.util.Date as Unix timestamp e.g. object-to-json transformer. JDBC sink will deserialize the date as java.lang.Long and later attempt to bind incorrect type to query parameter.  In case of GemFire XD following exception will be thrown during query parameter binding phase: {code} com.pivotal.gemfirexd.internal.shared.common.sanity.AssertFailure: ASSERT FAILED Number of parameters expected for message id 22005 (3) does not match number of arguments received (2)   com.pivotal.gemfirexd.internal.shared.common.sanity.SanityManager.ASSERT(SanityManager.java:239)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.formatMessage(MessageUtil.java:245)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:151)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:191)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:107)   com.pivotal.gemfirexd.internal.client.am.SqlException.<init>(SqlException.java:184)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement$PossibleTypes.throw22005Exception(PreparedStatement.java:4007)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setLong(PreparedStatement.java:843)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setObject(PreparedStatement.java:1688)   org.springframework.jdbc.core.StatementCreatorUtils.setValue(StatementCreatorUtils.java:402)   org.springframework.jdbc.core.StatementCreatorUtils.setParameterValueInternal(StatementCreatorUtils.java:235)   org.springframework.jdbc.core.StatementCreatorUtils.setParameterValue(StatementCreatorUtils.java:150)   org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.setValues(PreparedStatementCreatorFactory.java:300)   org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.createPreparedStatement(PreparedStatementCreatorFactory.java:252)   org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)   org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:909)   org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:933)   org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.update(NamedParameterJdbcTemplate.java:313)   org.springframework.integration.jdbc.JdbcMessageHandler.executeUpdateQuery(JdbcMessageHandler.java:130)   org.springframework.integration.jdbc.JdbcMessageHandler.handleMessageInternal(JdbcMessageHandler.java:112)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) 	... 372 more {code};0
XD-2582;"Provide missing JARs to enable #xpath() SpEL Spring XD should package *spring-integration-xml* JAR within distribution so we can invoke *#xpath()* SpEL from processors e.g. using transformer:  {code}... | transform --expression='#xpath(payload ""/*[name()=''Datasource'']/*[name()=''row'']/text()"" | ... {code}";0
XD-2584;Upgrade grunt/node plugins Upgrade in 1.0.x branch what was done in this commit on master.    https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b;0
XD-2586;Update to Reactor 2.0 build snapshots;0
XD-259;Add command for tap creation;0
XD-2591;Bump Spring Integration to 4.1.2 Spring AMQP to 1.4.2;0
XD-2596;KafkaMessageBusTests#testCompression failing Intermittent. Reported on ubuntu and OS/x;0
XD-2599;Create a BroadcasterMessageHandler that uses a 'Serialized' Broadcaster This is a parallel implementation to the RxJava     https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/SubjectMessageHandler.java    That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.;0
XD-260;Add command for listing streams;0
XD-2600;Backport XD-2411 to 1.0.x branch This fix for RichGauge should go into the 1.0.x line.;0
XD-2601;"Mismatch between configuration class and script XML for location/script The *org.springframework.xd.module.options.mixins.ScriptMixin* options class shipped with XD 1.0.3 refers to *script* rather than *location* however the XML configuration still references *$\{location\}* in the service activator:  {noformat} 	<service-activator output-channel=""output"" input-channel=""input""> 		<int-groovy:script location=""${location}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/> 	</service-activator> {noformat}  Creating a stream using the old *location* argument no longer works obviously:  {noformat} xd:>stream create myJobArchiveTrigger --definition ""tap:job:myJob.job > script --location=job-status.groovy --variables='tgtStatus=COMPLETED' > queue:job:archiveJob"" --deploy Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor     location: option named 'location' is not supported {noformat}  Creating the same stream using *--script* reports success at the shell prompt but results in an error in the container/admin logs:  {noformat} Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}"" {noformat}  Working around this by overriding the XML setting in our deployment:  {noformat} 	<service-activator output-channel=""output"" input-channel=""input""> 		<int-groovy:script location=""${script}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/> 	</service-activator> {noformat}";0
XD-2604;Change Grunt Build - Checkin Bower Artifacts In order to decrease CI build issues we should checkin bower dependencies.   See: http://addyosmani.com/blog/checking-in-front-end-dependencies/;0
XD-2605;TwitterStream/TwitterSearch sources fail when deploying on Yarn We're getting a CNF on org.apache.http.impl.client.HttpClients {noformat} 20:07:03556 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1 type=CHILD_ADDED 20:07:03557 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'file' for stream 'ec2Test3' 20:07:03828 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@8d11c70 moduleName = 'file' moduleLabel = 'file' group = 'ec2Test3' sourceChannelName = [null] sinkChannelName = [null] index = 1 type = sink parameters = map['binary' -> 'true' 'mode' -> 'REPLACE'] children = list[[empty]]] 20:07:04456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1 type=CHILD_ADDED 20:07:04456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'twitterstream' for stream 'ec2Test3' 20:07:05040 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream' moduleLabel = 'twitterstream' group = 'ec2Test3' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n' 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5' 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe' 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'] children = list[[empty]]] 20:07:05871 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)   org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) 	... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)   org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267) 	... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)   org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)   sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)   sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)   sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)   java.lang.reflect.Constructor.newInstance(Constructor.java:526)   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147) 	... 50 more Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients   java.net.URLClassLoader$1.run(URLClassLoader.java:366)   java.net.URLClassLoader$1.run(URLClassLoader.java:355)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:354)   java.lang.ClassLoader.loadClass(ClassLoader.java:425)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)   java.lang.ClassLoader.loadClass(ClassLoader.java:358) 	... 63 more 20:07:05874 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)   org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) 	... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)   org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267) 	... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)   org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)   sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)   sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)   sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)   java.lang.reflect.Constructor.newInstance(Constructor.java:526)   org.springframework.bean...;0
XD-2607;Windows build fails This Hadoop scenario will not work in Windows. The scope is to *disable* the test for windows build.    org.springframework.batch.integration.x.RemoteFileToHadoopTaskletTests > testWrite FAILED      java.lang.IllegalStateException          Caused by: org.springframework.beans.factory.BeanCreationException              Caused by: java.lang.UnsatisfiedLinkError    org.springframework.batch.integration.x.RemoteFileToHadoopTests > testSimple FAILED      java.lang.IllegalStateException          Caused by: org.springframework.beans.factory.BeanCreationException              Caused by: java.lang.UnsatisfiedLinkError  Java HotSpot(TM) Client VM warning: ignoring option MaxPermSize=512m support was removed in 8.0    3 tests completed 2 failed  :spring-xd-extension-batch:test FAILED    FAILURE: Build failed with an exception.;0
XD-2608;XD Gemfire modules fail to deploy in  Yarn 1 admin on slave1  1 container on slave2    Gemfire modules fail to deploy.  with the following exception:  Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy  This is because the modules require a XD_HOME environment variable and this is not set by the yarn deployment.    {noformat}  Offending resource: URL [file:null/modules/common/gemfire-sink.groovy] nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: null/modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:null/modules/common/gemfire-sink.groovy] nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans$_run_closure1.doCall(beans:4)    beans$_run_closure1.doCall(beans)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.Closure.call(Closure.java:423)    groovy.lang.Closure.call(Closure.java:417)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)    groovy.lang.Closure.call(Closure.java:439)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans.run(beans:1)    groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 29 more  Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    java.io.FileInputStream.open(Native Method)    java.io.FileInputStream.<init>(FileInputStream.java:146)    java.io.FileInputStream.<init>(FileInputStream.java:101)    sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)    sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)    org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)    org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 79 more  {noformat};0
XD-2610;Job definition is deleted after restart the srping xd service in single node mode Job definition is deleted after restart the srping xd service in single node mode  repro step: 1.start service as single node 2.create a batch module 3.create a job based on batch module 4.restart service  expect result: job definition is displayed on the job list  actual result: job list is empty all job definitions are missed;0
XD-2611;Missing Log Configuration for throughput-sampler http://stackoverflow.com/questions/28019801/how-to-read-throughput-sampler-sink-values-in-spring-xd/28027544#28027544;0
XD-2612;Use Kryo instance pooling to reduce instantiation overhead https://github.com/EsotericSoftware/kryo#pooling-kryo-instances;0
XD-2613;Add module properties files to yarn config directory Currently any properties files located in the ${xd.config.home}/ directory are not included in the config directory provided by the yarn deployment. And thus modules are pulling props from the  spring-xd-yarn-1.1.0.BUILD-SNAPSHOT.zip file.   We need to include these property files in the config dir.;0
XD-2617;Create reactor module in spring-xd-modules project;0
XD-2620;Add tests and refactor ZooKeeperStreamRepository Looks like there is a bit of technical debt in *ZooKeeperStreamRepository*. Additionally there is not a single test for this class yet. However testability looks tricky.;0
XD-2622;Update documentation for Kafka sources Include new features added by using Spring Integration Kafka M3;0
XD-2623;Add assertion text to Junit Tests Discovered Junit test failures that do not provide an assertion message. Therefore the Junit report is rather useless.  2 Classes (Maybe we should check the entire code-base):  Class org.springframework.xd.shell.command.JobCommandWithHadoopTests testLaunchFtpHadoopJob  {code} java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.AbstractJobIntegrationTest.checkForJobInList(AbstractJobIntegrationTest.java:213)   org.springframework.xd.shell.command.JobCommandWithHadoopTests.testLaunchFtpHadoopJob(JobCommandWithHadoopTests.java:73)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {code}  Class org.springframework.xd.shell.command.HttpCommandTests testHttpPostUtfText {code} java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)   org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)   org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)   org.springframework.xd.shell.command.HttpCommandTests.testHttpPostUtfText(HttpCommandTests.java:97)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {code};0
XD-2624;Add more comprehensive tests for the simple consumer-based Kafka Message Bus;0
XD-263;Support GET /streams Pagination support maybe querying by name as well;0
XD-2631;For time being checkin UI build artifacts;0
XD-2637;Shell processor is not thread safe Multiple threads invoke the shell processor result in I/O errors and/or data corruption. send() and receive() should be synchronized.;0
XD-2638;"The shell distribution zip is missing hadoop26 libraries The spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries so we get the following exception when starting the shell:    Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration";0
XD-2639;Acceptance tests updated to be able to test XD Yarn deployment In order to run Acceptance tests in their current state there had to be * changes to the code  ** Set the location of the data node for the hdfs tests. (because the data nodes were no located with the master.) ** disable the copying of batch basic because we did not know the container location. * Had to configure tests by hand so that we could identify the: ** admin port (with new features we should be able to write code to find it.  Should be able to set it but we had a problem.  Possible yarn bug) ** JMX Port ( We could set it for the master but not the container this was a Yarn deployBug ) ** Where the build was deployed on the container node so we could copy the batch-basic test.;0
XD-264;Spring MVC infrastructure tests;0
XD-2641;Validate that topics used for storing offsets are compacted;0
XD-2643;Acceptance tests need to create or use an existing topic prior to executing test;0
XD-2644;Refactor ModuleFactory to remove direct spark dependency on XD dirt Currently the ModuleFactory needs to know about `SparkStreamingDriverModule` to create the spark streaming module. It is for this reason the spring-xd-module has direct dependency on spark streaming. We need to refactor this code so that there is no direct dependency on spark streaming for spring-xd-module and subsequently spring-xd-dirt.;0
XD-2646;XD should use same hadoop security keys as Spring for Apache Hadoop For kerberos and other security related settings we use keys like 'spring.hadoop.userPrincipal' mentioned in https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos. However when we added boot config props to shdp we used a sub keys like 'spring.hadoop.security.userPrincipal'.    It'd be good if we'd fix these to be same in both XD and SHDP not to cause confusion.;0
XD-2649;Add Kafka-based implementation for AbstractSingleNodeStreamDeploymentIntegrationTests;0
XD-265;Retrieve description of all registered modules GET /streams/{streamname}/modules     and  GET /streams/{streamname}/modules/{modulename}    The former returning links to the latter;0
XD-2651;Spike: Research request/reply support to Kafka Message Bus The scope is to research the available options to provide request/reply support for Kafka.     * Document findings  * POCs    Previous Desc:  The bindRequestor and bindReplier methods of the message bus need to be implemented.;0
XD-2653;HdfsTest picks up data from a previous run. If a stream foo has messages in its queue when it is destroyed and another stream named foo is created of similar structure those messages will be delivered to sink.  This is seen when twitterstream runs prior to hdfssink test.  The twitters stream data is written to hdfs instead of the trigger data that was intended. The solution is to give hdfstest its own unique name instead of the default ec2test3 name.;0
XD-2655;Make deployment timeout configurable Currently ModuleDeploymentWriter uses default timeout 30s which can not be overridden. We need to make this configurable.;0
XD-2669;XD Requires a CI build for Windows Platform We need the ability to have bamboo provision a Windows instance on EC2 and launch a XD build.   Capture the results of the XD Build and report back to Bamboo Success or failure. If the build is successful shutdown the EC2 Windows instance.  Else leave it running so someone can diagnose the problem.;0
XD-267;Job as a Source h2. Narrative  As an XD developer I need to be able to use a batch job to stream data as a source.    h2.  Acceptance Criteria  # Implement the ability for a job to be defined as a source in the DSL  # Add the configurations for the batch infrastructure transparently to the user  # Add the ability to specify if the job is stateful (picks up where it left off if it stops or restarts at the beginning).;0
XD-2676;Resolve classloading issues for custom Hadoop based batch jobs There are several issues making it hard to impossible to create batch jobs that use Pig Hive HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.;0
XD-2677;Remove jline from xd-dirt classpath Currently jline 2.11 gets added via zookeeper dependency we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndencies    This jline version should remain for xd-shell classpath though;0
XD-268;Streamline command-line arg management Command line arguments (and especially their default values) are currently scattered around different places.    The aim is to regroup those in a common place (*Options classes make sense).    Also not very happy with how System properties are used as a vehicle for options.transport / options.home;0
XD-2683;Message conversion support for spark streaming module The spark streaming module needs to support inputType (for both processor and sink module) and outputType (for processor module) so that message conversion can happen at the MessageBusReceiver and MessageBusSender.;0
XD-2684;Set sourceCompatibility to JDK 1.7 Min JDK version for XD 1.1 is 7.  Change the sourceCompatibility to 1.7 but leave targetCompatibility at 1.6.   Changes are also needed in the mdule parent pom and gradle plugins.;0
XD-2685;Module delete command sporadically fails on windows When a user executes a module delete on a custom module it sporadically fails with the following exception below at the bottom of the description. Deployment: OS: Windows 8 or Windows Server 2012 R2 Java version Java 8 (build 25.31-b07 mixed mode) XD Deployment type. XD-Singlenode (embedded zookeeper)  Steps to reproduce: 1) build either the rss-feed-source or the payload-conversion samples from the spring-xd-samples 2) start xd-singlenode 3) start shell 4) from the shell execute module upload for the custom module i.e. module upload --file C:\project\spring-xd-samples\payloadconversion\build\libs\payload-conversion-1.0.0.BUILD-SNAPSHOT.jar --name myTupleProcessor --type processor 5) Verify that the module was uploaded by executing module info processor:myTupleProcessor 6) Execute module delete processor:myTupleProcessor  {noformat} 2015-02-18 14:48:43908 1.1.0.RELEASE ERROR qtp752571350-38 rest.RestControllerA dvice - Caught exception while handling a request org.springframework.xd.dirt.module.DependencyException: Cannot delete module pro cessor:myTupleProcessor because it is used by [stream:test]         at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod uleDefinitionService.java:116)         at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont roller.java:155)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl. java:62)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces sorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:483)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvok e(InvocableHandlerMethod.java:221)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeF orRequest(InvocableHandlerMethod.java:137)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt er.handle(AbstractHandlerMethodAdapter.java:85)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch erServlet.java:943)         at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche rServlet.java:877)         at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame workServlet.java:966)         at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe rvlet.java:890)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer vlet.java:842)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684 )         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1496)         at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf iguration.java:291)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna l(HiddenHttpMethodFilter.java:77)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter nal(HttpPutFormContentFilter.java:87)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter Internal(WebRequestTraceFilter.java:100)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi lterChainProxy.java:186)         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai nProxy.java:160)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java :499)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:137)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav a:557)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl er.java:231)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl er.java:1086)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java: 428)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle r.java:193)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle r.java:1020)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:135)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper .java:116)         at org.eclipse.jetty.server.Server.handle(Server.java:370)         at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac tHttpConnection.java:494)         at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra ctHttpConnection.java:971)         at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header Complete(AbstractHttpConnection.java:1033)         at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)         at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)          at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti on.java:82)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn dPoint.java:667)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd Point.java:52)         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo l.java:608)         at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool .java:543)         at java.lang.Thread.run(Thread.java:745) 2015-02-18 14:50:38191 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@14b69ddf moduleName = 'http' modu leLabel = 'http' group = 'test' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map[[empty]] children = list[[em pty]]] 2015-02-18 14:50:38380 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@7c2cd32 moduleName = 'myTupleProce ssor' moduleLabel = 'myTupleProcessor' group = 'test' sourceChannelName = [nu ll] sinkChannelName = [null] index = 1 type = processor parameters = map['in putType' -> 'application/x-xd-tuple'] children = list[[empty]]] 2015-02-18 14:50:38470 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@30ba1084 moduleName = 'log' modul eLabel = 'log' group = 'test' sourceChannelName = [null] sinkChannelName = [n ull] index = 2 type = sink parameters = map[[empty]] children = list[[empty] ]] 2015-02-18 14:50:38527 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.Initia lDeploymentListener - Path cache event: path=/deployments/streams/test type=CHI LD_REMOVED 2015-02-18 14:50:38528 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.source.http.1 type=CHILD_REMOVED 2015-02-18 14:50:38530 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.processor.myTupleProcessor.1 type=CHILD_ REMOVED 2015-02-18 14:50:38532 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.sink.log.1 type=CHILD_REMOVED 2015-02-18 14:50:41486 1.1.0.RELEASE  INFO LeaderSelector-0 server.DeploymentSu pervisor - Leadership canceled due to thread interrupt 2015-02-18 14:50:41592 1.1.0.RELEASE  WARN NIOServerCxn.Factory:0.0.0.0/0.0.0.0 :5156 server.NIOServerCnxn - caught end of stream exception EndOfStreamException: Unable to read additional data from client sessionid 0x14b 9d2656c30000 likely client has closed socket         at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228 )         at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFac tory.java:208)         at java.lang.Thread.run(Thread.java:745) {noformat};0
XD-2689;Fix Sqoop job to allow for setting yarn.application.classpath Running Sqoop job against non Apache Hadoop installation    - YARN app fails         Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster    - Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera Hortonworks Pivotal HD);0
XD-269;Create JobDefinition repository h2. Narrative As XD I need a persistent way to register job definitions (beyond the map registry implementation provided by Spring Batch).    h2.  Acceptance Criteria # XD should be able to register unregister and find job definitions via the registry. # The registry should be backed by Redis so that it is persistent.;0
XD-2691;Upgrade to the latest Gradle 2.x Release Gradle 2.x is required for the latest Sonar version (sonar.spring.io)    We may need to wait for a fix in Groovy itself (2.4.1) - Please see the following links for details:    * http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property    * http://jira.codehaus.org/browse/GROOVY-7023;0
XD-2696;Downgrade reactor based modules to reactor 1.x GA Can revert part of the commit that went into upgrading to reactor 2.0    https://github.com/spring-projects/spring-xd/pull/1342/files;0
XD-27;Gemfire CQ module for ingestion;0
XD-270;The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files A file that is in the process of being written to should have a customized suffix added to the name e.g. 'temp'.    Once the file is closed the suffix is removed and replaced with another value - default value can be dependent on the serialization format used but can be customized;0
XD-2705;"Add ability to add Custom Metrics/Controllers To Admin Context See original report here https://github.com/spring-projects/spring-xd/issues/1300  ""I've created a module with a custom Metric Handler and Repository patterned after the AggregateCounter but then it appears that there doesn't seem to be a way to add anything to the Admin Context.  The diagram at https://github.com/spring-projects/spring-xd/wiki/Extending-XD shows the Plugin Context as a sibling to the Admin Context which seems to verify my fears.  It would be convenient to be able to add custom Metrics/Controllers/Repositories into the Admin Context so that they can be accessed through the same REST api as the other Metrics.""";0
XD-2706;"Improve Redis Bus Error Log Entry {code}  logger.error(""Failed to deliver message retries exhausted message sent to queue 'ERRORS:name'""										context.getLastThrowable())  {code}    Should be:    {code}  logger.error(""Failed to deliver message retries exhausted message sent to queue 'ERRORS:"" + name + '""										context.getLastThrowable())  {code}    So the actual name is logged.";0
XD-2709;Investigate root cause of Spring XML parsing failures The error below appears to be a concurrency issue related to multiple classloaders loading the same spring XML resource.  The root cause needs further investigation but it causes intermittent test failures in JobCommandsTests.  see https://build.spring.io/browse/XD-JDK8-1375  java.lang.AssertionError: java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false result=null exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml] nested exception is java.lang.NullPointerException: Inflater has been closed ] java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false result=null exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml] nested exception is java.lang.NullPointerException: Inflater has been closed ];0
XD-271;The HDFS Sink should support a number of rollover options A strategy to roll over files that allows the user to choose between   1) the size of the file  2) the number of events/items in the file  3) an idle timeout value that if exceeded will close the file;0
XD-2710;Kafka Tests shouldn't assume offset 0 In `org.springframework.xd.dirt.stream.KafkaSingleNodeStreamDeploymentIntegrationTests#verifyOnDemandQueues` when testing the queue partitions for content the read is assumed to start at offset 0.    This is incorrect because the topics may exist already especially in a CI environment;0
XD-2711;CI Environment Needs test resources updated to latest versions Update Hadoop Spark Mongo gemfire and ubuntu to latest versions for both CI  and Utility instances.;0
XD-2720;Frequent connection pool errors with multi-partitioned jdbchdfs jobs I'm running a jdbchdfs job with 8 partitions and 2 containers. Some steps complete ok while some (3-4 on average) fail with a connection pool error (see below). This happens with a decent size table (1.8M rows).    I tried two different databases - Oracle 11g on a separate server and MySQL running locally where the XD containers where running. Same pattern with both databases.    {code}  2015-02-13 12:21:33436 1.1.0.RELEASE ERROR inbound.files3.0-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step step1 in job files3  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.itemReader' defined in file [/home/trisberg/Test/spring-xd-1.1.0.RELEASE/xd/modules/job/jdbchdfs/config/jdbchdfs.xml]: Invocation of init method failed nested exception is org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:342)    org.springframework.batch.core.scope.StepScope.get(StepScope.java:110)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:187)    com.sun.proxy.$Proxy90.open(Unknown Source)    org.springframework.batch.item.support.CompositeItemStream.open(CompositeItemStream.java:96)    org.springframework.batch.core.step.tasklet.TaskletStep.open(TaskletStep.java:310)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195)    org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:64)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276)    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy94.handleMessage(Unknown Source)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    sun.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy91.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)    org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)    org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:302)    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:329)    org.springframework.batch.support.DatabaseType.fromMetaData(DatabaseType.java:95)    org.springframework.xd.jdbc.NamedColumnJdbcItemReaderFactory.afterPropertiesSet(NamedColumnJdbcItemReaderFactory.java:101)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 90 more  Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80)    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:289)  	... 95 more  Caused by: java.sql.SQLException: Failed to validate a newly established connection.    org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)    org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)    org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)    org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)    org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)    org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)  	... 96 more  {code};0
XD-2722;Partitioned job throws: java.lang.RuntimeException: Could not serialize lambda Running a partitioned jdbchdfs job with 12 partitions and 3 xd-containers. Some steps fail with the jdbc connection pool exception XD-2720. I also sometimes see a serialization exception. This results in the partitioner never getting the status for some of the steps so it keeps running until it times out even though all steps are either complete of failed.    {code}  2015-02-13 13:18:36294 1.1.0.RELEASE ERROR inbound.files4.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message retries exhausted message sent to queue 'ERRORS:name'  org.springframework.messaging.MessageHandlingException: error occurred in message handler [files4.0.bridge.handler] nested exception is com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda  Serialization trace:  stepExecutions (org.springframework.batch.core.JobExecution)  jobExecution (org.springframework.batch.core.StepExecution)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)    org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)    org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    java.lang.Thread.run(Thread.java:745)  Caused by: com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda  Serialization trace:  stepExecutions (org.springframework.batch.core.JobExecution)  jobExecution (org.springframework.batch.core.StepExecution)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)    com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)    com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:682)    org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.doDeserialize(PojoCodec.java:41)    org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec$1.execute(AbstractKryoMultiTypeCodec.java:63)    com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.run(KryoPoolQueueImpl.java:43)    org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec.deserialize(AbstractKryoMultiTypeCodec.java:60)    org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.deserialize(PojoCodec.java:30)    org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:72)    org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:78)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:588)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:573)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:556)    org.springframework.xd.dirt.integration.redis.RedisMessageBus.access$1000(RedisMessageBus.java:68)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:465)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  	... 21 more  Caused by: java.lang.RuntimeException: Could not serialize lambda    com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:52)    com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:786)    com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:116)    com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:22)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)  	... 40 more  Caused by: java.lang.ArrayIndexOutOfBoundsException: -2    java.util.ArrayList.elementData(ArrayList.java:418)    java.util.ArrayList.get(ArrayList.java:431)    com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)    com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:830)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)    com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:49)  	... 45 more  {code};0
XD-2725;"http does not report failure to bind to port Stumbled upon this while having Hadoop daemons running but simple way to repoduce:  {noformat} nc -lp 9000  stream create foo --definition ""http | log"" --deploy ==> all seems ok  http post --data hello ==> Error 500 rightfully so {noformat}";0
XD-2726;"Allow deletion of all metrics of a kind To be added in AbstractMetricsController as well as the various shell commands (""counter all delete"" etc...)";0
XD-2729;Update payload-conversion demo to latest module spec Upload payload conversion demo such that a user can use the module upload feature against the sample.;0
XD-2731;Temp files for stream create not being cleaned During testing for Spring XD for PivotalCF we create deploy use undeploy and destroy many streams. Each stream generates {{tmp}} directories (I think 2 one for source one for sink) in the xd-admin VM's {{/tmp}} directory e.g.    {noformat}  dummy-module4635787551932601017sinkredis  dummy-module252960009195893204sourcehttp  {noformat}    These {{tmp}} directories are not being cleared up so our system has hit the inode limit of 32768 files for a volume:    {noformat}  Filesystem     Inodes IUsed  IFree IUse% Mounted on  /dev/loop0      32768 32768      0  100% /tmp  {noformat}    This causes a Java {{IOException}} the immediately relevant part of which appears to be:    {noformat}  [Caught] exception while handling a request  Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  [java.lang.RuntimeException] java.io.IOException: No space left on device  Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  []    at org.springframework.xd.module.ModuleDefinitions.dummy(ModuleDefinitions.java:81)  {noformat}    This causes the test system to fail entirely.;0
XD-2733;Custom Modules can't be found wen using xd.customModule.home on windows XD can not find the custom modules directory after Setting the xd.customModule.home in the windows environment   Deployment * xd-singlenode (embedded zookeeper) * Java 8 * Windows 8 or Windows Server 2012 r2  Steps to reproduce:  1) Start xd-singlenode 2) Start Shell 3) Build either the payload-conversion or rss-feed-source from the spring-xd-samples 4) use the shell to execute a module upload for the custom module (rss-feed-source payload-conversion) 5) verify it uploaded xd:>module info processor:myTupleProcessor 6) stop xd single node 7) From the command line execute set xd.customModule.home=[path to your custom modules] i.e. C:\project\spring-xd-1.1.0.RELEASE\xd\custom-modules 8) restart xd-singlenode 9) execute module info processor:myTupleProcessor 10) you will get the following error {noformat} Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'myTupleProcessor' and type 'processor' {noformat};0
XD-2736;Revert XD specific support for JsonPath 1.2 Thanks to INT-3624 we don't need our specific class anymore;0
XD-2739;Add a Sqoop example;0
XD-2743;Improve acceptance testing coverage The scope is to address the sub-tasks linked with this story.;0
XD-2744;Placeholder for Spring XD Lab;0
XD-2749;Placeholder for Lattice/Diego POC #1;0
XD-2752;SqoopTasklet not using hadoop configuration Hey Guys    I'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log).  Could please you guys help me to solve this problem?    Thanks in advance.  Regards;0
XD-2753;"Allow to install new XD modules from maven coordinates Currently new modules can be installed via the module upload command but for this to work one needs to  build the artifacts beforehand.    It would be great to have support for installing new XD modules from maven coordinates (e.g. from a public or   controlled maven repository).  With this one would make it easy to consume community modules without much hassle.    This could also serve as some kind of starting ground for some ""special solution packages"" that provides support  for c.f. natural language processing (via a bunch of jars that contain the modules for language detection entity detection sentiment analysis topic clustering) etc. that could be consumed via some kind of .bom (bill of materials) dependency like:    module install ""pivotal:toolkits:nlp""";0
XD-2754;ClassLoading interaction issue between MessageBus and modules See discussion at http://stackoverflow.com/questions/28551506/spring-xd-jms-message-bus-with-jms-sink;0
XD-2756;"Large number of required options in jdbc sink definition I'd like to use the following command to define a stream in our Spring XD for PivotalCF test environment:    {code}  stream create --name test --definition ""http --port=9999 | jdbc --username=spring-xd --password=spring-xd --driverClassName=org.postgresql.Driver --url=jdbc:postgresql://1.2.3.4:5432/spring-xd""  {code}    I have to add the following options to the definition to make it work (otherwise I get exceptions and a failed deploy):    {code}  -validationQuery='' --validatorClassName='#{null}' --connectionProperties='' --initSQL='' --jdbcInterceptors='' --initializerScript=''   {code}    Given that they're empty anyway it seems like some or all of these should not be necessary.    _Notes_  * The validatorClassName cannot be '' like the others it needs the null.  * Without initSQL='' stream creation fails because it can't find init_db.sql (a file I don't have in my environment) even though it won't be run anyway.";0
XD-2758;Add module description to the JSON response As  a user I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).;0
XD-2759;LocalMessageBus PubSub Needs a Bounded Task Exectutor Since 1.1 {{PubSub}} channels in the {{LocalMessageBus}} run on a {{CachedThreadPoolExecutor}}.    For high volume environments where back-pressure might occur on a {{topic:}} thread we could overwhelm the system with threads.    Add a local bus configuration to limit the thread pool used for PubSubs and queue tasks where there are no threads available.    It would be a bus-wide setting.;0
XD-2761;Register only known classes with Kryo in PojoCodec Currently PojoCodec calls kryo.register(Class<?> type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules);0
XD-2765;Spike: Research Zookeeper-based mechanism for partitioned job management The current implementation of partitioned job management is entirely based on message exchange over the message bus in a request reply scenario.  This creates challenges when it comes to using certain types of transports as well as acknowledging crashes.   To that effect the option of using a different partitioned job coordination strategy that relies on a distributed computing coordination mechanism such as ZooKeeper should be investigated.;0
XD-2769;Inconsistent API in AbstractSingleNodeNamedChannelSink In [AbstractSingleNodeNamedChannelSink|https://github.com/spring-projects/spring-xd/blob/6bd17162c8a6da0f09f6f8809f694a060c71ecc0/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/test/sink/AbstractSingleNodeNamedChannelSink.java] the receive() and receivePayload() methods  are non-blocking.    Methods without timeout parameter are usually blocking and return the first message delivered to the channel (e.g. org.springframework.integration.channel.AbstractPollableChannel#receive()).     Integration tests based on spring-xd-test dependency and embedded xd-singlenode are asynchronous. This makes AbstractSingleNodeNamedChannelSink receive method return null in all invocations because test thread is progressing faster than container can process the message in the background.    Would it be possible to make receive methods behave like in AbstractPollableChannel?;0
XD-2771;"spring-xd-dirt is not providing all $XD_HOME/lib libraries Spring XD is packaging a spring-xd-dirt dependency which aims to provide runtime libraries.    spring-xd-drit-1.1.0.RELEASE is not providing all libraries from $XD_HOME/lib. See spring-xd-dirt-vs-lib.xlsx attachment generated with ""ls  $XD_HOME/lib"" and ""mvn dependency:list"" on a module with spring-xd-module-parent parent:  - 100+ JARs are not provided  - some are provided in different versions  - some are provided but not available in $XD_HOME/lib    This forces us to add and maintain missing dependencies in our own module parent e.g. to use commons-lang3 in our code which is present in $XD_HOME/lib but is not provided by spring-xd-dirt.    Why there are so many differences between $XD_HOME/lib and spring-xd-dirt?";0
XD-2774;"Update to SHDP 2.1.1 for fixing hdfs store writer to recover after error writing to hdfs The hdfs sink doesn't recover after error writing to hdfs.  Steps to reproduce -  create a stream using hdfs sink with a small rollover:  {code} xd:>stream create --name errtest --definition ""time | hdfs --rollover=50"" --deploy  {code}  stop the datanode(s) and wait for an exception like:  {code} 2015-03-03 10:41:57832 1.1.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS nested exception is org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.   org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)   org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)   org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)   org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)   org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)   org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)   java.security.AccessController.doPrivileged(Native Method)   javax.security.auth.Subject.doAs(Subject.java:415)   org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)   org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)    org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)   org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy136.handleMessage(Unknown Source)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)   org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)   org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy125.send(Unknown Source)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)   org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)   org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy137.send(Unknown Source)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)   org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)   org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)   org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)   org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)   org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.   org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)   org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)   org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)   org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)   org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)   org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)   java.security.AccessController.doPrivileged(Native Method)   javax.security.auth.Subject.doAs(Subject.java:415)   org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)   org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)    org.apache.hadoop.ipc.Client.call(Client.java:1468)   org.apache.hadoop.ipc.Client.call(Client.java:1399)   org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)   com.sun.proxy.$Proxy134.addBlock(Unknown Source)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)   org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)   com.sun.proxy.$Proxy135.addBlock(Unknown Source)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588) {code}  start the datanode(s) again the sink never recovers and has to be undeployed and redeployed.";0
XD-2779;Fix error handling in jdbchdfs job The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.    We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.;0
XD-2783;RabbitMQ server.yml options ignored {{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. These values are not being retrieved and hence have to be manually added to each stream definition. * {{addresses}} * {{username}} * {{password}} * {{virtual_host}}  (cf XD-2675 XD-2741);0
XD-2790;Rabbit source and sink mappedRequestHeaders should include all headers by default Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink otherwise no headers are mapped to AMQP.  This should be the default behavior.;0
XD-2792;Automate provisioning story for XD;0
XD-2798;Redis and In-memory offset storage profiles for the kafka source have wrong definitions;0
XD-2803;Custom User Configuration file for Jobs Allow users to submit a configuration file as part of the job definition.  The configuration file should contain all job definition parameters as well as customer parameters that can be reference during runtime.  Thanks Buelent;0
XD-2804;Module options are not trimmed Spring XD 1.1 container will throw following exception:   {code}  java.lang.IllegalStateException: Can't find class used for type of option 'myField': String     org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)    org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)    org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)    org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)  	...  {code}    when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value):    {code}  options.myField.description = this is my field  options.myField.type = String   {code}    Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map  to avoid this problem?;0
XD-2806;"Module count not respected when label is used {code}  xd:> stream create test --definition ""http | t1:transform --expression=payload | log""  xd:>stream deploy test --properties module.t1.count=2  Deployed stream 'test'  xd:>runtime modules    Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status    -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------    test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=1 producer.next.module.count=1 count=1 consumer.count=1 sequence=1}  deployed    test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test expression=payload level=INFO}                                                                                                                                                        {consumer.sequence=1 count=1 consumer.count=1 sequence=1}                                deployed    test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties maxContentLength=1048576 port=9000 messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter https=false}  {producer.next.module.count=1 count=1 sequence=1}                                         deployed  {code}    *************************************  Works fine without the label:  *************************************  {code}  xd:>stream destroy test  Destroyed stream 'test'  xd:>stream create test --definition ""http | transform --expression=payload | log""  Created new stream 'test'  xd:>stream deploy test --properties module.transform.count=2  Deployed stream 'test'  xd:>runtime modules    Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status    --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------    test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=1 producer.next.module.count=1 count=2 consumer.count=2 sequence=1}  deployed    test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=2 producer.next.module.count=1 count=2 consumer.count=2 sequence=2}  deployed    test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test expression=payload level=INFO}                                                                                                                                                        {consumer.sequence=1 count=1 consumer.count=1 sequence=1}                                deployed    test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties maxContentLength=1048576 port=9000 messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter https=false}  {producer.next.module.count=2 count=1 sequence=1}                                         deployed  {code}";0
XD-2809;jdbdhdfs job definition parameter 'partitionResultsTimeout' issues The 'partitionResultsTimeout' parameter for jdbchdfs job definition cannot be set for the master step if the job has a partition definition.  The partitionResultsTimeout is set for the individual partition steps only. The master steps fails after the default timeout.;0
XD-2810;partition jobs (jdbchdfs) are running in sequence The jdbchdfs jobs that are partitioned are running in sequence rather than in parallel. Our expectation with partition jobs is that they run in parallel.  Job configuration is:  jdbchdfs --driverClassName='oracle.jdbc.OracleDriver' --url='jdbc:oracle:thin:@=**********' --username='=**********' --password=********** --validationQuery='SELECT CURRENT_TIMESTAMP FROM DUAL' --tableName='HZ_ORGANIZATION_PROFILES' --columns='ORGANIZATION_PROFILE_ID ... VERSION_NUMBER' --partitions=10 --partitionColumn='ORGANIZATION_PROFILE_ID' --directory='/ingest/source/oracle11i/ar/hz_organization_profiles' --fileName=hz_organization_profiles --fileExtension=csv --delimiter=| --commitInterval=10000 --rollover=262144000 --dateFormat=yyyy-mmm-dd --partitionResultsTimeout=1800000 --testOnBorrow=false;0
XD-2811;deployed modules are not redeployed properly once the container come back online Deployed component s are not deployed to the containers that failed and restarted.   We have 3 containers and 3 jobs where all jobs are deployed evenly one job per container. However when two of the containers fail and come back up we end up with 3 jobs on 1 container.  See attached document for detail.;0
XD-2812;Batch Job deployment screen only show 10 items... The Batch Jobs Deployment screen  ('http://*****************:9393/admin-ui/#/jobs/deployments') UI screen is only showing 10 items without pagination and prohibiting users from launching their deployed jobs from the UI.  The jobs can only be launched via the RESTApi call  In release 1.0.3 the deployment page has not pagination but grows beyond 10 entries.;0
XD-2813;Investigate running Camus as a batch job Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.;0
XD-2814;RabbitMQ Dead Letter for TAP not deleted If automatic binding of dead letter is enabled for rabbit mq and taps are deployed anytime the tap is undeployed the dead letter for that tap still remains.  The tap uses a unique name and the queue for that is automatically deleted but the dead letter queue for it is not.  This problem becomes worse when containers are running in yarn and may not live for long periods of time.  Many dead letter queues for taps can become overwhelming.;0
XD-2818;upgrade to io.projectreactor breaks generated POMS ./gradlew install fails for spring-xd-extension-batch and spring-xd-extension-reactor. The first case is a simple update to gradle/build-extensions.gradle. The 2nd causes several compilation errors that are not trivial for a Reactor noob.;0
XD-2819;"Broken ""Deployment"" link in docs Please see ""Deployment"" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/#_module_deployment page.     !broken-link-deployment.png!    The link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/Deployment which is a 404.";0
XD-282;The HDFS Sink should support writing POJOs to HDFS using Avro Serialization Writing POJOs using CDK Data (Avro)  We should support both partitioned and un-partitioned.  This story addresses only un-partitioned.  Document limitations in terms of which Java types are supported and not supported by the Avro serialization;0
XD-2820;"Composing transformer and gemfire-json-server leads to FileNotFoundException during deployment Composing ""transform"" and ""gemfire-json-server"" modules leads to FileNotFoundException during stream deployment when:  - xd-admin and xd-container are started as system services (after installing from RPM).   - xd-singelonde is started outside of $XD_HOME/bin directory e.g. {code}  $ cd ""$XD_HOME""  $ bin/xd-singelonde  {code}    but it's fully working and exception is *not* thrown when:  - xd-singlenode script is started from within ""$XD_HOME/bin directory {code}  $ cd ""$XD_HOME/bin""  $ ./xd-singelonde  {code}    Then using the XD Shell:    {code}  $ xd-shell  > module compose --name ""cm-gem-sink"" --definition ""transform --outputType='application/json' | gemfire-json-server --regionName=timeRegion --keyExpression=payload.getField('location')""  > stream create --name ""cm-test-gem"" --definition ""tail --name='/tmp/time.json' | cm-gem-sink""   > stream deploy --name ""cm-test-gem""  {code}    Stream deployment will result in following exception    {code}  [2015-03-11 16:38:10.918] boot - 17402  INFO [DeploymentsPathChildrenCache-0] --- DeploymentListener: Deploying module [ModuleDescriptor@2095e9f9 moduleName = 'tail' moduleLabel = 'tail' group = 'cm-test-gem' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map['name' -> '/tmp/time.json'] children = list[[empty]]]  2015-03-11 16:38:11263 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'cm-test-gem': DeploymentStatus{state=failederror(s)=org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy] nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/modules/sink/gemfire-json-server/config/gemfire-json-server.groovy] nested exception is org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy] nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)    org.springframework.xd.module.core.CompositeModule.initialize(CompositeModule.java:105)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy] nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans$_run_closure1.doCall(beans:4)    beans$_run_closure1.doCall(beans)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.Closure.call(Closure.java:423)    groovy.lang.Closure.call(Closure.java:417)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)    groovy.lang.Closure.call(Closure.java:439)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans.run(beans:1)    groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 30 more  Caused by: java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    java.io.FileInputStream.open(Native Method)    java.io.FileInputStream.<init>(FileInputStream.java:146)    java.io.FileInputStream.<init>(FileInputStream.java:101)    sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)    sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)    org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)    org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 80 more  {code}    Exporting XD_HOME as a global variable seems to have no effect on this behavior.";0
XD-2822;Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop's DataStoreWriter implementations such as partitioning.  Update the jdbchdfs job to use <int-hadoop:store-writer/> (similar to the HDFS Sink) inside a new ItemWriter implementation;0
XD-2824;"hdfs sink loses messages/data when container killed Scenario running a ""rabbit | hdfs"" stream and killing the xd-container while stream is running.  Looks like the messages get's acked before the data is flushed to hdfs.  This results in some data lost due to data either in tmp file or cached in the dfs client.  Reference: VESC-387";0
XD-2826;Remove Reactor Stream processor from ref docs to spring-xd-modules Not going to integrate with Reactor for stream processing.;0
XD-2829;Add the Dependencies Required to Use #xpath in Streams Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class).     http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload;0
XD-2837;XD-Admin fails to start When starting xd-admin getting the following exception:  {noformat}  2015-03-20 14:25:53904 1.2.0.SNAP  WARN main annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1] nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)    org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)    org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)    org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 22 more  Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    java.lang.Class.forName0(Native Method)    java.lang.Class.forName(Class.java:190)    org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)    org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)    org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 25 more  Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:425)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:358)  	... 32 more  2015-03-20 14:25:53911 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1] nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)    org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)    org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)    org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 22 more  Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    java.lang.Class.forName0(Native Method)    java.lang.Class.forName(Class.java:190)    org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)    org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)    org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 25 more  Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:425)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:358)  	... 32 more  2015-03-20 14:25:53915 1.2.0.SNAP ERROR main server.AdminServerApplication - Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1] nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  {noformat}    Reproduced Locally (mac) and on EC2.  xd-singlenode works fine.  Commit: 4673b5ab97;0
XD-2842;Kafka source should not try to decode payloads as Strings Currently the Kafka source uses a StringDecoder by default - which is an invalid assumption if the payload is not the result of String conversion.;0
XD-2847;SqoopRunner should use resource manager scheduler option In SqoopRunner we manually set rm address fs address and yarn classpath. YarnConfiguration.RM_SCHEDULER_ADDRESS is also needed for appmaster to function properly.  Current workaround is to use config values which gets imported automatically: {code} spring:     hadoop:         config:             yarn.resourcemanager.scheduler.address: <host>:8030 {code};0
XD-2851;"Module loading error handling improvement Modules are loaded in the container as such (in DeploymentListener):  {code} try { 	module = (ModuleType.job.toString().equals(moduleType)) ? 			deployJobModule(client unitName moduleLabel properties) : 			deployStreamModule(client unitName moduleType moduleLabel properties) 	if (module == null) { 		status = new ModuleDeploymentStatus(container moduleSequence key ModuleDeploymentStatus.State.failed 				""Module deployment returned null"") 	} 	else { 		status = new ModuleDeploymentStatus(container moduleSequence key 				ModuleDeploymentStatus.State.deployed null) 	} } catch (Exception e) { 	status = new ModuleDeploymentStatus(container moduleSequence key ModuleDeploymentStatus.State.failed 			ZooKeeperUtils.getStackTrace(e)) 	logger.error(""Exception deploying module"" e) }  try { 	writeModuleMetadata(client module path) 	client.setData().forPath(status.buildPath() ZooKeeperUtils.mapToBytes(status.toMap())) } catch (KeeperException.NoNodeException e) { 	logger.warn(""During deployment of module {} of type {} for {} with sequence number {}"" + 					""an undeployment request was detected this module will be undeployed."" moduleLabel 			moduleType unitName moduleSequence) 	if (logger.isTraceEnabled()) { 		logger.trace(""Path "" + path + "" was removed"" e) 	} } {code}  The problem is if an {{Error}} is thrown such as {{NoClassDefFoundError}} or {{NoSuchMethodError}}. We need to make a best effort when writing the deployment status to prevent the supervisor from timing out waiting for a status.";0
XD-2853;XD admin ZK distributed queue consumer initialization issue The ZK distributed queue consumer is initialized even before the module stream job deployment requests path cache are started. This could lead to issue when the consumer start processing the requests before the cache are initialized.    On such scenario the following exception could be thrown:    2015-03-23 21:00:25919 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000002  org.springframework.xd.dirt.server.admin.deployment.DeploymentException: dataSender          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:70)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)          at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)          at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)          at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)          at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)          at java.util.concurrent.FutureTask.run(FutureTask.java:262)          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)          at java.lang.Thread.run(Thread.java:745)  Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.          at org.springframework.util.Assert.notNull(Assert.java:112)          at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161);0
XD-2854;Launching XD admin fails with ZK holding existing stream data Following exception is thrown when starting XD admin withe ZK holding the stream data:    2015-03-23 17:21:13831 1.2.0.SNAP ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception  java.lang.NullPointerException  at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:822)  at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:896)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:157)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:56)  at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:654)  at org.springframework.xd.dirt.stream.dsl.ChannelNode.resolve(ChannelNode.java:144)  at org.springframework.xd.dirt.stream.dsl.SourceChannelNode.resolve(SourceChannelNode.java:54)  at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:125)  at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:110)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:121)  at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)  at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)  at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.recalculateStreamStates(DefaultDeploymentStateRecalculator.java:96)  at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.onSupervisorElected(DefaultDeploymentStateRecalculator.java:182)  at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:468)  at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)  at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745);0
XD-2859;UI: Deploy Stream - Return key does not submit form *http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*;0
XD-2860;remove ModuleDefinitions.dummy() This method should be replaced with a utility method in a test support class so that it is only available in a testing context.;0
XD-2861;Admin leader election issue when using different management port When the admin is started with the different management port (default is the same as that of admin http port) then the leadership is requested when the management context is setup. The leadership election should happen only using the Admin server application context.  With this the following exception is thrown when deployment requests are handled:  2015-03-24 21:48:26340 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000004 org.springframework.xd.dirt.server.admin.deployment.DeploymentException: testStream   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:73)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)   org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)   org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)   org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)   org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.   org.springframework.util.Assert.notNull(Assert.java:112)   org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161) 	... 17 more;0
XD-2863;When Scheduling a Job I cannot provide Job parameters Add the ability to provide job parameters when scheduling jobs;0
XD-2864;JavaConfiguredModule should throw an exception when no @Configuration class is present I had a custom module with a typo:  base_packages=base_packages=com.acme.config    The module deploys without error but the stream hangs since the channels etc. are not found in the stream plugin. Very hard to debug.;0
XD-2865;Message Bus: Shut down Kafka Consumers completely before unbinding This causes the following exception to be thrown in the log (without functional adverse effects)    org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'. nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)    org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)    org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)    org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 13 more;0
XD-2866;"Admin UI does not show all containers We have 3 reported incidents so still working on reproducing the issue.    1) You start multiple ""nodes"" but the admin-ui does not show all of them but logs do  2) By restarting the ""missing"" nodes they eventually show up in the Admin UI";0
XD-2867;STS Gradle Import Missing Dependencies without Enabling Scala Dirt errors after {{cleanEclipse eclipse}} - same problem after a complete gradle reimport.  Manually adding the spring-xd-spark-streaming project to the xd-dirt classpath didn't help.  {code} Description	Resource	Path	Location	Type The import org.springframework.xd.spark cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 33	Java Problem The import org.springframework.xd.module.ModuleType is never used	ModuleDeploymentTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins	line 33	Java Problem The import org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean is never used	BatchJobRegistryBeanPostProcessor.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job	line 31	Java Problem The value of the field KafkaMessageBusTests.embeddedHeadersMessageConverter is not used	KafkaMessageBusTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/bus/kafka	line 56	Java Problem SparkStreamingSupport cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 68	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 75	Java Problem SparkMessageSender cannot be resolved to a type	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 38	Java Problem The import org.springframework.beans.factory.annotation.Value is never used	MessageBusClassLoaderFactory.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server	line 27	Java Problem The import org.springframework.xd.spark cannot be resolved	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 28	Java Problem The method send(Message) of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 104	Java Problem The method start() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem The method isRunning() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 123	Java Problem The method stop() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 109	Java Problem The import org.springframework.xd.dirt.plugins.job.support.JobLaunchingJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 37	Java Problem Resource leak: 'cache' is never closed	TestKafkaCluster.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/kafka	line 116	Java Problem The value of the field StreamDeployer.parser is not used	StreamDeployer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream	line 42	Java Problem The import org.springframework.batch.core.repository.support.SimpleJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 31	Java Problem The method endPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 555	Java Problem The method startPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 546	Java Problem The expression of type AbstractInstancePersistingDeployer<DI> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 268	Java Problem The expression of type AbstractInstancePersistingDeployer<DI> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 217	Java Problem Resource leak: 'context' is never closed	SparkStreamingChannel.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 45	Java Problem The value of the field StreamConfigParserTests.zooKeeperConnection is not used	StreamConfigParserTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/stream/dsl	line 63	Java Problem The value of the field JobPluginTests.deploymentProperties is not used	JobPluginTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins/job	line 94	Java Problem The import org.springframework.xd.spark cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 41	Java Problem SparkStreamingSupport cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 68	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 79	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 97	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 99	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 100	Java Problem The value of the field ModuleTypeConversionPlugin.logger is not used	ModuleTypeConversionPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/stream	line 45	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 82	Java Problem SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 87	Java Problem The method getComponent(Class<SparkStreamingSupport>) from the type Module refers to the missing type SparkStreamingSupport	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem  {code};0
XD-2872;"Able to bypass authorization checks by appending "".json"" or "".xml"" How to reproduce:    1) Enable security  2) Use a user that has the following role only: ""ROLE_CREATE""  3) Make a normal REST call:    {code}  http://localhost:9393/runtime/containers  {code}    yields the *desired response*:    {code}      {         ""timestamp"": ""2015-03-26T16:51:17.010Z""         ""status"": 403         ""error"": ""Forbidden""         ""message"": ""Access is denied""         ""path"": ""/runtime/containers""      }  {code}    Now try:    {code}  http://localhost:9393/runtime/containers.json  {code}    This produces:    {code}          {         ""links"":         [             {                 ""rel"": ""self""                 ""href"": ""http://localhost:9393/runtime/containers{?pagesizesort}""             }         ]         ""content"":         [             {                 ""containerId"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                 ""groups"": """"                 ""deploymentSize"": 0                 ""deployedModules"":                 [                 ]                 ""messageRates"": null                 ""attributes"":                 {                     ""ip"": ""10.0.1.119""                     ""host"": ""INTEGRATION.local""                     ""groups"": """"                     ""pid"": ""52686""                     ""id"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                 }                 ""links"":                 [                     {                         ""rel"": ""self""                         ""href"": ""http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                     }                 ]             }         ]         ""page"":         {             ""size"": 20             ""totalElements"": 1             ""totalPages"": 1             ""number"": 0         }      }  {code}";0
XD-2873;"Creating Streams sporadically using Kafka as a message bus throws TopicNotFound exception XD Version Spring XD 1.1.1.Release  1 Admin on own (on-metal) Rackspace machine  2 Containers each having own (on-metal) rackspace machine  1 zookeeper node collocated with admin    While executing XD performance testing on Rackspace using Kafka as a transport we occasionally get the following exception:  {noformat}  2015-03-26 18:36:30677 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/4c3c9ccf-44db-4772-87c2-70c63b82c3aa/foo3.sink.throughput.1 type=CHILD_ADDED  2015-03-26 18:36:30685 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'throughput' for stream 'foo3'  2015-03-26 18:36:30820 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@19f0b0a6 moduleName = 'throughput' moduleLabel = 'throughput' group = 'foo3' sourceChannelName = [null] sinkChannelName = [null] index = 1 type = sink parameters = map[[empty]] children = list[[empty]]]  2015-03-26 18:36:31372 1.1.1.RELEASE ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  org.springframework.integration.kafka.core.TopicNotFoundException: No topic named 'foo3.0' found    org.springframework.integration.kafka.core.DefaultConnectionFactory.getPartitions(DefaultConnectionFactory.java:209)    org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.createKafkaConsumer(KafkaMessageBus.java:640)    org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindConsumer(KafkaMessageBus.java:454)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:275)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:158)    org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)    org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  {noformat}    stream used to create the exception:  stream create foo4 --definition ""load-generator --messageSize=1000 --messageCount=10000000 | throughput"" --deploy    After failed deployment.  I destroy the stream and recreate it and it works fine.";0
XD-2874;Improve the enforcement of meta-properties being set in build.gradle Last Sync Errors: Invalid POM: /org/springframework/xd/spring-xd-module-parent/1.1.1.RELEASE/spring-xd-module-parent-1.1.1.RELEASE.pom: Developer information missing Invalid POM: /org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE/spring-xd-module-plugin-1.1.1.RELEASE.pom: Project name missing Project description missing Project URL missing License information missing SCM URL missing Developer information missing Missing: no javadoc jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Missing: no sources jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Dropping existing partial staging repository.;0
XD-2878;Using a newer version of a spring-xd dependency is ignored in packaging When creating a new module with a dependeny which has a newer version than the one Spring-xd uses (in my example I use Jedis 2.6.1 and Spring-xd uses Jedis 2.5.2) the packaging ignores the dependency.  Using the solution of spring-boot-maven-plugin doesn't help because it will only include what you explicitly add to the include section (transitive dependencies are not included);0
XD-2884;Document dynamic classpath feature;0
XD-2885;Only ship relevant modules files The current build ships everything that is found in the modules directory including build artifacts such as build/ or IDEA *.iml files.    Restrict the build to only include config/ lib/ at the moment.;0
XD-29;Create rich gauge service A rich gauge stores a number and also rmd min max. Implementations for in-memory and redis.;0
XD-2909;Produce Kafka Baseline numbers on Rackspace;0
XD-2920;Dynamic router should allow to discard messages Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.    Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router/>}}.;0
XD-2923;"Not able to connect a pubsub channel to spark streaming module If a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel) then it doesn't bind to it.    For instance if I have a stream ""ingest"" with a definition ""http | log"" and want to create another stream as  ""tap:stream:ingest > spark-processor | count"" then this stream doesn't work.";0
XD-2924;Ability to tap spark streaming processor output We need to support adding a tap stream that connects to spark streaming processor module's output channel.;0
XD-2931;Login page is missing style info when secured If the admin UI is secured the login page is displayed without any styles.;0
XD-2937;xd-admin silently fails if servers.yml is invalid for example:  {code} xd:   transport: rabbit    messagebus: #    local: #      queueSize:                   2147483647 #      polling:                     1000 #      executor: #        corePoolSize:              0 #        maxPoolSize:               200 #        queueSize:                 2147483647 #        keepAliveSeconds:          60     rabbit: #      compressionLevel:            1             # bus-level property applies only when 'compress=true' for a stream module             # See java.util.zip.Deflater 1=BEST_SPEED 9=BEST_COMPRESSION ...       default: #        ackMode:                   AUTO             # Valid: AUTO (container acks) NONE (broker acks) MANUAL (consumer acks).             # Upper case only.             # Note: MANUAL requires specialized code in the consuming module and is unlikely to be             # used in an XD application. For more information see             # http://docs.spring.io/spring-integration/reference/html/amqp.html#amqp-inbound-ack #        autoBindDLQ:               false #        backOffInitialInterval:    1000 #        backOffMaxInterval:        10000 #        backOffMultiplier:         2.0 #        batchBufferLimit:          10000         batchingEnabled:           true #        batchSize:                 100 #        batchTimeout:              5000 #        compress:                  false #        concurrency:               1 #        deliveryMode:              PERSISTENT #        maxAttempts:               3 #        maxConcurrency:            1 #        prefix:                    xdbus.             # prefix for queue/exchange names so policies (ha dle etc.) can be applied #        prefetch:                  1 #        replyHeaderPatterns:       STANDARD_REPLY_HEADERS* #        requestHeaderPatterns:     STANDARD_REQUEST_HEADERS* #        requeue:                   true #        transacted:                false #        txSize:                    1  #    redis: #      headers:             # comman-delimited list of additional (string-valued) header names to transport #      default:             # default bus properties if not specified at the module level #        backOffInitialInterval:    1000 #        backOffMaxInterval:        10000 #        backOffMultiplier:         2.0 #        concurrency:               1 #        maxAttempts:               3 #   kafka: #      brokers:                                 localhost:9092 #      zkAddress:                               localhost:2181 #      numOfKafkaPartitionsForCountEqualsZero:  10 #      socketBufferSize:                        2097152 #      offsetStoreTopic:                        SpringXdOffsets #      offsetStoreSegmentSize:                  25000000 #      offsetStoreRetentionTime:                60000 #      offsetStoreRequiredAcks:                 1 #      offsetStoreMaxFetchSize:                 1048576 #      offsetStoreBatchSize:                    200 #      offsetStoreBatchEnabled:                 false #      offsetStoreBatchTime:                    1000 #      offsetUpdateTimeWindow:                  10000 #      offsetUpdateCount:                       0 #      offsetUpdateShutdownTimeout:             2000       default:         batchingEnabled:           true {code};0
XD-2944;"twittersearch stream returns duplicate tweets The twittersearch source module picks up the same tweet in successive iterations of the REST request. The reason for this is that the since_id value being set at the end of each iteration is the last item in the list of tweets but not the latest value of tweet id.  Steps to reproduce:  Created a stream using below definition  stream create --name twittersearchspring --definition ""twittersearch --consumerKey=<key> --consumerSecret=<secret> --query='spring' | tweet-transformer | file"" --deploy  tweet-transformer referred here is used from the spring-xd-samples repo and is logging the tweet ID being transformed https://github.com/spring-projects/spring-xd-samples/tree/master/tweet-transformer-processor  Below is the log  __________ 2015-04-14 15:47:22154 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'twittersearchspring': DeploymentStatus{state=deployed} 2015-04-14 15:47:22158 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Stream Stream{name='twittersearchspring'} deployment attempt complete 2015-04-14 15:47:24301 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:24312 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:24315 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:24318 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:24320 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:24325 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:24340 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:24342 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:24343 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:24344 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884737307549696 2015-04-14 15:47:24346 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884734723702784 2015-04-14 15:47:24348 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884730059771905 2015-04-14 15:47:24356 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884729225125888 2015-04-14 15:47:24358 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884725802405888 2015-04-14 15:47:24359 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884724938481665 2015-04-14 15:47:26465 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884724938481665 2015-04-14 15:47:26865 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:26867 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:26869 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:26871 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:26872 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:26878 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:26880 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:26882 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:26884 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:26886 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:26887 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:26889 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:26890 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:26900 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:26903 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:29004 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884739387719680 2015-04-14 15:47:29369 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884782945611776 2015-04-14 15:47:29371 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884781305663488 2015-04-14 15:47:29374 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884779506311169 2015-04-14 15:47:29376 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884775895072768 2015-04-14 15:47:29377 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771893739520 2015-04-14 15:47:29379 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771717578753 2015-04-14 15:47:29384 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884769138081792 2015-04-14 15:47:29386 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:29388 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:29389 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:29390 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:29391 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:29395 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:29399 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:29401 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:31502 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884752591544320  __________  Notice that tweet ID 587884752591544320 is picked up in second iteration as well although it was picked in the first.   The issue can be fixed in the doSendLine method of  TwitterSearchChannelAdapter.java where this.sinceId is being set to the last value of id. Instead the statuses map can be sorted on ID and the highest ID can be set for sinceId.";0
XD-2946;Allow direct binding even for module.count != 0;0
XD-2950;"SingleNode Logging for AMQP Listener Container is too Narrow (ERROR) See https://gopivotal-com.socialcast.com/messages/24095632  However it was set to ERROR last year to ""reduce log noise"".  I would prefer to elevate to at least WARN in XD and address the ""noise"" issue in Spring AMQP.";0
XD-2953;Get rid of SparkStreamingDriverModule Code that is in there could be moved to the SparkStreamingModule.    Then as part of a later refactoring that plugin should be made part of the module (and loaded by the module classloader);0
XD-296;Add log config file to gemfire in final distro The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts but the separate gemfire app doesn't.;0
XD-297;File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight just to avoid dealing with a single enormous file (in case I collected more data than my demo could handle and needed to split it up).;0
XD-2972;STS - Spring XD Imported with Compilation Error Cannot import Spring XD into STS without compilation errors in class:    *org.springframework.xd.dirt.rest.ModulesController#list*    Error is in:    {code}  return assembler.toResource(page detailed ? detailedAssembler: simpleAssembler)  {code}    {code}  The method toResource(Page<ModuleDefinition> Link) in the type PagedResourcesAssembler<ModuleDefinition> is not applicable for the arguments (Page<ModuleDefinition> (detailed ? detailedAssembler : simpleAssembler))  {code}    Seems to be an STS specific issue.;0
XD-2975;Incorrect message bus is used at runtime For some reason the message bus is bound to incorrect transport (different from what is set as XD_TRANSPORT) at runtime.    This is from the container log:  2015-04-21 13:42:12331 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: rabbit  ...  2015-04-21 13:42:35144 1.2.0.SNAP  INFO RedisMessageListenerContainer-4 sink.a2 - test;0
XD-2976;"Allow ""--path=..."" configuration in HTTP channel adapter Currently each HTTP stream channel uses its own port which is a limitation if we want to use large numbers of HTTP streams with fine granularity. It would be nice to (additionally) use URI paths to identify HTTP channels allowing to re-use a single HTTP port for multiple channels in XD.  Example usage:  stream create --name s1 --definition ""http --port=9495 --path=/foo  | log"" --deploy  For a PoC implementation see: https://github.com/spring-projects/spring-xd/pull/1538";0
XD-2977;"Routing json arrays When i create following stream i am able to route json messages. But if i send same message as an array its not working. Is it possible to do something about it?  stream create --name reference-data-import --definition ""rabbit --outputType=text/plain | router --expression=#jsonPath(payload'$.REJECTED').contains('true')?'queue:Rejected':'queue:Accepted'"" --deploy";0
XD-298;"Refactor gardenhose into more generic twitterstream source Twitter's streaming APIs have more capabilities than just the plain statuses/sample.json. In particular we should support the filter.json option and the use of ""track"" (https://dev.twitter.com/docs/streaming-apis/parameters#track) as well as other request parameters (delimited language etc).";0
XD-2982;Shell processor cannot recover from an Exception see http://stackoverflow.com/questions/29822845/custom-python-module-can-not-re-excute-when-raise-exception-in-module;0
XD-2985;Update spring-data-hadoop to version 2.1.2.RELEASE;0
XD-299;Creating a tap with same name as existing streams results in infinite loop See http://stackoverflow.com/questions/17157068/counter-analytics-in-springxd    The underlying issue is stream creation with a name already taken though;0
XD-3000;Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations;0
XD-3001;"Unable to call Sqoop Job commands other than --create from within Spring-Xd Job Running a (SQOOP Job --create) from within (Spring-XD JOB create) statement runs successfully.Unable to run the (Sqoop Job --exec) from within (Spring-XD Job)    CREATE DEFINITION:  job create sqoop_lookup_d_job_v1 --definition ""sqoop --command=job  --args='--create lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx\"" -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query \""SELECT ROW_WID LKUP_ID TRIM(TRANSLATE(LKUP_CD CHR(10)||CHR(13) ''-'')) AS LKUP_CD TRIM(TRANSLATE(LKUP_DESC CHR(10)||CHR(13) ''-'')) AS LKUP_DESC TRIM(TRANSLATE(LKUP_TYPE CHR(10)||CHR(13) ''-'')) AS LKUP_TYPE TRIM(TRANSLATE(LKUP_VAL CHR(10)||CHR(13) ''-'')) AS LKUP_VAL SRC_STRT_DT SRC_END_DT W_INSERT_DT W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND $CONDITIONS\"" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by \""|\"" --append'""    Validated job definition details stored in PostgreSQL repository    Trying to run EXECUTE In Same fashion.    EXECUTION DEFINITION:  job create sqoop_lookup_d_exec_v1 --definition ""sqoop --command=job --args='--exec lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxx\""'""      Stack Trace:  batch.stepType	org.springframework.batch.core.step.tasklet.TaskletStep  batch.taskletType	org.springframework.xd.sqoop.SqoopTasklet  sqoop.command	job --exec lookupd_job --meta-connect ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxx&password=xxxxxxx"" -- exec  sqoop.errors	No job operation specified  Try --help for usage instructions.  Exception in thread ""main"" java.lang.RuntimeException: Sqoop failed - return code 1  at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:81)  sqoop.log	16:01:45668 INFO main sqoop.SqoopRunner - Sqoop command: job  16:01:45668 INFO main sqoop.SqoopRunner - Using args: [--exec lookupd_job --meta-connect ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxxx&password=xxxxx""]  16:01:45668 INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.1.1.RELEASE/xd/lib/phd21  16:01:45679 INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://xxxxxxxxxxxxx.com:8020  16:01:45759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=xxxxxxxxxxxx.com:8032  16:01:45759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=$HADOOP_CONF_DIR$HADOOP_COMMON_HOME/*$HADOOP_COMMON_HOME/lib/*$HADOOP_HDFS_HOME/*$HADOOP_HDFS_HOME/lib/*$HADOOP_MAPRED_HOME/*$HADOOP_MAPRED_HOME/lib/*$HADOOP_YARN_HOME/*$HADOOP_YARN_HOME/lib/*$USS_HOME/*$USS_CONF  16:01:45759 INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn  16:01:45817 WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.  16:01:45863 INFO main sqoop.Sqoop - Running Sqoop version: 1.4.5    I have tested --list --exec--delete they are all erroring same way. Looking at SqoopRunner not sure what makes --create any different from other saved-job functionality.    Please let me know how i can call or execute save job definition's through spring-xd Sqoop tasklet";0
XD-3002;Support Spark streaming processor/sink specific module options Currently the module options provided for Spark streaming processor/sink modules use the same DefaultSparkStreamingModuleOptionsMetadata. Since we start adding new module options for processor/sink specific modules it would be better if we expose specific ModuleOption classes so that would help the implementing developers.;0
XD-3004;Detailed module list performance improvement The call to /modules?detailed=true that was introduced for Flo proves to be a performance hog most certainly because of all the metadata resolution that has to occur there (and no caching takes place);0
XD-3005;spring-xd services randomly report failure after correct shutdown On multiple occasions we have seen that {{spring-xd-container}} and {{spring-xd-admin}} services can exit reporting {{FAILED}} state however most of the times the Java process is correctly terminated.  {code} $ sudo service spring-xd-container stop Stopping xd-container:                                     [FAILED] $ ps uax | grep [x]d-container $ {code}  and in the container logs:  {code} [info 2015/04/28 09:42:15.167 EDT  <Distributed system shutdown hook> tid=0x88] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.168 EDT  <Distributed system shutdown hook> tid=0x88] GemFireCache[id = 2029162775 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:34 EDT 2015 se  [info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] GemFireCache[id = 389249684 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:14 EDT 2015 ser  [info 2015/04/28 09:42:15.177 EDT  <Distributed system shutdown hook> tid=0x77] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.179 EDT  <Distributed system shutdown hook> tid=0x77] GemFireCache[id = 1768828050 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:27 EDT 2015 se  [info 2015/04/28 09:42:15.181 EDT <Distributed system shutdown hook> tid=0x63] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.199 EDT <Distributed system shutdown hook> tid=0x63] GemFireCache[id = 548938309 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:19 EDT 2015 serv 2015-04-28 09:42:15410 1.1.1.RELEASE DEBUG xdbus.queue:radius-1 transform.RadiusMsgTransformer - Transformed message: GenericMessage [payload=FACILITY=22 SEVERITY=5 TIMESTAMP=Tue Apr 28 09:42:15 EDT 2015 HOST=hopisepsnprd01 Messa  [info 2015/04/28 09:42:15.626 EDT  <Distributed system shutdown hook> tid=0x53] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.630 EDT  <Distributed system shutdown hook> tid=0x77] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.621 EDT  <Distributed system shutdown hook> tid=0x88] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.662 EDT <Distributed system shutdown hook> tid=0x63] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen 2015-04-28 09:42:15854 1.1.1.RELEASE  WARN Thread-4 support.DisposableBeanAdapter - Invocation of destroy method failed on bean with name 'client-pool': java.lang.IllegalStateException: Pool could not be destroyed because it is still  [config 2015/04/28 09:42:15.857 EDT <Thread-4> tid=0x12] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.897 EDT  <Thread-4> tid=0x12] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.898 EDT  <Distributed system shutdown hook> tid=0x53] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.908 EDT  <Distributed system shutdown hook> tid=0x88] Destroying connection pool client-pool {code};0
XD-3009;Manual acknowledgement with Kafka bus doesn't work When the kafka message headers are expected to be set with acknowledgement flags to manually acknowledge the messages at the consumer side the message headers are missing.;0
XD-3010;"Can't compose script processor Consider this simple stream which works out of the box because {{transform.groovy}} is shipped with Spring XD: {code} stream create --name ""stream1"" --definition ""time | script --script='transform.groovy' | log"" --deploy {code}  Composing {{time}} and {{script}} modules like that  {code} module compose --name ""cmp-time"" --definition ""time | script --script='transform.groovy'"" stream create --name ""stream2"" --definition ""cmp-time | log"" --deploy {code}  will throw following exception in xd-shell:  {code} Apr 29 2015 11:28:57 AM org.springframework.shell.core.AbstractShell handleExecutionResult INFO: Successfully created module 'cmp-time' with type source Apr 29 2015 11:28:57 AM org.springframework.shell.core.SimpleExecutionStrategy invoke SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module cmp-time of type source:     valid: 'script' cannot be null or empty {code}  and following exception in xd-container:  {code} 2015-04-29 11:28:57263 1.1.1.RELEASE ERROR qtp616131272-35 rest.RestControllerAdvice - Caught exception while handling a request org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module cmp-time of type source:     valid: 'script' cannot be null or empty   org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:180)   org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)   org.springframework.xd.dirt.rest.XDController.save(XDController.java:235)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)   org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)   javax.servlet.http.HttpServlet.service(HttpServlet.java:755)   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)   javax.servlet.http.HttpServlet.service(HttpServlet.java:848)   org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)   org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)   org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)   org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)   org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)   org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)   org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)   org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)   org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)   org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)   org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)   org.eclipse.jetty.server.Server.handle(Server.java:370)   org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)   org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)   org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)   org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)   org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)   org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)   org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)   org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)   org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)   org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors Field error in object 'target' on field 'valid': rejected value [false] codes [AssertTrue.target.validAssertTrue.validAssertTrue.booleanAssertTrue] arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.validvalid] arguments [] default message [valid]] default message ['script' cannot be null or empty]   org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)   org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)   org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)   org.springframework.xd.module.options.HierarchicalCompositeModuleOptionsMetadata.interpolate(HierarchicalCompositeModuleOptionsMetadata.java:105)   org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:177) 	... 61 more {code}";0
XD-3011;Job failed to deploy (Sporadic) Commit: 433d18f03fd7f3bf7d9aeee80ab292f9c92af5a4 Transport: Rabbit 1 Admin 2 Containers Admin Log is attached. (Exception is at line 52) During Acceptance Tests for  testJobCreateDuplicateWithDeployFalse failed with the following error reported from the admin.  {noformat}  org.springframework.xd.rest.client.impl.SpringXDException(KeeperErrorCode = NoNode for /xd/jobs/jobFalseDeploy )   org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:67)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39)   org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)   org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) {noformat};0
XD-3012;gemfire-json-server multiple PdxTypes Types I am using SpringXD to ingest tweets to a gemfire-json-server sink.  I am running into an issue where the json documents get defined as a pdx type twice.  See the reweet_count field below.  This causes problems later when using OQL to access this data.  Incompatible types.  What are the recommended ways to resolve this?  The field type should account for the largest possible value which is unknown because it is twitter.  This would likely be a int or long.  I was asked to log this as a SXD JIRA issue but I am not sure if the problem is in SXD or GemFire.    [info 2015/04/25 06:51:28.767 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[      dsid=0typenum=1 name=__GEMFIRE_JSON fields=[          id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1          from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1          created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2          text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3          language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4       retweet_count:short:5:4:idx0(relativeOffset)=-3:idx1(vlfOffsetIndex)=-1          retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]]    [info 2015/04/25 06:51:29.307 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[       dsid=0typenum=2 name=__GEMFIRE_JSON fields=[        id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1        from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1        created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2        text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3        language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4        retweet_count:byte:5:4:idx0(relativeOffset)=-2:idx1(vlfOffsetIndex)=-1        retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]];0
XD-3014;Add documentation for connecting to HDFS with HA Namenode;0
XD-3015;RemoteFileToHadoopTests fails on 1.1.x This error surfaced recently as a result of a fix to a bug in HostNotWindowsRule which disabled this test in all environments. Now the test has been reactivated it is failing on the 1.1.x branch.  The test runs OK on master.  {noformat}  Encountered an error executing step step1-master in job job  org.springframework.messaging.MessageDeliveryException: failed to send Message to channel 'null' nested exception is java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:292)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.xd.dirt.integration.bus.local.LocalMessageBus$3.handleMessage(LocalMessageBus.java:262)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:85)    org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:224)    org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)    org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:161)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)    org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)    org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)    org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)    org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)    org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)    org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)    org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)    org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)    org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)    org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)    org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)    org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)    org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)    org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)    org.junit.rules.RunRules.evaluate(RunRules.java:20)    org.junit.runners.ParentRunner.run(ParentRunner.java:363)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)    org.junit.runner.JUnitCore.run(JUnitCore.java:137)    com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)    com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)    com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  Caused by: java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.getThreadPoolExecutor(ThreadPoolTaskExecutor.java:221)    org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:252)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:89)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  	... 76 more    java.lang.AssertionError:   Expected :exitCode=COMPLETEDexitDescription=  Actual   :exitCode=FAILEDexitDescription=     <Click to see difference>        org.junit.Assert.fail(Assert.java:88)    org.junit.Assert.failNotEquals(Assert.java:834)    org.junit.Assert.assertEquals(Assert.java:118)    org.junit.Assert.assertEquals(Assert.java:144)    org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:162)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)    org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)    org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)    org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)    org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)    org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)    org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)    org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)    org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)    org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)    org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)    org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)    org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)    org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)    org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)    org.junit.rules.RunRules.evaluate(RunRules.java:20)    org.junit.runners.ParentRunner.run(ParentRunner.java:363)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)    org.junit.runner.JUnitCore.run(JUnitCore.java:137)    com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)    com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)    com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  {noformat};0
XD-302;User wants ability to create a mock source To send a pre-set message to process(es);0
XD-3023;SSL Config for RabbitMessageBus Connections is Ignored;0
XD-3031;Document the RabbitMQ Bus Cleanup REST API;0
XD-3035;Kafka source module: Handling delete offsets When the *stream* that holds the kafka source module is undeployed(but not destroyed yet) the underlying offset manager deletes the offsets associated with the steam.  When same stream is re-deployed the offset manager reads the offsets from kafka broker (if initial offsets are *not* provided) for each partition the module is configured to listen.  If the initial offset values are provided for the stream then I think the offset manager should delete the offsets from the XD offset topic only when the stream is *destroyed*. Since we want to re-use the offset topic data upon stream undeploy/re-deploy.;0
XD-3036;Fix section headers in reference TOC See:  http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26    There should be chapter/section title before this.;0
XD-3038;Add value-expression to gauges See http://stackoverflow.com/questions/30112430/payload-filters-transforms-rich-gauges/30115234 for the use case. It should be possible to extract both a numeric value and a gauge name from the message.;0
XD-304;User wants ability to test processors Be able to point to the processor xml file e.g. modules/processors/transformer.xml and have access to a source channel that drives messages into the processor and a output channel where output messages are send.  The outbound channel is queue backed.  Test sending JSON to a processor module that uses Tuples.;0
XD-3041;Disable MongoDB boot autoconfiguration at XD runtime XD runtime (admin container and singlenode) have MongoDB boot autoconfiguration enabled. This spins off MongoDB client and thereby the cleaner thread running on all these runtime.    The MongoDB based modules won't have any impact when we disable this autoconfiguration.;0
XD-3046;Fix compilation errors after moving SingleNodeApplication package Samples including Singlenode tests need to update for package changes;0
XD-3048;RabbitMQ queue cleanup uses wildcard unexpectedly Calling the API to delete queues uses a wildcard-like behaviour unexpectedly. If I request to delete:    {{test-1}}    I expect it to delete streams named with the pattern:    {{test-1.*}}    For example it would delete:    {{test-1.0 test-1.1 etc}}    In fact I believe it wildcards before and after the period e.g.:    {{test-1*.*}}    And hence would delete:    {{test-1.0 test-11.0 test-123.0 etc}}    That way of working is potentially helpful but it's also dangerous because it removes the ability to know that you're only deleting the exact queue you want to in all cases.    For the record the commit (https://github.com/spring-projects/spring-xd/commit/2d5f3f706330a6ead8e91c9a7a23d4372715614d) implies that it should work in the more restricted way above not the less restricted way.    (Note: I've marked this as an improvement because absent documentation I don't know what the correct functionality is and hence can't say this is a bug);0
XD-3049;Profile byte array on In-Memory and Kafka Transport Identify and report hotspots while running the load-generator source and the throughput sink on :  # Singlenode -> In Memory Transport  # Singlenode -> Kafka Transport  # Admin/Container -> Kafka Transport;0
XD-3051;Gradle launch task is broken Spring XD has a gradle task available in the build called launch that starts a single node instance.  This is currently broken.  The command I was using for this command was:  {code}  $ ./gradlew clean build -x test -x javadoc launch  {code};0
XD-3054;Deployment validation when processing the deployment message Currently the deployment message is being validated before pushed the ZK distributed queue for deployment. When the message is consumed there is no validation done. Since the consumer consumes the messages asynchronously we need validation at both sides.;0
XD-3058;Windows CI FTP based tests fail. Currently Windows EC2 (master JDK8) test is failing  I've attempted to replicate on my EC2 environment.  The best bet is to try and reproduce using the AMI and machine size that CI uses.  We need to check with Trevor to get this info.  The error is: {noformat} java.lang.AssertionError: java.lang.AssertionError java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)   org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)   org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)   org.springframework.xd.shell.command.FtpModulesTests.testRefOptionEqualsFalse(FtpModulesTests.java:70)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {noformat};0
XD-306;"User wants ability to test sources Examples: 1. Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml pass in some property file for parameters to be replaced and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.   2. Test for as many source types as is 'reasonable' e.g. MQTT/TCP testing might be harder than say rabbitmq. 3. Test that sending json results in media-type header is set to json 4. Test that sending POJO   ""  POJO 5. Test that sending Tuple ""   Tuple 6. Test that sending raw bytes "" raw bytes";0
XD-3063;Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default.    When polling say a file directory with many files files will be emitted once per {{fixedDelay}}.    As a user I need to configure a limit for the number of messages that will be emitted per poll.;0
XD-3066;Make Enum Conversions for ModuleOptions more lenient If you have a an option *--mode=textLine* presently the enum MUST be named *textLine*.  I think it would improve the user-experience if we allowed users to pass in values such as:  * --mode=textLine * --mode=text_line * --mode=TEXT_LINE;0
XD-3067;Spark streaming integration module fails to initialize codec XD Spark streaming module fails to load:    Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.springframework.xd.tuple.serializer.kryo.TupleCodec] for bean with name 'org.springframework.xd.tuple.serializer.kryo.TupleCodec#2e8f5f36' defined in class path resource [META-INF/spring-xd/bus/codec.xml]: problem with class file or dependent class nested exception is java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec    org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1331)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:453)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 67 more  Caused by: java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec    java.lang.ClassLoader.defineClass1(Native Method)    java.lang.ClassLoader.defineClass(ClassLoader.java:760)    java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)    java.net.URLClassLoader.defineClass(URLClassLoader.java:455)    java.net.URLClassLoader.access$100(URLClassLoader.java:73)    java.net.URLClassLoader$1.run(URLClassLoader.java:367)    java.net.URLClassLoader$1.run(URLClassLoader.java:361)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:360)    java.lang.ClassLoader.loadClass(ClassLoader.java:424)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:357)    org.springframework.util.ClassUtils.forName(ClassUtils.java:249)    org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:395)    org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1349)    org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1320);0
XD-307;User to send a message directly to module and receive a message from a module;0
XD-3070;Spike: introduce xolpoc-admin to XD Admin The POC for XD on Lattice uses the following interface for module deployment:    https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java    {code}  public interface ModuleDeployer {    	void deploy(ModuleDescriptor descriptor)    	void undeploy(ModuleDescriptor descriptor)    	ModuleStatus getStatus(ModuleDescriptor descriptor)    }  {code}    This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to:  * Demo a POC showing simple stream deployment with the existing shell/admin to Lattice  * Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).    Note that this work will not necessarily be merged into XD itself although some of the concepts may be included in a future PR.;0
XD-3074;Backport metadata retrieval stability improvements Backport stability improvements added as part of XD-2958 to the 1.1.x branch.;0
XD-3079;Create a new Kerberos ticket instead of renew the current one Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7.  The kerberos ticket policies are:  * expiration: 24 hours  * renew: 7 days    I need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.    Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?    The Spring XD server has configured the hadoop.properties like:    # Use servers.yml to change URI for namenode  # You can add additional properties in this file  dfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COM  yarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COM    yarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*/opt/cloudera/parcels/CDH/lib/hadoop/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*    hadoop.security.authorization=true  hadoop.security.authentication=kerberos    spring.hadoop.userKeytab=file:///export/home/user/user.keytab  spring.hadoop.userPrincipal=user@ERS.COMPANY.COM    #Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D)  spring.hadoop.security.authMethod=kerberos  spring.hadoop.security.userKeytab=/export/home/user/user.keytab  spring.hadoop.security.userPrincipal=user@ERS.COMPANY.COM  spring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COM  spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM;0
XD-308;User wants ability to test multiple processors in a chain;0
XD-3083;"Creating multiple Stream/Job definitions from command file is broken I have a file that has the DSLs:  stream create a1 --definition ""http | log""  stream deploy a1    xd-shell --cmdfile test.cmd  May 19 2015 1:49:29 PM org.springframework.shell.core.AbstractShell handleExecutionResult  INFO: Created new stream 'a1'  May 19 2015 1:49:29 PM org.springframework.shell.core.SimpleExecutionStrategy invoke  SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is no stream definition named 'a1'";0
XD-3091;Update build to use SHDP 2.2.0.RC1;0
XD-3095;Update to Reactor 2.0.2;0
XD-3096;Support for BroadcasterMessageHandler to work with concurrent producing threads Also provide better lifecycle (shutdown) mgmt of handler.;0
XD-3100;"module.*.count > 1 duplicates messages on taps Using module.name.count > 1 when deploying taps causes duplication of messages in those modules. This impacts balancing of the containers and modules in a cluster as messages should not be duplicated across modules if the same module is deployed twice to two containers in order to spread the load.  We use taps quite heavily in our project mainly for analytics of the life feed in real time but due to issue we have discovered and described in this bug we are currently facing a limitation where heavily processing modules can not be load balanced across the cluster as they are causing duplication of the messages and therefore the same module deployed to two  containers would still process the same message twice.  To demonstrate the problem please see test case scenario set up below:  h4. 1. Environment  - Spring-XD version 1.1.1-RELEASE - Running two spring-xd containers and one spring-xd admin  h4. 2. Set up  Stream definition is as follows:   {quote}stream create --name test-module-count --definition ""syslog-udp --port=5140 | transform | log"" stream deploy --name test-module-count --properties ""module.*.count=2"" stream create --name tap-test-module-count --definition ""tap:stream:test-module-count.syslog-udp > transform --expression='payload.toString() + \""TAPPED\""' | log"" stream deploy --name tap-test-module-count --properties ""module.*.count=2""{quote}   Please refer to the screen shots attached to see that after deploying those two streams we have:  - streams successfully deployed ( module-count-spring-xd-streams.png ) - streams successfully deployed with count=2 to both containers ( module-count-spring-xd-containers.png )  - 5 queues created in Rabbit ( module-count-rabbit.png ) where two were created for the syslog-udp collector as a result of using module.syslog-udp.count=2 - this is causing messages to be duplicated. Normally the expectation would be to have only one queue for the tap  h4. 3. Test input data  I have sent a very simple UDP message to the listening udp collector running on second container:   {quote}echo test-module-count >> /dev/udp/host02/5140{quote}  h4. 4. Test output data in the logs ( module-count-container01.log and module-count-container02.log )  h5. Expected result:  Below messages logged only on 1 container (it does not matter which one) {quote}2015-05-26 09:52:21630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count}{quote} Below message logged only on one container (it does not matter which one)  {quote}2015-05-26 09:52:21843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  h5. Actual result:  Stream that has been create as a tap has duplicated the same message and as a result the same message was proccessed twice on both containers by the same module ( transformer ) and logged twice to the console on both containers  Container01: {quote}2015-05-26 14:52:21143 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  Container02: {quote}2015-05-26 09:52:21630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count } 2015-05-26 09:52:21843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}";0
XD-3101;Fix Gradle “dist�? build task;0
XD-3108;Module failed to deploy because ZK said it already exists. Identified in a stream of commits ending with:0f4d4ea6b2f16c73c0048e32d8a8753aa25a48fd  Transport: Redis  Admin: 1   Container: 1   Stream deployed: time|file  Attachments: Admin and container logs.  [Description]  Admin reports that File sink Module failed to deploy at 00:19:32 because ZK stated it already exists.  Container shows no deployment of the file sink.  **** This could be an artifact in that the old Acceptance tests use the same stream name hence a previous undeploy failed to remove the file.  This is not seen in the log per se'.  The filejdbc fail above is a legitimate test verifying that a job can't be deployed twice.;0
XD-3109;SFTP socket closed error. Infinite loop Having the follow messages poping up on xd log. It seems they are being generated indefinitely.     Log files getting huge.     [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsassh-dss  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctraes192-ctraes128-ctrarcfour256  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctraes192-ctraes128-ctrarcfour256  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512hmac-sha2-256hmac-sha1hmac-ripemd160  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512hmac-sha2-256hmac-sha1hmac-ripemd160  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: nonezlib@openssh.com  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: nonezlib@openssh.com  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1diffie-hellman-group-exchange-sha1  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsassh-dss  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctraes128-cbc3des-ctr3des-cbcblowfish-cbc  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctraes128-cbc3des-ctr3des-cbcblowfish-cbc  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5hmac-sha1hmac-sha2-256hmac-sha1-96hmac-md5-96  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5hmac-sha1hmac-sha2-256hmac-sha1-96hmac-md5-96  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server->client aes128-ctr hmac-sha1 none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client->server aes128-ctr hmac-sha1 none  [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent  [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received  [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent  [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received  [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-micpublickeykeyboard-interactivepassword  [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic  [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickeykeyboard-interactivepassword  [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey  [2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey).  [2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22  [2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception leaving main loop due to Socket closed;0
XD-3112;Hide the passwords used as module properties in streams from being displayed. This type is used in password field in the jdbc sink module provided by Spring XD (defined in org.springframework.xd.jdbc.JdbcConnectionMixin class). It seems that Spring XD Admin UI is always displaying the password in plain text please see attached screen shot.  Is there a way to somehow hide the passwords used as module properties in streams from being displayed in Spring XD Admin UI?  This is similar issue as below and fixed in batch jobs but not in streams.  https://github.com/spring-projects/spring-xd/pull/1325;0
XD-3117;"Add Logging to ZooKeeperContainerRepository Occasional CI test build failures:    {quote}  Caused by: java.lang.IllegalStateException: Container cache not initialized (likely as a result of a ZooKeeper connection error)    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.ensureCache(ZooKeeperContainerRepository.java:184)    org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findOne(ZooKeeperContainerRepository.java:263)  {quote}    e.g. https://build.spring.io/browse/XD-JDK8-JOB1-1514    Add logging to {{ensureCache()}} (e.g. in {{childEvent()}} ) and {{closeCache()}} to log that the cache was closed it appears that's the only way the ""cache not initialized"" message can be emitted.";0
XD-3119;The performance of the pipe [in singlenode] Do as a developer in the case of large data from the source to the sink will after multiple processors I found that even if the processor does not do anything message from the source to the sink of performance with the number of processors the message forwarding performance will decrease very much. For example:  spring xd run in  singlenode  After the tcp-client connects the socket service receive very many text (a line of text messages)  stream definition: tcp-client |t1:transform |t2:transform |t3:transform |t4:transform |null   Message passing rate: 20000 per second Transform didn't do anything.  stream definition: tcp-client|null Message passing rate: 170000 per second  Message is a line of text my business requires me to a second processing 300000 pieces of data.(About 100 MB/s in a machine )  Tell me how to solve the performance bottleneck. Can stream only have source and sink to get high performance?;0
XD-312;Add Jolokia Agent Depending on Run Mode WAR Vs. JVM Jolokia Agent    Jolokia Vs. JVM MBeanServer    Probably needs support for Spring Profiles.;0
XD-3121;skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode] when use rabbit as source always have the warn message: skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode]  similar issure is https://jira.spring.io/browse/XD-2567  but i have no use rabbit sink.;0
XD-3122;Refactor deployment interfaces/class hierarchy (continued) Refactoring of the {{ResourceDeployer}} to split apart the concepts of repository and deployment. For reference see XD-2835 XD-2671 XD-2877 and XD-3070.;0
XD-3124;`minPartitionCount` is ignored by the consumer `minPartitionCount` is ignored by the consumer so downstream modules end up listening to fewer partitions;0
XD-3126;Support for registering custom Kryo Serializers This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement however initial benchmarks show that custom serializers are about 10% more performant than Serializable.;0
XD-3128;Misleading instruction when admin server not running on localhost:9393 Starting teh shell without having admin running on localhost:9393 results in the following message:  {code} 1.2.0.RC1 | Admin Server Target: http://localhost:9393 ------------------------------------------------------------------------------- Error: Unable to contact XD Admin Server at 'http://localhost:9393'. Please execute 'admin config info' for more details. ------------------------------------------------------------------------------- {code}  Running {code}admin config info{code} gives a nasty stacktrace though so these instructions are misleading and should be changed;0
XD-313;Add Spring/Integration MBean Exporters to Module ApplicationContexts Global option?    Override for individual modules? module types?;0
XD-3131;Spark streaming plugin shouldn't need tap listener cache Since Spark streaming doesn't use ZK to keep track taps being created we don't need the tap listener cache setup at the container startup.;0
XD-3135;Spark streaming module includes logback jar when using dist zip When running spark streaming module on spark standalone cluster from XD distribution I see the following error:    [Stage 3:=============================>                             (1 + 1) / 2]2015-06-02T10:05:53-0700 1.2.0.SNAP WARN task-result-getter-3 scheduler.TaskSetManager - Lost task 0.0 in stage 3.0 (TID 50 192.168.2.8): java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/Users/igopinatha/workspace/git/ilayaperumalg/spark/assembly/target/scala-2.10/spark-assembly-1.2.1-hadoop2.2.0.jar). If you are using Weblogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml Object of class [org.slf4j.impl.Log4jLoggerFactory] must be an instance of class ch.qos.logback.classic.LoggerContext       at org.springframework.util.Assert.isInstanceOf(Assert.java:339)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:151)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLogger(LogbackLoggingSystem.java:143)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:89)       at org.springframework.boot.logging.LoggingApplicationListener.onApplicationStartedEvent(LoggingApplicationListener.java:152)       at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:139)       at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)       at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)       at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)       at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:54)       at org.springframework.boot.SpringApplication.run(SpringApplication.java:277)       at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)       at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusConfiguration.createApplicationContext(MessageBusConfiguration.java:82)       at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.start(MessageBusSender.java:105)       at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:58)       at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:53);0
XD-3137;Upgrade to 3.1.1 of the Gradle Artifactory Plugin This addresses The plugin issue https://www.jfrog.com/jira/browse/GAP-172 to disable spring-xd/pom.xml;0
XD-3143;Test coverage for RuntimeModuleDeploymentPropertiesProvider There are more calculations done at the RuntimeModuleDeploymentPropertiesProvider implementations and would be good to have some tests to cover them.;0
XD-3146;Strict flag for jdbchdfs h2. Narrative  As a developer when using jdbchdfs's incremental imports I need to be notified that something went wrong in a previous run of the jdbchdfs job so that I can take the appropriate actions based on the data previously imported.    h2.  Back story  As the incremental import currently works if the job fails half way through there is no check on the next run to see if the last run failed or not and how to address partially imported data.;0
XD-3148;Remove mr1 jar from cdh5 hadoop build There is an hadoop-core-2.5.0-mr1-cdh5.3.3.jar in the lib/cdh5 directory - we need to remove that from the dist;0
XD-315;"Package Shell ""binary"" next to xd-admin and xd-container The shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now. If we follow how redis/mongo distribut the shell it sits side by side with the other binaries";0
XD-3161;Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x;0
XD-3162;Update Master Environment for 2.0 CI Acceptance Tests;0
XD-3168;Type conversion should set Content-Type header See http://stackoverflow.com/questions/30714828/spring-xd-http-client-processor-sends-text-plain-instead-of-application-json;0
XD-317;Add Documentation Chapter on Executing Batch Jobs;0
XD-3171;"Composed modules not working on YARN From https://github.com/spring-projects/spring-xd/issues/1704  I am trying to use composed modules when running on YARN.    In ZK each child module definition of the composed module gets serialized as follows:  ``` {""@class"":""org.springframework.xd.module.SimpleModuleDefinition""""name"":""transform""""type"":""processor""""location"":""file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1433789137218_0001/filecache/17/spring-xd-yarn-1.1.2.RELEASE.zip/modules/processor/transform/""} ```  When I try to use the composed module on YARN it may be deployed to a different container where the ""location"" file path is not valid.  In this case I get the following exception:  ``` java.lang.IllegalArgumentException: File must exist   org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:67)   org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:51)   org.springframework.boot.loader.jar.JarFile.<init>(JarFile.java:95)   org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:61)   org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:57)   org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:54)   org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:47)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:186)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)   org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveComposedModuleMetadata(DefaultModuleOptionsMetadataResolver.java:175)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:167)   org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174) ```  I think the issue may be related to the following line in ArchiveModuleRegistry:  ``` String filename = resource.getFile().getCanonicalFile().getName() ```";0
XD-3175;Consider using the ConversionService to convert incoming message payload to Reactor based processor's input type. In  {noformat} BroadcasterMessageHandler.handleMessageInternal {noformat}  the call   {code:java} } else if (ClassUtils.isAssignable(inputType message.getPayload().getClass())) {             //TODO handle type conversion of payload to input type if possible             ringBufferProcessor.onNext(message.getPayload()) {code}  could try to invoke a conversion service;0
XD-3183;Upgrade to Spring Boot 1.2.5 Spring Boot 1.2.4 (and earlier) does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of (for example) {{vcap.services.rabbitmq.credentials.protocols.amqp.ssl}} it will fail as that value returns a boolean.    Spring Boot 1.2.5 (as yet unreleased) contains a fix for this issue (https://github.com/spring-projects/spring-boot/pull/3237);0
XD-3186;DefaultModuleOptionsResolver to use parent classloader to load options metadata classes There are cases where it would be required to load the options metadata classes from the parent classloader *first* than the module's ParentLastURLClassLoader. It would be nice to have a configuration option in DefaultModuleOptionsResolver to set which classloader to use.;0
XD-3188;FileDeletionListener resolves resources once In the {{filejdbc}} job there is the option to delete the imported files.  This functionality is created using a listener called the {{FileDeletionStepExecutionListener}}.  When you run the job the first time with the {{--deleteFiles=true}} everything works as expected.  The second time you run the job the files are not deleted.    I believe the issue here is that since the {{FileDeletionStepExecutionListener}} is a singleton the resources are resolved only once (the first time the job runs) and so it works the first time but if the job is run again later and new files match the expression they are not picked up.  I believe the fix is to make the {{FileDeletionStepExecutionListener}} used in this job step scoped.;0
XD-3189;Testers need ability to wait for a file to be created in XD directory User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.;0
XD-319;Add command for deleting a tap;0
XD-3190;No way to remove a job from Job repository if its gone from job definitions I am trying to deploy a job I destroyed after running a few times. I removed all the jobs using job all destroy. When i try to recreate the same name job it is saying it already exists. JobController.java save() method is throwing the exception if job exists in Job Repository database but they are gone from job definition list. These jobs were originally created using XD Template REST client dynamically but that should not make any difference.  This leaves me in an inconsistent state between XD definitions/job repository. How do I get rid of the job without having to log in to the database and play with the job repository tables.  I had to delete data folder for myself to continue development.   There should be a force mechanism to recreate a job with the same name a flag that by passes this validation against the repository or overwrites the information in the repository.;0
XD-3201;Documentation for reactor-ip source has conflicting information According to the documentation at: http://docs.spring.io/spring-xd/docs/current/reference/html/#reactor-ip one of the options available for this source is {{transport}}. It's listed as having no default but the sample definition doesn't provide it yet appears to default to {{tcp}}. The two should match up.  It might also be useful if the possible values for {{transport}} were listed (I assume {{TCP}} and {{UDP}});0
XD-3206;An error message occurs about the shortDescription (header-enricher) Here is an error I got using the header-enricher from spring-xd-modules :      {code:java}  Field error in object 'info' on field 'shortDescription': rejected value [A Header Enricher to set message headers in a stream] codes [Pattern.info.shortDescriptionPattern.shortDescriptionPattern.java.lang.StringPattern] arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescriptionshortDescription] arguments [] default message [shortDescription][Ljavax.validation.constraints.Pattern$Flag@11eeec65^\p{IsUppercase}.*\.$] default message [Short description must start with a capital letter and end with a dot]  {code}    And if I look the config properties indeed short description doesn't end with a dot.  {code:java}  info.shortDescription = A Header Enricher to set message headers in a stream  {code};0
XD-3207;spring-xd-extension-sqoop dependency overrides test logger setup As per [Chapter 3: Logback configuration|http://logback.qos.ch/manual/configuration.html] only XML configuration can be overidden with {{-test}} file. It's impossible to do this with groovy configuration.  There are Spring XD modules that are packaging {{logback.groovy}} e.g. {{spring-xd-extension-sqoop}}. If a custom module depends on those libraries it becomes impossible to nicely override log settings for tests\[1\]. The configuration is taken from classpath because {{logback.groovy}} is always prioritized over {{logback-test.xml}}.  If those modules would switch to {{logback.xml}} there will be no such problem and custom modules would be easier to set up.  \[1\] One can put own {{logback.groovy}} file under {{src/test/resources}} but this setup will output a number of warning into console. Forcing logback configuration path with {{-D}} option is not nice either.;0
XD-3208;Change in file source breaks backward compatibility With version 1.2.0 the option ref of the file source was removed and a new option mode was introduced.  see XD-2850 and PR  https://github.com/spring-projects/spring-xd/pull/1624.  This means you have to destroy all streams using the ref option before you do an upgrade.  It would have been much better to leave the ref option in the code and emit a deprecation warning if it is still used. This way an upgrade would be possible without interruption.;0
XD-3209;"ClasspathEnvironmentProvider should support packaged Spring XD modules Custom Spring XD modules are packaged into a JAR file with 3rd party libraries packaged into {{lib}} folder.  Let's say we have a {{my-job}} custom job module packaged as JAR and deployed with {{module upload}} shell command. It wants to use {{org.springframework.xd.sqoop.SqoopTasklet}} provided by {{spring-xd-extension-sqoop}} library. Unfortunately {{org.springframework.batch.step.tasklet.x.ClasspathEnvironmentProvider}} will only add {{my-job.jar}} to {{SqoopRunner}} classpath (code in {{ClasspathEnvironmentProvider#createClassPath()}} method).  {{ClasspathEnvironmentProvider}} should add all 3rd party JARs packaged in custom job module to classpath.  This works with {{sqoop}} module shipped with Spring XD because it's deployed as ""exploded"" module under $XD_HOME/modules/job. In such case {{ClasspathEnvironmentProvider}} correctly adds all JARs from $XD_HOME/modules/job/sqoop/lib to classpath.";0
XD-3219;Fix random configuration in SecuredShellTests Since the SecuredShellTests initialize singlenode app in a static way the random configuration needs to be setup statically as well.;0
XD-322;Support for DELETE of taps;0
XD-3221;Enabling security breaks xd-shell After enabling security in {{XD_HOME/config/servers.yml}}  {code} spring:   profiles: admin security:   basic:     enabled: true # false to disable security settings (default)     realm: SpringXD   user: # valid only if security.basic.enabled=true     name: johndoe     password: johndoe     role: ADMIN VIEW CREATE {code}  It's no longer possible to connect to admin server through xd-shell  {code} server-unknown:>admin config server --username johndoe --password johndoe Unable to contact XD Admin Server at 'http://localhost:9393/'. server-unknown:>admin config info   -------------  --------------------------------------------------------------   Credentials    [username='johndoe password=****']   Result         Unable to contact XD Admin Server at 'http://localhost:9393/'.   Target         http://localhost:9393/   Timezone used  Greenwich Mean Time (UTC 0:00)   -------------  -------------------------------------------------------------- ------------------------------------------------------------------------------- An exception ocurred during targeting: org.springframework.web.client.HttpClientErrorException: 403 Forbidden     at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)     at org.springframework.xd.rest.client.impl.VndErrorResponseErrorHandler.handleError(VndErrorResponseErrorHandler.java:50)     at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:614)     at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:570)     at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:545)     at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:253)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:114)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:102)     at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:112)     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)     at java.lang.reflect.Method.invoke(Method.java:606)     at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:202)     at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)     at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)     at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)     at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:533)     at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)     at java.lang.Thread.run(Thread.java:745) {code}  It looks like admin base URL (http://localhost:9393/) is not defined in security section of {{application.yml}} so {{SpringXDTemplate}} can't be initialized.;0
XD-3235;FileJdbc Job throws exception during Acceptance Tests Currently the testFileJdbcJobMultipleInvocations fails on line 156 stating data is different in table that what is expected.  Currently this is failing on the single admin/container deployment using redis as a transport.      Also seeing the following exception in the attached log:  {noformat}  2.0.0.SNAP ERROR xdbus.job:ec2Job3.0.requests-1 step.AbstractStep - Encountered an error executing step step1 in job ec2Job3  org.springframework.batch.item.ItemStreamException: Failed to initialize the reader  ...  Caused by: java.lang.IllegalStateException: Input resource must exist (reader is in 'strict' mode): URL [file:/tmp/xd/output/filejdbctest/filejdbctest1.out]  {noformat}  The file is should be present and data present for the test.  At least according to the checker on EC2 and local deployments.;0
XD-3237;Additional REST endpoint not working with security enabled I see the following error from the Admin UI:  GET http://localhost:9393/jobs/executions/4/steps/4/progress.json 403 (Forbidden);0
XD-3241;Add support for update in gpfdist sink Currently we can only do plain inserts should follow same logic from native gpfdist sink and add upserts.;0
XD-3242;Copy spring-xd-codec to SCS as spring-cloud-streams-codec Create the equivalent library in spring-cloud-streams;0
XD-3243;Remove spring-xd-codec from Spring XD source tree and build replace with spring-cloud-streams (or spring-cloud-streams-codec) dependency;0
XD-3245;Replace spring-xd-messagebus-* dependencies with SCS XD 2.0 will not have direct dependency on the s-c-s Binder (as MB has been renamed).  The message bus code is obsolete/orphaned in XD 2.0 but some is required to support current integration tests. We can look at pruning it some more but complete removal likely depends on integrating the s-c-s enabled Admin SPI.  MB will remain in XD 1.x.;0
XD-3246;"Automatic support for --fooExpression style options It would be nice if either one of the two options would come ""for free"" when you're authoring a module. Currently it has been a pain including handling exclusivity of options at the module options level.  Also it would be nice if XD/S-C-S provided ease of creation of xxExpression style options (ie not having the author have to deal with ExpressionParser etc)";0
XD-3248;Investigate inconsistent Spark streaming test failure These tests fail inconsistently:  org.springframework.xd.spark.streaming.LocalTransportSparkStreamingTests > testTapSparkProcessor FAILED    java.lang.AssertionError  org.springframework.xd.spark.streaming.RedisTransportSparkStreamingTests > testTapSparkProcessor FAILED    java.lang.AssertionError  java.lang.AssertionError:  Expected: an existing metric trying at most 20 times     but: failed after 20*100=2000ms: counter named 'random5656' did not exist;0
XD-3249;Change module option type from Class to String This better aligns with boot. Moreover using Class was a bad design choice (one can always get a Class from a String [modulo knowing which CL to use] while to converse is not always easy [CL not being available]);0
XD-3250;Refactor s-c-s samples to use @ConfigurationProperties The spring-cloud-streams samples have module options classes copied over from XD.  They should use a pure @ConfigurationProperties approach making sure metadata is generated/hand written as appropriate.    @Mixins are still referenced there but obviously can't work so provide an equivalent;0
XD-3251;A a boot ConfigurationPropertiesModuleOptionsResolver This allows incremental adoption of boot @ConfigurationProperties as a way of being recognized as XD options;0
XD-3253;Strange language prefix shown on some code listings when hovering the mouse over them Looking at the online docs the code listings have inconsistent  syntax highlighting and when you hover the mouse over some of them there is a language  prefix like ruby or javascript inserted at the beginning of the first line. Very strange.  To see this go to http://docs.spring.io/spring-xd/docs/1.2.0.RELEASE/reference/html/#_server_configuration and scroll down to the HSQLDB section. The listing for HSQLDB looks fine but scroll down further and put the mouse pointer on the MySQL or PostgreSQL listings and you should see 'javascript' being inserted on the first line.;0
XD-3255;SCS - split kryo implementation to spring-cloud-streams-codec-kryo;0
XD-3262;UI: Add Pagination to Containers Page Add Pagination to Containers Page;0
XD-328;Retrieve information for a Counter;0
XD-3280;FilePollHdfsTest needs to write to a unique directory vs. the default Occasionally 2 acceptance tests are running simultaneously and the filepollhdfs tests writes their data to the same hdfs directory.  This will cause the test to fail sporadically.  By creating a unique directory each time we can share the hadoop instance and not have a conflict.;0
XD-329;Retrieve information for a Field Value Counter TODO as part of this (see XD-537):   * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO) * Have REST controllers depend on XRepository in all cases;0
XD-3294;RPM upgrades should not to wipe-out previous installation configs/settings As an operator I'd like to upgrade to the latest releases of Spring XD and yet not lose the older installation {{dirs}}/{{files}} so I can copy and reuse the previously used {{servers.yml}} configurations.;0
XD-3296;"Spike: Design a tasks repository h2. Narrative  As a developer I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.    h2. Back story  Currently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However obtaining the result of said task can be an issue.  There are two ways to do so:    # Poll for the result.  # Register a callback URL to be called once the task completes.    Since a task is only available for a short time after its completion before it is deleted polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.    Registering a callback URL would be a better option however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  ""Successful"" is defined in this case as anything other than a 502 or a 503 return code.    In order for Spring XD to be able to support Diego tasks a more durable option for maintaining the result of tasks will need to be developed.    *Note:* The outcome of this spike may be feature requests for the CF/Diego team.";0
XD-3299;Create a Receptor PartitionHandler and related StepExecutionRequestHandler h2. Narrative  As a developer I need to be able to create a partitioned batch job that uses Diego Tasks for partition slaves.    h2. Back story  A new partition handler should be created that uses the Receptor API to launch tasks for each of the slaves (configurable via grid size).;0
XD-3300;Spike: Determine best way to centrally configure the job repository for batch jobs. h2. Narrative  As a developer I need to be able to run batch jobs that use the centrally configured job repository to store job state.    h2. Back story  The XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.;0
XD-3307;Add support for offline module resolution h2.  Narrarive As a developer I need to be able to test modules without pushing them to a remote maven repository.  I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.;0
XD-3308;With Security - Unable to upload module Once security is enabled one cannot upload modules using the shell any longer.;0
XD-331;Retrieve information for a Rich Gauge TODO as part of this (see XD-537):   * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO) * Have REST controllers depend on XRepository in all cases;0
XD-3321;Make requirement for MD5 hash files configurable for the custom module registry Post 1.2 upgrade the custom modules no longer show up by just copying the jars to the {{xd.customModule.home}} directory. Instead I have to use the 'module upload' command to install the modules. This is because an MD5 file is required. More details in [SO thread|http://stackoverflow.com/questions/31792220/spring-xd-1-2-0-custom-module-deployment].;0
XD-3323;Test Spark Module with maven spring-xd-module-parent java.lang.NoClassDefFoundError A test for a java spark module managed by maven with parent *spring-xd-module-parent* launch a _*java.lang.NoClassDefFoundError*_.  I've forked the example repo [https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor|https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor] the samples project and created the *pom* file for the *spark-streaming-wordcount-java-processor* project and the corresponding test.  Partial stack trace:  {code:title=StackTrace} 2015-08-04 09:30:07211 ERROR [DeploymentsPathChildrenCache-0] listen.ListenerContainer (ListenerContainer.java:run(96)) - Listener (org.springframework.xd.dirt.server.container.DeploymentListener@729c251b) threw an exception java.lang.NoClassDefFoundError: org/eclipse/jetty/util/component/AggregateLifeCycle   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   org.apache.spark.HttpServer.org$apache$spark$HttpServer$$doStart(HttpServer.scala:74) {code}  When the *WordCountTest* test is launched the exception is launched.  Is there a problem with the  *spring-xd-module-parent* module ? Are some dependencies left?;0
XD-3327;Add Unit Tests for CC SPI infrastructure Test Converter Configuration Definition and Status objects.;0
XD-3328;Return full ModuleStatus information Remove all stubs and check all required information is returned accurately.;0
XD-3330;Implement undeploy operation for CC SPI Currently undeploy is a no-op.;0
XD-3331;Add real ModuleRunner application The current ModuleRunner is test app used for validation. This should be replaced by a real app.;0
XD-3333;Refactor CloudFoundryApplicationFactory This class should not know what the test app is. This means changing the constructors on CloudFoundryApplication.;0
XD-3347;Run all shell integration tests also with enabled security Apply the same strategy for the Module Command Tests also to all other Shell integration tests.;0
XD-3349;Design the foundation to port XD modules to s-c-s As an s-c-s developer I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules so I can use it as the base and start migrating the modules.;0
XD-3352;[SCS] - Replace Binder XML config with @Configuration Create Confguration and ConfigurationProperties. Configuration must support replacing the default Kryo Codec implementation with something else.;0
XD-3358;Admin UI deploys job with wrong module count When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1.    More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties];0
XD-3360;Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules  * Add spring cloud config client to pom dependencies.  * Add bootstrap.yml to scs project;0
XD-3361;Create a standard way to configure Spring Cloud Data and Stream projects;0
XD-337;Test connection pooling on Redis blocking/nonblocking operations;0
XD-3373;First deploy/launch of Pig job that includes yarn-site.xml file fails Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.    The error is:     Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster    which indicates that the yarn-site.xml file never made it to the classpath.    Un-deploying and re-deploying the job seems to fix the problem.;0
XD-3377;Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.;0
XD-338;Create tcp/udp load generator script for XD performance testing Create a load generator script which can generate messages at specific    1) Rate  2) Payload  3) Concurrency    to a specific tcp/udp port where a syslog adapter is listening.;0
XD-3380;Refactor Binder @Configuration to use AutoConfiguration Currently @EnableModule hardcodes references to both the redis and rabbit configuration classes which trigger or don't trigger based on the presence of another jar (which itself has the meat of the configuration).  This is typically what boot AutoConfiguration is for.    Moreover adding a new binding (eg Kafka or a stub for module testing) would require to crack open @EnableModule;0
XD-3385;"Can't build and run singlenode spring-cloud-data-rest app on Ubuntu Building and then running spring-cloud-data-rest app on Ubuntu fails when trying to create the first stream. The configuration ends up with a CloudFoundryConfig instead of LocalConfig for the moduleDeployer.  Env: Ubuntu 15.04 java version ""1.8.0_51"" Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03 mixed mode)  Error: {code} 2015-08-10 11:43:47.199 ERROR 11062 --- [nio-9393-exec-1] o.s.c.d.r.c.RestControllerAdvice         : Caught exception while handling a request java.lang.UnsupportedOperationException: null   org.springframework.cloud.data.module.deployer.cloudfoundry.CloudFoundryModuleDeployer.deploy(CloudFoundryModuleDeployer.java:30) ~[spring-cloud-data-module-deployer-cloudfoundry-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   org.springframework.cloud.data.rest.controller.StreamController.deployStream(StreamController.java:213) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   org.springframework.cloud.data.rest.controller.StreamController.save(StreamController.java:140) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51]   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51]   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51]   java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51]   org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   javax.servlet.http.HttpServlet.service(HttpServlet.java:648) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:235) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:69) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1521) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1478) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51]   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]   org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   java.lang.Thread.run(Thread.java:745) [na:1.8.0_51] 2015-08-10 11:43:47.284  WARN 11062 --- [nio-9393-exec-1] .m.m.a.ExceptionHandlerExceptionResolver : Handler execution resulted in exception: null {code}";0
XD-3390;"UI + Shell: Remove any usage of REST endpoints using the "".json"" notation Accessing REST endpoint using the "".json"" file extension causes maintenance issues for the authorization rules and is not necessary. Remove any usage for the Admin UI and the Shell.   At the same time the "".json"" endpoint shall be deprecated or removed ultimately.";0
XD-3391;Come up with a consistent Link consumption scheme on the REST client side See discussion at https://github.com/spring-cloud/spring-cloud-data/pull/37#discussion_r36849117  Also relevant: http://docs.spring.io/spring-hateoas/docs/current/reference/html/#client;0
XD-3394;Known Hosts Configuration for SFTP Source Spring Integration 4.2 changed the default SFTP session factory to *not* accept keys from unknown hosts by default. This is more secure.  You either have to provide a pre-populated {{known_hosts}} file or set {{allowUnknownKeys}} to true.  If you do both the keys will be automatically added to the known hosts file.  When updating XD to 4.2.0.RC1 I simply set the boolean to true to retain the previous behavior.  Add properties to the SFTP source to allow configuration of these properties at the stream level.;0
XD-3395;Module Launcher properties improvments Improve Spring Cloud Stream module launcher/resolver properties:  1) Support comma separated remoteRepositories 2) Classify/group the properties;0
XD-3396;Add cloud connector dependencies for spring-cloud-data admin Spring-cloud-data admin requires lattice connector and `spring-cloud-spring-service-connector` dependencies so that the admin controllers get access to any services while running on lattice.  One example is CounterContoller using `redis` service for MetricRepository.;0
XD-3402;Add support to start Apps in YARN automatically by type As an s-c-d developer I'd like to add support to negotiate with the ResourceManager REST-APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as  {{appType=CLOUDDATA}} and {{appName=spring-cloud-data-yarn-app}}.;0
XD-3417;Add SmartLifecycle to ChannelBindingAdapter Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.;0
XD-342;Fix classpath error caused by multiple conflicting servlet-api jars There is some conflicting Servlet API jars on the claspath that needs cleanup. Building and running with xd-singlenode script gave this error:    Jun 27 2013 3:18:16 PM org.apache.coyote.http11.AbstractHttp11Processor process  SEVERE: Error processing request  java.lang.NoSuchMethodError: javax.servlet.ServletContext.getEffectiveSessionTrackingModes()Ljava/util/Set    org.apache.catalina.connector.CoyoteAdapter.postParseRequest(CoyoteAdapter.java:674)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:402)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)    org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680);0
XD-3420;RedisSink to support in-memory store;0
XD-3422;Create unit tests for CounterSinkProperties in s-c-s-m;0
XD-3424;Fix Cloud connector dependencies and service resolution This JIRA addresses couple of issues: 1) When the modules are deployed into cloud environment there is an issue where local configuration beans collide with cloud service beans. We witnessed an issue where there are two `RedisConnectionFactory` beans registered in the same application context. We need to have a control the way in which the auto configuration gets invoked and service beans are created. 2) We need to align the cloud connector dependencies into a common place so that we don't have to specify them at various places like (SCS SCS-Binder SCS-modules) etc. It is a good idea to have these dependencies specified in SCS-modules so that it get used subsequently by SCS when the module is assembled at runtime.;0
XD-343;Investigate JMX object naming of deployed modules and inbound/outbound channel adapters. The object naming is still not ideal for XD since SI conventions add some noise. Likely  need to design and implement a custom naming strategy;0
XD-3431;Use mocks in shell tests Instead of using real `moduleDeployer` try using mocks so that the module deployer downloading the maven co-ordinates from repo can be avoided (for module deployment case).  Since module deployer and controllers are tested individually it would be good to focus on shell functionality only for the shell tests.;0
XD-3432;Update documentation for module launcher The s-c-s-module-launcher document requires update for running it on standalone docker lattice. Also the docker-compose yml requires fix so that modules in there are bound together.;0
XD-3433;[Flo] UI unresponsive after some time The Chrome UI Interface for flo stream creation stops responding after some time. It starts working once the browser history/ cookies etc. are cleaned up.   . The drop down stops working   . i'm unable to look at or edit module properties  . connecting different modules doesn't work either . Drag and drop operations still work . command line stream creation still works  is anyone else facing these issues ?   Thanks !;0
XD-3434;Issue with pagination in web UI In JOBS tab Quick-filter search box paging functionality is not working as expected. Items stay in the page they were first loaded after filtering.   ex. If there were 500 pages of jobs and you are filtering for a job which was in 345. page after the filtering you have to navigate to that page in order to see the job. It needs to be rendered on the first page.;0
XD-3436;Create a spring cloud stream timestamp task module Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs.;0
XD-344;Add BatchMbeanExporter for batch modules;0
XD-3440;Tasks Launcher should be able to record status to a central repository Need infrastructure to capture the state from the environment (lattice local) running the task.    Task Launcher needs ability to map the task state as it is reported from the cloud environment (lattice local) to the enumerated state as specified [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].    The state information needs to be recorded in the task_execution table enumerated [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].;0
XD-3441;"User wants ability to cancel a running task from SCD CLI User should be able to execute a task cancel <task name>.  Which will terminate a running task.  And set the state of the task to ""cancelled"".";0
XD-3446;"The tooltip for source displays incorrect information when using HDFS as sink Deploying a Stream with HDFS sink and JDBC as source displays incorrect information on the tooltip for the JDBC source. The issue occurs when there are more than 1 containers deployed and the source is deployed on one container and the sink is deployed on another container. I have checked the REST endpoints and they seem to show the correct information. (http://localhost:9393/runtime/containers.json)    In my test case say if there are 2 containers and source and sink are deployed on the same container the tooltip's show correct information. The Stream I used for testing purposes is as follows -  {noformat}   stream create swagataTestIssue --definition ""jdbc --query='select employee_id employee_name employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy   {noformat}    I will attach the screenshots. This issue has also been reported when using Gemfire as source and HDFS as sink.    Thanks  Swagata";0
XD-3449;Task Repository h2. Narrative  As a user I need to be able to query the current state of a task that has been launched.    h2. Back story  Given the fact that tasks are intended to go away we need to record the state of them as well as their end result in a repository for a user to be able to query.  This repository will be the system of record when reporting the state of an executing/executed task.;0
XD-3452;Handle paginated responses Currently we handle only a single page response from CC SPI list requests but potentially there could be multiple ones.;0
XD-3457;Remove Timestamp task from SCSM;0
XD-3460;Support underscore delimited module args for module launcher If the module launcher's module arg is delimited by underscore (--args_0_fixedDelay=1) then boot ignores that property. It is important to support the underscore delimited property arguments as we set environment properties of these in CF and lattice environment.    The spring boot fix (https://github.com/spring-projects/spring-boot/commit/5a287455273270a20742f03e4546acde9e857bee) doesn't resolve the property if the value type of the Map is Map itself.;0
XD-3464;"Stream Destroy fails if stream deploy failed (From Eric)  Deploying using the following stream fails (probably because of issues around quoting):  `stream create foo --definition ""time | filter --expression=payload.contains('0') | log"" --deploy`  When you try to destroy the stream the destroy fails which shouldn't happen whether the stream was valid or not.";0
XD-347;"Investigate Redis connection timeout issues when running performance test With the performance test run the numbers (messages sent/received per second) keep varying as there are   ""redis client connection timeout exceptions"" (Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out) at both redis inbound/outbound channel adapters as I increase the total number of messages being processed (max. 10K/second).  Some of the exception messages for the review:  1) With connection pool (at Redis outbound):  Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool nested exception is com.lambdaworks.redis.RedisException: Unable to connect  at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:95)  at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:36)  at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:318)  at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:109)  at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)  at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)  at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:157)  at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:137)  at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)  at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:71)  at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:67)  at org.springframework.xd.perftest.redis.outbound.RedisQOutboundChannelAdapter.handleMessageInternal(RedisQOutboundChannelAdapter.java:71)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  ... 17 more  Caused by: com.lambdaworks.redis.RedisException: Unable to connect  at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)  at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)  at org.springframework.data.redis.connection.lettuce.DefaultLettucePool$LettuceFactory.makeObject(DefaultLettucePool.java:252)  at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1181)  at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:93)  ... 29 more  Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379  at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)  at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)  at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)  at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)  2) Without connection pool (at Redis inbound):  Caused by: com.lambdaworks.redis.RedisException: Unable to connect  at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)  at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)  at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:321)  ... 12 more  Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379  at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)  at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)  at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)  at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)  ... 3 more";0
XD-3470;Unnecessary format enforcement on module short description What is the functional justification for enforcing this validation on modules? Is it really necessary to enforce that the short description must start with a capitol letter and end with a period? Seems a bit unnecessary and opinionated to me.    Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors  Field error in object 'info' on field 'shortDescription': rejected value [...snip...] codes [Pattern.info.shortDescriptionPattern.shortDescriptionPattern.java.lang.StringPattern] arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescriptionshortDescription] arguments [] default message [shortDescription][Ljavax.validation.constraints.Pattern$Flag@3984374e^\p{IsUppercase}.*\.$] default message [Short description must start with a capital letter and end with a dot];0
XD-3472;Spring XD processor module classloader issue: ClassNotFoundException See http://stackoverflow.com/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception;0
XD-3473;Web Admin app not loading for slow connections When opening manager webapp if the internet connection is slow enough to make one of the biggest javascript dependencies to make requirejs throw a timeout the webapp becomes unusable displaying only the loading gif and showing a javascript error saying:    Uncaught Error: Load timeout for modules: angular    It typically takes ~ 10 seconds to throw that error.;0
XD-3474;Composing modules ignores output/input type specified in definition When composing two or more modules together if any output or input type is specified between modules it is ignored.     I created a stream with definition:  {code}  mySourceModule --outputType=application/json | myProcessorModule  {code}  that worked fine as expected. When i composed this definition as a composed module I got errors stating that the processors message handler had no handler method for the object the source module emitted. The process was only configured to accept JSON as string. I simply had to create a second handler method but if i didnt own the module this could be an issue.;0
XD-3476;Add the various property sources to the Spring Environment bean It would be extremely nice to have the various property sources available in the Spring Environment bean for a module to use.;0
XD-349;Trigger - Add support for date-based one-time execution Currently Jobs can be either executed using cron expression or immediately at once. We should also support the one-time scheduling of jobs in the future.    Would this possibly require us to implement schedule-persistence? That could severely impact story-points.;0
XD-3490;Port load-generator & throughput modules to SCS-Modules Migrate load-generator and throughput to SCS.;0
XD-3491;Move Cassandra sink to XD proper;0
XD-350;Support hourly resolution in redis aggregate counter;0
XD-3506;UI - Container List - Module Properties - Escape Passwords;0
XD-3509;"CORS issue when trying to use HTTP in singlenode When I'm trying to send a json object to spring-xd I get the following error even though I opened up requests to allow all.     XMLHttpRequest cannot load http://localhost:9000/. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:3000' is therefore not allowed access.    Config:   spring:    profiles: singlenode  xd:    transport: local    ui:       allow_origin: ""*""";0
XD-3516;Document partitioning through deployment properties As an s-c-d user I'd like to have documentation on deployment manifest so I could refer to the relevant bits on {{partitions}}. I'd like to understand how streams withe;0
XD-3517;"Document direct binding As an s-c-d user I'd like to refer to documentation on ""direct binding"" so I can use it as a reference to deploy a stream that includes directly bound modules.     Example:  {code}  java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-1.0.0.BUILD-SNAPSHOT.jar --modules=org.springframework.cloud.stream.module:time-source:1.0.0.BUILD-SNAPSHOTorg.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOTorg.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT --args.0.fixedDelay=7 --args.1.expression='payload.contains(""6"")' --aggregate=true --spring.cloud.stream.bindings.output=filtered  {code}";0
XD-3519;Add TAP support for Rabbit binder As an s-c-d user I'd like to {{tap}} the primary pipeline so I can fork the same data and do some ad-hoc analysis without impacting the original stream.;0
XD-352;In-memory implementation of aggregate counter;0
XD-3522;Add dynamic addition to module registry As an s-c-d user I'd like to contribute modules that immediately reflects in module registry so I can create stream or task definitions using the shell/rest-api's.     Currently the registry isn't flexible as it is pretty much [hard-coded at registry bootstrap level|https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-admin/src/main/java/org/springframework/cloud/dataflow/admin/config/ModuleRegistryPopulator.java#L75].;0
XD-3550;Re-add Spark job acceptance test with spark standalone cluster The spark app test on spark standalone cluster is currently commented out:  https://github.com/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/SparkAppTests.java#L74    We need to add it back once the cluster is setup on acceptance test environment.;0
XD-3554;Spike: Destroy composed job As an XD developer I'd like to explore options to remove composed job so I can clean-up unused resources and memory footprints.;0
XD-3555;Spike: Store DSL definition in ZK As an XD developer I'd like to explore options to save composed job definition in ZK metadata so I can use the repository to recreate jobs to recover from failure scenarios.;0
XD-3556;Develop tasklet to execute a Job h2. Narrative  As the system I would like a way to launch a previously deployed job module from another job module.    h2.  Back story  For the composed job story we will have a driver job that consists of each step that represents the execution of a job.  This story is the creation of a {{Tasklet}} that will launch the child job and upon it's completion set the results of the driver's step to that of the slave job's results.;0
XD-356;Test startup scripts on windows startup scripts on windows should be tested xd-admin xd-container xd-shell.;0
XD-3560;Better printing of array default valuesin documentation When a default value is an array the current behavior (using toString()) not only produces useless results (like `[Ljava.lang.String@2638011`) but also constantly changing results.;0
XD-3561;Configurable response status code in HTTP Source We have a use case where we need the HTTP source module to return a 204 status instead of the 200 status that is currently returned. There may be other status codes that it would be useful to be able to return. A simple additional option on the module would allow this to be configured.;0
XD-3566;TwitterStream test must use unique name to prevent test collision XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.;0
XD-3567;Fix classpath and servlet container issues Several issues with 1.3.0.M1 staged version    - we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN    - we now have Guava 18.0 on classpath instead of 16.0.1    - xd-yarn push doesn't work hadoop client for 2.7.1 needs Servlet API     - updating Hadoop to 2.7.1 instead of 2.6.0    -- this causes Curator to also update to 2.7.1 which throws exception on startup;0
XD-3568;AdminServer fails on HDP 2.3 Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795    The xd-admin sysout is:    {code}  Started : AdminServerApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    02:51:36624  ERROR main boot.SpringApplication - Application startup failed  java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer    org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)    org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)    org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)    org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)    org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)    org.springframework.boot.SpringApplication.run(SpringApplication.java:320)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)    org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)  Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type name or annotation)    org.springframework.util.Assert.isTrue(Assert.java:68)    org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)    org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)    org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)  	... 17 more  02:51:36628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context close  java.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015] root of context hierarchy    org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)    org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)    org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)    org.springframework.boot.SpringApplication.run(SpringApplication.java:342)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)    org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)  02:51:36642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer  {code};0
XD-3576;Add support to retrieve job details As an XD user I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.;0
XD-3578;Add support to restart job composition As an XD user I'd like have support restart an existing composed job so I could re-launch it at will.;0
XD-358;Add support for creating named cron triggers Simple cron based triggers;0
XD-3584;"Have consistent file format requirements in Spring XD and Hadoop When the following format is specified  -  {noformat}   home: file://hadoop/xd/custom-modules  {noformat}  There is no root-path ('/') following the 'file://' scheme. That makes the Hadoop job launcher interpret what follows as a host name and will look for '/xd/custom-modules' on the host 'hadoop'. This results in ""java.net.UnknownHostException: hadoop"".    This format works for module upload though. The module upload relies on resource location resolution from Spring Framework which is more lenient [1]. The MapReduce job submission uses code from the Apache Hadoop project and uses a more stringent resolution.     This results in ambiguity 'file://my/directory' and requires the root path to be specified.  [1] http://docs.spring.io/autorepo/docs/spring/4.2.x/spring-framework-reference/html/resources.html#resources-filesystemresource-caveats";0
XD-3586;Move Kafka @Rule to a separate repo As an s-c-d developer I'd like to move kafka {{@Rule}} to a separate repo so I can consume the test fixtures in different projects.;0
XD-359;Add support for creating a spring batch job that has an embedded trigger expression;0
XD-3591;Accessing Admin REST APIs on CF returns unexpected results As an s-c-d user I'm trying to access {{admin}} REST endpoints running on CF but I'm getting SSL authentication errors.;0
XD-3597;Separate Lifecycle of Input and Output adapter endpoints Described in https://github.com/spring-cloud/spring-cloud-stream/issues/144    As a developer I want Input enpoints to be started after all the beans in the context so that received messages can be delivered to components.;0
XD-360;Add support for creating a spring batch job that references a named trigger;0
XD-3604;Container process id's still showing after shutting them down In my test case I have security enabled. I tested this on distributed mode. I have a few Streams deployed.  * Started 3 XD containers.   * Issue *Shutdown* from UI  * The containers don't show up on the UI any more  * jps lists the process id of 2 ContainerServerApplication(there should be none listed)    I have noticed different test results every time like at times 2 out of 3 containers are terminated and at times 1 out of 3 are terminated. Please let me know if you have issues replicating this.;0
XD-3613;"Multiple module instances consuming from taps or topics get duplicate messages on redis Message Bus If I deploy more than one instance of a module (eg using module.name.count > 1 or module.name.count =0) that consumes from a tap or topic then I get duplicate messages if I’m using Redis as the message bus. It looks like this is the same issue as XD-3100 but the fix for that only fixed Rabbit as the message bus.    This is easy to reproduce on a 2 container cluster using a Redis Message Bus:    Create and deploy streams as follows:    {code}  stream create --definition ""http | log"" --name httpLog  stream deploy --name httpLog --properties ""module.*.count=0""  stream create --definition ""tap:stream:httpLog > transform --expression='payload.toString() + \"" TAPPED\""' | log"" --name httpLogTap   stream deploy --name httpLogTap --properties ""module.*.count=0""  {code}    On container 1 send a message:    {code}  curl --data ""test message 001"" http://localhost:9000/httpLog  {code}    Container 1 logs are then:    {code}  2015-10-13 14:16:28.853  INFO 22774 --- [ol-28-thread-18] xd.sink.httpLog                          : test message 001  2015-10-13 14:16:28.855  INFO 22774 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  {code}    and container 2:    {code}  2015-10-13 14:16:28.859  INFO 22719 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  {code}    Ie the tapped message is duplicated (picked up by both tap module instances)    Similarly for topics create and deploy these streams:    {code}  stream create --definition ""http > topic:mytopic"" --name httpTopic  stream deploy --name httpTopic --properties ""module.*.count=0""  stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 1\""' | log"" --name topicConsumer1  stream deploy --name topicConsumer1 --properties ""module.*.count=0""  stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 2\""' | log"" --name topicConsumer2  stream deploy --name topicConsumer2 --properties ""module.*.count=0""  {code}    On container 1 send a message:    {code}  curl --data ""test message 002"" http://localhost:9000/httpLog  {code}    Container 1 logs are then:    {code}  2015-10-13 14:34:23.168  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2  2015-10-13 14:34:23.172  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1  {code}    and container 2:    {code}  2015-10-13 14:34:23.173  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2  2015-10-13 14:34:23.177  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1  {code}    Ie the topic message is picked up by each instance of the module in each stream. In this case I would expect each stream to pick up the message once   ie I would get a single output for each stream     test message 002 TOPIC CONSUMER 2  once (on either container)  test message 002 TOPIC CONSUMER 1  once (on either container)";0
XD-3614;Harmonize common deployer runtime properties applied to modules Most if not all of the deployers have some concept of customization of the deployed modules: be it memory or cpu disk etc.    This ticket is about harmonizing the handling of such properties with the assumption that we want a per-deployer set of defaults and overridability at deployment time.;0
XD-3616;Add standardized way to pass props from Deployers/Admin to ModuleLauncher There is a need to customize the ModuleLauncher behavior (itself NOT pass options to modules that are launched which is already supported) for example to set the location of the maven repository.;0
XD-3617;Update build to use SHDP 2.3.0.RC1;0
XD-3621;Add support for custom headers with the Kafka bus Currently the Kafka Message Bus does not have the ability to configure a set of custom headers to persist in the `embeddedHeaders` mode (only the message-bus specific) message headers are persisted.;0
XD-3623;Job in unknown state after run long sqooptasklet Hello guys    I hope you are doing good. I found a problem when I try run long sqoop imports (4 hours or more). For some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems.    2015-10-17T03:04:03-0400 1.2.0.RELEASE ERROR SimpleAsyncTaskExecutor-4 step.AbstractStep - Encountered an error saving batch meta data for step import-logs in job ingestion-flow. This job is now in an unknown state and should not be restarted.    Please see attached log file for more details.   Could you please let me know if you need other details to find what is the problem?     Thanks in advance  Héctor;0
XD-3626;Support partitioning properties Using these as a starting point support the standard binder partitioning properties:    https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/BinderProperties.java#L69    https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupport.java#L663;0
XD-3628;"Ambari plugin doesn't work with security_enabled It seems like springxd_shell will pull jhs principal and keytab from mapred-site.xml. When springxd_shell is installed in edge node Amabri returns ""can't find jhs keytab"" and failed.    Details [here|https://github.com/spring-projects/spring-xd-ambari/issues/8].";0
XD-3630;Launch GF cache server for integration tests The comments in [22|https://github.com/spring-cloud/spring-cloud-stream-modules/pull/22] indicate that we also need to run a gemfire cache server in order for the tests to pass. We should create an embedded cache server since it would be much easier not have to have an XD or gemfire install in order to test the sink.;0
XD-3639;"Create bridge processor See https://github.com/spring-cloud/spring-cloud-dataflow/issues/128    This is needed to support ""channel > channel"" type constructs";0
XD-3640;Library support changes at shell level Following merge of https://github.com/spring-cloud/spring-cloud-dataflow/commit/5cb81c49a240304be14bcf5d724cfd36df403d39 the following changes need to happen at shell/REST level:    {{module list}} should not show libraries  {{library list}} should be added to show libs  {{module register}} should not accept type=library  {{library register}} should be added  {{module info}} should not accept libs  {{library info}} should be added;0
XD-3642;Spring XD unable to save metadata for long steps Hey Guys    We are facing an annoying problem and I can't figure out how solve it. For some reason when we run a step that takes long time (4 hours or more) spring XD is unable to save the metadata and throws the following error.     2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error executing step ingest-logs in job ingest-logs-flow  org.springframework.orm.jpa.JpaSystemException: commit failed nested exception is org.hibernate.TransactionException: commit failed    org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:244) ~[na:na]    org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:155) ~[na:na]    org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:521) ~[na:na]    org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:757) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:150) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:368) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    com.sun.proxy.$Proxy53.run(Unknown Source) [na:na]    org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50) [spring-batch-integration-3.0.3.RELEASE.jar:3.0.3.RELEASE]    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:129) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_67]    java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_67]    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_67]    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_67]    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_67]    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_67]    java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]  Caused by: org.hibernate.TransactionException: commit failed    org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:187) ~[na:na]    org.hibernate.jpa.internal.TransactionImpl.commit(TransactionImpl.java:77) ~[na:na]    org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[na:na]  	... 97 common frames omitted  Caused by: org.hibernate.TransactionException: unable to commit against JDBC connection    org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:116) ~[na:na]    org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:180) ~[na:na]  	... 99 common frames omitted  Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Communications link failure during commit(). Transaction resolution unknown.    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]    java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]    com.mysql.jdbc.Util.handleNewInstance(Util.java:389) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.Util.getInstance(Util.java:372) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:958) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:937) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:872) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.ConnectionImpl.commit(ConnectionImpl.java:1616) ~[mysql-connector-java-5.1.34.jar:5.1.34]    org.apache.commons.dbcp.DelegatingConnection.commit(DelegatingConnection.java:301) ~[commons-dbcp-1.4.jar:1.4]    org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.commit(PoolingDataSource.java:200) ~[commons-dbcp-1.4.jar:1.4]    org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:112) ~[na:na]  	... 100 common frames omitted  2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error saving batch meta data for step ingest-logs in job ingest-logs-flow. This job is now in an unknown state and should not be restarted.  org.springframework.dao.OptimisticLockingFailureException: Attempt to update step execution id=8 with wrong version (1) where current version is 2    org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.updateStepExecution(JdbcStepExecutionDao.java:255) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    We are using a MySQL database with the following configurations.     spring:    datasource:      url: jdbc:mysql://hosttomysql:3306/singnode      username: admin      password: admin      driverClassName: com.mysql.jdbc.Driver      validationQuery: select 1      testOnBorrow: true      If you guys know this issue or have some ideas how solve please let me know. Thanks in advance.  Héctor;0
XD-3643;Allow sending to multiple named channels at once Currently it’s possible to do this via   {code}  source | router --expression=''queue:queue1queue:queue2''  {code}  but this involves an additional hop to the message bus for the pipe between the source and router.    It would be better if this was supported directly with the existing named channel syntax to remove this pipe ie  {code}  source > queue:queue1queue:queue2  {code}  This would be useful as a possible solution in the scenario described in XD-3613 as an alternative to using topics on the Redis message bus which don’t support having multiple instances of the same consumer.;0
XD-3646;Composite Multiple Sink Module This would allow multiple individual sink modules to be combined via the shell DSL so that each message sent to the composite sink module will be sent to each of the individual sink modules in turn.   Internally this would probably use a recipient list router to send to each individual sink.    Module options for each individual sink would be combined to create the overall options for the composite sink module in a similar way to existing composite modules.    This would allow construction of streams with less communication with the message bus for example as an alternative to using a named topic in the message bus.    Using this in conjunction with sinks built using existing composite module functionality (as a combination of processors and a sink) would allow more sophisticated combinations to be constructed and deployed as a single module (with no message bus communication).    One particular application of this would be with tap and counter functionality. If multiple fields in a message need counted this currently needs to be done as separate streams tapping the original with the overhead of the tapped message being read from the message bus multiple times potentially on different nodes this enhancement would allow all the counters to be combined to make a more cohesive composite counter module so that the tapped message would only need to be read once.;0
XD-3647;Update support for Hortonworks to HDP 2.3.2 We currently support HDP 2.3.0. The most recent HDP version is 2.3.2. This latest HDP release also changes Spark version to 1.4.1.;0
XD-365;Support having multiple property placeholders defined in different modules Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties.  Need to determine a strategy such that multiple PPCs can be used.;0
XD-3655;Document admin-ui improvements;0
XD-3657;Unable to find an option for restart Sqoop Job automatically when it is failed I am able to run a Sqoop Job to copy data from oracle to Hadoop and I can relaunch the job manually through shell command or admin UI. But I don't see option to set some number or auto retry option so that when ever failure happens system will automatically retry some number of times that we specify.;0
XD-367;Final review of REST API structure document for streams taps and jobs Get closure on open discussion points for REST API wrt to streams taps and jobs.;0
XD-368;"Improve connection handling in RedisAggregateCounterService. This is currently too chatty. It should be possible to use a single connection for each ""increment"" operation.";0
XD-3687;Update Docs to add configs changes for Composed jobs Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:  1) uncomment and change the following from  :  ```spring:    batch:  # Configure other Spring Batch repository values.  Most are typically not needed      isolationLevel: ISOLATION_SERIALIZATION  ```  to  ```spring:    batch:  # Configure other Spring Batch repository values.  Most are typically not needed      isolationLevel: ISOLATION_READ_COMMITTED  ```    And update the hsqldb datasource to:  spring:    datasource:      url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob}sql.enforce_strict_size=truehsqldb.tx=mvcc;0
XD-3689;Update default configs to support Composed Jobs Users want the ability to use Composed Jobs (specifically parallel Jobs) without having to update the configurations for the hsqldb and the Isolation Level for spring batch.  These should be set by default.;0
XD-3690;"Improve ""Server Configuration - Database Configuration"" section Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653";0
XD-3691;"Ensure Job definitions are escaped in UI If using the definition <aaa || bbb> where the definition starts with a ""<"" and ends with a "">"" the definition for the composed job does not appear on the definition page.";0
XD-3697;"Output modules cannot use minPartitionCount when sending to named channels If the output module is connected to a named channel cannot be set up the property minPartitionCount it is giving an exception.    Streams:  stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log""   stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log""  stream deploy --name f --properties ""module.transform.count=2""  stream deploy --name b --properties ""module.transform.count=2""    stream create r --definition ""time | router --expression=payload.contains('10')?'queue:foo':'queue:bar'""  stream deploy --name r --properties ""module.router.producer.minPartitionCount=20""    The error is:  Caused by: java.lang.IllegalArgumentException: KafkaMessageBus does not support producer property: minPartitionCount for queue:bar.  at org.springframework.xd.dirt.integration.bus.MessageBusSupport.validateProperties(MessageBusSupport.java:781) ~[spring-xd-messagebus-spi-1.2.1.RELEASE.jar:1.2.1.RELEASE]";0
XD-3701;Improve Shell Connection Diagnostics When a problem occurs connecting to admin we just get {{Unable to contact Data Flow Admin}} even if the connection is successful and some problem occurs when interpreting the result.    The exception is eaten.    Log an error including the exception.    Currently investigating an NPE in DataFlowTemplate @ line 77.;0
XD-3703;Add SSL and attachments to mail sink Add SSL and attachments to Mail sink module. see XD-2076 & XD-2498.;0
XD-371;Command for creating a job optional --autostart switch to also deploy the job;0
XD-3710;"Facing issue while running Spring XD batch job on HDP version 2.3.2.0-2950 ***Version  	Spring XD Version : spring-xd-1.3.0.RELEASE spring-xd-1.3.0.RELEASE-yarn  	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64   	Java Version: java version ""1.7.0_65""    ***Description  	The simple word count map reduce job using spring xd is failing with inline error message.    ***Steps to recreate the problem  	1. Created a jar for simple word count map reduce job.  	2. Created jar using information given in ( http://docs.spring.io/spring-hadoop/docs/2.0.2.RELEASE/reference/html/hadoop.html#hadoop:tasklet )  	3. Once the final jar was ready uploaded using ""module upload --name test_mr_module --type job --file /home/user/jar/samplemrjob.jar""  	4. After that created and deployed job using ""job create --name test_mr_job --definition test_mr_module --deploy""  	5. Finally launched using ""job launch test_mr_job"" which failed with inline error.    ***Describe XD Deployment : Distributed     Deployment Type : Distributed - YARN ( on AWS EC2 cloud )  Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers       ***Describe Other Components    Transport: Redis 3.0.1  ZooKeeper: Version 3.4.6.2.3.2.0-2950      Hadoop deployment  Data Platform : Hortonworks HDP 2.3.2.0-2950  RDBMS: MySQL       ***Error Message:     *****************************************************  05:29:52673   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'test_mr_job'  05:29:53655   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@6e5af900 moduleName = 'test_mr_module' moduleLabel = 'test_mr_module' group = 'test_mr_job' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]]  05:30:24351  ERROR inbound.job:test_mr_job-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step teststep in job test_mr_job  java.lang.IllegalArgumentException: Unable to parse '/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework' as a URI check the setting for mapreduce.application.framework.path          at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:443)   	.  	.	  	.          at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:54)          at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:323)          at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)          at java.lang.Thread.run(Thread.java:745)  Caused by: java.net.URISyntaxException: Illegal character in path at index 11: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework          at java.net.URI$Parser.fail(URI.java:2848)          at java.net.URI$Parser.checkChars(URI.java:3021)          at java.net.URI$Parser.parseHierarchical(URI.java:3105)          at java.net.URI$Parser.parse(URI.java:3063)          at java.net.URI.<init>(URI.java:588)          at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:441)  *****************************************************";0
XD-3711;XD  / Zookeeper connection lost. XD container loose connection with Zookeeper.    I'm in a distributed environnement:  - 3 XD container nodes (1.2.1)  - 1 XD admin  - 3 Zookeeper  - 3 RabbitMQ  - 3 Redis/Sentinel    Logs:    *zookeeper.log*  {noformat}  2015-11-25 06:53:07235 [myid:3] - INFO  [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:ZooKeeperServer@617] - Established session 0x251250651910006 with negotiated timeout 40000 for client /172.20.1.9:58070  2015-11-25 06:54:08525 [myid:3] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@357] - caught end of stream exception  EndOfStreamException: Unable to read additional data from client sessionid 0x251250651910006 likely client has closed socket          at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)          at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)          at java.lang.Thread.run(Thread.java:745)  2015-11-25 06:54:08621 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.20.1.9:58070 which had sessionid 0x251250651910006  {noformat}    *container.log*  {noformat}  2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR main-EventThread curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181172.20.1.8:2181172.20.1.9:2181) and timeout (30000) / elapsed (34187)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.getZooKeeper(CuratorFrameworkImpl.java:474) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) [curator-framework-2.6.0.jar:na]          at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) [curator-framework-2.6.0.jar:na]          at org.springframework.xd.dirt.server.container.DeploymentListener$StreamModuleWatcher.process(DeploymentListener.java:596) [spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67) [curator-framework-2.6.0.jar:na]          at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) [zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) [zookeeper-3.4.6.jar:3.4.6-1569965]  2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181172.20.1.8:2181172.20.1.9:2181) and timeout (30000) / elapsed (34189)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]          at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]  2015-11-25T06:53:39+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181172.20.1.8:2181172.20.1.9:2181) and timeout (30000) / elapsed (36191)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]  [...]  2015-11-25T06:54:34+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 26 seconds)...  2015-11-25T06:55:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 57 seconds)...  2015-11-25T06:56:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 117 seconds)...  2015-11-25T06:57:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 177 seconds)...  {noformat}    *admin.log*  {noformat}  2015-11-25T06:54:23+0100 1.2.1.RELEASE ERROR DeploymentSupervisor-0 cache.PathChildrenCache -  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/b1de9530-1837-42c0-a6bc-840b1b15aefc/JOB_TRIGGER.source.trigger.1          at org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) ~[curator-framework-2.6.0.jar:na]          at org.springframework.xd.dirt.server.admin.deployment.zk.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:116) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.springframework.xd.dirt.server.admin.deployment.zk.ContainerListener.childEvent(ContainerListener.java:140) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]          at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]          at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_60]          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]          at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]  {noformat}    If a module is deployed on the node which has lost the connection it's not redeployed on one of the two others.    The only difference between node is that the node in error has less memory.    When this occurs node doesn't appear anymore on the admin ui. And deployed streams do not appear as incomplete but they should if a node has disappear and deployment property _module.*.count_ is set to the number of nodes.    Thanks.    Mickaël;0
XD-3719;Spring flo issue with unexpected char In Flo when creating a stream if you use asterisk you get an error. See the image attached.;0
XD-3720;Custom job with RabbitMq dependencies Hi    I've develop a custom Job which have to publish message on RabbitMq when it's finished.    To develop this module I'veto include this libraries:  * com.rabbitmq:amqp-client:jar  * org.springframework.amqp:spring-rabbit:jar  * org.springframework.amqp:spring-amqp:jar    My job use this writer: org.springframework.batch.item.amqp.AmqpItemWriter    I've this error log:  {noformat}   support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode]  {noformat}    This is typically due to a library loaded several times.    What is the solution to resolve this?    I'd like to use the same libraries has RabbitMq Source/Sink or the transport bus.    Does module classloader isolated from others?    Thanks    Mickaël;0
XD-3726;Processor module does not load classes from custom module package The processor module which is failing to load castor classes from the module path.The code works fine with eclipse DIRT based test cases. I am attaching the code to this email. The jar that it built has the jars that it need at runtime in /module../lib folder.     The code worked fine when i put all the custom jars and application jar in xd/lib. Spoke to Thomas Risberg and confirm this is broken and need to be fixing.[^attachment-name.zip];0
XD-373;Command to create a tap To store it's definition and optionally deploy with --autostart flag;0
XD-3730;NPE in spring-integration when using kafka as message bus when using aggrzgation module as stated in https://jira.spring.io/browse/INT-3908 sprint-integration in springxd can't use kafka as message bus in most case. Could it spring-xd integrat this fix for us to use it?;0
XD-3733;Document redis pool properties in servers.yml Add spring.redis.pool.*  properties to server.yml commented out to show default values. e.g.        maxIdle: 8     minIdle: 0      maxActive: 8     maxWait: -1;0
XD-3736;Rabbit Pub/Sub Consumers Should Support Concurrency PubSub consumers can support concurrency since the threads are competing consumers on the queue.;0
XD-3738;"Encrypt secret information in XD configuration files Spring XD keeps passwords in text files such sas servers.yml properties files and module configuration files. Some users have requested a way to store encrypted values rather than clear text.  XD should provide a ""hook"" for users to provide a custom component to detect encrypted property values and decrypt them during container admin and module initialization.";0
XD-3739;"Incorrect refresh period for groovy scripts All modules that allow groovy implementations (filter script transform router tcpclient) allow automatic refresh of the script when it changes. In the XD documentation it is stated that this refresh occurs every minute eg for filter at http://docs.spring.io/spring-xd/docs/1.3.0.RELEASE/reference/html/#filter ""The script is checked for updates every 60 seconds so it may be replaced in a running system. ""     This set up can be seen in the spring xml for the modules - eg (again for filter)    {code:xml}  <filter input-channel=""to.script"" output-channel=""output"">  	<int-groovy:script location=""${script:filter.groovy}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/>  </filter>  {code}    However from the spring integration documentation http://docs.spring.io/spring-integration/docs/4.2.4.RELEASE/reference/html/messaging-endpoints-chapter.html#scripting-config  it specifies that the refresh-check-delay parameter is actually in milliseconds - ie the above XD configuration would recheck the script every 60 milliseconds which may be a performance concern as it will be checking the lastmodified time of the script file.     Ideally this parameter would be configurable - in our case we would usually eliminate the refresh check altogether (set to -1) as our scripts will not change (or if they did a redeploy of the module would pick it up)";0
XD-374;Command to list taps;0
XD-3743;Update to Spring Integration 4.2.5 When Available (Fix Metrics) See INT-3956;0
XD-3746;Update Spring Framework to 4.2.4;0
XD-3748;Unable to register the JMX bean MessageHistory from Spring Integration If I try to use <int:message-history/> when developing a Spring XD module it fails when try to export the JMX bean. I've seen that the naming strategy used is org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy    The stackTrace:  {code}  2016-02-24T10:40:39+0000 1.3.1.RELEASE ERROR DeploymentsPathChildrenCache-0 container.DeploymentListener - Exception deploying module  org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.history.MessageHistoryConfigurer@24902b5f] with key 'messageHistoryConfigurer' nested exception is javax.management.MalformedObjectNameException: Key properties cannot be empty    org.springframework.integration.monitor.IntegrationMBeanExporter.registerBeanInstance(IntegrationMBeanExporter.java:375) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]    org.springframework.integration.monitor.IntegrationMBeanExporter.afterSingletonsInstantiated(IntegrationMBeanExporter.java:288) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:792) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.SpringApplication.run(SpringApplication.java:320) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:213) ~[spring-xd-module-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:334) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]    java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]    java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_72]    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_72]    java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]  Caused by: javax.management.MalformedObjectNameException: Key properties cannot be empty    javax.management.ObjectName.construct(ObjectName.java:483) ~[na:1.8.0_72]    javax.management.ObjectName.<init>(ObjectName.java:1382) ~[na:1.8.0_72]    javax.management.ObjectName.getInstance(ObjectName.java:1273) ~[na:1.8.0_72]    org.springframework.jmx.support.ObjectNameManager.getInstance(ObjectNameManager.java:62) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy.getObjectName(ModuleObjectNamingStrategy.java:50) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.jmx.export.MBeanExporter.getObjectName(MBeanExporter.java:751) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]  {code};0
XD-375;Command to delete tap;0
XD-3751;"gpfdist may fail to shutdown with backlog In a case where reactor's ringbuffer is full and thus handling backpressure by blocking `onNext` shutdown phase where `onComplete` is send will cause a deadlock.    This is shown by a thread dump during a shutdown. This will basically break further deployments for this stream in distributed mode while single node will show more errors during undeployment.    {code}  ""pool-7-thread-1"" #58 prio=5 os_prio=0 tid=0x979fe800 nid=0x54de runnable [0x986ad000]     java.lang.Thread.State: TIMED_WAITING (parking)    sun.misc.Unsafe.park(Native Method)    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)    reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)    reactor.core.processor.util.RingBufferSubscriberUtils.onNext(RingBufferSubscriberUtils.java:30)    reactor.core.processor.RingBufferProcessor.onNext(RingBufferProcessor.java:575)  {code}    {code}  ""main-EventThread"" #19 daemon prio=5 os_prio=0 tid=0x9b93a400 nid=0x54b1 runnable [0x9aefe000]     java.lang.Thread.State: TIMED_WAITING (parking)    sun.misc.Unsafe.park(Native Method)    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)    reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)    reactor.core.processor.util.RingBufferSubscriberUtils.onComplete(RingBufferSubscriberUtils.java:54)    reactor.core.processor.RingBufferProcessor.onComplete(RingBufferProcessor.java:585)    org.springframework.xd.greenplum.gpfdist.GPFDistMessageHandler.doStop(GPFDistMessageHandler.java:170)  {code}    I've been crafting workaround for this by trying to wait reactor stream/buffer to get drained by gpdb and finally as last resort forcing processor in reactor to shutdown.";0
XD-3753;"Add ""yarn.resourcemanager.scheduler.address"" to mapreduce samples The MapReduce samples should have ""yarn.resourcemanager.scheduler.address"" since it might be needed in a multi node production cluster.";0
XD-3754;"Composed Module Child Module Validated Too Early {{module compose foo --definition ""time --fixedDelay=5 | shell --command=my.sh""}}    {code}  xd:>stream create bar --definition ""foo | log"" --deploy  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module foo of type source:      command: may not be empty      command: may not be null  {code}    The problem stems from the fact that the options metadata validation is performed on the shell module before the property from the composed module is injected.    Disabling the validation annotations on the metadata avoids the problem.    {code}  //	@NotEmpty  //	@NotNull  public String getCommand() {  	return command  }  {code}";0
XD-3755;"Composed Modules Can't Have Duplicate Processors {code}  xd:>module compose foo --definition ""time --fixedDelay=5 | t1:transform --expression=payload+'a' | t2:transform --expression=payload.toUpperCase()  {code}    Produces {{2016-05-02 17:27:20aa}} - the first transform is applied twice.";0
XD-3756;wordcount failed to run in cloudera VM 5.7 I download the spring XD example projects and run through the steps acccording the README file for the project. I tried to change the hadoop-site.xml server.yml and wordcount.xml files but I failed get the . I am blocked by this issue. Thank you very much in advance for help. Best Regards.;0
XD-3757;Dead Letter is not created on all RabbitMQ queues for partionned stream Hi    If I use the module.[name].producer.paritionKeyExpression and the module as also autoBindDLG enabled the creates RabbbitMQ queues do not have the DeadLetter policy.  The first queue has it (xdbus.<stream>.0-0) but others do not have it (xdbus.<stream>.0-N).    Thanks    Mickaël;0
XD-3758;"flo don't work i  unzip flo-spring-xd-admin-ui-client-1.3.1.RELEASE.jar to replace the existing spring-xd-admin-ui-client-1.3.1.RELEASE.jarand clear my browser cache  then restart the  xd-singlenode，but i can't access Flo for Spring XD at the following URI endpoints :http://HOST_NAME:PORT/admin-ui/#/streams/create  i can't find the ""flo"" page!";0
XD-3759;Composed job endpoint is missing from the defined authorization rules More details in the support ticket: https://issuetracker.springsource.com/browse/VESC-679    Following entires should be added to {{application.yml}} file.    {code}          - POST   /tools/parseJobToGraph                      => hasRole('ROLE_CREATE')          - POST   /tools/parseJobToGraph.*                   => hasRole('ROLE_CREATE')          - POST   /tools/convertJobGraphToText            => hasRole('ROLE_CREATE')          - POST   /tools/convertJobGraphToText.*          => hasRole('ROLE_CREATE')  {code};0
XD-377;add create() and deploy() methods to JobDeployer see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit    Create the deployer if it doesn't exist.;0
XD-382;Create TapRepository see StreamsRepository as an example. This includes in memory and Redis implementations;0
XD-385;Error handling on Streams Have proper exceptions for common error cases on Stream creation/deployment and propagate those to clients correctly.;0
XD-386;"Automate copyright header management Some (java) files are currently missing headers.    The plugin at https://github.com/hierynomus/license-gradle-plugin can help but initial trial revealed that:    - skipExistingHeaders does not seem to be honored. We may then need to use a year construction like 2001-${current} or force all files to have ${current} year. Don't know the legal implications of this  - Default source sets encompass all files ""in the classpath"" basically so that means .xml as well as .properties files for example. It would seem logical to add header to those as well but I don't think this is what we do on other projetcs.";0
XD-388;Create design document for implementation strategy for ingesting data from twitter into HDFS that can be analyzed by HAWQ As part of the Hadoop World demonstration work the flow of data using XD from twitter to be analyzed by HAWQ as done.  Part of this work had the data going into HDFS that HAWQ was able to query using external tables.    The work for this story is to identify the concrete technical tasks/stories to be created do deliver and document this functionality in XD.;0
XD-397;Document Monitoring & Management Features This section should discuss what is exposed via JMX how you can view it in JConsole and how you can view it over http via Jolikia.    in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream that indicate the number of messages processed per section.;0
XD-398;Update Getting Started chapter to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#getting-started;0
XD-399;"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after ""start the runtime"" and before ""create the stream""";0
XD-40;Build script that creates an executable server as an artifact Gradle application plugin is a good starting point.  this should be the main server that would host SI based modules to do syslog->file ingestion (as an example);0
XD-400;Update Streams Chapter to use shell commands instead of curl the current streams chapter    http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams    shows creation and deleting streams using CURL - switch to use shell.  Also add listing of a stream.    there is also an example of creating a stream this should be replaced as well.;0
XD-407;Update Sources Gemfire CQ section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire-cq;0
XD-408;Update Source Syslog section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#syslog;0
XD-411;Update Processors Transform section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#transform;0
XD-414;Update Sink's Log section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#log_sinks;0
XD-415;Update Sink's File section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#file_sinks;0
XD-417;Update Sink's TCP section to use Shell commands instead of curl See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp_sinks;0
XD-422;Update Analytics Field Value Counter section to use Shell commands instead of curl;0
XD-423;Update Analytics Gauge section to use Shell commands instead of curl;0
XD-427;Update Creating a Source Module section to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module;0
XD-428;Update Creating a Sink Module section to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module_3;0
XD-429;Document time source time source is used in some examples but it isn't documented explicitly eg. --interval option in seconds.;0
XD-43;Metric repositories should support Spring Data CrudRepository interface This provides common CRUD behavior and a shared interface that can be useful in testing scenarios.;0
XD-430;Use a Different Default Jolokia Port for Admin Vs. Container Avoid the need for {{--jmxPort=xxxx}} when running both a {{Container}} and {{Admin}} on the same server;0
XD-431;Make String conversion optional with local transport;0
XD-435;Create tests to load the standard runtime app context configurations The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren't broken by changes.;0
XD-438;"More DSL work: exploiting source/sink channels The DSL changes under XD-369 now build stream Ast objects that can include a source and sink channel:    {code}  // Source Channel  :mystream.foo > count | log    // Sink Channel  http | count > :foo  {code}    These new fields in the Ast object need to be copied into the module deployment request objects and then used at the destination as the channels for wiring things together.  Currently the only channels used are the .NNN numeric channels where NNN is the index of the module in the stream definition. The source/sink channels are 'extra' channels that need creating - the source channel acting as a real source for the next module in the chain whilst the sink channel acts as a sink output for the last channel in the chain.      I can think of two ways to handle the implementation:  - In order to police the stream structure as ""source | processor* | sink"" maybe special SourceChannel and SinkChannel modules are created to represent these channels and when deployment happens the deployer understands that they don't represent a real request to deploy a module but simply the channels to wire up to the adjacent module.    - Carry source/sink channel info in the existing module definitions. But then the verification of source/processor*/sink structure will need modification to say a source isn't necessary if the first processor has a source channel attached and a sink isn't necessary if the last processor has a sink channel attached.";0
XD-439;More DSL work: hooking up stream directory Following stream parsing there is now a stream resolution stage that chases down substream references and fills in parameterization. The 'lookup' of streams is done through implementors of the StreamLookupEnvironment interface. Currently the parser implements this itself but it is really a job for the stream directory.  The parser implementation doesn't know about stream deletions for example so may still resolve streams that no longer exist.;0
XD-440;More DSL work: using and policing & for job step lists The new parser supports | for connecting regular modules and & for connecting job steps. The modules in the ast that were connected with & are tagged but nothing is currently using that information (it doesnt get into the module deployment request). We need to think about using this data: policing the modules that are being deployed to ensure they are job steps for example.;0
XD-448;The user needs the ability to set up a end-time where the trigger should no longer be in effect.;0
XD-45;Remove the expiry of keys in Redis based repositories There is duplicated code in Redis based repositories that related to expiry behavior move into a common shared helper class and/or base class.;0
XD-450;Retrieve description of all registered modules by type The following will retrieve the names of all module types (eg- sources sinks jobs processors triggers).   {code} GET /module-types/ {code}  I'm expecting that the plural would be used but singular would work as well.  The following gets modules of a given type: {code} GET /module-types/{type} {code}  This would be similar to the {{/modules/}} call in XD-265 but it would only return modules of the specified type.;0
XD-453;Use wants the ability to persist Trigger Context;0
XD-455;User wants the ability to limit the total number of jobs a trigger can have running simultaneously;0
XD-459;The user needs the ability to pause and resume triggers ad-hoc. A pause means that a trigger will wait to fire its job until after the pause is removed.  It does not apply the misfire behavior.;0
XD-460;The user needs the ability to pause and resume triggers based on a calendar.;0
XD-461;User wants to be able to know what triggers are associated with a job;0
XD-465;"Shell should display error messages returned from the server For example using tcpdump I can see both an exception and message information:  'HTTP/1.1 500 Internal Server Error Server: Apache-Coyote/1.1 Content-Type: application/jsoncharset=UTF-8 Transfer-Encoding: chunked Date: Fri 12 Jul 2013 13:38:26 GMT Connection: close  275 [{""links"":[]""logref"":""MessageHandlingException""""message"":""org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=nullChannel sends=0 receives=0]] with key 'xd.tap1:type=MessageChannelname=nullChannelindex=1module=log' nested exception is javax.management.InstanceAlreadyExistsException: xd.tap1:type=MessageChannelname=nullChannelindex=1module=log""}]  However the client only shows:  http://localhost:8080:>tap create --name ""tap1"" --definition ""tap@test1.file | log"" --deploy true 14:38:26113  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/taps"" resulted in 500 (Internal Server Error) invoking error handler Error creating tap 'tap1'  The error doesn't seem to be logged in the XD Admin server either so the information is effectively lost.";0
XD-466;Add JSON conversion to tuple Support toString() to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations.  Also provide toTuple(String json). This supports seamless mapping JSON<->Tuple in XD;0
XD-467;"JMX shouldn't register taps or streams if the creation fails There's a lifecycle problem when a tap creation fails (e.g. because the DSL syntax is wrong). Subsequent attempts to create the tap will fail with an error:   [{""links"":[]""logref"":""MessageHandlingException""""message"":""org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=nullChannel sends=0 receives=0]] with key 'xd.tap1:type=MessageChannelname=nullChannelindex=1module=log' nested exception is javax.management.InstanceAlreadyExistsException: xd.tap1:type=MessageChannelname=nullChannelindex=1module=log""}]  Disabling JMX solves the issue.   reproduce Create a bad stream definition name 'bad' Try to recreate with the same name but correct stream definitions.  The system will report that the stream already exists.";0
XD-469;Upgrade to spring-data-hadoop 1.0.1.RC1 spring-data-hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros/versions and we should make use of that.;0
XD-47;HDFS sink module;0
XD-473;Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopDistro=phd1;0
XD-474;Create JSON to tab-delimited text transformer script We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.;0
XD-476;"The stream definition is not deleted in redis container when the stream is destroyed This only happened with distributed mode that uses redis as store. The single mode which uses in memory store works fine.  Step to reproduce:  Create stream: curl -X POST -d ""name=httptest"" -d ""definition=http|log"" http://localhost:8080/streams  redis 127.0.0.1:6379> keys *httptest* 1) ""modules:httptest"" 2) ""streams.httptest"" 3) ""stream.definitions.httptest""  Delete Stream: curl -X DELETE http://localhost:8080/streams/httptest  redis 127.0.0.1:6379> keys *httptest* 1) ""streams.httptest"" 2) ""stream.definitions.httptest""  stream still there not deleted  Recreate the stream curl -X POST -d ""name=httptest"" -d ""definition=http|log"" http://localhost:8080/streams  Got: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><errors xmlns:ns2=""http://www.w3.org/2005/Atom""><error logref=""StreamAlreadyExistsException""><message>There is already a stream with name 'httptest'</message></error>";0
XD-478;Add accepted type logic to module A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin;0
XD-481;Running Job with time delay (non cron) launches 2 instances before job is supposed to fire;0
XD-486;All controllers to return XYZResource objects not the raw domain objects. Resource objects should be returned from all controller methods.  MVC Tests should be added to check returned values.;0
XD-488;Rename controllers to have pluralized named (e.g. JobsController) See implementation used for Steams and apply to jobs taps triggers.;0
XD-489;Introduce distinction between TapDefinition and Tap (the instance) Rename existing Tap class to something else.;0
XD-495;Document MQTT Source and Sink;0
XD-496;Disable Collection to Object conversion in DefaultTuple DefaultFormattingConversionService provides Collection -> Object conversion which will produce the first item if the target type matches. Here this results in an unfortunate side effect getTuple(List<Tuple> list) would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.;0
XD-497;"Fix Sonar build! Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains.    One solution would be to add Jackson 2 to the Sonar ""classpath"" but I did not manage to do that.";0
XD-50;Add tap support to DIRT syntax:    {code}  tap @ somechannel --key=value | somecounter  {code};0
XD-506;Support pagination in list() command for jobs See XD-477;0
XD-508;Support pagination in list() command for triggers See XD-477;0
XD-509;Investigate intermittent failure of RedisStreamDefinitionRepositoryTests the test for findAll often fails for me when running inside gradle. (Could not reproduce inside eclipse)    I already tried fixing it by using a different redis key space but to no avail.  One explanation would be if gradle runs tests concurrently but my understanding is that it does not.;0
XD-51;Add xd.stream.name property in StreamPlugin;0
XD-510;Ensure that each controller's list() returns PagedResources;0
XD-513;Add CI job in bamboo to run XD integration tests CI job will run integration tests that are tagged for CI build.;0
XD-514;Create proper test coverage for Controllers Create proper test coverage for Controllers;0
XD-517;Add Server Runtime Info to Banner Standalone Admin currently has no shiny banner as container has. More importantly it does not say which port it's listening on the transport used etc.;0
XD-519;Modules need to validate their parameters at create time. We need to fail fast.;0
XD-52;add twitter search source module;0
XD-520;"All parameters for modules need to use ""hump case"" formerly camel hump";0
XD-521;The parser should be able to handle a parameter name with a '-' hyphen embedded. Right now it treats it as a new parameter start and fails.;0
XD-523;"Parser blows on modules names with '-' Tried to create a module named ""tcp-poll"" and got this:  XD108E:(pos 3): missing expected character '-'  tcp-poll --host=54.208.22.193 --port=8081 | log      I believe this should be supported and indeed we have several module names of this form already";0
XD-524;Update jobs section to use shell;0
XD-526;Make module files classpath aware Currently living at the root of the project those files don't benefit from IDE SI awareness.  Make it so that they belong to a java project which sees the correct version of the SI jars used.  Has impact on the build.gradle file;0
XD-527;Create new implementations of existing infrastructure (syslog adapters and TaskExecutors);0
XD-528;Create SI components that wrap Reactor's TCP server;0
XD-530;Create XD module for syslog-tcp-reactor Still keep existing one.;0
XD-531;Check for high CPU usage with syslog-tcp-reactor module;0
XD-533;Create shell integration tests for stream lifeycle create delete deploy streams...;0
XD-536;Create shell integration tests for job lifeycle creating job defs deploying jobs undeploying jobs deleting job defs;0
XD-539;Investigate using Redis txs and pipeline for Inbound/Outbound Q Adapter perf improvements Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre-release of SDR 1.1 M2.;0
XD-54;XD Metrics backed Message Counter A Spring Integration based @ServiceActivator that counts the number of messages using the Spring XD metrics support;0
XD-540;Broadcast Undeploy Requests Use an 'undeploy' topic to broadcast undeploy requests to all containers.    Applies to Redis and Rabbit transports not local.    Also rename {{ModuleDeploymentRequest}} to {{ModuleOperationRequest}} with an enum {{DEPLOY}} {{UNDEPLOY}}.;0
XD-542;Refactor Module to Encapsulate Group and Index Currently many methods take module group index - defining a module instance group and index can be encapsulated in {{Module}} so one arg can be passed around.;0
XD-544;"Fix In-Memory Analytics Most of the infrastructure and code cleanup has been done for In-Memory Analytics. The only remaining issue is that by including memory-analytics.xml from common.xml we're actually creating e.g. a new InMemoryCounterRepository that is different from the one present in the Admin process space.    This story involves fixing that. It may actually be done as part of XD-353 handling the ""local"" transport as a special case (context inheritance) rather than import based on xd.transport";0
XD-546;Display a Field Value Counter;0
XD-548;Display a Gauge;0
XD-549;Display a Rich Gauge;0
XD-55;SI ServiceActivator for an XD Metrics backed Field Value Counter A Spring Integration based @ServiceActivator that counts the occurrence of field names from either a tuple data structure or a POJO using the Spring XD metrics support.;0
XD-551;"Add ""trigger list"" support to Spring XD Shell";0
XD-552;Add status column for 'stream list'  shell command result {{stream list}} shell command should display status of the stream (deployed undeployed);0
XD-553;Add additional options to File source Seems like the current file source results from an initial POC. Very few things can be parameterized including the polled directory that needs to be in /tmp/xxx  To be useful in production we might want to revisit;0
XD-556;CORS support XD instances will not accept xhr requests from browsers whose page origin does not match the XD instance.      As an example the Kodiak UI is served from a different process (and url) than the XD instance.  When users open the Kodiak UI in a browser requests from the browser to the XD instance but these requests will fail due to cross-site scripting limitations.    CORS (Cross-Origin Resource Sharing) is a way to get around this.  We can configure the server to accept requests from browsers whose origins are not the XD instance.    I have this working in a local branch and will submit a pull request.      More information:  CORS Spec: http://www.w3.org/TR/cors/  SPR-9278 CORS support for SpringFramework;0
XD-559;Send failing sonar build message to spring-xd mailing list.;0
XD-561;Failure when creating/deploying stream leaves invalid stream registry/definitions in the Repository implementations. reproduce  1) Create a bad stream definition name 'bad'  Try to recreate with the same name but correct stream definitions.  The system will report that the stream already exists.;0
XD-562;Documentation for use of conversion service and creating custom processing modules that use the Tuple data structure.;0
XD-564;Upgrade sink and processor modules to use new conversion service;0
XD-572;Prepare Blog post for XD M2;0
XD-574;Replace usage of 'raw' curl with shell command to post http data in documentation e.g. http://localhost:8080:>post httpsource --target http://localhost:9090 --data 10    I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.;0
XD-575;Change http command to post data by putting 'http' as the main command option The current http command is of the form    http://localhost:8080:>post httpsource --target http://localhost:9090 --data 10      It isn't intuitive to think 'post' rather the command can be     http post --target http://localhost:9090 --data 10    which will allow us to have support for other http verbs and cleanly separate the namespace from 'hadoop' etc.    The RestShell from which this came was only concerned with http actions so the leading command classification probably seemed superfluous.;0
XD-576;Change banner of shell to say only 'xd';0
XD-580;"XD Shell needs to support multiple Hadoop distros From https://github.com/SpringSource/spring-xd/pull/161:  ""The command shell needs to also support different hadoop distribution options. Perhaps the shell just uses a relative path to the location of xd/lib/""";0
XD-581;"configuration conflict when using ""--transport"" ""local"" ""--store"" ""redis"" ""--disableJmx"" ""true"" ""--analytics"" ""redis"" results in both in-memory and redis based definitions of RichGaugeService - can't satisfy autowiring because there are two candidates.  Had to change --analytics=memory to get the application context to load.";0
XD-583;Dispatcher Has No Subscriber Error when posting a message to a stream This has been observed intermittently with Redis transport by myself and others when sending a message to a valid stream. Not sure how to recreate it yet.    11:27:10082 ERROR ThreadPoolTaskScheduler-1 redis.RedisQueueInboundChannelAdapter:126 - Error sending message  org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'org.springframework.context.support.GenericApplicationContext@3f73865d.input'.;0
XD-585;Deploying with twittersearch source throws Jackson ClassDefNotFound exception The upgrade to Jackson 2.2 included the following change to the build script  {code}  project('spring-xd-dirt') {  	description = 'Spring XD DIRT'  	configurations {  	  [runtimetestRuntime]*.exclude group: 'org.codehaus.jackson'  	}  {code}    Spring social twitter template depends on these classes;0
XD-588;"RedisAggregateCounterRepository doesn't give proper results back Both Luke's original code and my refactored PR[1] (which uses same code snippet) seem to behave strangely.    Stored values seem fine but the getCounts() method seems phony.    To test:  1) stream create foo --definition ""time|log""  2) tap create bar --definition ""tap@foo | aggregatecounter""  3) curl -H ""application/json"" http://localhost:8080/metrics/aggregate-counters/bar    this gives default bucketing (hourly) but chances are that they are empty.";0
XD-589;Create AbstractStreamIntegrationTest that will destory streams that were created during test method execution Keep track of named streams that were create and use @After to destroy them.;0
XD-59;Tuple should support storing nested tuples Nested tuple structures shoudl be supported  getTuple(int index) getTuple(String name);0
XD-593;"Add ""counter delete"" shell command Add ""counter delete"" shell command. This also requires implementation of DELETE rest end point at CountersController.";0
XD-596;Add CONTRIBUTING.md file Add CONTRIBUTING.md file use the Spring Integration file as the basis.;0
XD-598;"Gemfire cache closed when a gemfire module is undeployed Need to investigate why this is happening normally setting   {code:xml}  <gfe:client-cache close=""false""/>  {code}  prevents the (singleton) cache from closing when the application context is closed.";0
XD-599;"Gradle Import Broken by Hadoop Pseudo Projects When importing Spring-XD as a gradle project in STS while building the model we get    Root exception:  java.lang.IllegalArgumentException: Project location doesn't exist:   .../spring-xd/spring-xd-hadoop/hadoop11    ./gradlew eclipse creates these directories but the plugin needs them before running that task    The problem seems to be that these ""projects"" are not really projects.    Perhaps a quick fix would be to commit these directories (with a dummy file) ??";0
XD-6;Channel Registry;0
XD-60;Saving a metric (Counter Gauge..) with an existing name should throw an exception The difference between saving a new metric and updating an existing one needs to be defined.  Suggest that if we try to save when an existing counter is already in the database to throw exception such as DataIntegrityViolationException.;0
XD-600;Add deploy/undeploy/destroy 'all' commands for all applicable resources (streams tap job & trigger);0
XD-601;"./xd-container  --transport local throws NumberFormatException ./xd-container [OK] ./xd-container --transport redis [OK] ./xd-container --transport rabbit [OK] ./xd-container --transport local [FAIL]  wkoh-mbp:bin administrator$ ./xd-container --transport local Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.jolokia.jvmagent.spring.SpringJolokiaAgent#0': Invocation of init method failed nested exception is java.lang.NumberFormatException: For input string: ""${xd.jmx.port}""   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1488)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:626)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)   org.springframework.xd.dirt.server.ContainerMain.launch(ContainerMain.java:89)   org.springframework.xd.dirt.server.ContainerMain.main(ContainerMain.java:72) Caused by: java.lang.NumberFormatException: For input string: ""${xd.jmx.port}""   java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)   java.lang.Integer.parseInt(Integer.java:449)   java.lang.Integer.parseInt(Integer.java:499)   org.jolokia.jvmagent.JolokiaServerConfig.initConfigAndValidate(JolokiaServerConfig.java:211)   org.jolokia.jvmagent.JolokiaServerConfig.init(JolokiaServerConfig.java:84)   org.jolokia.jvmagent.JolokiaServerConfig.<init>(JolokiaServerConfig.java:68)   org.jolokia.jvmagent.spring.SpringJolokiaAgent.afterPropertiesSet(SpringJolokiaAgent.java:78)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1547)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1485) 	... 11 more";0
XD-602;Fix ChannelRegistry Cleanup During Module Undeploy;0
XD-603;"NPE on stream destroy xd:>stream create ticktock --definition ""time | log"" --deploy true  18:45:13310  WARN Spring Shell client.RestTemplate:524 - POST request for ""http://localhost:8080/streams"" resulted in 400 (Bad Request) invoking error handler  Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a stream named 'ticktock'    xd:>stream destroy ticktock  18:45:16505  WARN Spring Shell client.RestTemplate:524 - DELETE request for ""http://localhost:8080/streams/ticktock"" resulted in 500 (Internal Server Error) invoking error handler  Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.NullPointerException      Caused by: java.lang.NullPointerException    org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:143)    org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:97)";0
XD-607;"Integration tests for ""DSL Reference"" examples";0
XD-61;Create distributable artifact that contains server application and start/stop scripts The gradle application task should get us most of the way to create a distributable artifact akin to what you see when downloading tomcat/jetty etc.    Now there is a launch task    task(launch dependsOn: 'classes' type: JavaExec) {  		main = 'org.springframework.xd.dirt.stream.StreamServer'  		classpath = sourceSets.test.runtimeClasspath  	}      The same main should be referenced in the application plugin a task to create a .zip distributable is needed.    Ideally would be nice to   1. download .zip  2. unzip  3. cd spring-xd/bin  4. xdserver start      and gracefully shutdown later with     5. xdserver stop    I don't know if we can/should bundle redis I think we should bundle it.    The scripts can be for unix/linux and for windows.      Discuss a brew based install as well.;0
XD-610;Documentation for jms source http://static.springsource.org/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#sources    should have 'jms' added to the list and also the corresponding section that shows some basic usage.;0
XD-612;Create a rabbit sink module and documentation https://github.com/springsource/spring-xd/wiki/Sinks    should have 'rabbit' added to the list and also the corresponding section that shows some basic usage.;0
XD-613;Deployed streams should be restarted on container start When using Redis store stored deployed streams should be deployed on container restart.;0
XD-614;"Conversion Enhancements Content-Type during transport transit is not the same as the content-type within modules.    ""Real"" transports always use byte[] which may contain raw byte[] from a source a byte[] converted from a String (which may or may not already contain JSON) or a byte[] containing JSON converted by the transport on the outbound side.    The transport needs to convey which of these was applied on the outbound side so it can properly reconstruct the message.    Retain any content-type header that already exists in the message and restore it.    For Rabbit use normal SI/Rabbit headers to convey this information.    For Redis add the information to the byte[].";0
XD-615;"CommandResult return sucess even if hadoop shell command fails when automating tests for creating http|hdfs stream I run into an issue where CommandResult object always set success=true even if the actual hadoop shell command fail.  == valid hdfs url getShell().executeCommand(""hadoop config fs --namenode hdfs://localhost:8020"") CommandResult cr = getShell().executeCommand(""hadoop fs ls /"")  == output Found 2 items drwxr-xr-x   - administrator supergroup          0 2013-08-05 17:18 /user drwxr-xr-x   - administrator supergroup          0 2013-08-05 17:18 /xd  CommandResult [success=true result=null exception=null]  == invalid hdfs url getShell().executeCommand(""hadoop config fs --namenode hdfs://localhost:8021"") CommandResult cr = getShell().executeCommand(""hadoop fs ls /"")  == output Bad connection to FS. command aborted. exception: Call to localhost/127.0.0.1:8021 failed on connection exception: java.net.ConnectException: Connection refused CommandResult [success=true result=null exception=null]  Ideally we should set success=false if hadoop command fail and if hadoop command succeeds we should set success=true and populate result= output from hadoop command instead of result=null";0
XD-617;"Making an http post with json double quoted will hang the shell. Was following the (now updated) directions for gemfire-cq source.    xd:> stream create --name stocks --definition ""http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')""  xd:> stream create --name cqtest --definition ""gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | file""  xd:> http post --target http://localhost:9090 --data ""{""symbol"":""VMW"" ""price"":73}""    The double quotes were causing a problem with xd-singlenode    Aug 06 2013 5:38:15 PM org.jboss.netty.channel.SimpleChannelUpstreamHandler  WARNING: EXCEPTION please implement org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.exceptionCaught() for proper handling.  org.springframework.integration.transformer.MessageTransformationException: org.springframework.integration.MessageHandlingException: org.springframework.integration.transformer.MessageTransformationException: Expected a ':' after a key at 22 [character 23 line 1]    org.springframework.integration.transformer.MessageTransformingHandler.handleRequestMessage(MessageTransformingHandler.java:73)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    Using single quotes inside the json brackets worked need to investigate.";0
XD-620;Refactor test cases to move away from inheritance model of utility methods for streams counters Model the API more akin to SpringXDOperations api.;0
XD-623;catch erroneous hadoop config fs --namenode url early currently we can specify any bogus url using 'hadoop config fs --namenode' without any warning.  e.g. hadoop config fs --namenode hdfs://localhost:8888  doing a 'hadoop fs ls /' will catch the error and throw exception. Ideally we should catch the bogus url error early in the 'hadoop config fs' command. similar to 'admin config server --uri';0
XD-624;Use External Connection Factory in TCP Syslog Source WARN log emitted because the embedded connection factory does not get an application event publisher.    Will be fixed in SI M3 (INT-3107).;0
XD-627;"shell command ""stream list"" fails Run the shell command {{stream list}} and you get the following error:  {code} xd:>stream list Command failed org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Unrecognized field ""metadata"" (class org.springframework.xd.rest.client.domain.StreamDefinitionResource$Page) not marked as ignorable (3 known properties:  ""links"" ""content"" ""page""])  at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@30721965 line: 1 column: 148] (through reference chain: org.springframework.xd.rest.client.domain.Page[""metadata""]) nested exception is com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field ""metadata"" (class org.springframework.xd.rest.client.domain.StreamDefinitionResource$Page) not marked as ignorable (3 known properties:  ""links"" ""content"" ""page""])  at [Source: sun.net.www.protocol.http.HttpURLConnection$HttpInputStream@30721965 line: 1 column: 148] (through reference chain: org.springframework.xd.rest.client.domain.Page[""metadata""]) {code}  You get a similar error when running any of the following:  {code} tap list trigger list job list {code}";0
XD-629;Problem with tapping on a module using a named sink channel {code} mystream = http | transform --payload=expression.toUpperCase() > :foo tap mystream.transform | log {code} This appears to fail because we can't tap into whatever was created to represent the named channel 'foo'. There is an @Ignore test in StreamCommandTests called testTappingModulesVariationsWithSinkChannel() which checks this.  (The parser is currently resolving 'tap mystream.transform' to 'tap --channel=foo'.);0
XD-63;Document tuple data structure on XD wiki;0
XD-631;Pluralize test classes in package org.springframework.xd.shell.command The classes under test are pluralized. Therefore the test classes themselves should reflect that. E.g. rename *JobCommandTests* to *JobCommandsTests* as it tests class *JobCommands*. Please check all tests in that package for correct naming.;0
XD-632;Shell: HTTP Post - Allow posting of local file contents E.g. allow for posting of JSON data stored in local files.    * Allow users to specify the *content-type*.  * Ensure that Unicode data (UTF) posts correctly.;0
XD-635;OOTB source modules with poller should use fixed-delay pollers should standardize on fixed-delay vs fixed-rate. The value should accept a property with a standard name like 'interval';0
XD-636;x-xd-* Transport Content-Type Leakage The {{AbstractReplyProducingMessageHandler}} in the Rabbit transport exposes the internal transport content-type if none existed on the original transported message.;0
XD-639;"Update error message for usage of hadoop rm with --recursive option I had the following interaction with the shell. It does work if I do ""hadoop fs rm /xd/tweets --recursive"". Either the order shouldn't matter or the doc should be more clear on placement of the option.  xd:>hadoop fs rm /xd/tweets To remove directory please use fs rm --recursive instead xd:>hadoop fs rm --recursive /xd/tweets java.lang.IllegalArgumentException: Failed to convert '/xd/tweets' to type boolean for option 'recursive' Cannot convert /xd/tweets to type Boolean.";0
XD-641;"Problem with tapping and > (source channels) This is a follow on from XD-592. In that bug we fixed up the ability to use tap with pipe.  Tap when used as a source channel should also work (and should deploy in a more optimized fashion since source channels can be directly connected to the subsequent module creation of a pass-through tap instance isn't necessary).  This test shows the syntax that should work and the current information about how it fails:  {code} public void testTapSourceChannel() throws IOException {   FileSink sink1 = newFileSink()   FileSink sink2 = newFileSink()    stream().create(""myhttp""     ""http --port=9314 | transform --expression=payload.toUpperCase() | filter --expression=true > :foo"")    // fails with: java.lang.IllegalArgumentException: bean 'myhttp.1' is already   // registered but does not match the required type   tap().create(""wiretap1"" ""tap myhttp.transform > transform --expression=payload.replaceAll('a''.') | %s"" sink1)    // fails in TapDefinition ctor with: java.lang.IllegalArgumentException:   // streamName cannot be empty or null   tap().create(""wiretap2"" ""tap :foo > transform --expression=payload.replaceAll('a''.') | %s"" sink2)    httpPostData(""http://localhost:9314"" ""Dracarys!"") } {code}  I suspect part of the problem initially lies with the code around EnhancedStreamParser that builds the module deployment requests from the Ast parsed from the input DSL string.  Whether a source channel was originally specified with 'tap' is captured in that Ast but that knowledge doesn't appear to be getting used.";0
XD-644;Connection props in rabbit.properties ignored by xd-admin and xd-container I modified rabbit.hostname in rabbit.properties and xd-container still attempted to find Rabbit at localhost with --transport rabbit. Looks like the PPC for xd-container and xd-admin is not pointing to rabbit.properties;0
XD-647;HTTP source should emit raw payload Current implementation converts to a String.    See if we can emit raw payload (given that we also emit content-type header)    Setting to 8 points as this may have lots of implications down the line though;0
XD-648;Regression test on file source As we overwrote changes to file source by mistake let's add some regression tests esp. to the file location.    Plan on extending the utility source and sink functionality;0
XD-65;Gemfire Sink to update a gemfire cache. Update a gemfire region.;0
XD-651;End point to retrieve a list of all XD artifacts of all kinds Any kind of sophisticated artifact retrieval mechanism in XD will need to grab more than one kind of artifact at once.  For example if I want to see all taps streams triggers and jobs (ie- everything) I need to make 4 http requests.  I can imagine dashboards that need to display information on artifacts of multiple kinds.  There will also need to be a way to pass a query to return a sub-set of artifacts but that should be designed separately.;0
XD-652;"File Source Name and Duplicates options not working as documented The doc says the name option is ""the absolute path to the directory to monitor for files"" but it actually seems to be the name of a dir in /tmp/xd/input. Not sure which is the correct behavior. Also ""name"" as an option name seems a little vague. Maybe something like ""--directory""?    Also if I set --duplicates=true it actually prevents duplicates (setting prevents-duplicates to true)";0
XD-660;Rename spring-xd-shell to xd-shell;0
XD-661;Batch Jobs: Add the ability to provide JobParameters;0
XD-662;"No indication of failure in shell when deploying job referencing nonexistent trigger I see the following output on the shell if I create a job and reference a non-existent trigger. There's a big stack trace in the server log but nothing on the shell side indicating failure. A subsequent ""jobs list"" also shows the job. The same thing happens if I deploy an undeployed Job after deleting its associated Trigger.    $ job create --name helloWorldJob --definition ""myjob --trigger=nonexistenttrigger""  Successfully created and deployed job 'helloWorldJob'";0
XD-663;Use correct FS_DEFAULT_NAME_KEY constant based on Hadoop version used Keep getting the following warning:    WARN Spring Shell conf.Configuration:817 - fs.default.name is deprecated. Instead use fs.defaultFS    Should switch to use the runtime value of the FS_DEFAULT_NAME_KEY constant based on Hadoop version used.;0
XD-665;"AggregateCounter display command options with ""lastHours"" and ""lastDays"" It would be nice to have ""lastHours"" and ""lastDays"" options for aggregatecounter display command.";0
XD-666;Remove Redis Transport Headers from Tapped Stream Redis transport headers are not removed in taps.;0
XD-667;Add Accepted Media Type Support to Tap Currently the initial tap module accepted media types are not retrieved from the module when creating the tap.;0
XD-67;Submit a brew-based install for Spring XD - Host the Spring XD distributable zip somewhere that is accessible by external http request.  - Create brew formula for Spring XD install while specifying redis as dependency.   - starting up stream server upon successful brew install    couple of questions:  - should we name the brew task springxd? (name not taken yet)  - should we start the stream server as part of the brew install process?  - should we specify redis as a recommended dependency? user can pass in 'brew install springxd --without-redis' to skip redis installation. by default 'brew install springxd' will install redis as well.;0
XD-670;TAB completion for existing entities Provide Shell TAB completion when referencing an existing entity;0
XD-671;"Add support for dynamic routing It should be possible to create streams like the following which rely upon named channel support and dynamic routing capabilities:    {code}  http | somerouter  :x > xtransformer | hdfs  :y > ytransformer | hdfs  {code}    The 'somerouter' processor could return ""x"" or ""y"" which determines the downstream path for each message.    This should be implemented in such a way that any developer adding a router module would only need to deal with existing Spring Integration semantics (in this case only considering the return of ""x"" or ""y"" - whether it be SpEL or a POJO method invocation). Perhaps in the plugin that modifies a module context we could simply add a new ChannelResolver implementation (by adding that ChannelResolver as a bean and/or a BeanPostProcessor that configures that as the resolver for any router if necessary). That ChannelResolver would have a reference to the ChannelRegistry so that the router actually sends its messages to those shared channels. The shared channels themselves would have been created as long as a valid downstream flow has been defined.";0
XD-674;Add Spring Batch word-count Sample to Spring XD Samples repo;0
XD-675;Cannot chain json-field-value-filter & json-field-extractor Because StringToJsonNodeTransformer expects a String as input one cannot chain json related processors.    A simple solution would be to also accept Jackson IN and forward it directly in that case.;0
XD-678;change accepted-media-types to accpted-content-types;0
XD-679;Update settings file and reformat existing codebase. Please put in suggestions for the current .settings file.  Maybe one suggestion is to not format on save?;0
XD-68;Export of data from HDFS to a relational database Based on a single process running a Spring Batch job support the ETL of data from HDFS to a RDBMS;0
XD-682;"Modify file sink to avoid dot with empty suffix The expression currently appends ""."" + ${suffix} (where the default suffix is 'out').    If the suffix value were an empty String this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.";0
XD-683;Change jmxDisabled option to jmxEnabled and do not enable by default also the current behavior is broken it checks if the property is set but does not actually check whether it's true or false;0
XD-685;Refactor Taps to Avoid Transport Hop Taps are currently source modules.    They could be refactored to simply bridge the tapped module's tap pub/sub topic directly (with conversion) to the first tap module's input channel.    Note - ensure destroy works. Currently the tap is destroyed by the simple fact it is a module if it's no longer a module we'll need special handling to stop/remove the tap adapter.;0
XD-688;"error messages not thrown when creating gemfire sink without starting gemfire server stream create --name test1 --definition ""http --port=8827 | gemfire-server"" Created new stream 'test1'  stream create --name test2 --definition ""http --port=8828 | gemfire-json-server"" Created new stream 'test2'  even if gemfire server is not started streams are successfully created. This behavior is inconsistent with hdfs where if hdfs connection is not available creating stream using 'http | hdfs' will fail.";0
XD-691;Change JMX option to reference 'enableJmx' instead of 'disableJmx' Make the default value of enableJmx false until we have tested/documented JMX functionality;0
XD-692;http source module should copy Content-Type header to SI MessageHeaders.CONTENT_TYPE;0
XD-693;Add deploy/undeploy commands for taps;0
XD-694;Need to check the deployment requests in StreamsControllerIntegrationTest we should check the actual deployment requests were built correctly for each module in the testCreateUndeployAndDeleteOfStream test.  Currently we just use the anyListOf check.;0
XD-698;Shell integration tests should be able to be run across all transports Automate running integration tests on all supported transports;0
XD-699;Handling tap operations on a tap that has reference to a deleted stream When trying to undeploy/destroy a tap that has reference to an already deleted stream fails with the following exception: Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD116E:(pos 4): unrecognized stream reference '<stream_name at the tap defintion>'.  As expected the StreamConfigParser's lookupStream fails to find the stream name as the stream doesn't exist in the repository.   In this scenario what is a better way to handle the tap operations.  Should we undeploy the tap when the stream is destroyed? ( though I don't see an easy way to find the taps that use a specific stream).;0
XD-70;Create general structure for AsciiDoc based wiki and Spring XD guide. Adopt Asciidoc as the markdown syntax useful for generating pdf and more feature rich than standard github flavored markdown.  Loosely following the conventions of https://community.jboss.org/wiki/TheHolyGrailAsciiDocOnGitHubToDocBookTrain that have generate docbook/pdf docs from the Asciidoc wiki.    The asciidoctor project is a key element in the adoption of AsciiDoc for use as the format in github it is the rendering engine used by github for AsciiDoc.  See http://asciidoctor.org/docs/asciidoc-writers-guide/ for guidance.;0
XD-701;"Refactor Message conversion in ChannelRegistrySupport After an initial attempt which was not ready for M2 we are rethinking our strategy. One of the fundamental things we have come to realize is that its important to treat serialization and type conversion as separate concerns.  Serialization:  A core principle is the consumer should by default receive exactly what the producer sent:    -   If the producer sends a byte[] payload then no serialization is required.      -   A String payload can use simple byte conversion taking the Charset into account    -  Transporting an Object uses whatever serialization is configured (json xml avro protocol buffer java.io msgpack etc.).   The actual serialization performed for each message must be shared with the producer and consumer. I.e. the consumer needs to know which case above applies to each payload. Currently we are using the MessageHeaders.CONTENT_TYPE defining custom mime types for this (The designated header is subject to change)  Conversion:     - The consumer optionally defines one or more content-types (read MimeType) it can accept in order of preference. If no conversion succeeds we can either give them the byte[] payload or throw an exception (configurable?).  Examples:  - Consumer accepts a Java Object (application/x-java-objecttype=example.Foo).  Assume for simplicity the consumer may send a JSON String or a Foo.  On the receiving end we need to distinguish a String payload containing a JSON representation of Foo from a serialized Foo payload. If the payload is a String we need to know that its original content is application/json. We are currently using a 2nd ""original-content-type"" message header to supply this information.  So in the first case we have (conceptually) content-type: ""XD plain text""  original-content-type ""application/json"".  In the second case we have content-type: ""XD Serialized JSON"" original-content-type not used in this case since the serialized JSON includes type information (using Jackson conventions which are a bit brittle).   -If the producer type is different from the accepted type we use the conversion service and the consumer must register appropriate converters.   A twist for XD that may be generally relevant is that some optimization is possible when we know the bytes represent JSON:  -  Tuple conversion:  Since we serialize using JSON and we know how to transform JSON <->Tuple  we can convert any Object  payload or any JSON String to a Tuple.  We can avoid the two step deserialization+conversion  e.g.   1) Foo->JSON->Foo 2) Foo->Tuple.";0
XD-702;"stack overflow when trying to create a stream with the same name as a module (NOTE: even if we do want to prevent the use of module names for stream names we obviously need to avoid a StackOverflowError)    to reproduce:    start the xd-singlenode container    start the xd-shell and type the following:    {code}  xd:>stream create time --definition ""time | log""  {code}    that should produce an Internal Server Error output message    check the xd-singlenode console and find:    {code}  SEVERE: Servlet.service() for servlet [xd] in context with path [] threw exception [Handler processing failed nested exception is java.lang.StackOverflowError] with root cause  java.lang.StackOverflowError    java.lang.StringValue.from(StringValue.java:24)    java.lang.String.<init>(String.java:178)    org.springframework.xd.dirt.stream.dsl.Token.<init>(Token.java:46)    org.springframework.xd.dirt.stream.dsl.Tokenizer.lexIdentifier(Tokenizer.java:195)    org.springframework.xd.dirt.stream.dsl.Tokenizer.process(Tokenizer.java:62)    org.springframework.xd.dirt.stream.dsl.Tokenizer.<init>(Tokenizer.java:41)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:65)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)    org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)    org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)    org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)    org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)    org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)  	...ad nauseum  	  {code}";0
XD-703;JobRepository should be persistent and shared across xd-admin/xd-container The current code is creating an in-memory job repository for each batch job that is launched.  This makes it impossible to query the tables in the job repository across the cluster.  A single job repository that is backed by a file need to be shared across all jobs that are a launched.    *Implementation Suggestions*  * The XDAdmin server should create the job repository schema if not found in a HSQLDB database when it starts up  * The bean definitions should be added to the same context that the analytics are being loaded in as it is already shared across xd-admin/xd-container.  The ‘analytics’ context should be renamed to something more generic ‘shared parent context’ or something.  * There is some clean up (removal) of the code in the current JobPlugin META-INF/spring-xd/plugins/job/common.xml wouldn’t be needed anymore.  That might be all not sure.    *How to verify it works*  * A JUnit test that verifies the spring batch tables were created in the job repository when xd-admin is launched.  This would require deleting the backing db file before instantiating singlenode/xd-admin/xd-container.    * If you start the xd-container it should be able to find the necessary DataSource/JobRepository beans information to be able to contact the database.  We don’t have DI style JUnit tests so this will required getting a reference to the xd-container and it’s application context and performing ‘getBean(JobRepository.class)’;0
XD-707;Support use of separate control and message transports Control transport - Deploy/Undeploy requests  Message transport - Inter module communication    Currently complicated because starting a Job for example currently uses message transport vs control transport. Testing scenarios require local control and ability to switch to various message transports.    One option is to change the interpretation of transport command line arg depending on SingleNode Admin or Container. e.g.  SingleNode --transport rabbit (always use local for control messages)  Admin (requires --transport message transport does not apply)  Container (enforces the same transport for message and control. Local optimization done via composite module)    The other option is use a separate transport for control vs messages.   Either way need to rationalize the design with respect to control and module messages;0
XD-713;Support for @Configuration based module definitions;0
XD-715;Upgrade Lettuce and Netty Upgrade Lettuce to 2.3.3 and subsequently Netty to 3.6.6;0
XD-716;"TapCommandTests hangs when using a lazily instantiated Lettuce connection A change was made in spring-data-redis to instantiate the shared Lettuce connection lazily instead of when the context is initialized. This caused TapCommandTests to hang due to a Netty worker thread trying to initialize the Lettuce connection (Lettuce uses Netty). The change was temporarily backed out of SDR but we need to consider using a NettyExecutionHandler in NettyHttpInboundChannelAdapter or making the HTTP module's ""input"" channel an ExecutorChannel to avoid potentially long operations like from happening in an I/O thread.    Also we need to address why this failure simply hangs the shell. Shell was hung waiting on IO here:    org.springframework.http.client.SimpleClientHttpResponse.getRawStatusCode(SimpleClientHttpResponse.java:47)    org.springframework.http.client.AbstractClientHttpResponse.getStatusCode(AbstractClientHttpResponse.java:32)    org.springframework.xd.shell.command.HttpCommands$1.hasError(HttpCommands.java:93)    org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:484)    org.springframework.web.client.RestTemplate.execute(RestTemplate.java:460)    org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:335)    org.springframework.xd.shell.command.HttpCommands.postHttp(HttpCommands.java:103)    sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    java.lang.reflect.Method.invoke(Method.java:597)    org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191)    org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)   ringframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)  	- locked <7fd3c7d40> (a java.lang.Class for org.springframework.shell.core.SimpleExecutionStrategy)    org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)    org.springframework.xd.shell.AbstractShellIntegrationTest.executeCommand(AbstractShellIntegrationTest.java:99)    org.springframework.xd.shell.AbstractShellIntegrationTest.httpPostData(AbstractShellIntegrationTest.java:112)    org.springframework.xd.shell.command.TapCommandTests.testCreateAndDeployTap(TapCommandTests.java:56)    Full stack trace of server exception:     Aug 19 2013 9:59:00 AM org.jboss.netty.channel.SimpleChannelUpstreamHandler      WARNING: EXCEPTION please implement org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.exceptionCaught() for proper handling.      org.springframework.integration.MessageHandlingException: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379 nested exception is com.lambdaworks.redis.RedisException: Unable to connect        org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:76)        org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)        org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)        org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)        org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)        org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)        org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)        org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)        org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)        org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)        org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)        org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)        org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)        org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)        org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)        org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)        org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)        org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)        org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)        org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)        org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)        org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:121)        org.springframework.integration.dispatcher.BroadcastingDispatcher.dispatch(BroadcastingDispatcher.java:112)        org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)        org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:121)        org.springframework.integration.channel.AbstractMessageChannel$ChannelInterceptorList.preSend(AbstractMessageChannel.java:248)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:173)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)        org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)        org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)        org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)        org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)        org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)        org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)        org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)        org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)        org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)        org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)        org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)        org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$200(NettyHttpInboundChannelAdapter.java:59)        org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:122)        org.jboss.netty.handler.codec.http.HttpContentEncoder.messageReceived(HttpContentEncoder.java:81)        org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:148)        org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)        org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)        org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)        org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:485)        org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)        org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)        org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)        org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)        org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)        org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)        org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)        java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)        java.lang.Thread.run(Thread.java:680)      Caused by: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379 nested exception is com.lambdaworks.redis.RedisException: Unable to connect        org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:345)        org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:116)        org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:325)        org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:106)        org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)        org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)        org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:173)        org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)        org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)        org.springframework.data.redis.core.DefaultZSetOperations.add(DefaultZSetOperations.java:41)        org.springframework.data.redis.core.DefaultBoundZSetOperations.add(DefaultBoundZSetOperations.java:47)        org.springframework.xd.store.AbstractRedisRepository.trackMembership(AbstractRedisRepository.java:202)        org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:88)        org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:82)        org.springframework.xd.analytics.metrics.integration.MessageCounterHandler.process(MessageCounterHandler.java:28)        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)        java.lang.reflect.Method.invoke(Method.java:597)        org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)        org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:97)        org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:82)        org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)        org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:103)        org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)        org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)        org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)        org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)      	... 84 more      Caused by: com.lambdaworks.redis.RedisException: Unable to connect        com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)        com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)        org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:339)      	... 111 more      Caused by: java.lang.IllegalStateException: await*() in I/O thread causes a dead lock or sudden performance drop. Use addListener() instead or call await*() from a different thread.        org.jboss.netty.channel.DefaultChannelFuture.checkDeadLock(DefaultChannelFuture.java:342)        org.jboss.netty.channel.DefaultChannelFuture.await(DefaultChannelFuture.java:231)        com.lambdaworks.redis.RedisClient.connect(RedisClient.java:166)      	... 113 more";0
XD-719;Refactor the file source module to have lib/config directories Convert a simple module such as file to further test that what was done in the previous story “Use ParentLastClassLoader to create the Modules ApplicationContext.�? works as expected.    *Implementation Suggestions*    Remove from build.gradle the dependency on spring-integration-file and place that jar inside a directory    ./modules/source/file/lib     place the current file.xml inside ./modules/source/file/config    *How to verify it works.*    1. Running tests that currently use the file source e.g. in spring shell should work as before  2. When deploying a stream file | log we should be able to interrogate the channel registry and make sure it found the dependencies for the module ModuleDescriptor should have a not-null URL[] property.;0
XD-72;Provide a http source stream should be able to ingest data from http;0
XD-720;Deploy a new source module *after* XD-singlenode container has started. After the xd-singlenode process has started create a new module that has dependencies not already in the parent application context and then create a stream that uses the new module.    *Implementation Suggestions*  Develop in the test tree maybe of the xd-shell project a new module.  the lib and config should be sititng around in a directory waiting to be copied into the appropriate spot.    Could try http://www.date4j.net/..The config file  would be similar to time.xml but use the date4j class.    *How to verify it works*  In a JUnit test case copy in a new module that has new dependencies ..copy the lib and config directories into the location where the ModuleRegisty will pick it up.    Deploy a new stream date4j | file and see if there are contents in the file.;0
XD-722;Batch jobs send job and step events on channels This is the other side of launching a job by sending a message.  The Job plugin should add listeners at the job/step level so that the job/step context information can be sent out on a channel.    :myjob.notifications is a suggested channel name that would be created automatically.;0
XD-723;Change inconditionnal Thread.sleep() calls in tests to smarter incremental pauses There are a lot of Thread.sleep() calls with delays chosen in the 1-2 seconds range.  Change to a while loop with smaller pauses until a timeout is reached and give up.  This applies to verification code (e.g. verifying that a counter has expected value) as well as File setup or http being ready to accept requests etc;0
XD-726;Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink;0
XD-727;Create directory structures and move existing UI code into Spring XD repository Create a directory structure that best benefits UI development.      The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story;0
XD-729;Package up the UI code when building the distribution so that it can be shown by xd-admin The UI code will be sitting in one or more top level directories in the repository    This story will address the need to     1) copy over the UI code into a location so that it can be picked up by the embedded servlet container when the distribution zip is 'unzipped'.      After running ./xd-admin or ./xd-singlenode one should be able to hit the UI at http://localhost:8999/xd    (just an example);0
XD-737;"Trigger can send a message to a named channel Trigger can send a message to a named channel.  For example: trigger create --name mytrigger --definition ""trigger --cron='*/10 * * * * *' --message='Good Luck we are all counting on you'""  --channel foo   Where the --message contains the message that will be sent to foo job/component.";0
XD-742;REST API for Job Management Spring Batch Admin provides a complete but outdated implementation style which covers the full administrative lifecycle of batch jobs their creation stop/start and retrieving information about previous job executions and the status of currently executing job executions.  SpringXD has a different way of deploying starting and stopping jobs - by sending messages to containers that run the batch job.  However the reporting state of a job is still stored in a common job repository.  The purpose of this story is to take the first step to merging in the existing code base that focuses only on the retrieval of information from Spring Batch Admin’s Job controller.  The current ‘REST API’ style of these commands should stay as close to the original spring batch admin style as possible.  There are several reasons for this 1. It works and time to springone is short and we mgmt has expectations around deliverables that we must strive to meet. 2. It gives Andrew a working contract to start developing a UI 3. We can take on this technical debt but refactor after RC1 and before GA while and deliver end-user functionality.    Attached is the list of endpoints in spring batch admin;0
XD-743;"Ensure that when batch jobs are created they are created with the job bean definition id equal to the ‘stream name’ Unlike in spring-batch-admin in SpringXD all the jobs the /modules/jobs directory is not ‘visible’ to query when the server starts.  Jobs only become visible to XD’s ‘jobs list’ command once they have been ‘created’.      Creating a Job in XD is an opportunity to specify additional values to any property placeholders in the job bean definition.  This isn’t part of spring-batch-admin.    We will not worry about the creation of job definition in this story.  Assume that they have been created already and that the GET for /jobs works as it does now for Spring XD.     We should however make sure that there is always a replacement of the job name in the job bean definition to match the ‘--name’ specified in the command line.  That is “job create --name myjob --description “thisfunkyjob�?    will use ‘myjob to replace <job id=""${xd.stream.name}"" in the file thisfunkyjob.xml    *Implementation Suggestions*    This should hopefully just be a matter of changing job definition files to follow the naming pattern.    <job id=""${xd.stream.name}"" … />    *How to verify it works*    1. Create a JUnit integration style test that has ‘job create --name myjob --defintion “testJob�?’ and then deploy the job.  The name ‘myjob’ should appear in the job execution table";0
XD-748;Interacting with XD on Yarn 1. How we talk to the XD instance(s) on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface implementation(i.e. thrift or spring int);0
XD-749;Comm protocol for appmaster We need to be able to talk to appmaster which will control the whole xd yarn app.  1. Choose the implementation? Thrift? Spring Int? Something else?;0
XD-754;Fix Class/Package Tangle Introduced by XD-353 {{container}} and {{event}}. {{XDContainer}} references and is referenced by {{ContainerStartedEvent}} (and stopped).    https://sonar.springsource.org/drilldown/measures/7173?metric=package_cycles&rids%5B%5D=7717;0
XD-755;Reactor Environment Improvements Use a profile or similar to only include the {{Environment}} conditionally (currently in module-common.xml.  Also  Jon Brisbin one thing to keep in mind: we talked about having a properties file for XD that configured the RingBuffer et al in a non-default way  Jon Brisbin e.g. no event loop Dispatchers…a ThreadPoolDispatcher with a large thread pool size (50 threads? 100?)…and maybe even two RingBufferDispatchers: input and output  Jon Brisbin so we might want to change from strictly a default Environment bean to an EnvironmentFactoryBean with a specific configuration…thinking about it now I maybe should add a namespace element for the Environment;0
XD-758;Create Syslog -> Tuple Reactor Codec Change UDP Syslog Adapter to Emit a Tuple UDP and Legacy syslog sources emit a {{Map}} reactor emits a POJO. Make them consistent and emit {{Tuple}}s.;0
XD-759;The xd-singlenode script should have execute permissions The xd-singlenode script currently has '644' permissions unlike xd-admin and xd-container (which have '755'):     {code}  -rwxr-xr-x  1 mark  staff  5899 Aug 26 16:19 xd-admin  -rwxr-xr-x  1 mark  staff  5955 Aug 26 16:19 xd-container  -rw-r--r--  1 mark  staff  5919 Aug 26 16:19 xd-singlenode  {code};0
XD-76;Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server;0
XD-761;Make Spring XD buildable with Java 8 JavaDoc issues are causing the build to fail with Java 8;0
XD-764;Consolidate Trigger Sources into a single Source Currently we have 2 trigger sources: trigger & cron-trigger.  The preference is to have a user to just use a single trigger source.  for example: * trigger > :myjob * trigger --cron='...' >:myjob * trigger --fixedDelay='...' > :myjob  One option to handle this is to use spel to reference a bean and then have different trigger beans defined. i.e. trigger='cronTriggerBean'.  Each trigger bean would setup the channel with the correct poller.;0
XD-766;Parser needs to handle a  ':' embedded in a name. Also drop the enhanced portion of the EnhancedStreamParser.;0
XD-767;Add Email Source;0
XD-780;Avoid use of module name twice in location when using a custom modules See https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724;0
XD-783;Support higher level structure for complex module registry See discussion at https://github.com/SpringSource/spring-xd/pull/240#discussion_r6045724;0
XD-784;Build needs to override $XD_* environment variables export XD_HOME=foo  gradle clean test     build fails. Need to detected environment variables and override for the build;0
XD-787;Add a JobExecution DTO Object related to XD-779.   * We need the ability to provide JSON serializable JobExecution information. * Change from using JavaSerialization back to returning objects;0
XD-788;Add Integration Tests to run JobCommands Tests against all transports similar to ChannelRegistry:    - AbstractChannelRegistryTests that has the real tests  - subclasses for each impl provide the registry to be tested    Thus one test can run against multiple transports.;0
XD-79;End user guide for data streams Put on the guide as a section in an 'streams' wiki page.    End user focused no need to mention spring underpinning impl details.;0
XD-791;Document mail related sources & sinks;0
XD-794;Add integration tests for SpEL and Groovy based routing;0
XD-796;"Create separate commands for ""--all"" shell commands Commands like ""stream deploy"" have changed over time to allow passing a ""--all"" option.    So it's either {{stream deploy foo}} or {{stream deploy --all}}. This has a number of drawbacks given that these are the only 2 alternatives:  - Implementation code is cumbersome  - None of the options can be marked mandatory yet one of them is required. This has to be checked in the command code itself  - TAB completion is less powerful as the shell doesn't know if we want the first or the second form.      Consider splitting those commands into two distinct commands one as before and one literally named {{stream deploy all}}.";0
XD-797;Package Tangle Introduced by XD-790 https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717;0
XD-799;"Change rabbitmq sink to use routing-key-expression instead of routing-key The current rabbitmq sink uses the attribute routing-key which defaults to the name of the stream.  This should be change to use the attribute routing-key-expression so that the routing-key can be determined using SpEL.  This will enable a dynamic evaluation of the routing-key based on message payload/header.    *Implementation Suggestions*    This hopefully should be changing the XML description of the sink to 		    routing-key-expression=""${routingKey:'${xd.stream.name}'}    This way the ${xd.stream.name} is surrounded by a single quote to indicate a string literal to SpEL in the default case.      *How to verify it works.*    One of the simple uses of this is to create a routing key based on payload.  In a distributed word-count example the hashcode of a word would be sent to a certain number of processing modules that would perform the count. The idea is that the same word is sent to the same node over and over again in particular if in-memory counters or state is computed - using centralized redis counters this wouldn't be necessary in the case of only counter state.    The stream     http | rabbit --routingKey=""'word-' + payload.hashCode() % 3""    is an example of a stream that can be used to verify that messages published to a direct exchange will have routing keys of the value word-0 word-1 and word-2.  Binding a queue to each of these routing keys one can observe the contents of messages in the queue to make sure that words are being routed to the appropriate queue e.g. publishing ""hello"" as the payload of an http request should always appear in the same queue.  The rabbitmq admin console can be used for this purpose.";0
XD-8;Syslog Ingestion Have a syslog.xml config file that can be added to a module and registered with a module registry.;0
XD-800;Job channels need to denote a namespace Job channels need to have a namespace.    i.e. job-somejobname.  Where the - is the delimiter for the namespace.    The preference is to use the : instead of the -.  But XD-766 needs to be completed in order to support this.;0
XD-802;Document splitter & aggregator processors;0
XD-804;"Add Named Channel API We need an abstraction in place to retrieve messages from a ""named channel"" programmatically.    Right now there is no implementation agnostic way of doing this (such as receiveMessage() queueSize()).    This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to ""temp-files"" and non-essential sinks or sources etc. - e.g.     {code}  :routeit > router --expression=payload.contains('a')?':foo':':bar'  {code}";0
XD-807;"Shell: Standardize counter name parameter The parameters are not optimal for the counter name between ""Aggregate Counter"" ""Field Value Counter""  --counterName versus --name";0
XD-808;Update to spring-data-hadoop 1.0.1.RELEASE This might mean we should adjust our hadoopDistro options to the ones supported in the new release - hadoop12 (default) cdh4 hdp13 phd1 and hadoop21;0
XD-809;Shell integration with XD on Yarn We should provide a better shell integration when XD is run on Yarn.  1. yarn kill --id TAB completion 2. yarn submit more options like app name 3. yarn list filter by app states etc 4. admin config server TAB completion for running xd apps on yarn;0
XD-81;"Documentation for ""syslog | file"" processing Put on the guide as a section in an 'input-stream' wiki page.";0
XD-810;"Deleting a stream with reference to named channel disconnects channel from all streams The following sequence results in ""Dispatcher has no subscribers"" error  (stack trace below) because deleting stream2 disconnects stream1 from the foo channel. Current work on XD-685 has infrastructure for disconnecting just the channels involved in a stream so should make it easier to fix this issue once merged.     stream create stream1 --definition ""time > :foo""  stream create stream2 --definition ""http > :foo""  stream create stream3 --definition "":foo > file""  stream destroy stream2  // expect file sink to still get time but instead blows up b/c  // deleteOutbound(""foo"") killed links b/w foo and both local output channels    Server stack trace:  10:47:11921 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)    java.util.concurrent.FutureTask.run(FutureTask.java:138)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 24 more    10:47:12924 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)    java.util.concurrent.FutureTask.run(FutureTask.java:138)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 24 more    10:47:13926 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)    java.util.concurrent.FutureTask.run(FutureTask.java:138)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 24 more    10:47:14928 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)    java.util.concurrent.FutureTask.run(FutureTask.java:138)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)    java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    java.lang.Thread.run(Thread.java:680)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 24 more    10:47:15930 ERROR task-scheduler-1 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)";0
XD-816;Support for composed streams Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time rather than deploy time.  By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.;0
XD-820;Jobs and taps should not require a leading : since they have name spaces.;0
XD-821;Change url to access UI from browser Currently the url for accessing the XD UI is {{http://localhost:8080/admin-ui/index.html}}.  This feels messy and dated.  We should be able to access the ui without explicitly including the index.html like this:  {code} http://localhost:8080/admin-ui {code};0
XD-823;add discardDeletes property to twitterstream source If true(default): filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.;0
XD-827;provide a property on twittersearch to enable the object-to-json transformer Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly (e.g. zero arg constructor). The twittersearch module should have a parameter --json true/false (default true) to control the output type.;0
XD-829;Upgrade hsqldb version on XD batch admin to the latest We also would like to upgrade the hsqldb version on spring batch admin so that both are compatible.;0
XD-83;"Documentation for ""tail | hdfs"" processing Put on the guide as a section in an 'input-stream' wiki page.";0
XD-830;Expose Job parameters for JobExecutions Currently the way that we are accessing JobExecutions from batch admin the JobParameters are not being filled in.  We are using a {{org.springframework.batch.admin.service.JdbcSearchableJobExecutionDao}} to grab the job executions from the database. The database queries that it uses does not include the JobParameters (which is stored in a different table).  I think that this will require a change to batch admin in order to properly expose the parameters.;0
XD-831;Update docs to cover Module config and lib directory structure;0
XD-832;Update docs for new Tap syntax Now that taps are just channels we need to update the docs.    The preceding colon is no longer needed (and will be removed altogether) so all examples should be like this:    {code}  tap:foo > bar  {code};0
XD-834;Handle XD admin server shutdown cleanly There are couple of issues here:  1) The admin server destroy() - close event's onApplicationEvent(ContextClosedEvent) listener has stop() to stop the admin server's tomcat instance. The stop() also calls the applicationContext's destroy() which loops again to stop.  2) With HSQLServer or any batch db server(in future) the admin server stop() also needs to handle the batch db server shutdown.;0
XD-837;Tipsy tooltip hovers are not responsive after jobs list is refreshed from server In the XD UI the list of jobs is refreshed from the server every 5 seconds.  There are also tooltips that are activated when hovering over a job execution. These tooltips are no longer responsive (ie- they remain on the page and don't disappear) after the list of jobs is refreshed.;0
XD-838;Refactor out Trigger docs from the Batch Job chapter;0
XD-842;"Add back classifier = 'dist' to distZip build target Add back ""classifier = 'dist'"" to distZip build target - it was was accidentally removed.";0
XD-843;Initial XD on CloudFoundry support First take on this involves - being able to deploy the two separate applications: xd-admin & xd-container - being able to CF-service provided redis & rabbit for internal needs of XD - to some extent make modules smart and CF aware (e.g. http source uses correct port);0
XD-844;"Enable Spring Boot Loader support As part of running in Cloud Foundry one quick workaround for the lack of ""classpath"" support would be to use the Spring Boot Loader special ClassLoader and jar-inside-a-jar support: https://github.com/spring-projects/spring-boot/tree/master/spring-boot-tools/spring-boot-loader";0
XD-845;Remove support for the leading : on items that have a declared namespace When using jobs taps we no longer need to have the leading :.  i.e. :tap:foo.  We should only support tap:foo.;0
XD-846;Remove deprecated tap syntax from the parser. Tap '@' and using numbers instead of module names.;0
XD-847;Revise the available hadoopDistro options We should adjust our --hadoopDistro options to the ones supported in the new spring-data-hadoop 1.0.1.RELEASE - hadoop12 (default) cdh4 hdp13 phd1 hadoop20  This includes updating the wiki pages;0
XD-850;JAR version mismatches Looks like there are some version mismatch issues with the build/packaging of the XD components. Looking in xd/lib I see the following which looks suspicious:  mqtt-client-0.2.1.jar mqtt-client-1.0.jar  jackson-core-asl-1.9.13.jar jackson-mapper-asl-1.9.12.jar  spring-integration-core-3.0.0.M3.jar spring-integration-http-2.2.5.RELEASE.jar  spring-data-commons-1.6.0.M1.jar spring-data-commons-core-1.4.0.RELEASE.jar;0
XD-852;DSL needs to have wildcard support for taps Wildcard support for associating inbound and outbound channels with modules.   The wild card will be represented by an asterisk '*'. Example:  myEmailSource > tap:job:*	send message to all jobs myEmailSource > tap:*		send message to all stream/job taps myEmailSource > :*foo*		send message to all channels that contain the channels that contains the word 'foo' tap:*bar > myEmailSource;0
XD-853;Add definition of serialVersionUID to Twitter classes Add serialVersionUID to the objects in package org.springframework.integration.x.twitter:  * XDEntities * XDUrlEntity * XDHashTagEntity * XDMentionEntity * XDMediaEntity * XDTickerSymbolEntity * XDTweet  The absence creates warnings during compile time.;0
XD-854;Update doc about modules and spring The doc at http://docs.spring.io/spring-xd/docs/1.0.0.M3/reference/html/#_modules_and_spring refers to an old version of the counter sink when it was still hardwired to use redis.  The text next to it that explains placeholders is out of date (with respect to the redis placeholders);0
XD-855;Change metrics assertions in integration tests to use smart Thread.sleep Similar to what has been done for e.g. FileSink refactor metrics related sinks to use smart Thread.sleep() timings;0
XD-857;"Refactor FileModuleRegistry as ""ResourceModuleRegistry"" Apart from sanity checks there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same and would allow loading modules from the classpath in constrained environments or other file systems/locations. (HDFS /HTTP)";0
XD-861;Type Conversion across modules This story will need to be broken down further.    The current code mixes together the type conversion that happens within a single JVM (for data that is passed on a local transport between modules) and serialization/deserialization between JVMs.  This should be separated.    There was a suggestion that we could perhaps use typed data channels in SI as a means implement the type conversion between modules.  The media-type conversion support in Spring 4 is another part of this solution.;0
XD-864;Move BatchJobExecutionsByJobName to BatchJobsController from BatchJobExecutionsController We need to move the BatchJobExecutionsByJobName method to BatchJobsController as that seems appropriate;0
XD-865;Add a test suite to the admin-ui The admin-ui currently has no unit tests.  Need to add a test suite and hook it up to the build so that tests are run on every build.;0
XD-866;Remove remaining Thread.sleeps from the job tests Get rid of all the thread.sleeps and code that supported them.;0
XD-868;"Create microbenchmark performance test of reactor syslog adapter vs standard syslog adapter We need to verify that we are seeing improved throughput when using the reactor based syslog adapter.      A suggestion on a basic stream to perform a microbenchmark this would be using in-memory counters singlenode with the stream definition ""syslog | counter"".    Based on the results of this microbenchmark other stories may need to be created.";0
XD-871;"No errors in Shell when creating stream with HTTP Source + already used port 2 issues exist:    1)     Current this does not create an error in the shell    {code}  stream create --name s1 --definition ""http | log""  stream create --name s2 --definition ""http | log""  {code}    On the server-side I see:    {code}  Caused by: java.net.BindException: Address already in use    sun.nio.ch.Net.bind0(Native Method)    sun.nio.ch.Net.bind(Net.java:344)    sun.nio.ch.Net.bind(Net.java:336)    sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:199)    sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)    org.jboss.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)    org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:366)    org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:290)    org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)  	... 3 more  {code}    2)  The Stream should not be saved to the StreamDefinitionRepo in case of an error.";0
XD-878;Remove code in StreamPlugin to extract target output channel from proxy The SI JMX MBeanExporter proxies the output channel created in a module context when JMX is enabled. We have to unwrap the proxy in StreamPlugin in order to add the tap. XD-877 temporarily introduced this code but a more elegant solution is called for. Perhaps this will involve SI making addInterceptor an interface method.;0
XD-880;Update Java Version to 7;0
XD-881;Introduce wire.js into the XD admin UI We should consider moving to wire.js to encourage dependency injection in the UI Javascript code.  See here: https://github.com/cujojs/wire/blob/master/docs/get.md;0
XD-882;Disable the JMX setting in SingleNodeMainIntegrationTests.testConfiguration Set the enableJmx to false because contexts are not getting destroyed properly and in some cases prevents testSystemPropertiesOverridesDefault from running successfully.;0
XD-884;Do not initialize spring batch schema on each test run If the spring batch database has already been initialized do not re-initialize for each test run.;0
XD-885;Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically    * Each major listener category should send notifications to own channel (StepExecution Chunk Item etc.)  * Add attribute to disallow automatic adding of listeners;0
XD-886;Fix package tangle between org.springframework.xd.dirt.plugins.job and org.springframework.xd.dirt.job;0
XD-888;Remove org. in hsqldb dependency;0
XD-89;Documentation for gauge taps Put on the guide as a section in an 'input-stream' wiki page.;0
XD-890;Run JavaScript tests (Jasmine) as part of the build process We probably need to look into some options to run our JavaScript tests (Jasmine) as part of the build process - some possibilities:    * Jasmine Gradle Plugin https://github.com/dzhaughnroth/jasmine-gradle-plugin  * Saga - http://timurstrekalov.github.io/saga/    Looks like Maven has slightly better support: http://searls.github.io/jasmine-maven-plugin/index.html    See also: XD-865;0
XD-892;"Spring Batch Behavior change from M2 to M3 In M3 the batch job behavior has changed. In M2 it was much easier to create an invoke a batch job. In M3 a trigger is required. Figuring that change out isn't a big deal but the behavior of this batch job in M3 throws a stack trace yet it executes.   In M2 this same batch job runs fine with no stack trace.   Logs are attached. I can't see a difference in the container log property files from M2 to M3. Turning the log settings down will suppress the traces but I was not expecting the traces since they did not show up in M2.  Stream Definitions:  job create --name pdfLoadBatchJob --definition ""batch-pdfload --inputPath='LOCAL_PDF_PATH' --hdfsPath='REMOTE_HDFS_PATH'""   stream create --name pdfloadtrigger --definition ""trigger > job:pdfLoadBatchJob""";0
XD-894;"Create an easier short-cut for launching adhoc Batch Jobs Currently for adhoc launching of Batch jobs you have to use:  {code} stream create --name myTriggerStream --definition ""trigger > job:helloSpringXD"" {code}  For renewed triggering of the job you have to undeploy and then redeploy the job. It would be nice if there was possibly a slightly simpler way of doing this.  Just FYI - As a different approach you can also use the HTTP source:  {source} job create --name myjob --definition ""myjob"" stream create --name myjobhttp --definition ""http > job:http"" http post --data ""{}"" {source}";0
XD-896;Add --inputType and --outputType module parameters The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type e.g. application/json or a java class name.;0
XD-899;xd-container should start even if xd-admin is not running currently xd-container will not start due to a DB connection failure if the xd-admin is not already running    In fact if someone is not using Batch jobs at all with XD they should not even need a DB connection for either xd-admin or xd-container to run    so... consider using LazyConnectionDataSourceProxy so a connection failure would only occur when the DataSource is actually invoked to retrieve a connection;0
XD-900;Move SpEL PropertyAccessors to Module Parent Context When INT-3133 is resolved SpEL {{PropertyAccessor}} s are inherited from parent contexts.    Instead of adding the {{JsonPropertyAccessor}} to each module's context add it to the parent instead.;0
XD-901;Wrong Jetty Util on classpath for WebHdfs We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jar    Need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro;0
XD-902;Properly close Redis/Rabbit connection factories in tests Tests that leverage [Redis|Rabbit]AvailableRule often create another connection factory in the test body but fail to close it.  Tests should properly close the resource. As an added benefit the rule itself can expose the resource that it created for deciding whether to skip the test or not;0
XD-903;Split xd-dirt in 3 (or 5) The xd-dirt project should be split in at least 3 parts:  - Classes and resources pertaining to the admin-server  - Container server  - Shared classes  Additionally we may consider splitting the first two in half as well having a separate project for CLI handling (and hence introduce 2 other projects for YARN etc);0
XD-907;Add aggregate counter year resolution query support;0
XD-909;Support additional aggregate counter query options;0
XD-91;Documentation for field value taps Put on the guide as a section in an 'input-stream' wiki page.;0
XD-913;The XD build breaks with Gradle 1.8 The XD build breaks with Gradle 1.8 due to some changes in dependency resolution.;0
XD-914;Add documentation for #jsonPath functionality with SpEL based processors See issue https://jira.springsource.org/browse/XD-862    The docs should be updated to include examples that show how to use the standard 'SpEL' based splitter transformer filters with #jsonPath expressions.;0
XD-915;Convert modules to be CP-aware Once XD-887 is merged gradually convert more modules.    Recipe:  1) Move the <module>.xml file to <module>/config/<module>.xml  2) Declare a :module.<type>.<module> gradle project  3) Move dependencies from dirt project to newly created module project  4) gradle build picks it up.    gradle clean build + manual test  Also have a look at gradle cleanEclipse eclipse;0
XD-917;Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example:   {noformat:nopanel=true} source   --outputType=my.Foo  | sink --inputType=some.other.Bar   is likely invalid since XD doesn't know how to convert Foo->Bar.  {noformat};0
XD-921;"Add more ""hands on"" example to MQTT doco Not everyone may be familiar with MQTT or esp. with MQTT inside Rabbit";0
XD-922;Handle SingleNodeServer's stop()  method cleanly SingleNode server needs to stop cleanly with stopping both the admin server & container server.     Also all the tests that require SingleNode main server needs to handle the server shutdown appropriately.;0
XD-924;Split integration.x in dedicated XD projects where appropriate Similar to what is done for e.g. hadoop reactor and http some of the classes in the .x package (namely gemfire splunk twitter) should go in dedicated (albeit small) projects. This would enable further modularization (see XD-915);0
XD-926;Update Core Spring Dependency to 4.0.0.M3;0
XD-93;Normalize and refactor component packaging decomposition Normalize and refactor as needed functionality currently included in   - spring-integration-core (LocalChannelRegistry)  - spring-integration-module (Module types upon which Flow are built)  - xd-module (Depend Module types common to DIRT and Spring Integration)  - spring-integration-flow (Flow specific types namespace support etc);0
XD-933;Remove work around Spring HATEOAS#89 See https://github.com/spring-projects/spring-hateoas/issues/89    Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg https://github.com/spring-projects/spring-xd/blob/4919ea2498a13ef47aaa9437937308fb26a7a24f/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/XDController.java#L219;0
XD-935;Implement Kryo serialization for Tuple Currently TupleCodec uses JSON for serialization/deserialization. It should use Kryo. This will require some customization and potentially changes to Tuple to address the Tuple's conversionService field.;0
XD-936;"Find runtime modules by type and/or name We need a way to find the runtime module info by module type(""source"" ""sink"" ""processor"" ""job"").";0
XD-938;List runtime modules by wrong containerId should throw exception With PR#340 listing of runtime modules with a non-existent containerId will display empty table. Instead we can throw exception saying Container doesn't exist.;0
XD-94;"Document The ability to use flows in streams Test and document e.g. ""http | flow1 | flow2 | file""";0
XD-940;Splunk Pulls in an Old SI Jar into STS;0
XD-945;Spike for writing to HDFS See Epic https://jira.springsource.org/browse/XD-234;0
XD-947;Spike for Deployment SPI SPI for deployment on to YARN + Local 'dirt' cluster.;0
XD-95;"The ability to override default module path for the plugin or an individual flow Currently modules are assumed to be in classpath:/META-INF/spring/integration/module/${flow}.xml. To reuse modules defined with DIRT  may require more flexibility.  e.g.   <int-flow:flow root-path=""file:///dirt/module""/>";0
XD-952;Spring-XD shell can't run commands with kerberized CDH 4.3.0 Basically when I launch the spring-xd shell I can't interact with the namenode I receive security violations despite the fact that I try and set the proper configs. Authentication/Authorization (true/kerberos)  details of this issue can be found here:  http://stackoverflow.com/questions/19258321/the-spring-xd-xd-shell-cant-run-the-hadoop-fs-ls-command-the-command-returns;0
XD-956;Refactor DSL parser according to latest syntax proposals We have recently revised the syntax for stream definitions this issue covers that refactoring.;0
XD-957;Update SI Dependency to 4.0.0.BUILD-SNAPSHOT;0
XD-958;Build failure on Ubuntu Build fails:  gradle clean build  ...  :spring-xd-dirt:test  org.springframework.xd.dirt.stream.FileSourceModuleTests > classMethod FAILED     java.io.IOException at FileSourceModuleTests.java:53  org.springframework.xd.dirt.stream.FileSourceModuleTests > classMethod FAILED     java.lang.IllegalArgumentException at FileSourceModuleTests.java:130  328 tests completed 2 failed 11 skipped :spring-xd-dirt:test FAILED  FAILURE: Build failed with an exception.   Looks like it is trying to create a directory under the local filesystem /  java.io.IOException: Unable to create directory /tmpfilesourcetests   org.apache.commons.io.FileUtils.forceMkdir(FileUtils.java:2024)   org.springframework.xd.dirt.stream.FileSourceModuleTests.createTempDir(FileSourceModuleTests.java:53)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.junit.runners.ParentRunner.run(ParentRunner.java:309)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:80)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:47)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:49)   sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:103)   sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:66)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:724);0
XD-96;The ability to import beans referenced in the main context into a module This should be a core feature of any Spring based module. The plugin should be able to import explicitly referenced beans. This minimizes potential side effects of making the module a child context and is simpler than declaring a shared context (parent) of the application and the module. Provide namespace support for flow:;0
XD-963;Features and bug fixes for named channels;0
XD-968;Create google doc with instructions on managing EC2 Instances * Logging into your XD Account For Example: https://946513944028.signin.aws.amazon.com/console * Discuss how to terminate running instances. ** Users can terminate all instances using the UI on the EC2 admin page * Usage monitoring via CloudWatch * Investigate what metadata in each instance is required so that cloudwatch can track;0
XD-970;Install XD admin instance on EC2 *Update the Deployer class to add the following methods * ** RunningInstance  deployAdminServer  * The install script steps: ** Using XD-977 install distribution ** Setup XD_HOME variable ** start up redis and rabbit using ports as specified in xd-ec2.properties on admin server ** Create configurator directory ** Copy the configurator to containers ** Use port watch to make sure they started ** start admin server ** use port watch to make sure the admin started on 9393 ** Report if admin server started.  If it didn't start abort install. ** Report public DNS name of admin-server    * Integration Testing ** Verify XD admin has been started *** Create a basic stream (trigger>log)and make sure we get a success code from xd admin was received. *** Query the redis to see if the stream was created.;0
XD-975;Users need the ability to provision an XD cluster on EC2 via command line tool. we need the ability to run an XD cluster to get a handle on general issues and missing features based on running the system in a 'true' clustered environment.  We don’t need to make this an end-user facing feature in the short term e.g. set a few keys in the shell and then install via a shell command.;0
XD-979;Batch Wordcount Sample to use File Source;0
XD-982;OOTB batch jobs for common cases;0
XD-987;Create OOTB batch job for export and processing multiple files from HDFS to MongoDB The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no-op groovy script. The ItemWriter will write the data to a MongoDB collection ** A TupleToDBObject converter will need to be developed.  *the sample job should be documented*;0
XD-989;Create OOTB batch job that uses the Hadoop Shell to copy multiple files from HDFS to a local directory This is the inverse of XD-986 and will require creating a custom tasklet but with the input/output reversd.;0
XD-99;Sonar build is failing https://build.springsource.org/browse/XD-SONAR-34    Caused by: java.lang.ClassNotFoundException: org.sonar.api.Plugin          at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)          at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:244)          at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:230)          ... 94 more;0
XD-994;The HDFS Sink should support writing POJOs to HDFS using Parquet Writing POJOs using Kite SDK;0
XD-997;The HDFS Sink should support writing POJOs to HDFS using Avro/Kite SDK with support for partitioning Support for partitioning on a field e.g. date.;0
XD-998;Add documentation for gemfire cache-listener source Need some sample usage docs for     https://github.com/spring-projects/spring-xd/tree/master/modules/source/gemfire;0
XD-999;Return the step execution information in the current job execution controller Related to https://jira.springsource.org/browse/BATCH-2109    DistributedJobService#listJobExecutionsForJob overrides   SimpleJobService#listJobExecutionsForJob    and does not include the *StepExecution*s. This is due to serializion issues with Jackson.     In order to fix this we need to add a Jackson MixIn.;0
