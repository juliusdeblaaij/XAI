testing_labels = [0, 0, 0, 3, 5, 0, 0, 4, 0, 0, 0, 1, 0, 3, 4, 4, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0,
                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 5, 0, 0, 0, 0,
                   0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,
                   1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,
                   0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 5, 4, 0, 0, 0, 0, 0, 0,
                   0, 0, 0, 0, 5, 0, 0]

testing_cases = [
    'refactor modulefactory to remove direct spark dependency on xd dirt currently the modulefactory needs to know about `sparkstreamingdrivermodule` to create the spark streaming module. it is for this reason the spring-xd-module has direct dependency on spark streaming. we need to refactor this code so that there is no direct dependency on spark streaming for spring-xd-module and subsequently spring-xd-dirt.',
    'fail fast on kryo registration conflicts currently kryo class registration is hard coded in spring-xd-codec. users may register their own classes using an extension mechanism but it is possible to conflict with internal xd class registration e.g. tuple. exposing this using the same extension mechanism will make it more transparent.',
    'spring_rabbitmq_addresses environment variable is ignored when trying to configure xd to use a rabbitmq instance other than the default localhost:5672 a user is supposedto updated the "spring_rabbitmq_addresses" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file. in this case xd is ignoring this environment variable. h3. steps to reproduce # set the transport by using "export xd_transport=rabbit" # set the spring_rabbitmq_addresses by "export spring_rabbitmq_addresses=foo:5672" # startup a admin container on your local machine # deploy ticktock #* this should fail #* start up a local rabbitmq #* deploy a new ticktock and stream will deploy.',
    "as a cf user i'd like to have the ability to override the hdfs location so that i can change where the custom module _uber-jar_ can be stored and retrieved.",
    'as a user i should be able to leverage native _elasticsearch_ sink so that i can aggregate search and analyze data insights in real-time.',
    'update documentation section "running in distributed mode" to show use of rabbitmq in addition to redis the documentation in the running in distributed mode chapter should discuss that the distributed runtime can use essentially any middleware to communicate between nodes. this functionality is provided by the core channelregistry abstraction. a new intro paragraph shoul convey that it isn\'t a \'redis\' only or \'rabbitmq\' only system. there should be "installing rabbitmq" and "starting rabbitmq" sections to match those for redis. "starting spring xd in distributed mode" should cover how to configure the system to select to use redis or rabbit.',
    'filepollhdfs sporadically fails need to add a retry to the mkdir command in the case that it fails.',
    "as a user i'd like to mass ingest data from databases (and others) into hdfs/hawq/gpdb so that i don't have to write custom code and as well as be able to ingest in an efficient way.",
    'job creation fails saying it exists (there isn\'t any job with that jobname) running spring-xd in singlenode using pivotal hd 2.1 as the hadoop distribution. xd-singlenode --hadoopdistro phd21 i was testing jdbchdfs job definitions. i am seeing this error that the job exists when in reality there is no job with that jobname. xd:>job create testemployeejobagain1 --definition "jdbchdfs --sql=\'select employee_id employee_name employer from employee\' --url=jdbc:oracle:thin:@//localhost:1521/orcl --driverclassname=oracle.jdbc.oracledriver --username=springxd --password=xdpwd --testonborrow=false --directory=/usr/swatest1" command failed org.springframework.xd.rest.client.impl.springxdexception: batch job with the name testemployeejobagain1 already exists xd:>job list job name job definition status -------- -------------- ------',
    "validate processing modules declare the required channels validate that modules have required channels declared according to their type. currently the stream deployer accepts processors with no input but the stream doesn't complete. we should fail earlier and more loudly.",
    'document jdbc module',
    "as a s-c-s developer i'd like to create auto configuration for {{singlenode}} binder configuration/properties so i can automatically configure the spring application based on the dependencies.",
    'update diagrams that show control transport the first 2 images in the documentation section linked below should no longer show redis rabbit or local for the communication between admins and containers. rather we need to show zookeeper. https://github.com/spring-projects/spring-xd/wiki/architecture',
    "as a s-c-d developer i'd like to add support to deploy yarn app into hdfs automatically so i can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.",
    "as a developer i'd like to upgrade to reactor 2.0 rc1 release so that we can synchronize with stable dependencies.",
    "as a user i'd like to have the option to version the custom modules so i can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.",
    'assess xd fails to connect to remote redis instance deployment: admin/container redis as data transport sha: 45e1beb [description] in the case that the redis is not running locally xd cannot connect to the redis instance even though the environment variable spring_redis_host has been set. [steps to reproduce] * shutdown local instance of redis. * for both the admin and container execute the command prior to running the instances: ** export spring_redis_host=yourredishost * start admin and container instances * deploy a simple stream ** you will see the following error: 13:56:59647 error task-scheduler-9 handler.logginghandler:145 - org.springframework.messaging.messagehandlingexception: error occurred in message handler [org.springframework.integration.redis.outbound.redisqueueoutboundchanneladapter@6a1f1d12] org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:84) org.springframework.xd.dirt.integration.redis.redismessagebus$sendinghandler.handlemessageinternal(redismessagebus.java:235) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:255) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:223) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:606) org.springframework.aop.support.aoputils.invokejoinpointusingreflection(aoputils.java:317) org.springframework.aop.framework.reflectivemethodinvocation.invokejoinpoint(reflectivemethodinvocation.java:190) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:157) org.springframework.integration.monitor.directchannelmetrics.monitorsend(directchannelmetrics.java:113) org.springframework.integration.monitor.directchannelmetrics.doinvoke(directchannelmetrics.java:97) org.springframework.integration.monitor.directchannelmetrics.invoke(directchannelmetrics.java:91) org.springframework.aop.framework.reflectivemethodinvocation.proceed(reflectivemethodinvocation.java:179) org.springframework.aop.framework.jdkdynamicaopproxy.invoke(jdkdynamicaopproxy.java:207) com.sun.proxy.$proxy57.send(unknown source) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:114) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:44) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:93) org.springframework.integration.endpoint.sourcepollingchanneladapter.handlemessage(sourcepollingchanneladapter.java:110) org.springframework.integration.endpoint.abstractpollingendpoint.dopoll(abstractpollingendpoint.java:205) org.springframework.integration.endpoint.abstractpollingendpoint.access$000(abstractpollingendpoint.java:55) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:149) org.springframework.integration.endpoint.abstractpollingendpoint$1.call(abstractpollingendpoint.java:146) org.springframework.integration.endpoint.abstractpollingendpoint$poller$1.run(abstractpollingendpoint.java:284) org.springframework.integration.util.errorhandlingtaskexecutor$1.run(errorhandlingtaskexecutor.java:52) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.integration.util.errorhandlingtaskexecutor.execute(errorhandlingtaskexecutor.java:49) org.springframework.integration.endpoint.abstractpollingendpoint$poller.run(abstractpollingendpoint.java:278) org.springframework.scheduling.support.delegatingerrorhandlingrunnable.run(delegatingerrorhandlingrunnable.java:54) org.springframework.scheduling.concurrent.reschedulingrunnable.run(reschedulingrunnable.java:81) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$201(scheduledthreadpoolexecutor.java:178) java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:292) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) caused by: org.springframework.data.redis.redisconnectionfailureexception: cannot get jedis connection nested exception is redis.clients.jedis.exceptions.jedisconnectionexception: could not get a resource from the pool org.springframework.data.redis.connection.jedis.jedisconnectionfactory.fetchjedisconnector(jedisconnectionfactory.java:97) org.springframework.data.redis.connection.jedis.jedisconnectionfactory.getconnection(jedisconnectionfactory.java:143) org.springframework.data.redis.connection.jedis.jedisconnectionfactory.getconnection(jedisconnectionfactory.java:41) org.springframework.data.redis.core.redisconnectionutils.dogetconnection(redisconnectionutils.java:85) org.springframework.data.redis.core.redisconnectionutils.getconnection(redisconnectionutils.java:55) org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:169) org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:149) org.springframework.data.redis.core.abstractoperations.execute(abstractoperations.java:84) org.springframework.data.redis.core.defaultlistoperations.leftpush(defaultlistoperations.java:68) org.springframework.data.redis.core.defaultboundlistoperations.leftpush(defaultboundlistoperations.java:60) org.springframework.integration.redis.outbound.redisqueueoutboundchanneladapter.handlemessageinternal(redisqueueoutboundchanneladapter.java:109) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) ... 43 more caused by: redis.clients.jedis.exceptions.jedisconnectionexception: could not get a resource from the pool redis.clients.util.pool.getresource(pool.java:42) org.springframework.data.redis.connection.jedis.jedisconnectionfactory.fetchjedisconnector(jedisconnectionfactory.java:90) ... 54 more caused by: redis.clients.jedis.exceptions.jedisconnectionexception: java.net.connectexception: connection refused redis.clients.jedis.connection.connect(connection.java:142) redis.clients.jedis.binaryclient.connect(binaryclient.java:75) redis.clients.jedis.binaryjedis.connect(binaryjedis.java:1724) redis.clients.jedis.jedisfactory.makeobject(jedisfactory.java:65) org.apache.commons.pool2.impl.genericobjectpool.create(genericobjectpool.java:819) org.apache.commons.pool2.impl.genericobjectpool.borrowobject(genericobjectpool.java:429) org.apache.commons.pool2.impl.genericobjectpool.borrowobject(genericobjectpool.java:360) redis.clients.util.pool.getresource(pool.java:40) ... 55 more caused by: java.net.connectexception: connection refused java.net.plainsocketimpl.socketconnect(native method) java.net.abstractplainsocketimpl.doconnect(abstractplainsocketimpl.java:339) java.net.abstractplainsocketimpl.connecttoaddress(abstractplainsocketimpl.java:200) java.net.abstractplainsocketimpl.connect(abstractplainsocketimpl.java:182) java.net.sockssocketimpl.connect(sockssocketimpl.java:392) java.net.socket.connect(socket.java:579) redis.clients.jedis.connection.connect(connection.java:137) ... 62 more',
    'support for hadoop name node ha configuration hadoop supports namenode ha with two name nodes running one being active and other in standby. if the active name node fails the standby name node has all the data readily available and can start serving requests. in this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime. this is to ensure spring xd stream can handle a name node failure for instance when writing a hdfs sink seamlessly',
    'replace testsource with time and testsink with log this should facilitate testing while avoiding any class dependencies. also log is a generally useful sink by itself and time is a more interesting source for testing (should accept --interval for the seconds between time messages).',
    "change banner of shell to say only 'xd'",
    "configuration for rabbitmq message bus concurrent consumers by having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.",
    "as a developer i'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release. perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/deployment#troubleshooting] section in our wiki.",
    'as a user i\'d like to have the option to explicitly define/configure "error channel" so that i can stage and route the errors/exceptions through the dedicated channel and continue ingestion. *scenario:* * \'http\' source ingest * failure at either source processor or sink module * regardless of whether it is a custom module or not traverse through the exception to propagate the actual _caused by:..._ stage the error as payload and route it to the error channel *example configuration:* * error channel definition similar to "topic.errors.stream.module" * configure custom exception similar to "catch=**exception" * exception hierarchy ** globalexception ** defaultexception ** modulespecificexception',
    'consider usage of jackson afterburner see https://github.com/fasterxml/jackson-module-afterburner',
    'parser should only allow one label instance per module', 'tail file channel adapters',
    'update spring-data-hadoop version to 2.0.4 for xd 1.0.3',
    'vary queue number on 32 core machine (ecb-8) rerun test xd-2278 on a ec2 32 core machine and see when we max out.',
    'change rabbitmq sink to use routing-key-expression instead of routing-key the current rabbitmq sink uses the attribute routing-key which defaults to the name of the stream. this should be change to use the attribute routing-key-expression so that the routing-key can be determined using spel. this will enable a dynamic evaluation of the routing-key based on message payload/header. *implementation suggestions* this hopefully should be changing the xml description of the sink to routing-key-expression="${routingkey:\'${xd.stream.name}\'} this way the ${xd.stream.name} is surrounded by a single quote to indicate a string literal to spel in the default case. *how to verify it works.* one of the simple uses of this is to create a routing key based on payload. in a distributed word-count example the hashcode of a word would be sent to a certain number of processing modules that would perform the count. the idea is that the same word is sent to the same node over and over again in particular if in-memory counters or state is computed - using centralized redis counters this wouldn\'t be necessary in the case of only counter state. the stream http | rabbit --routingkey="\'word-\' + payload.hashcode() % 3" is an example of a stream that can be used to verify that messages published to a direct exchange will have routing keys of the value word-0 word-1 and word-2. binding a queue to each of these routing keys one can observe the contents of messages in the queue to make sure that words are being routed to the appropriate queue e.g. publishing "hello" as the payload of an http request should always appear in the same queue. the rabbitmq admin console can be used for this purpose.',
    'as a user i would like to have shell interface to the spring-cloud-data rest api. the scope for this jira could be limited to stream commands.',
    'use alternativejdkidgenerator instead of 3rd party library spring 4.0 provides a uuid generator (used by default in si) that should be used instead of the com.eaoi.uuid library in the xd-tuple library',
    "as a spring xd user i'd like to capture module (aka: {{cf apps}}) metrics directly so i can relay that information via rest-apis and not depend on the current coupling of {{xd-container}}'s. currently there are two different ways we could consume this information from applications. si's {{channel()}} and sboot's {{actuator()}} apis are the few to explore as part of this scope.",
    "as a s-c-d user i'd like to have the option to choose hadoop distribution of choice so i can load the right hadoop libraries in the cp.",
    'add stream/job destroy option at the ui add an option to destroy the stream/job definitions. also add confirm action that asks for user to confirm to proceed with destroy.',
    'update jclouds to 1.8 have to update the code because of deprecation and to get ready for 2.0.',
    'gradle based multi-project build multi project build. - look to spring framework for source of starting point.',
    'create design document for implementation strategy for ingesting data from twitter into hdfs that can be analyzed by hawq as part of the hadoop world demonstration work the flow of data using xd from twitter to be analyzed by hawq as done. part of this work had the data going into hdfs that hawq was able to query using external tables. the work for this story is to identify the concrete technical tasks/stories to be created do deliver and document this functionality in xd.',
    'zookeeper job deployments path state is not updated after successful deployment after successful job deployment the job deployments path in zk doesn\'t get updated with the data {"state": "deployed"} though this data is not used for deployed instance repository (org.springframework.xd.dirt.stream.zookeeper.zookeeperjobrepository) to check for the deployment status it may be better to have this state updated like stream deployment path.',
    'kafka message bus maxwait property is not set up the maxwait property from server.yml in the message bus section for kafka is not propagated through the code it is ignored.',
    'xd should run offline trying to run xd offline results in an error in redis.xml because the cloudfoundry schema file is missing. we need to add the cf-runtime jar to the classpath to resolve this.',
    'tapcommandtests hangs when using a lazily instantiated lettuce connection a change was made in spring-data-redis to instantiate the shared lettuce connection lazily instead of when the context is initialized. this caused tapcommandtests to hang due to a netty worker thread trying to initialize the lettuce connection (lettuce uses netty). the change was temporarily backed out of sdr but we need to consider using a nettyexecutionhandler in nettyhttpinboundchanneladapter or making the http module\'s "input" channel an executorchannel to avoid potentially long operations like from happening in an i/o thread. also we need to address why this failure simply hangs the shell. shell was hung waiting on io here: org.springframework.http.client.simpleclienthttpresponse.getrawstatuscode(simpleclienthttpresponse.java:47) org.springframework.http.client.abstractclienthttpresponse.getstatuscode(abstractclienthttpresponse.java:32) org.springframework.xd.shell.command.httpcommands$1.haserror(httpcommands.java:93) org.springframework.web.client.resttemplate.doexecute(resttemplate.java:484) org.springframework.web.client.resttemplate.execute(resttemplate.java:460) org.springframework.web.client.resttemplate.postforentity(resttemplate.java:335) org.springframework.xd.shell.command.httpcommands.posthttp(httpcommands.java:103) sun.reflect.generatedmethodaccessor135.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) java.lang.reflect.method.invoke(method.java:597) org.springframework.util.reflectionutils.invokemethod(reflectionutils.java:191) org.springframework.shell.core.simpleexecutionstrategy.invoke(simpleexecutionstrategy.java:64) ringframework.shell.core.simpleexecutionstrategy.execute(simpleexecutionstrategy.java:57) - locked <7fd3c7d40> (a java.lang.class for org.springframework.shell.core.simpleexecutionstrategy) org.springframework.shell.core.abstractshell.executecommand(abstractshell.java:127) org.springframework.xd.shell.abstractshellintegrationtest.executecommand(abstractshellintegrationtest.java:99) org.springframework.xd.shell.abstractshellintegrationtest.httppostdata(abstractshellintegrationtest.java:112) org.springframework.xd.shell.command.tapcommandtests.testcreateanddeploytap(tapcommandtests.java:56) full stack trace of server exception: aug 19 2013 9:59:00 am org.jboss.netty.channel.simplechannelupstreamhandler warning: exception please implement org.springframework.integration.x.http.nettyhttpinboundchanneladapter$handler.exceptioncaught() for proper handling. org.springframework.integration.messagehandlingexception: org.springframework.data.redis.redisconnectionfailureexception: unable to connect to redis on localhost:6379 nested exception is com.lambdaworks.redis.redisexception: unable to connect org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:76) org.springframework.integration.handler.serviceactivatinghandler.handlerequestmessage(serviceactivatinghandler.java:67) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:137) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:115) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:223) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:207) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:172) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:166) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:144) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:115) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:223) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:207) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:172) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:166) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:144) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:115) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:223) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:207) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:172) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:166) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:144) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) org.springframework.integration.dispatcher.broadcastingdispatcher.invokehandler(broadcastingdispatcher.java:121) org.springframework.integration.dispatcher.broadcastingdispatcher.dispatch(broadcastingdispatcher.java:112) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.interceptor.wiretap.presend(wiretap.java:121) org.springframework.integration.channel.abstractmessagechannel$channelinterceptorlist.presend(abstractmessagechannel.java:248) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:173) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendmessage(abstractreplyproducingmessagehandler.java:223) org.springframework.integration.handler.abstractreplyproducingmessagehandler.sendreplymessage(abstractreplyproducingmessagehandler.java:207) org.springframework.integration.handler.abstractreplyproducingmessagehandler.producereply(abstractreplyproducingmessagehandler.java:172) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handleresult(abstractreplyproducingmessagehandler.java:166) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:144) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:73) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:115) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:102) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:178) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:149) org.springframework.integration.core.messagingtemplate.dosend(messagingtemplate.java:304) org.springframework.integration.core.messagingtemplate.send(messagingtemplate.java:165) org.springframework.integration.endpoint.messageproducersupport.sendmessage(messageproducersupport.java:92) org.springframework.integration.x.http.nettyhttpinboundchanneladapter.access$200(nettyhttpinboundchanneladapter.java:59) org.springframework.integration.x.http.nettyhttpinboundchanneladapter$handler.messagereceived(nettyhttpinboundchanneladapter.java:122) org.jboss.netty.handler.codec.http.httpcontentencoder.messagereceived(httpcontentencoder.java:81) org.jboss.netty.handler.codec.http.httpchunkaggregator.messagereceived(httpchunkaggregator.java:148) org.jboss.netty.channel.channels.firemessagereceived(channels.java:296) org.jboss.netty.handler.codec.frame.framedecoder.unfoldandfiremessagereceived(framedecoder.java:459) org.jboss.netty.handler.codec.replay.replayingdecoder.calldecode(replayingdecoder.java:536) org.jboss.netty.handler.codec.replay.replayingdecoder.messagereceived(replayingdecoder.java:485) org.jboss.netty.channel.channels.firemessagereceived(channels.java:268) org.jboss.netty.channel.channels.firemessagereceived(channels.java:255) org.jboss.netty.channel.socket.nio.nioworker.read(nioworker.java:88) org.jboss.netty.channel.socket.nio.abstractnioworker.process(abstractnioworker.java:107) org.jboss.netty.channel.socket.nio.abstractnioselector.run(abstractnioselector.java:312) org.jboss.netty.channel.socket.nio.abstractnioworker.run(abstractnioworker.java:88) org.jboss.netty.channel.socket.nio.nioworker.run(nioworker.java:178) java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) java.lang.thread.run(thread.java:680) caused by: org.springframework.data.redis.redisconnectionfailureexception: unable to connect to redis on localhost:6379 nested exception is com.lambdaworks.redis.redisexception: unable to connect org.springframework.data.redis.connection.lettuce.lettuceconnectionfactory.createlettuceconnector(lettuceconnectionfactory.java:345) org.springframework.data.redis.connection.lettuce.lettuceconnectionfactory.initconnection(lettuceconnectionfactory.java:116) org.springframework.data.redis.connection.lettuce.lettuceconnectionfactory.getsharedconnection(lettuceconnectionfactory.java:325) org.springframework.data.redis.connection.lettuce.lettuceconnectionfactory.getconnection(lettuceconnectionfactory.java:106) org.springframework.data.redis.core.redisconnectionutils.dogetconnection(redisconnectionutils.java:81) org.springframework.data.redis.core.redisconnectionutils.getconnection(redisconnectionutils.java:53) org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:173) org.springframework.data.redis.core.redistemplate.execute(redistemplate.java:153) org.springframework.data.redis.core.abstractoperations.execute(abstractoperations.java:86) org.springframework.data.redis.core.defaultzsetoperations.add(defaultzsetoperations.java:41) org.springframework.data.redis.core.defaultboundzsetoperations.add(defaultboundzsetoperations.java:47) org.springframework.xd.store.abstractredisrepository.trackmembership(abstractredisrepository.java:202) org.springframework.xd.analytics.metrics.redis.rediscounterrepository.increment(rediscounterrepository.java:88) org.springframework.xd.analytics.metrics.redis.rediscounterrepository.increment(rediscounterrepository.java:82) org.springframework.xd.analytics.metrics.integration.messagecounterhandler.process(messagecounterhandler.java:28) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) java.lang.reflect.method.invoke(method.java:597) org.springframework.expression.spel.support.reflectivemethodexecutor.execute(reflectivemethodexecutor.java:69) org.springframework.expression.spel.ast.methodreference$methodvalueref.getvalue(methodreference.java:97) org.springframework.expression.spel.ast.compoundexpression.getvalueinternal(compoundexpression.java:82) org.springframework.expression.spel.ast.spelnodeimpl.gettypedvalue(spelnodeimpl.java:102) org.springframework.expression.spel.standard.spelexpression.getvalue(spelexpression.java:103) org.springframework.integration.util.abstractexpressionevaluator.evaluateexpression(abstractexpressionevaluator.java:126) org.springframework.integration.util.messagingmethodinvokerhelper.processinternal(messagingmethodinvokerhelper.java:230) org.springframework.integration.util.messagingmethodinvokerhelper.process(messagingmethodinvokerhelper.java:129) org.springframework.integration.handler.methodinvokingmessageprocessor.processmessage(methodinvokingmessageprocessor.java:73) ... 84 more caused by: com.lambdaworks.redis.redisexception: unable to connect com.lambdaworks.redis.redisclient.connect(redisclient.java:176) com.lambdaworks.redis.redisclient.connectasync(redisclient.java:139) org.springframework.data.redis.connection.lettuce.lettuceconnectionfactory.createlettuceconnector(lettuceconnectionfactory.java:339) ... 111 more caused by: java.lang.illegalstateexception: await*() in i/o thread causes a dead lock or sudden performance drop. use addlistener() instead or call await*() from a different thread. org.jboss.netty.channel.defaultchannelfuture.checkdeadlock(defaultchannelfuture.java:342) org.jboss.netty.channel.defaultchannelfuture.await(defaultchannelfuture.java:231) com.lambdaworks.redis.redisclient.connect(redisclient.java:166) ... 113 more',
    'update processors script section to use shell commands instead of curl see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#script',
    "implement kryo serialization for tuple currently tuplecodec uses json for serialization/deserialization. it should use kryo. this will require some customization and potentially changes to tuple to address the tuple's conversionservice field.",
    'make trigger options explicitly exclusive see problem reported at http://stackoverflow.com/questions/27368351/spring-xd-module-sourcetrigger-does-not-work-as-expected',
    "correct hadoop classpath versions for the distros when using hdp13 the xdconfiglogginginitializer throws this info: 12:02:06064 info main util.xdconfiglogginginitializer:77 - hadoop distro: hdp13 12:02:06068 warn main util.xdconfiglogginginitializer:84 - hadoop version detected from classpath: 1.2.0 but you provided '--hadoopdistro hdp13'. did you mean '--hadoopdistro hdp20'? 12:02:06069 warn main util.xdconfiglogginginitializer:84 - hadoop version detected from classpath: 1.2.0 but you provided '--hadoopdistro hdp13'. did you mean '--hadoopdistro hadoop12'? since hdp13 uses hadoop 1.2.0 we need to fix that in the versions map containeroptions.gethadoopdistroversions()",
    'add options for supporting compression on the message bus with rabbitmq https://jira.spring.io/browse/amqp-453 added support for compression with rabbitmq. xd should expose configuration options to enable and configure compression on the message bus. note some options may be specific for brokers or require additional functionality in xd. this issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations but expose what makes sense with the current code base for rabbitmq as an example kafka supports compressed.topics which lets you pick a subset of topics to be compressed.',
    'document redis pool properties in servers.yml add spring.redis.pool.* properties to server.yml commented out to show default values. e.g. maxidle: 8 minidle: 0 maxactive: 8 maxwait: -1',
    'support for @configuration based module definitions', 'release 1.0.1',
    'xd ui on yarn technically speaking of we want to integrate xd ui on hadoop tools we should do it so that the proxy on resource manager works with xd ui. from hadoop yarn resource manager point of view this proxied url is the applications tracking url(which is registered when application is deployed).',
    "jdbchdfs job password issue password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (see attached image). the password has an '_' char but it shouldn't matter. the entire password should be masked with '*' instead.",
    'support json to object register a json to object converter in the defaultcontenttypeawareconverterregistry. currently we only support object to json but not the other way. this may or may not work for an arbitrary object but is useful in many cases.',
    'the hdfs sink should support copying file payloads we should support *java.io.file* payloads in order to support non-textual file and large text file payloads being uploaded to hdfs. currently text file payloads are converted to a text stream in memory and non-string payloads are converted to json first using an "object-to-json-transformer". ultimately we need to support streams such as "file | hdfs" where the actually payload being copied to hdfs is not necessarily json or textual. need to be able to support headers in the message that will indicate which hdfs file the data should be stored in.',
    "as a developer i'd like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1). (0): {code} /lib/*.jar:lib/${distro}/*.jar {code} (1): {code} ${xd.home}/lib/hadoop/${distro}/*.jar {code} *example:* {code} http | hdfs --distro=phd22 http | mycustommodule --classpath=/my/funky/dir http | jpa --provider=eclipse jpa: /config/ /lib/something-that-is-common.jar /eclipse/eclipse-link-3.2.jar /hibernate/hibernate-core-5.0.jar module.classpath = /lib/*.jar:/lib/${provider}/*.jar {code}",
    'acceptance tests updated to be able to test xd yarn deployment in order to run acceptance tests in their current state there had to be * changes to the code ** set the location of the data node for the hdfs tests. (because the data nodes were no located with the master.) ** disable the copying of batch basic because we did not know the container location. * had to configure tests by hand so that we could identify the: ** admin port (with new features we should be able to write code to find it. should be able to set it but we had a problem. possible yarn bug) ** jmx port ( we could set it for the master but not the container this was a yarn deploybug ) ** where the build was deployed on the container node so we could copy the batch-basic test.',
    'rabbitmq source is not ingested the data into jdbc sink i am using spring xd to ingest the data into pivotal hd.my source is log files which is coming from logstash through rabbitmq. i could able to ingest the log files in hdfs (by using rabbitmq source and hdfs sink) however when i try to ingest the data directly into hawq by using jdbc sinkit\'s not working. shall we directly load rabbitmq source into any databases like hawq? stream create --name pivotalqueue --definition "rabbit --host=<my host name> | jdbc --columns=\'colum list\'" ---not working i configured jdbc in jdbc.properties. there was no issue with jdbc configuration(because i tested this with simple tail source it\'s working and load the data into hawq. stream create --name pivotalqueue --definition "tail --name=/tmp/xd/output/test.out | jdbc --columns=\'columns list\'" )',
    'the user needs the ability to set up a end-time where the trigger should no longer be in effect.',
    'update settings file and reformat existing codebase. please put in suggestions for the current .settings file. maybe one suggestion is to not format on save?',
    'messagechannelitemwriter h2. narrative as a user of xd i want to be able to use a job as a source. to do so we need the output of a job to be written to a message channel h2. acceptance criteria # create a new itemwriter in the spring batch project to write to a spring integration message channel.',
    'shell should display error messages returned from the server for example using tcpdump i can see both an exception and message information: \'http/1.1 500 internal server error server: apache-coyote/1.1 content-type: application/jsoncharset=utf-8 transfer-encoding: chunked date: fri 12 jul 2013 13:38:26 gmt connection: close 275 [{"links":[]"logref":"messagehandlingexception""message":"org.springframework.context.applicationcontextexception: failed to start bean \'org.springframework.integration.monitor.integrationmbeanexporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2\' nested exception is org.springframework.jmx.export.unabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=nullchannel sends=0 receives=0]] with key \'xd.tap1:type=messagechannelname=nullchannelindex=1module=log\' nested exception is javax.management.instancealreadyexistsexception: xd.tap1:type=messagechannelname=nullchannelindex=1module=log"}] however the client only shows: http://localhost:8080:>tap create --name "tap1" --definition "tap@test1.file | log" --deploy true 14:38:26113 warn spring shell client.resttemplate:524 - post request for "http://localhost:8080/taps" resulted in 500 (internal server error) invoking error handler error creating tap \'tap1\' the error doesn\'t seem to be logged in the xd admin server either so the information is effectively lost.',
    "as a user i'd like to have the option to store the custom module uber-jar in hdfs so that i can rely on the ha feature to reliably read and reinstall under failure scenarios.",
    'add "yarn.resourcemanager.scheduler.address" to mapreduce samples the mapreduce samples should have "yarn.resourcemanager.scheduler.address" since it might be needed in a multi node production cluster.',
    "remove usage of <context:property-placeholder location=.../> in module defitions this doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc. this is in hdfs and some others.",
    "as a s-c-d developer i'd like to collaborate with boot engineering team and derive a strategy for module metadata via {{@configurationproperties}} so i can implement the functionality to support {{shell}} {{autocompletion}} {{flo}} and {{ascii}} documentation in _spring-cloud-data_. eric's [gap analysis|https://docs.google.com/document/d/1a-9rpgsnl6sxd61q9ew2yrkrkn3txk09rdkx7ecklxy/edit#] document captures all the specifics in detail.",
    'correctly report state of module instances currently only the started application (and application instance) status is recognised. this issue will look at the other possible states and report them as module instance states. this would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.',
    "the hdfs sink should support a file naming strategy to distinguish between file currently being written and completed files a file that is in the process of being written to should have a customized suffix added to the name e.g. 'temp'. once the file is closed the suffix is removed and replaced with another value - default value can be dependent on the serialization format used but can be customized",
    'create externalized property file to support connectivity to redis we need to have an externalized property file(under xd/conf/) for the xd-container & admin scripts to use as options.',
    'update to reactor 2.0.3',
    "rest endpoint/command interface for runtime module deployment properties we need a way to access the deployment properties for the deployed modules. for example: 'runtime module foo.sink.bar-2'",
    'better classloader strategy for xd admin/container this is in reference to the investigation done as part of xd-2548',
    "as a developer i'd like to add support for {{undeployed}} status consistently across all the deployers so i can present the correct status instead of the current {{unknown}}. this is applicable for existing streams without any deployment context associated with it.",
    'mbeans are not destroyed if stream is created and destroyed with no delay problem: the container that the stream was deployed to will not allow new streams to be deployed. once the error occurs the only solution is to terminate the xd container and restart it. to reproduce create a stream foo and destroy the stream then create the stream foo again. this best done programmatically taking the same steps using the "shell" may not reproduce the problem. i.e. if you put a sleep of 1-2 seconds between the destroy and the next create it works fine',
    'on specific shutdown scenarios the stream resumes from the start of the bus topic https://github.com/spring-projects/spring-xd/issues/1727',
    'harmonize common deployer runtime properties applied to modules most if not all of the deployers have some concept of customization of the deployed modules: be it memory or cpu disk etc. this ticket is about harmonizing the handling of such properties with the assumption that we want a per-deployer set of defaults and overridability at deployment time.',
    "as a developer i'd like to create separate repo for yarn spi so i don't have to bundle all spi variants under one admin project.",
    'sqooptasklet doesn\'t use keytab configuration from hadoop.properties file hey guys i have been using the sqooptasklet for a while but i found an unexpected problem. basically i\'m not able to configure kerberos authentication from hadoop.properties file as follow: <util:properties id="hadoopproperties" location="${xd.config.home}/hadoop.properties" /> <bean id="sqooptasklet" class="org.springframework.xd.sqoop.sqooptasklet"> <property name="arguments"> <list> <value>import</value> <value>--connect otheroptions</value> </list> </property> <property name="hadoopproperties" ref="hadoopproperties" /> </bean> hadoop.properties file: fs.defaultfs=hdfs://hdfshost:8020 yarn.resourcemanager.hostname=host001 yarn.resourcemanager.address=host001:8032 yarn.resourcemanager.scheduler.address=host001:8030 mapreduce.jobhistory.address=host003:10020 yarn.application.classpath=$hadoop_client_conf_dir$hadoop_conf_dir$hadoop_common_home/*$hadoop_common_home/lib/*$hadoop_hdfs_home/*$hadoop_hdfs_home/lib/*$hadoop_yarn_home/*$hadoop_yarn_home/lib/*$hadoop_mapred_home/*$hadoop_mapred_home/lib/* mapreduce.framework.name=yarn spring.hadoop.security.authmethod=kerberos spring.hadoop.security.userprincipal=user1@company.com spring.hadoop.security.userkeytab=/home/user1/user1.keytab spring.hadoop.security.namenodeprincipal=hdfs/_host@company.com spring.hadoop.security.rmmanagerprincipal=yarn/_host@company.com spring.hadoop.security.jobhistoryprincipal=mapred/_host@company.com or fs.defaultfs=hdfs://hdfshost:8020 yarn.resourcemanager.hostname=host001 yarn.resourcemanager.address=host001:8032 yarn.resourcemanager.scheduler.address=host001:8030 mapreduce.jobhistory.address=host003:10020 yarn.application.classpath=$hadoop_client_conf_dir$hadoop_conf_dir$hadoop_common_home/*$hadoop_common_home/lib/*$hadoop_hdfs_home/*$hadoop_hdfs_home/lib/*$hadoop_yarn_home/*$hadoop_yarn_home/lib/*$hadoop_mapred_home/*$hadoop_mapred_home/lib/* mapreduce.framework.name=yarn security.authmethod=kerberos security.userprincipal=user1@company.com security.userkeytab=/home/user1/user1.keytab security.namenodeprincipal=hdfs/_host@company.com security.rmmanagerprincipal=yarn/_host@company.com security.jobhistoryprincipal=mapred/_host@company.com running the job i\'m getting the following error: encountered ioexception running import job: org.apache.hadoop.security.accesscontrolexception: simple authentication is not enabled. available:[token kerberos so it means the sqooptasklet isn\'t setting the kerberos authentication this basically because in the sqooptasklet class is adding some prefix to the configurations (spring_hadoop_config_prefix) https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/sqooptasklet.java really doesn\'t make sense for me add those prefix and remove it later in the next call in the sqooprunner class. https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/sqooprunner.java if i inject the security.* configurations directly to the list arguments it works. i\'m sure you guys have a good reason to add the prefix but i don\'t see why. unfortunately is annoying when you are developing in a local vm where you can test the simple authentication and after move the job to dev/prod environments with kerberos auth the above because you must change your sqooptasklet configuration injecting the new parameters. if the sqooptasklet allows inject those parameters directly from the hadoop.properties file you don\'t need change tasklet configurations to run your jobs with different authentication methods. thanks in advance. hctor',
    'the hdfs sink should roll over based on the number of events.',
    'only ship relevant modules files the current build ships everything that is found in the modules directory including build artifacts such as build/ or idea *.iml files. restrict the build to only include config/ lib/ at the moment.',
    "as a developer i'd like to build batch sample using _sqoop_ so that we can demonstrate some of the capabilities. *use cases to consider:* * jdbc to hdfs * hdfs to jdbc",
    'composed modules destination binding order incorrect created a stream with definition: {code} mysourcemodule | myprocessormodule | log {code} this stream worked fine but when created composed module with definition {code} mysourcemodule | myprocessormodule {code} then stream definition {code} mycomposedmodule | log {code} get an error stating that the output channel of mysourcemodule has no subscribers. looking at previous bugs this appears to be a module binding order in which the source is started before the processor has subscribed to the output channel of the source.',
    "as a user i'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that i don't have to incur the batch read/write overhead.",
    'remove retry from tcp sink now that the bus supports retry it is no longer necessary to have the retry advice in the tcp sink.',
    'cleanup and optimize gradle tasks to bundle spring-xd distribution we need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions. currently distxd does the copy of distributions from "spring-xd-dirt" "redis" and "spring-xd-gemfire-server" projects into "$rootdir/dist/spring-xd". and the task "zipxd" makes the zip archive. these tasks should be combined with the "distzip" & "doczip" tasks. we also need to remove the duplicate artifacts configuration from these tasks.',
    'investigate throwing of exception in batchjobregistrybeanpostprocessor the condition that leads to this exception does not seem like it would ever occur namely the bpp processing a job deployment for a job that was already deployed to the same container.',
    'npe in containerredeploymenttests running the distributed tests ({{-drun_distributed_tests=true}}) against d109a3a and got the following: {noformat} java.lang.nullpointerexception org.springframework.xd.dirt.module.store.zookeepermodulemetadatarepository.updatedeploymentstatus(zookeepermodulemetadatarepository.java:209) org.springframework.xd.dirt.module.store.zookeepermodulemetadatarepository.findallbycontainerid(zookeepermodulemetadatarepository.java:313) org.springframework.xd.dirt.container.store.zookeepercontainerrepository.findallruntimecontainers(zookeepercontainerrepository.java:339) org.springframework.xd.dirt.rest.containerscontroller.list(containerscontroller.java:97) sun.reflect.generatedmethodaccessor100.invoke(unknown source) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:483) org.springframework.web.method.support.invocablehandlermethod.invoke(invocablehandlermethod.java:215) org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:132) org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:104) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:749) org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:689) org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:83) org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:938) org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:870) org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:961) org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:852) javax.servlet.http.httpservlet.service(httpservlet.java:620) org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:837) javax.servlet.http.httpservlet.service(httpservlet.java:727) org.apache.catalina.core.applicationfilterchain.internaldofilter(applicationfilterchain.java: {noformat}',
    'documentation for "syslog | file" processing put on the guide as a section in an \'input-stream\' wiki page.',
    'test recent hadoop distro changes test basic functionality (hdfs sink jdbchdfs job) on hadoop26 hdp22 cdh5 phd21 test xd on yarn on hadoop26 hdp22 cdh5 and phd21',
    'document mqtt source and sink',
    'copy spring-xd-codec to scs as spring-cloud-streams-codec create the equivalent library in spring-cloud-streams',
    "deploying custom code when a module is deployed it should run in its own isolated classpath. the current code has all dependencies in a single classpath taken from the lib directory at startup. this has a number of drawbacks one of the most important is the batch jobs can not be contributed to the system at runtime. the work for this epic is decoupled from any module deployment story. the assumption is that there will be a directory layout as shown below. current layout ./modules/. |-- common |-- job |-- processor |-- sink |-- source |-- trigger and inside source |-- source | |-- file.xml | |-- gemfire-cq.xml | |-- gemfire.xml | |-- http.xml | |-- jms.xml | |-- mqtt.xml | |-- rabbit.xml | |-- syslog-tcp.xml | |-- syslog-udp.xml | |-- tail.xml | |-- tap.xml | |-- tcp.xml | |-- time.xml | |-- twittersearch.xml | |-- twitterstream.xml using an example of the source directory from the current layout.e.g ./modules/source/file the new layout would be ./modules/source/file/lib/spring-integration-file.jar ./modules/source/file/config/file.xml we should support both the new and old layout styles simultaneously. there what is under 'file' directory is the 'package' no .zip war is required.",
    "as a s-c-d developer i'd like to enhance integration test coverage for {{cc}} spi so i can continuously evaluate functionalities via ci pipeline.",
    'create a gauge module spring config for simple gauge plus message handler to process message. there is some code common to richgaugehandler to coerce the payload to a double that should be refactored for reuse.',
    "fix 'cluster/containers' rest endpoint if security is enabled if the security is enabled for the container then admin server won't be able to fetch the message rates for the deployed modules in that container. the rest endpoint 'cluster/containers' needs to be fixed.",
    'surface the provenance of a default to the user when using @value for providing a default value in a module options pojo make it so that the rest api (and hence the module info command) advertises that 1) the expression was ${foo.something} 2) to the best extent possible (value may come from another property source) tell which config file it came from (introspecting the @propertysource annotation)',
    'upgrade to zookeeper 3.4.6 3.4.6 was released on 2014.03.10: http://zookeeper.apache.org/doc/r3.4.6/releasenotes.html especially relevant for us they updated netty from 3.2.2 to 3.6.6: https://issues.apache.org/jira/browse/zookeeper-1715',
    "as a s-c-d developer i'd like to move {{kafka}} module from xd to s-c-s repo so i can use it as {{source}} to build streaming pipeline.",
    'create rich gauge module spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.',
    'set bean name in consumerendpointfactorybean {{localmessagebus}} and {{compositemodule}}.',
    'introduce wire.js into the xd admin ui we should consider moving to wire.js to encourage dependency injection in the ui javascript code. see here: https://github.com/cujojs/wire/blob/master/docs/get.md',
    '"script" processor options incorrect on docs the example in the documentation (and the paragraph preceding the example) for the "script" processor uses both "location" and "properties-location" options but these are in actuality "script" and "locationproperties" according to "module info processor:script" and the text of the documentation. see: http://docs.spring.io/spring-xd/docs/1.0.2.release/reference/html/#script {quote}to use the module pass the location of a groovy script using the location attribute. if you want to pass variable values to your script you can optionally pass the path to a properties file using the properties-location attribute. all properties in the file will be made available to the script as variables. {code}xd:> stream create --name groovyprocessortest --definition "http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log" --deploy{code} {quote}',
    "create aggregator module create a processing module based on si's aggregator component. the completion criteria for the aggregator should be a simple count of messages (e.g. received 50 messages) and a timeout so that messages don't stay in the aggregator module for more than 30 seconds. *implementation suggestions* create an xml based processing module definition using the si aggregator namespace. only the options to support the features in the description should be exposed as property placeholders. *how to know it works* a shell style integration test that has a source that sends a known amount of messages. a ticktock like module would perhaps be a good example. 10 messages sent every 100ms with an aggregator set to a 'aggregate count' of 10 should have 1 message output (perhaps to file sink whose name is based on time as well is that possible.). a ticktock example with a 1 second delay and with the aggregator module set to have a timeout of 0.5 seconds will have only one message in the file (again assumign the file name has a timestamp/counter in the filename).",
    'provide missing jars to enable #xpath() spel spring xd should package *spring-integration-xml* jar within distribution so we can invoke *#xpath()* spel from processors e.g. using transformer: {code}... | transform --expression=\'#xpath(payload "/*[name()=\'\'datasource\'\']/*[name()=\'\'row\'\']/text()" | ... {code}',
    "as a user i'd like to have latest spring boot snapshot pulled as a dependency so that i can inherit and implement the ootb security features.",
    'display a gauge',
    "redis 'install-redis' script fails on ubuntu64 the installation script for redis fails on ubuntu64 when trying to untar the redis distribution. the script uses redis_zipname instead of redis_zip_path. this bug will be seen on any linux 64 bits platform and looking at the code even linux 32 bits platform.",
    "sparkapp batch job is not running from the latest master i couldn't run sparkapp as batch job. the spark application process gets launched and it doesn't complete and there are no errors at the output.",
    "fix jobrepotests to use different batch job repo currently the jobrepotests use the same batch job repository that the xd runtime uses. since the batch job repo doesn't delete the job instances there would be stale data from this test.",
    "batch job's step execution count is always '0' the batch job's step execution count is retrieved from org.springframework.batch.admin.web.jobexecutioninfo in batch job repository. but the jobexecutioninfo always have the stepexecutioncount set to '0'.",
    'make batch job restarts work using single node see also xd-1320.',
    'the hdfs store library should support compression when writing to sequence files support for using compression when writing sequence files either block or record-based compression.',
    'xd shell crashes when the stream dsl has "!" the xd shell crashes when the following command issued: stream create test --definition "http | filter --expression=!payload.contains(\'test\') | log" it looks like the jline consolereader\'s expandevents is set to true by default and this causes the issue: exception in thread "spring shell" java.lang.illegalargumentexception: !payload.contains(\'test\') | log": event not found jline.console.consolereader.expandevents(consolereader.java:734) jline.console.consolereader.finishbuffer(consolereader.java:604) jline.console.consolereader.accept(consolereader.java:1912) jline.console.consolereader.readline(consolereader.java:2537) jline.console.consolereader.readline(consolereader.java:2162) jline.console.consolereader.readline(consolereader.java:2150) org.springframework.shell.core.jlineshell.promptloop(jlineshell.java:517) org.springframework.shell.core.jlineshell.run(jlineshell.java:178) java.lang.thread.run(thread.java:722)',
    'support partitioning/bus properties in the redismessagebus pr: https://github.com/spring-projects/spring-xd/pull/926',
    "springxd logs error and large stack trace when metric can't be found. distracting. when a rest client of springxd (i.e. a dashboard) attempts to query (get) a metric (e.g. counter gauge etc.) that does not exist the admin sever logs an error and a large stack trace (attached). in usage of spring xd we see this frequently because a dashboard is running but the streams and counters have not been created quite yet or initialized by messages flowing through the streams. with a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues. i would suggest logging a one line warning or info message instead of the error and stack trace.",
    'message conversion support for spark streaming module the spark streaming module needs to support inputtype (for both processor and sink module) and outputtype (for processor module) so that message conversion can happen at the messagebusreceiver and messagebussender.',
    "enhance jdbc sink test to include more options to enrich acceptance test i'd like to add coverage to jdbc sink by including *-- driverclass* and *-- url* options.",
    'web admin app not loading for slow connections when opening manager webapp if the internet connection is slow enough to make one of the biggest javascript dependencies to make requirejs throw a timeout the webapp becomes unusable displaying only the loading gif and showing a javascript error saying: uncaught error: load timeout for modules: angular it typically takes ~ 10 seconds to throw that error.',
    "the command line for xd-admin and xd-container to support an additional option pipeprotocol that is used to determine the middleware for sending admin requests and data between processing steps the name 'pipeprotocol' is tentative. 1. the command line scripts for xd-admin and xd-container would support a --pipeprotocol option with the default being to use redis. (otherwise use xd-singlenode). 2. the xd-admin and xd-container scripts will use the value of pipeprotocol to set the java system property xd.pipeprotocol when launching the app.",
    'intermittent tcpmodulestests.testtcpsink test failure {noformat} org.junit.comparisonfailure: org.junit.comparisonfailure: expected:<[hi there! ]> but was:<[]> org.junit.comparisonfailure: expected:<[hi there! ]> but was:<[]> org.junit.assert.assertequals(assert.java:115) org.junit.assert.assertequals(assert.java:144) org.springframework.xd.shell.command.tcpmodulestests.testtcpsink(tcpmodulestests.java:63) sun.reflect.nativemethodaccessorimpl.invoke0(native method) (60 more lines...) {noformat} https://build.spring.io/browse/xd-jdk8-job1-1162/test',
    'change xd.sink logging level to info the log sink is not writing information to the log. not the solution but when log4j.rootlogger is set to info the log sink information is written to the log.',
    'upgrade to spring boot 1.3 upgrade dependencies to spring boot 1.3.x',
    'streamserver context lifecycle issues the {{moduledeployer}} calls {{getbeansoftype}} before the context has had its {{propertysourcesplaceholderconfigurer}} attached. this can cause issues with {{factorybean}} s with placeholders in constructor args because the unresolved placeholder is used when the {{factorybean}} is pre-instantiated to determine the type of object it will serve up.',
    "remove autolaunch feature from batch jobs jobs will be started via trigger. so we won't need the jobtriggerbean.",
    'refactor module dependency tracking to be closer to stream deployment see comments on this pr (which is part of the code that needs to be refactored): https://github.com/spring-projects/spring-xd/pull/390',
    'unable to set --closetimeout on scsm hdfs sink module creating a stream like this: stream create --name myhdfsstream1 --definition "time | hdfs --closetimeout=5000" --deploy causes: java.lang.illegalargumentexception: task executor must be set at org.springframework.util.assert.notnull(assert.java:115) ~[spring-core-4.2.1.release.jar!/:4.2.1.release] at org.springframework.data.hadoop.store.support.pollingtasksupport.init(pollingtasksupport.java:105) ~[spring-data-hadoop-store-2.3.0.m2.jar!/:2.3.0.m2] at org.springframework.data.hadoop.store.support.storeobjectsupport.oninit(storeobjectsupport.java:97) ~[spring-data-hadoop-store-2.3.0.m2.jar!/:2.3.0.m2] at org.springframework.data.hadoop.store.support.outputstoreobjectsupport.oninit(outputstoreobjectsupport.java:81) ~[spring-data-hadoop-store-2.3.0.m2.jar!/:2.3.0.m2] at org.springframework.data.hadoop.store.support.lifecycleobjectsupport.afterpropertiesset(lifecycleobjectsupport.java:67) ~[spring-data-hadoop-store-2.3.0.m2.jar!/:2.3.0.m2] at org.springframework.cloud.stream.module.hdfs.sink.datastorewriterfactorybean.afterpropertiesset(datastorewriterfactorybean.java:175) ~[hdfs-sink-1.0.0.build-snapshot-exec.jar!/:1.0.0.build-snapshot] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.invokeinitmethods(abstractautowirecapablebeanfactory.java:1637) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.initializebean(abstractautowirecapablebeanfactory.java:1574) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] ... 35 common frames omittedwrapped by: org.springframework.beans.factory.beancreationexception: error creating bean with name \'datastorewriter\' defined in class path resource [org/springframework/cloud/stream/module/hdfs/sink/hdfssinkconfiguration.class]: invocation of init method failed nested exception is java.lang.illegalargumentexception: task executor must be set at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.initializebean(abstractautowirecapablebeanfactory.java:1578) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:545) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:482) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:305) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:301) ~[spring-beans-4.2.1.release.jar!/:4.2.1.release] at org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbea',
    "as a qa i'd like to include acceptance test coverage for _sftp_ source module so that i can validate the functionality as part of every ci build.",
    'add command for deleting a tap', 'create a standard way to configure spring cloud data and stream projects',
    'fix random configuration in securedshelltests since the securedshelltests initialize singlenode app in a static way the random configuration needs to be setup statically as well.',
    'xd:>runtime modules gives error from cli xd:>runtime modules command failed org.springframework.xd.rest.client.impl.springxdexception: java.lang.runtimeexception: org.apache.zookeeper.keeperexception$nonodeexception: keepererrorcode = nonode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/ticktock.sink.log-1/metadata this is on osx running in distributed mode with --transport rabbit --hadoopdistro hadoop22 redis 2.8.8 rabbit 3.2.3 hadoop 2.2.0 and zookeeper 3.4.5.',
    'spelparseexception is thrown when using empty string ("") inside of an expression i can only reproduce this when using single quotes around the expression: {code} stream create test --definition "http | transform --expression=\'payload.replace(\\"abc\\" \\"\\")\' | log" --deploy true {code} the following two alternatives work fine though: {code} # using trim on a single space stream create test --definition "http | transform --expression=\'payload.replace(\\"abc\\" \\" \\".trim())\' | log" --deploy true # not using single quotes or spaces in the expression stream create test --definition "http | transform --expression=payload.replace(\\"abc\\"\\"\\") | log" --deploy true {code}',
    "mask database passwords in rest controllers and admin ui when deploying a batch job the ui displays the database password found in the server.yml in plain text to the user. at the very least this should be displayed in a password field so it's masked out and have it masked out in the resulting definition at the bottom of the page. ideally we wouldn't provide the password on that page at all and only accept overriding options (if the user wants a password other than the configured one enter itotherwise we'll use what we have). i'm finding that this occurs in other places as well. a full pass though of the ui should be done to mask out passwords (or eliminate their display all together).",
    'admin should fail immediately if rabbit is not running container currently does that.',
    "as a developer i'd like to measure the baseline serialization characteristics in xd so i can determine the areas of performance improvements.",
    'add support for deploying a batch job with partitioning across multiple xd nodes. this is a very big story needs some planning/discussion before starting work. should be able to be implemented as a plugin.',
    'jdbc property settings need to be made externally configurable we need to have a properties section (documented as well) so that users can setup their jdbc connections for the various components.',
    'remove jersey test framework for xd/lib distribution the jars jersey-test-framework-core-1.9.jar jersey-test-framework-grizzly2-1.9.jar are incorrectly classified as compile time deps in hadoop vs. testcompile.',
    'simplify moduleregistry mr is responsible for looking up existing module definitions by name and type. moduledefinition should contain name type and resource where resource is a springframework.core.io.resource containing the root path of the module definition. this could be file classpath http hdfs or something else but the contents under this path will not be inspected or processed by mr. the exception is for composite modules which should contain a list of corresponding resources. simplify moduledefinition - remove classpath. provide support for compositemoduledefinition - requires a list of resources (possibly a subclass) also retire redismoduleregistry',
    'add moduleoptions support for rabbit sink we need to add moduleoptions support for rabbit sink.',
    'refactor deployment interfaces/class hierarchy (continued) refactoring of the {{resourcedeployer}} to split apart the concepts of repository and deployment. for reference see xd-2835 xd-2671 xd-2877 and xd-3070.',
    "as a spring xd developer i'd like to move {{mail}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline.",
    'kafkamessagebustests#testcompression failing intermittent. reported on ubuntu and os/x',
    'additional rest endpoint not working with security enabled i see the following error from the admin ui: get http://localhost:9393/jobs/executions/4/steps/4/progress.json 403 (forbidden)',
    'embeddedheadersmessageconverter buffer overflow see https://github.com/spring-projects/spring-xd/issues/1871',
    'create a simple counter service a simple counters can increment/decrement a number. implementations for in-memory and redis.',
    'fix anchor links so that they work in both the wiki and generated docs part of the issue is likely with the build script https://github.com/spring-projects/spring-xd/blob/master/build.gradle#l1859 we should also add a link checker to the ci build.',
    "command to create a tap to store it's definition and optionally deploy with --autostart flag",
    'fix module type guessing heuristics commit 96de9fcfaf32719413015a1a6bace1b30b6b9610 strengthened module type inference but some corner cases remain (marked as todos and commented out assertions in tests). to be effective we need to look at the whole deployed stream (or composed module). modify parsincontext accordingly.',
    'create xd integration test framework add top level utility methods to manage xd runtime (deploy start and stop). these methods will be used by underlying integration tests to control runtime test environment.',
    'spike for writing to hdfs see epic https://jira.springsource.org/browse/xd-234',
    'add paging and sorting to field value counter api see discussion at https://github.com/spring-projects/spring-xd/commit/2f0e80b5e337b71c9c70de510a44d2f050d10fa7',
    "as a qa i'd like to include acceptance test coverage for _reactor-syslog_ source module so that i can validate the functionality as part of every ci build.",
    'create script-based batch itemprocessor this would be included in the ootb batch jobs to optionally process the loaded tuple with a configured script.',
    'add acceptance tests for stream with sources of tcp http and time and sinks of file and log need to be able to test the following sources: tcp http time',
    'mqtt: support the new spring integration 4.1 features ha configuration async sends. http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt',
    'test redis sentinel setup and document recommended configuration configure redis cluster with sentinal v 2.8.19. verify fail over experiment with settings. useful reference https://code.flickr.net/2014/07/31/redis-sentinel-at-flickr/ all analytics test cases should be run as well as test that deploy streams that make use of redis analytics. there might be some minor code changes required as mentioned in the flickr article.',
    "rename create to 'save' in resourcedeployer to be consistent with spring data repository method names.",
    "password for sqoop job definition is in the open while creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a '*********'.",
    'create benchmarking application to demonstrate high performance message processing the application should live in in spring-xd-samples repository. the stream created in https://jira.spring.io/browse/xd-1402 should be documented how to run a benchmark and made easy to execute. can use ruby/bash-awk-sed to generate traffic via sendfile in order to saturate the stream.',
    'update xd-ec2 to use placement groups',
    "as a qa i'd like to include acceptance test coverage for _gauge_ sink module so that i can validate the functionality as part of every ci build.",
    "as a data scientist i'd like to have the option to process data using {{flink}} processor so i can take advantage of the streaming machine learning abstractions implemented on top of flink.",
    'enhancements to gemfire cq source the gemfire cq source needs some enhancements: * enable locator configuration * consider decoupling from json. currently designed to work with gemfire-json-server to avoid dependence on specific domain objects on the client and server side. so produces json strings from pdxinstance(s) stored in the cache.',
    "as a developer i'd like to publish performance benchmarks along with the infrastructure specifics so the users can use it as a reference while setting up spring xd cluster.",
    'as a user i\'d like to retain the data partitioning state so that when i restart the containers i continue to write based on the original partitioning strategy. currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different _hashcode()_. *design consideration:* mine through the container info to derive the "partition index" instead of relying on _hashcode()_.',
    'create tests for stream/job deployments path data verification based on the discussion here: https://github.com/spring-projects/spring-xd/pull/852#issuecomment-43356579 we would like to have tests created for verifying the stream/job deployments path "data"',
    'fix compiler warnings as of m3... {code} javadoc: warning - error fetching url: http://static.springsource.org/spring-shell/docs/current/api/package-list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/compositemoduleregistry.java:40: warning - @param argument "cp" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/compositemoduleregistry.java:40: warning - @param argument "file" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/jobfactorybean.java:62: warning - tag @link: can\'t find jobname in org.springframework.xd.dirt.plugins.job.jobfactorybean /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/xdcontroller.java:56: warning - @param argument "<v>" is not a type parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/xdcontroller.java:56: warning - @param argument "<t>" is not a type parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/batchjobalreadyexistsexception.java:32: warning - @param argument "message" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/batchjoblocator.java:32: warning - @distributedjobservice is an unknown tag. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/batchjoblocator.java:32: warning - @distributedjobservice is an unknown tag. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/nosuchbatchjobexception.java:31: warning - @param argument "message" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/containeroptions.java:30: warning - @param argument "defaulttransport" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/containeroptions.java:30: warning - @param argument "defaultanalytics" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/optionutils.java:35: warning - @return tag has no arguments. /users/gpr/documents/workspace-si/spring-xd/spring-xd-module/src/main/java/org/springframework/xd/module/plugin.java:32: warning - tag @see: reference not found: moduledeployer /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/messagebus.java:53: warning - @param argument "moduleinputchannel" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/messagebus.java:72: warning - @param argument "moduleoutputchannel" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/messagebus.java:102: warning - @param argument "moduleoutputchannel" is not a parameter name. /users/gpr/documents/workspace-si/spring-xd/spring-xd-reactor/src/main/java/org/springframework/xd/integration/reactor/config/reactornamespaceutils.java:46: warning - @return tag has no arguments. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/batchjoblocator.java:32: warning - @distributedjobservice is an unknown tag. /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job/batch/batchjoblocator.java:32: warning - @distributedjobservice is an unknown tag. {code} and {code} warning: [options] bootstrap class path not set in conjunction with -source 1.6 /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/localmessagebus.java:132: warning: [rawtypes] found raw type: localmessagebus.sharedchannelprovider sharedchannelprovider channelprovider = aliashint ? queuechannelprovider ^ missing type arguments for generic class localmessagebus.sharedchannelprovider<t> where t is a type-variable: t extends abstractmessagechannel declared in class localmessagebus.sharedchannelprovider /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/bus/localmessagebus.java:159: warning: [rawtypes] found raw type: localmessagebus.sharedchannelprovider sharedchannelprovider channelprovider = aliashint ? queuechannelprovider ^ missing type arguments for generic class localmessagebus.sharedchannelprovider<t> where t is a type-variable: t extends abstractmessagechannel declared in class localmessagebus.sharedchannelprovider /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:93: warning: [rawtypes] found raw type: list public list geturls() { ^ missing type arguments for generic class list<e> where e is a type-variable: e extends object declared in interface list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:101: warning: [rawtypes] found raw type: list public list gethashtags() { ^ missing type arguments for generic class list<e> where e is a type-variable: e extends object declared in interface list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:109: warning: [rawtypes] found raw type: list public list getmentions() { ^ missing type arguments for generic class list<e> where e is a type-variable: e extends object declared in interface list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:117: warning: [rawtypes] found raw type: list public list getmedia() { ^ missing type arguments for generic class list<e> where e is a type-variable: e extends object declared in interface list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:126: warning: [rawtypes] found raw type: list public list gettickersymbols() { ^ missing type arguments for generic class list<e> where e is a type-variable: e extends object declared in interface list /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdentities.java:37: warning: [serial] serializable class xdentities has no definition of serialversionuid public class xdentities implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdurlentity.java:31: warning: [serial] serializable class xdurlentity has no definition of serialversionuid public class xdurlentity implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdhashtagentity.java:32: warning: [serial] serializable class xdhashtagentity has no definition of serialversionuid public class xdhashtagentity implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdmentionentity.java:32: warning: [serial] serializable class xdmentionentity has no definition of serialversionuid public class xdmentionentity implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdmediaentity.java:32: warning: [serial] serializable class xdmediaentity has no definition of serialversionuid public class xdmediaentity implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdtickersymbolentity.java:31: warning: [serial] serializable class xdtickersymbolentity has no definition of serialversionuid public class xdtickersymbolentity implements serializable { ^ /users/gpr/documents/workspace-si/spring-xd/spring-xd-dirt/src/main/java/org/springframework/integration/x/twitter/xdtweet.java:34: warning: [serial] serializable class xdtweet has no definition of serialversionuid public class xdtweet implements serializable { ^ {code}',
    'fix xd modules parameters with "-" to use camel case xd-482 addresses the use of camel case in \'fixed-delay\' job module parameter name. and we need to fix the same for other module parameters wherever \'-\' is being used.',
    'the ability to import beans referenced in the main context into a module this should be a core feature of any spring based module. the plugin should be able to import explicitly referenced beans. this minimizes potential side effects of making the module a child context and is simpler than declaring a shared context (parent) of the application and the module. provide namespace support for flow:',
    "integrate grunt based ui build into the xd's gradle build blog post http://naleid.com/blog/2013/01/24/calling-gruntjs-tasks-from-gradle/ seems to be the definitive reference....",
    'new libraries to experiment we would like to experiment with open source libraries to further enrich spring xds service offerings and feature-set. this epic remains the anchor point for following categories and the respective experimentation outcomes will be documented in the associated stories. * measure based alerts * log analysis * machine learning and graph computation',
    'broken "deployment" link in docs please see "deployment" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.release/reference/html/#_module_deployment page. !broken-link-deployment.png! the link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.release/reference/html/deployment which is a 404.',
    'jobrepository should be persistent and shared across xd-admin/xd-container the current code is creating an in-memory job repository for each batch job that is launched. this makes it impossible to query the tables in the job repository across the cluster. a single job repository that is backed by a file need to be shared across all jobs that are a launched. *implementation suggestions* * the xdadmin server should create the job repository schema if not found in a hsqldb database when it starts up * the bean definitions should be added to the same context that the analytics are being loaded in as it is already shared across xd-admin/xd-container. the analytics context should be renamed to something more generic shared parent context or something. * there is some clean up (removal) of the code in the current jobplugin meta-inf/spring-xd/plugins/job/common.xml wouldnt be needed anymore. that might be all not sure. *how to verify it works* * a junit test that verifies the spring batch tables were created in the job repository when xd-admin is launched. this would require deleting the backing db file before instantiating singlenode/xd-admin/xd-container. * if you start the xd-container it should be able to find the necessary datasource/jobrepository beans information to be able to contact the database. we dont have di style junit tests so this will required getting a reference to the xd-container and its application context and performing getbean(jobrepository.class)',
    'add support for update in gpfdist sink currently we can only do plain inserts should follow same logic from native gpfdist sink and add upserts.',
    'payload conversion sample throws exception. after updating the dependency to use the snapshot (even with m5) the conversion throws an exception. stacktrace attached.',
    "as a developer i'd like to deploy a stream in the same container so all modules are colocated within the container. perhaps also consider building leader election within modules in order to automatically failover the application (stream) from one container to another.",
    'add json conversion to tuple support tostring() to emit json by default. should be backed by a simple strategy to allow the possibility of other representations. also provide totuple(string json). this supports seamless mapping json<->tuple in xd',
    "upon a container departure redeployment of batch job fails on an existing container when there are multiple containers (a b and c) and a batch job is deployed into one of the containers a. when the container a goes down the admin server tries re-deploy the job module that was deployed in container a into other matching container. but when the re-deployment happens it tries to update the distributed job locator as if a new job is being deployed and following exception is thrown: 17:13:38811 error deploymentspathchildrencache-0 cache.pathchildrencache:550 - java.lang.runtimeexception: org.springframework.beans.factory.beancreationexception: error creating bean with name 'job': post-processing of the factorybean's object failed nested exception is org.springframework.xd.dirt.job.batchjobalreadyexistsexception: batch job with the name myjob3 already exists org.springframework.xd.dirt.server.containerregistrar.deployjob(containerregistrar.java:411) org.springframework.xd.dirt.server.containerregistrar.onchildadded(containerregistrar.java:355) org.springframework.xd.dirt.server.containerregistrar.access$8(containerregistrar.java:349) org.springframework.xd.dirt.server.containerregistrar$deploymentlistener.childevent(containerregistrar.java:695) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:494) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:488) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:253) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:485) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$11.run(pathchildrencache.java:755) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:334) java.util.concurrent.futuretask.run(futuretask.java:166) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask$sync.innerrun(futuretask.java:334) java.util.concurrent.futuretask.run(futuretask.java:166) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:722) caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name 'job': post-processing of the factorybean's object failed nested exception is org.springframework.xd.dirt.job.batchjobalreadyexistsexception: batch job with the name myjob3 already exists org.springframework.beans.factory.support.factorybeanregistrysupport.dogetobjectfromfactorybean(factorybeanregistrysupport.java:167) org.springframework.beans.factory.support.factorybeanregistrysupport.getobjectfromfactorybean(factorybeanregistrysupport.java:103) org.springframework.beans.factory.support.abstractbeanfactory.getobjectforbeaninstance(abstractbeanfactory.java:1514) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:252) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:195) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:699) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:760) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:482) org.springframework.boot.springapplication.refresh(springapplication.java:648) org.springframework.boot.springapplication.run(springapplication.java:311) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:130) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:241) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:186) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:176) org.springframework.xd.dirt.module.moduledeployer.deployandstore(moduledeployer.java:166) org.springframework.xd.dirt.server.containerregistrar.deploymodule(containerregistrar.java:230) org.springframework.xd.dirt.server.containerregistrar.deployjob(containerregistrar.java:399) ... 20 more caused by: org.springframework.xd.dirt.job.batchjobalreadyexistsexception: batch job with the name myjob3 already exists org.springframework.xd.dirt.plugins.job.distributedjoblocator.addjob(distributedjoblocator.java:114) org.springframework.xd.dirt.plugins.job.batchjobregistrybeanpostprocessor.postprocessafterinitialization(batchjobregistrybeanpostprocessor.java:106) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.applybeanpostprocessorsafterinitialization(abstractautowirecapablebeanfactory.java:421) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.postprocessobjectfromfactorybean(abstractautowirecapablebeanfactory.java:1698) org.springframework.beans.factory.support.factorybeanregistrysupport.dogetobjectfromfactorybean(factorybeanregistrysupport.java:164) ... 36 more"],

explanations = [
    'User story is "{case}".\nIF (User story is similar to "create xdcontainer class to start stream server provide optional command line arg to embed the container launcher aka - xd-admin server. xdcontainer.sh --embeddadmin") OR\nIF (User story is similar to "create tcp source module based off si tcp inbound adapter. this will allow for event forwarding that can select among the existing si serialized/deserializer options.") OR\nIF (User story is similar to "create reactormessagehandler for reactor based xd processor/sink modules the module should be flexible to act as a sink as well as a processor. errorhandling will be considered as part of another jira")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "update reactor stream processor to use latest snapshots the code base is changing a bit so using 2.0 m1 for development is stable up until all major jira issues have bee completed. then we should track snapshots in preparation to move to 2.0. m2 when it gets released.") OR\nIF (User story is similar to "using a newer version of a spring-xd dependency is ignored in packaging when creating a new module with a dependeny which has a newer version than the one spring-xd uses (in my example i use jedis 2.6.1 and spring-xd uses jedis 2.5.2) the packaging ignores the dependency. using the solution of spring-boot-maven-plugin doesn\'t help because it will only include what you explicitly add to the include section (transitive dependencies are not included)") OR\nIF (User story is similar to "hsql always started even when using other database i set the config/xd-config.yml properties to use mysql including this profiles: active: defaultmysql when xd admin starts i still see hsql server started and localhost:9393/env shows: "profiles": [ "adminserver" "hsqldb" "default" ]")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create ci for xd-ec2 project automated test will use directly use the deployer class * asserts on basic info of runninginstance ** check that ebs was mounted ** that application was unzipped ** redis and rabbit are running via port checks * http requests on admin port for ** root path ** list of modules * @afterclass that will look for the cluster name and terminate all instances look at live tag in jclouds tests for some additional tactics") OR\nIF (User story is similar to "better approach to handle module execution framework currently when the module doesn\'t need to go through message bus binding the module interface provides \'shouldbind()` method to return false. the shouldbind() is being used in other place where moduletypeconversionplugin is excluded for spark streaming modules. we need a better approach to refactor this. also see the discussion here: https://github.com/spring-projects/spring-xd/pull/1438#discussion_r24150937") OR\nIF (User story is similar to "vary consumer size (ec-db-4) using a single producer message size of 1000 bytes pretch of 100. send 1m messages and increase or decrease so that a given test iteration takes about 2 minutes. vary the number of consumers. measure the msg/sec rate and calculate the data transfer rate in mb/sec. *number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50 during the measurements look at the rabbitmq admin ui and see if the queue is backing up.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to fix the offset management with kafka _source_ module so that i can efficiently perform fetch operation from the given offsets.") OR\nIF (User story is similar to "as a developer i\'d like to migrate the current master branch ci builds to ec2 instances so i can manage them all in one-place reliably.") OR\nIF (User story is similar to "as a user i\'d like to define security definitions so that i can configure entity (rest api) specific group/role access policies.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to troubleshoot the performance issues with rabbit as message bus implementation so i can isolate the bottleneck and fix as appropriate.") OR\nIF (User story is similar to "as a continuation we would like to further investigate spark develop poc and identify the best appropriate design and implementation for xd.") OR\nIF (User story is similar to "as a field engineer i\'d like to have a comparison of spark streaming examples in spring xd so that it is easy to relate from implementation standpoint.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "retrieve information for an aggregate counter todo as part of this (see xd-537): * get rid of so-called service layer in analytics project (doesn\'t do much right now and logic would better live in the \'handler\' imo) * have rest controllers depend on xrepository in all cases") OR\nIF (User story is similar to "retrieve information for a rich gauge todo as part of this (see xd-537): * get rid of so-called service layer in analytics project (doesn\'t do much right now and logic would better live in the \'handler\' imo) * have rest controllers depend on xrepository in all cases") OR\nIF (User story is similar to "retrieve information for a field value counter todo as part of this (see xd-537): * get rid of so-called service layer in analytics project (doesn\'t do much right now and logic would better live in the \'handler\' imo) * have rest controllers depend on xrepository in all cases")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "design for deploying xd on ec2 create enough of a design to develop additional stories.") OR\nIF (User story is similar to "add readme to be included in root directory of distribution should explain basic layout of the distribution") OR\nIF (User story is similar to "create acceptance test for source trigger create a test specific to for the trigger source instead of it being tested with other acceptance tests.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "provide cmdline options validation wherever they come from (cmd line args or env_vars) options such as transport analytics etc should be validated and issues should be reported to users") OR\nIF (User story is similar to "spark streaming plugin shouldn\'t need tap listener cache since spark streaming doesn\'t use zk to keep track taps being created we don\'t need the tap listener cache setup at the container startup.") OR\nIF (User story is similar to "add support to set the read timeout for http request we need to have the ability to set read timeout for http request. this is already implemented here: https://github.com/springsource/rest-shell/")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "spike for transformation of the parsed stream/job definition to a physical deployment model taking into account a deployment manifest the initial parsing of a stream/job definitions into a list of moduledeploymentrequests needs to be transformed into a physical deployment model that takes into account 1) module co-location 2) partitioning 3) number of instances 4) node assignment an potentially other data related to the runtime properties of a module (e.g. concurrency settings) the an external deploymentmanifest will be used to capture this information. a deployment of a stream or job will then need to optionally provide a reference to deployment manifest.") OR\nIF (User story is similar to "custom location for modules.yml not working tried local xd-admin/xd-container after setting {code} export xd_module_config_location=file:./spring-xd-1.0.0.build-snapshot-yarn/config/ {code} have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module also not working for me deploying on yarn this used to work at some point not sure how long ago i actually tested this part - m6/m7? the setting used for yarn deployment: {code} -dxd.module.config.location: "file:./" {code}") OR\nIF (User story is similar to "for file based item reader jobs step/job completion message should have name of file sent on named channel it looks like we don\'t handle deletion of source files currently. we should provide some support for that - maybe there is a way to into spring integration\'s pseudotransactionmanager support: http://docs.spring.io/spring-integration/api/org/springframework/integration/transaction/pseudotransactionmanager.html the *file source* should possibly also support file archival functionality (but that might also be a dedicated processor?). not sure where we want to set the semantic boundaries for the file source.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to document performance benchmark results along with the infrastructure specifics so i can publish the blog for customers/users to use it as a reference while setting up spring xd cluster.") OR\nIF (User story is similar to "as a developer i\'d like to develop a singlenode ? (in a single jvm) implementation of xd admin spi (based on module launcher) so i can run data pipeline use-cases locally.") OR\nIF (User story is similar to "as a developer i\'d like to build isolated boot-based {{modulerunner}} for use in container-managed environments so i can run xd without the hard requirement for running _xd-containers_.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add mqtt source") OR\nIF (User story is similar to "stream documentation review") OR\nIF (User story is similar to "support for get of /taps")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-s developer i\'d like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so i can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.") OR\nIF (User story is similar to "as a user i\'d like to evaluate spring boot dependency upgrades so that i can make sure there aren\'t any side effects or impacts to existing functionalities.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to enhance unit test coverage for {{yarn}} spi so i can continuously evaluate functionalities via ci pipeline.")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "update reactor stream processor to use latest snapshots the code base is changing a bit so using 2.0 m1 for development is stable up until all major jira issues have bee completed. then we should track snapshots in preparation to move to 2.0. m2 when it gets released.") OR\nIF (User story is similar to "tapping a stream with multiple labelled filters causes duplicate messages test case is here: https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/basic_stream_tests#l49 we would expect one message in the counter but get 3.") OR\nIF (User story is similar to "create a test case for insulating environment variables in module property lookup for pr https://github.com/spring-projects/spring-xd/pull/682 see if one can have a test case such that a test module would have a \'path\' property that overlaps with the environment variable. it should never resolve to the real unix/windows path.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "rest api for dsl completion should allow extension the rest api for dsl completion currently returns a list<string>. this prevents future backwards compatible extension. should change to list<completion> where completion has e.g. a "text" property.") OR\nIF (User story is similar to "remove xdcontainer and rename launcherapplication post-boot refactoring. xdcontainer lifecycle methods are not being used. refactor by merging relevant functionality into launcherapplication. rename launcherapplication to containerserverapplication (consistent with adminserverapplication).") OR\nIF (User story is similar to "spark streaming plugin shouldn\'t need tap listener cache since spark streaming doesn\'t use zk to keep track taps being created we don\'t need the tap listener cache setup at the container startup.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to create a example to demonstrate jdbc to hdfs data movement.") OR\nIF (User story is similar to "as a developer i\'d like to brainstorm and investigate various techniques around installation of xd modules from a maven repo so i could define the module {{artifactid}} from cli to have the module downloaded from the repo and installed to a running spring xd runtime.") OR\nIF (User story is similar to "as a user i\'d like to use the java receptor client so i can interact with diego runtime using the java receptor rest apis.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-s user i\'d like to have my modules add/update it\'s current state to eureka so i can use the repository to discover the current sate of the module as needed.") OR\nIF (User story is similar to "as a user i\'d like to have a config parameter preferably in _servers.yml_ file so that i can enable/disable message rates in the cluster view.") OR\nIF (User story is similar to "as a user i\'d like to have the ability to visually explore xd\'s cluster view so that i\'m aware where the components are deployed and how they are connected within the topology.")\nThen \'2\'',
    'User story is "{case}".\nIF (User story is similar to "a batch job can be launched by sending a message on a channel *description* when a job is created in springxd a control-channel for that job is also created. the listener for that channel will receive a message be able to take the jobparameters and other launch information from the message and be able to launch/run the job. note: i can see a few other stories that should probably be made to break this up after writing it. i put estimate of 10 for now but we should break this up. here are some suggestions 1. create data only jobparametersbean equivalent with primitive types 2. create joblauncher source 3. create jobparametertransformer processor 4. refactoring of channelregistrys aliashing to use a callback strategy. *implementation suggestions* job create --name helloworldjob --definition "myjob --somepropertytooverride=somevalue * this would not execute the batch job immediately but instead register the job definition and deploys a joblauncher ? and the job definition to an xd-container. * the xd-container that receives the deploy request message will create a module application context will also create a channel with the channel registry named after the job e.g. :myjob. this should be a pub/sub channel from the point of view of the middleware. from the point of view of the spring integration channel it should ideally be of the executor channel. there is a limitation in the current implementation of channelregistry now as createinbound only creates direct channels. the boolean aliashint should probably be extended to some type of callback that creates a channel. the aliashint was added to address the case of localchannelregistry creating or looking up a queue backed channel or a direct channel. there will be a consumer on the si channel in the module application context that will be responsible for getting the job launch information and launching the job. the launching of the job may need to be explicitly done in a separate thread if direct channels are created by the channelregistry. the contents of the message should be something similar to the current jobparametersbean ? it needs to be easily serializable with simple types via json over the wire. the current impl of jobparametersbean ? has objectmapper so that may require a bit of reworking. the handler of the message will use the joblauncher to launch the job using the information in the jobparametersbean. * the myjob can then be launched by sending a message perhaps this is handled by having a joblauncher source joblauncher [--jobparameters <jobparameters>] [--dateformat <dateformat>] [--numberformat <numberformat>] [--makeunique <makeunique>] > :myjob e.g. with no-args joblauncher > :myjob *how to verify it works* with the test hellospringxdtasklet we should be able to create the job job create --name hellospringxd --definition "myjob" this will not launch the job (as mentioned in the implementation section. it would then be launched by joblauncher > :myjob where joblauncher is a new source. ideally would like to be able to test a data driven triggering. this would require a new file source that doesnt use the file-to-string-transformer but lets a file object be the payload. file | jobparametertransformer > :myjob") OR\nIF (User story is similar to "twitterstream/twittersearch sources fail when deploying on yarn we\'re getting a cnf on org.apache.http.impl.client.httpclients {noformat} 20:07:03556 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2test3.sink.file.1 type=child_added 20:07:03557 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - deploying module \'file\' for stream \'ec2test3\' 20:07:03828 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - deploying module [moduledescriptor@8d11c70 modulename = \'file\' modulelabel = \'file\' group = \'ec2test3\' sourcechannelname = [null] sinkchannelname = [null] index = 1 type = sink parameters = map[\'binary\' -> \'true\' \'mode\' -> \'replace\'] children = list[[empty]]] 20:07:04456 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2test3.source.twitterstream.1 type=child_added 20:07:04456 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - deploying module \'twitterstream\' for stream \'ec2test3\' 20:07:05040 1.1.0.snap info deploymentspathchildrencache-0 server.deploymentlistener - deploying module [moduledescriptor@3ec4f104 modulename = \'twitterstream\' modulelabel = \'twitterstream\' group = \'ec2test3\' sourcechannelname = [null] sinkchannelname = [null] index = 0 type = source parameters = map[\'consumerkey\' -> \'5ynzlmxyvxxzalyhrlrb28u8n\' \'accesstoken\' -> \'2561860742-sfreurr2jxwupbk5eol4ow5gky4hyl12snkwfg5\' \'accesstokensecret\' -> \'481bgnzzdwdj8rvw2hg9irykutzsv1cv1hidpwdht19xe\' \'consumersecret\' -> \'c7zqhjvy5rqm3qs6ruskcrizzwtumrbjbnedch7uyacwjptbvi\'] children = list[[empty]]] 20:07:05871 1.1.0.snap warn deploymentspathchildrencache-0 annotation.annotationconfigapplicationcontext - exception encountered during context initialization - cancelling refresh attempt org.springframework.beans.factory.beancreationexception: error creating bean with name \'org.springframework.integration.x.twitter.twitterstreamchanneladapter#0\' defined in class path resource [config/twitterstream.xml]: cannot resolve reference to bean \'twittertemplate\' while setting constructor argument nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name \'twittertemplate\' defined in class path resource [config/twitterstream.xml]: bean instantiation via constructor failed nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:359) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvevalueifnecessary(beandefinitionvalueresolver.java:108) org.springframework.beans.factory.support.constructorresolver.resolveconstructorarguments(constructorresolver.java:648) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:140) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1131) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1034) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:476) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:303) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:299) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:194) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:762) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:757) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:480) org.springframework.boot.springapplication.refresh(springapplication.java:691) org.springframework.boot.springapplication.run(springapplication.java:321) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:139) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:211) org.springframework.xd.dirt.module.moduledeployer.dodeploy(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:200) org.springframework.xd.dirt.server.deploymentlistener.deploymodule(deploymentlistener.java:363) org.springframework.xd.dirt.server.deploymentlistener.deploystreammodule(deploymentlistener.java:332) org.springframework.xd.dirt.server.deploymentlistener.onchildadded(deploymentlistener.java:179) org.springframework.xd.dirt.server.deploymentlistener.childevent(deploymentlistener.java:147) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name \'twittertemplate\' defined in class path resource [config/twitterstream.xml]: bean instantiation via constructor failed nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:275) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1131) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1034) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:476) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:303) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:299) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:194) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:351) ... 39 more caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.beanutils.instantiateclass(beanutils.java:163) org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:122) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:267) ... 48 more caused by: java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.http.client.httpcomponentsclienthttprequestfactory.<init>(httpcomponentsclienthttprequestfactory.java:72) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator$1.<init>(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator.createrequestfactory(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector.getrequestfactory(clienthttprequestfactoryselector.java:52) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplatewithculledmessageconverters(abstractoauth1apibinding.java:188) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplate(abstractoauth1apibinding.java:169) org.springframework.social.oauth1.abstractoauth1apibinding.<init>(abstractoauth1apibinding.java:70) org.springframework.social.twitter.api.impl.twittertemplate.<init>(twittertemplate.java:79) sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) java.lang.reflect.constructor.newinstance(constructor.java:526) org.springframework.beans.beanutils.instantiateclass(beanutils.java:147) ... 50 more caused by: java.lang.classnotfoundexception: org.apache.http.impl.client.httpclients java.net.urlclassloader$1.run(urlclassloader.java:366) java.net.urlclassloader$1.run(urlclassloader.java:355) java.security.accesscontroller.doprivileged(native method) java.net.urlclassloader.findclass(urlclassloader.java:354) java.lang.classloader.loadclass(classloader.java:425) sun.misc.launcher$appclassloader.loadclass(launcher.java:308) java.lang.classloader.loadclass(classloader.java:358) ... 63 more 20:07:05874 1.1.0.snap error deploymentspathchildrencache-0 boot.springapplication - application startup failed org.springframework.beans.factory.beancreationexception: error creating bean with name \'org.springframework.integration.x.twitter.twitterstreamchanneladapter#0\' defined in class path resource [config/twitterstream.xml]: cannot resolve reference to bean \'twittertemplate\' while setting constructor argument nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name \'twittertemplate\' defined in class path resource [config/twitterstream.xml]: bean instantiation via constructor failed nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:359) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvevalueifnecessary(beandefinitionvalueresolver.java:108) org.springframework.beans.factory.support.constructorresolver.resolveconstructorarguments(constructorresolver.java:648) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:140) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1131) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1034) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:476) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:303) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:299) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:194) org.springframework.beans.factory.support.defaultlistablebeanfactory.preinstantiatesingletons(defaultlistablebeanfactory.java:762) org.springframework.context.support.abstractapplicationcontext.finishbeanfactoryinitialization(abstractapplicationcontext.java:757) org.springframework.context.support.abstractapplicationcontext.refresh(abstractapplicationcontext.java:480) org.springframework.boot.springapplication.refresh(springapplication.java:691) org.springframework.boot.springapplication.run(springapplication.java:321) org.springframework.boot.builder.springapplicationbuilder.run(springapplicationbuilder.java:139) org.springframework.xd.module.core.simplemodule.initialize(simplemodule.java:211) org.springframework.xd.dirt.module.moduledeployer.dodeploy(moduledeployer.java:217) org.springframework.xd.dirt.module.moduledeployer.deploy(moduledeployer.java:200) org.springframework.xd.dirt.server.deploymentlistener.deploymodule(deploymentlistener.java:363) org.springframework.xd.dirt.server.deploymentlistener.deploystreammodule(deploymentlistener.java:332) org.springframework.xd.dirt.server.deploymentlistener.onchildadded(deploymentlistener.java:179) org.springframework.xd.dirt.server.deploymentlistener.childevent(deploymentlistener.java:147) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:509) org.apache.curator.framework.recipes.cache.pathchildrencache$5.apply(pathchildrencache.java:503) org.apache.curator.framework.listen.listenercontainer$1.run(listenercontainer.java:92) com.google.common.util.concurrent.moreexecutors$samethreadexecutorservice.execute(moreexecutors.java:297) org.apache.curator.framework.listen.listenercontainer.foreach(listenercontainer.java:83) org.apache.curator.framework.recipes.cache.pathchildrencache.calllisteners(pathchildrencache.java:500) org.apache.curator.framework.recipes.cache.eventoperation.invoke(eventoperation.java:35) org.apache.curator.framework.recipes.cache.pathchildrencache$10.run(pathchildrencache.java:762) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.executors$runnableadapter.call(executors.java:471) java.util.concurrent.futuretask.run(futuretask.java:262) java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) java.lang.thread.run(thread.java:745) caused by: org.springframework.beans.factory.beancreationexception: error creating bean with name \'twittertemplate\' defined in class path resource [config/twitterstream.xml]: bean instantiation via constructor failed nested exception is org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:275) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.autowireconstructor(abstractautowirecapablebeanfactory.java:1131) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbeaninstance(abstractautowirecapablebeanfactory.java:1034) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.docreatebean(abstractautowirecapablebeanfactory.java:504) org.springframework.beans.factory.support.abstractautowirecapablebeanfactory.createbean(abstractautowirecapablebeanfactory.java:476) org.springframework.beans.factory.support.abstractbeanfactory$1.getobject(abstractbeanfactory.java:303) org.springframework.beans.factory.support.defaultsingletonbeanregistry.getsingleton(defaultsingletonbeanregistry.java:230) org.springframework.beans.factory.support.abstractbeanfactory.dogetbean(abstractbeanfactory.java:299) org.springframework.beans.factory.support.abstractbeanfactory.getbean(abstractbeanfactory.java:194) org.springframework.beans.factory.support.beandefinitionvalueresolver.resolvereference(beandefinitionvalueresolver.java:351) ... 39 more caused by: org.springframework.beans.beaninstantiationexception: failed to instantiate [org.springframework.social.twitter.api.impl.twittertemplate]: constructor threw exception nested exception is java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.beans.beanutils.instantiateclass(beanutils.java:163) org.springframework.beans.factory.support.simpleinstantiationstrategy.instantiate(simpleinstantiationstrategy.java:122) org.springframework.beans.factory.support.constructorresolver.autowireconstructor(constructorresolver.java:267) ... 48 more caused by: java.lang.noclassdeffounderror: org/apache/http/impl/client/httpclients org.springframework.http.client.httpcomponentsclienthttprequestfactory.<init>(httpcomponentsclienthttprequestfactory.java:72) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator$1.<init>(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector$httpcomponentsclientrequestfactorycreator.createrequestfactory(clienthttprequestfactoryselector.java:77) org.springframework.social.support.clienthttprequestfactoryselector.getrequestfactory(clienthttprequestfactoryselector.java:52) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplatewithculledmessageconverters(abstractoauth1apibinding.java:188) org.springframework.social.oauth1.abstractoauth1apibinding.createresttemplate(abstractoauth1apibinding.java:169) org.springframework.social.oauth1.abstractoauth1apibinding.<init>(abstractoauth1apibinding.java:70) org.springframework.social.twitter.api.impl.twittertemplate.<init>(twittertemplate.java:79) sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) java.lang.reflect.constructor.newinstance(constructor.java:526) org.springframework.bean...") OR\nIF (User story is similar to "remotefiletohadooptests fails on 1.1.x this error surfaced recently as a result of a fix to a bug in hostnotwindowsrule which disabled this test in all environments. now the test has been reactivated it is failing on the 1.1.x branch. the test runs ok on master. {noformat} encountered an error executing step step1-master in job job org.springframework.messaging.messagedeliveryexception: failed to send message to channel \'null\' nested exception is java.lang.illegalstateexception: threadpooltaskexecutor not initialized org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:292) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.xd.dirt.integration.bus.local.localmessagebus$3.handlemessage(localmessagebus.java:262) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:115) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:45) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:95) org.springframework.integration.handler.abstractmessageproducinghandler.sendoutput(abstractmessageproducinghandler.java:248) org.springframework.integration.handler.abstractmessageproducinghandler.produceoutput(abstractmessageproducinghandler.java:171) org.springframework.integration.handler.abstractmessageproducinghandler.sendoutputs(abstractmessageproducinghandler.java:119) org.springframework.integration.handler.abstractreplyproducingmessagehandler.handlemessageinternal(abstractreplyproducingmessagehandler.java:105) org.springframework.integration.handler.abstractmessagehandler.handlemessage(abstractmessagehandler.java:78) org.springframework.integration.dispatcher.abstractdispatcher.tryoptimizeddispatch(abstractdispatcher.java:116) org.springframework.integration.dispatcher.unicastingdispatcher.dodispatch(unicastingdispatcher.java:101) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:97) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:239) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:115) org.springframework.messaging.core.genericmessagingtemplate.dosend(genericmessagingtemplate.java:45) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:95) org.springframework.messaging.core.abstractmessagesendingtemplate.send(abstractmessagesendingtemplate.java:85) org.springframework.batch.integration.partition.messagechannelpartitionhandler.handle(messagechannelpartitionhandler.java:224) org.springframework.batch.core.partition.support.partitionstep.doexecute(partitionstep.java:106) org.springframework.batch.core.step.abstractstep.execute(abstractstep.java:198) org.springframework.batch.core.job.simplestephandler.handlestep(simplestephandler.java:148) org.springframework.batch.core.job.flow.jobflowexecutor.executestep(jobflowexecutor.java:64) org.springframework.batch.core.job.flow.support.state.stepstate.handle(stepstate.java:67) org.springframework.batch.core.job.flow.support.simpleflow.resume(simpleflow.java:165) org.springframework.batch.core.job.flow.support.simpleflow.start(simpleflow.java:144) org.springframework.batch.core.job.flow.flowjob.doexecute(flowjob.java:134) org.springframework.batch.core.job.abstractjob.execute(abstractjob.java:304) org.springframework.batch.core.launch.support.simplejoblauncher$1.run(simplejoblauncher.java:135) org.springframework.core.task.synctaskexecutor.execute(synctaskexecutor.java:50) org.springframework.batch.core.launch.support.simplejoblauncher.run(simplejoblauncher.java:128) org.springframework.batch.integration.x.remotefiletohadooptests.testsimple(remotefiletohadooptests.java:161) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:483) org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50) org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:47) org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:26) org.springframework.test.context.junit4.statements.runbeforetestmethodcallbacks.evaluate(runbeforetestmethodcallbacks.java:73) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.springframework.test.context.junit4.statements.runaftertestmethodcallbacks.evaluate(runaftertestmethodcallbacks.java:82) org.springframework.test.context.junit4.statements.springrepeat.evaluate(springrepeat.java:73) org.junit.runners.parentrunner.runleaf(parentrunner.java:325) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:217) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:83) org.junit.runners.parentrunner$3.run(parentrunner.java:290) org.junit.runners.parentrunner$1.schedule(parentrunner.java:71) org.junit.runners.parentrunner.runchildren(parentrunner.java:288) org.junit.runners.parentrunner.access$000(parentrunner.java:58) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268) org.springframework.test.context.junit4.statements.runbeforetestclasscallbacks.evaluate(runbeforetestclasscallbacks.java:61) org.springframework.test.context.junit4.statements.runaftertestclasscallbacks.evaluate(runaftertestclasscallbacks.java:68) org.springframework.xd.test.hostnotwindowsrule$1.evaluate(hostnotwindowsrule.java:38) org.junit.rules.runrules.evaluate(runrules.java:20) org.junit.runners.parentrunner.run(parentrunner.java:363) org.springframework.test.context.junit4.springjunit4classrunner.run(springjunit4classrunner.java:163) org.junit.runner.junitcore.run(junitcore.java:137) com.intellij.junit4.junit4ideatestrunner.startrunnerwithargs(junit4ideatestrunner.java:74) com.intellij.rt.execution.junit.junitstarter.preparestreamsandstart(junitstarter.java:211) com.intellij.rt.execution.junit.junitstarter.main(junitstarter.java:67) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) java.lang.reflect.method.invoke(method.java:483) com.intellij.rt.execution.application.appmain.main(appmain.java:134) caused by: java.lang.illegalstateexception: threadpooltaskexecutor not initialized org.springframework.util.assert.state(assert.java:385) org.springframework.scheduling.concurrent.threadpooltaskexecutor.getthreadpoolexecutor(threadpooltaskexecutor.java:221) org.springframework.scheduling.concurrent.threadpooltaskexecutor.execute(threadpooltaskexecutor.java:252) org.springframework.integration.dispatcher.unicastingdispatcher.dispatch(unicastingdispatcher.java:89) org.springframework.integration.channel.abstractsubscribablechannel.dosend(abstractsubscribablechannel.java:77) org.springframework.integration.channel.abstractmessagechannel.send(abstractmessagechannel.java:277) ... 76 more java.lang.assertionerror: expected :exitcode=completedexitdescription= actual :exitcode=failedexitdescription= <click to see difference> org.junit.assert.fail(assert.java:88) org.junit.assert.failnotequals(assert.java:834) org.junit.assert.assertequals(assert.java:118) org.junit.assert.assertequals(assert.java:144) org.springframework.batch.integration.x.remotefiletohadooptests.testsimple(remotefiletohadooptests.java:162) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50) org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:47) org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:26) org.springframework.test.context.junit4.statements.runbeforetestmethodcallbacks.evaluate(runbeforetestmethodcallbacks.java:73) org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) org.springframework.test.context.junit4.statements.runaftertestmethodcallbacks.evaluate(runaftertestmethodcallbacks.java:82) org.springframework.test.context.junit4.statements.springrepeat.evaluate(springrepeat.java:73) org.junit.runners.parentrunner.runleaf(parentrunner.java:325) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:217) org.springframework.test.context.junit4.springjunit4classrunner.runchild(springjunit4classrunner.java:83) org.junit.runners.parentrunner$3.run(parentrunner.java:290) org.junit.runners.parentrunner$1.schedule(parentrunner.java:71) org.junit.runners.parentrunner.runchildren(parentrunner.java:288) org.junit.runners.parentrunner.access$000(parentrunner.java:58) org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268) org.springframework.test.context.junit4.statements.runbeforetestclasscallbacks.evaluate(runbeforetestclasscallbacks.java:61) org.springframework.test.context.junit4.statements.runaftertestclasscallbacks.evaluate(runaftertestclasscallbacks.java:68) org.springframework.xd.test.hostnotwindowsrule$1.evaluate(hostnotwindowsrule.java:38) org.junit.rules.runrules.evaluate(runrules.java:20) org.junit.runners.parentrunner.run(parentrunner.java:363) org.springframework.test.context.junit4.springjunit4classrunner.run(springjunit4classrunner.java:163) org.junit.runner.junitcore.run(junitcore.java:137) com.intellij.junit4.junit4ideatestrunner.startrunnerwithargs(junit4ideatestrunner.java:74) com.intellij.rt.execution.junit.junitstarter.preparestreamsandstart(junitstarter.java:211) com.intellij.rt.execution.junit.junitstarter.main(junitstarter.java:67) sun.reflect.nativemethodaccessorimpl.invoke0(native method) sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) com.intellij.rt.execution.application.appmain.main(appmain.java:134) {noformat}")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "merge module.type and moduletype also likely rename remove or replace that module (maybe can be supplanted by moduledescriptor when used in the refactored parser). also considering the "url" property is not necessary (vestige of the prototype) all we\'d be left with here is the module name and type which are used to identify a module uniquely. therefore this module could be renamed to modulekey or something. it could be used within the streamdefinition itself (e.g. getdescriptor(modulekey)).") OR\nIF (User story is similar to "change module placeholder names and remove context:property-placeholder usage e.g. rabbit.xml source. <context:property-placeholder location="${xd.config.home}/${configproperties:rabbit}.properties" ignore-resource-not-found="true" /> would be removed and <rabbit:connection-factory id="rabbitconnectionfactory" host="${host:${spring.rabbitmq.host:localhost}}" port="${port:${spring.rabbitmq.port:5672}}" virtual-host="${vhost:${spring.rabbitmq.virtualhost:/}}" username="${username:${spring.rabbitmq.username:guest}}" password="${password:${spring.rabbitmq.password:guest}}"/> would look like port="${port}" and a property file in the module directory or pojo in the module lib would specify the default value of the port. for pojo it would be options_class = org.springframework.xd.dirt.modules.metadata.rabbitsourceoptionsmetadata for property file it would be option.port.default=5672 option.port.description="cool port number" this needs to be consistently done across all the modules.") OR\nIF (User story is similar to "user should be able to view the list of all the job definitions create a tab view with tabs job definitions ? runtime jobs ? (deployed jobs? job instances ? (is runtime jobs a better name here?) and job executions ?. on clicking job definitions ? tab we can have a table view of job definitions. since we bootstrap.js we can have a responsive table layout to list all the available job definitions. at the rest layer /jobs ? provides the list of job definitions. we can expand the jobscontroller list()s queryoptions to add more criteria (especially to list jobdefinitions status (deployed/undeployed). also this is the ui implementation for the shell command job list ?")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "redis sink: better handling of module options/profile activation please see the discussion here: https://github.com/spring-projects/spring-xd/pull/1188#discussion_r18788216") OR\nIF (User story is similar to "create runtimemoduledescriptor that represents runtime module instance see this for more info: https://github.com/spring-projects/spring-xd/pull/1021/files#r14611854") OR\nIF (User story is similar to "documentation for "http | file" processing put on the guide as a section in an \'input sources\' wiki page. https://github.com/springsource/spring-xd/wiki/guidegettingstarted")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "ssl config for rabbitmessagebus connections is ignored") OR\nIF (User story is similar to "test against spring boot snapshot build") OR\nIF (User story is similar to "add kafka-based implementation for abstractsinglenodestreamdeploymentintegrationtests")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i want spring xds message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesnt happen when a container crashes and/or its redeployed.") OR\nIF (User story is similar to "as a user i want to configure docker xd containers using service discovery so that i can have tools to manage how processes and services in a cluster can find and talk to one another.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to add support for having different binder types for module\'s channels so i can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "dead letter is not created on all rabbitmq queues for partionned stream hi if i use the module.[name].producer.paritionkeyexpression and the module as also autobinddlg enabled the creates rabbbitmq queues do not have the deadletter policy. the first queue has it (xdbus.<stream>.0-0) but others do not have it (xdbus.<stream>.0-n). thanks mickal") OR\nIF (User story is similar to "configurable response status code in http source we have a use case where we need the http source module to return a 204 status instead of the 200 status that is currently returned. there may be other status codes that it would be useful to be able to return. a simple additional option on the module would allow this to be configured.") OR\nIF (User story is similar to "update documentation related to transport and controltransport e.g. need to update this section (maybe others): https://github.com/spring-projects/spring-xd/wiki/running-distributed-mode remove all mentions of control bus and replace any mentions of the --transport cmd line arg with the xd.transport property in yml.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "tcp-client source module throws classnotfoundexception *version:* xd: 1.1 m1 *problem:* trying to use tcp-client source module and observing an exception while deploying the stream. *stream definition:* {code:xml} curl --data name=dummy-firehose --data definition=\'tcp-client --decoder=lf --port=8080 | log\' --data deploy=true http://localhost:9393/streams/definitions {"name":"dummy-firehose""status":null"definition":"tcp-client --decoder=lf --port=8080 | log""_links":{"self":{"href":"http://localhost:9393/streams/dummy-firehose"}}} {code} the same curl command works fine against xd 1.0.1 release.") OR\nIF (User story is similar to "job in unknown state after run long sqooptasklet hello guys i hope you are doing good. i found a problem when i try run long sqoop imports (4 hours or more). for some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems. 2015-10-17t03:04:03-0400 1.2.0.release error simpleasynctaskexecutor-4 step.abstractstep - encountered an error saving batch meta data for step import-logs in job ingestion-flow. this job is now in an unknown state and should not be restarted. please see attached log file for more details. could you please let me know if you need other details to find what is the problem? thanks in advance hctor") OR\nIF (User story is similar to "spike: determine options for configuring shared module dependencies h2. narrative as a developer i\'d like to be able to configure common dependencies for the entire environment. an example could be that i use mysql for my databases. i want to be able to configure the mysql driver once and have all modules use it. h2. back story spring batch uses a database to store job state (the job repository). this is a shared resource across all jobs (both custom developed and ootb). in order to support ootb jobs we\'ll need to have a way for users to provide the db driver to each module. ideally this would be possible without requiring that each of our ootb modules be repackaged.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create config support for redis we would like to have redis driven from a config property file under xd_home.") OR\nIF (User story is similar to "remove spring-xd-codec from spring xd source tree and build replace with spring-cloud-streams (or spring-cloud-streams-codec) dependency") OR\nIF (User story is similar to "shell - \'makeunique\' job parameter is true by default currently the shell assumes that the \'makeunique\'job parameter is by default *false*. that is not true. as a consequence the parameter has currently no impact/does not work.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create shell command for restarting a specific job instance") OR\nIF (User story is similar to "add dependencies needed for running a job using hbase") OR\nIF (User story is similar to "create ci process for xd build bamboo based")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "ensure dsm matrix is diagonal") OR\nIF (User story is similar to "add command for tap creation") OR\nIF (User story is similar to "add batchmbeanexporter for batch modules")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have a flexible rxjava module so that it can as a processor.") OR\nIF (User story is similar to "as a developer i\'d like to split up spring-xd dependencies to more fine-grained so i can get the ones "below the line" down to spring-bus-* instead of spring-xd-* bundle.") OR\nIF (User story is similar to "as a developer i\'d like to move \'serialization codec\' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to migrate the current master branch ci builds to ec2 instances so i can manage them all in one-place reliably.") OR\nIF (User story is similar to "as a developer i\'d like to fix the offset management with kafka _source_ module so that i can efficiently perform fetch operation from the given offsets.") OR\nIF (User story is similar to "as a user i\'d like to define security definitions so that i can configure entity (rest api) specific group/role access policies.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "provide user friendly messages when dealing with invalid gemfire sink xd:>stream create --name testgemfire --definition "http --port=8887 | gemfire" 16:20:28503 warn spring shell client.resttemplate:524 - post request for "http://localhost:8080/streams" resulted in 500 (internal server error) invoking error handler command failed org.springframework.xd.rest.client.impl.springxdexception: org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name \'region\' defined in null: could not resolve placeholder \'regionname\' in string value "${regionname}"") OR\nIF (User story is similar to "create modulefactory modulefactory is responsible for determining how the module application context is created from available sources at the resource location exposed via the moduledefinition. the factory creates the application context and creates a simplemodule or compositemodule as appropropriate. for example if an xml file is present it is assumed to be the bean definition file used to create a cxmlac. if no xml file is present inspect the properties file for the existence of well-known properties such as base-package-name for component scanning for an @configuration or a module-class-name for an annotated pojo based module (see xd-2100). the mf is also responsible for creating composite modules. also includes module refactoring add getapplicationcontext() and probably setapplicationcontext(). also refactor compositemodule code to use boot springapplicationbuilder") OR\nIF (User story is similar to "rest - listing of fieldvaluecounter not working http://localhost:8080/metrics/field-value-counters {code} <errors xmlns:atom="http://www.w3.org/2005/atom"> <error logref="httpmessagenotwritableexception"> <message> could not marshal [pagedresource { content: [links: [<http://localhost:8080/metrics/field-value-counters/hashtags>rel="self"]] metadata: metadata { number: 0 total pages: 1 total elements: 1 size: 0 } links: [] }]: null nested exception is javax.xml.bind.marshalexception - with linked exception: [com.sun.istack.saxexception2: unable to marshal type "org.springframework.xd.rest.client.domain.metrics.metricresource" as an element because it is not known to this context.] </message> </error> </errors> {code}")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to add support to _flush_ offsets intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer.") OR\nIF (User story is similar to "as a developer i\'d like to resolve remaining gaps wrt ci pipelines for data flow and the family so i can continuously evaluate functionalities on every commit.") OR\nIF (User story is similar to "as a developer i\'d like to study the state management requirements so i can brainstorm and identify the design to natively add _stateful_ stream processing support in xd.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring xd user i\'d like to use the latest releases of {{hdp}}/{{phd}} distros so i can leverage the latest features to create pipelines involving {{hdfs}}.") OR\nIF (User story is similar to "as a user i\'d like to have the option to configure default access control for endpoints so that i can grant access by _admin_ or _viewer_ roles.") OR\nIF (User story is similar to "as a developer i\'d like to refactor stream/job definition repository so i can decouple from module deployment concerns.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (e.g. during deployment of streams/jobs) ideally i would like to have this addressed on the server-side as well. it would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system. we could then use those to notify connected ui clients.") OR\nIF (User story is similar to "as a user i\'d like to have a redis based _aggregation_ over field-value counters so that i can continuously write the aggregation in redis as we ingest more data. *scope:* * port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/old---aggregate-field-value-counters]. * identify gaps * update reference documentation") OR\nIF (User story is similar to "as a user i\'d like to have the option to extend the default message handling behavior for http source-module so that i can override the settings via _servers.yml_ to control the default message size. *notes:* the adapter currently has that hard-coded (1mb limit) in the httpchunkaggregator. we will have to expose this property for overrides. [related pr|https://github.com/spring-projects/spring-xd/pull/1367].")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-d developer i\'d like to add support for hadoop commands in shell so i can use it to query the hadoop file system.") OR\nIF (User story is similar to "as a spring xd user i\'d like to create streaming pipelines so i can take advantage of latest specs from both xd and spark/spark streaming.") OR\nIF (User story is similar to "as a user i\'d like to refer to \'job orchestration\' documentation so i can use it as guideline for building batch workflows.")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "update creating a processor module section to use shell commands instead of curl "test the deployed module" sub-section uses curl.") OR\nIF (User story is similar to "update documentation for kafka sources include new features added by using spring integration kafka m3") OR\nIF (User story is similar to "add ci acceptance test for 1.2.x need acceptance tests to run on the 1.2.x branch. needs to be setup as a child of the publish 1.2.x")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "change accepted-media-types to accpted-content-types") OR\nIF (User story is similar to "add test for filejdbc to test scripts the filejdbc jobs isn\'t included in the test scripts") OR\nIF (User story is similar to "updated xd-ec2 xd deployment for 1.2 mask out all properties for xd-ec2")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "shell - \'makeunique\' job parameter is true by default currently the shell assumes that the \'makeunique\'job parameter is by default *false*. that is not true. as a consequence the parameter has currently no impact/does not work.") OR\nIF (User story is similar to "spring xd using redis as data transport is failing to start in ci acceptance test.") OR\nIF (User story is similar to "update build script to use correct version of spring-data-hadoop based on distro")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "improvements to executions tab 1. add quick filter 2. the table should have columns for name | instance | execution id getting the name might require a bit of extra work given some limitations with json serialization and cycles in the current object returned from spring batch. 3. the restart action should appear only if the job is restartable and the status was failed.") OR\nIF (User story is similar to "refactor job deploy to go through xdcontroller.deploy(name) job deployment currently goes through an overloaded version of deploy() that takes 4 parameters. this prohibits job handling code from benefiting from common behavior (and eg currently breaks deployall) given that the 3 additional parameters are in fine handled as module parameters let\'s push them to the job definition known at creation time rather than at deployment time (as it does not really make sense to change those between deploys)") OR\nIF (User story is similar to "routing json arrays when i create following stream i am able to route json messages. but if i send same message as an array its not working. is it possible to do something about it? stream create --name reference-data-import --definition "rabbit --outputtype=text/plain | router --expression=#jsonpath(payload\'$.rejected\').contains(\'true\')?\'queue:rejected\':\'queue:accepted\'" --deploy")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "investigate module classloader leakage see report at https://github.com/spring-projects/spring-xd/issues/661 this should not happen as the module holds the classes that hold the classloader but who knows. an integration test that verifies this would be nice albeit tricky.") OR\nIF (User story is similar to "handle \'deploying\' state at the admin ui when the job is in "deploying" state until we decide whether the job is actually "deployed" or "failed"/"incomplete" there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue). we could either disable both "deploy"/"undeploy" until the state changes from "deploying"?") OR\nIF (User story is similar to "create doc section about quotes handling document the different "onion layers" that come in play with regard to quoting and escaping (shell xd-parser spel expressions in some cases) and provide practical examples to common scenarios")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a pm i\'d like to have the smart grid demo (from s1-2014) ported into spring xd samples repo.") OR\nIF (User story is similar to "as a developer i\'d like to build _spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.") OR\nIF (User story is similar to "as a developer i\'d like to bench test cases around {{tuplebuilder}} so i can identify the bottlenecks and tune for performance optimizations.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to document performance benchmark results along with the infrastructure specifics so i can publish the blog for customers/users to use it as a reference while setting up spring xd cluster.") OR\nIF (User story is similar to "as a pm i\'d like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf. benchmarks and ref. architectures so that it\'s easy for anyone to quickly get up and running on xd.") OR\nIF (User story is similar to "as a developer i\'d like to develop a singlenode ? (in a single jvm) implementation of xd admin spi (based on module launcher) so i can run data pipeline use-cases locally.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "failure to get message rates for modules with labels. start xd distributed xd with specified management port and xd: messageratemonitoring: enabled: true in servers.yml to gather stats. create stream {{file | log}} deploy it navigate to containers tab in admin ui. rates are shown correctly. create stream {{myfile: file | log}} deploy it navigate to containers tab in admin ui - none of the message rates are shown. open browser dev tools console and note 500 error response. spring-xd-dirt -> containerscontroller lines 109-112 creates request to get message rates for modules. typical request: {{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=log.*component=*name=input/meansendrate}} typical response: {code:json} {"request":{"mbean":"xd.str4:component=*module=log.1name=input""attribute":"meansendrate""type":"read"}"value":{"xd.str4:component=messagechannelmodule=log.1name=input":{"meansendrate":0.0}}"timestamp":1428675070"status":200} {code} for file module with label `myfile` the request is: {{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=myfile.*component=*name=output/meansendrate}} response: {code:json} {"mbean":"xd.str4:component=*module=myfile.1name=output""attribute":"meansendrate""type":"read"}"stacktrace":"javax.management.instancenotfoundexception: no mbean with pattern xd.str4:module=myfile.1component=*name=output found for reading attributes\\n\\tat org.jolokia.handler.readhandler.searchmbeans(readhandler.java:160)\\n\\tat org.jolokia.handler.readhandler.fetchattributesformbeanpattern(readhandler.java:126)\\n\\tat org.jolokia.handler.readhandler.dohandlerequest(readhandler.java:116)\\n\\tat org.jolokia.handler.readhandler.dohandlerequest(readhandler.java:37)\\n\\tat org.jolokia.handler.jsonrequesthandler.handlerequest(jsonrequesthandler.java:160)\\n\\tat org.jolokia.backend.mbeanserverhandler.dispatchrequest(mbeanserverhandler.java:97)\\n\\tat org.jolokia.backend.localrequestdispatcher.dispatchrequest(localrequestdispatcher.java:98)\\n\\tat org.jolokia.backend.backendmanager.callrequestdispatcher(backendmanager.java:411)\\n\\tat org.jolokia.backend.backendmanager.handlerequest(backendmanager.java:158)\\n\\tat org.jolokia.http.httprequesthandler.executerequest(httprequesthandler.java:197)\\n\\tat org.jolokia.http.httprequesthandler.handlegetrequest(httprequesthandler.java:86)\\n\\tat org.jolokia.http.agentservlet$4.handlerequest(agentservlet.java:435)\\n\\tat org.jolokia.http.agentservlet.handlesecurely(agentservlet.java:320)\\n\\tat org.jolokia.http.agentservlet.handle(agentservlet.java:291)\\n\\tat org.jolokia.http.agentservlet.doget(agentservlet.java:252)\\n\\tat javax.servlet.http.httpservlet.service(httpservlet.java:735)\\n\\tat javax.servlet.http.httpservlet.service(httpservlet.java:848)\\n\\tat org.springframework.web.servlet.mvc.servletwrappingcontroller.handlerequestinternal(servletwrappingcontroller.java:158)\\n\\tat org.springframework.web.servlet.mvc.abstractcontroller.handlerequest(abstractcontroller.java:146)\\n\\tat org.springframework.boot.actuate.endpoint.mvc.jolokiamvcendpoint.handle(jolokiamvcendpoint.java:130)\\n\\tat sun.reflect.generatedmethodaccessor82.invoke(unknown source)\\n\\tat sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)\\n\\tat java.lang.reflect.method.invoke(method.java:483)\\n\\tat org.springframework.web.method.support.invocablehandlermethod.doinvoke(invocablehandlermethod.java:221)\\n\\tat org.springframework.web.method.support.invocablehandlermethod.invokeforrequest(invocablehandlermethod.java:137)\\n\\tat org.springframework.web.servlet.mvc.method.annotation.servletinvocablehandlermethod.invokeandhandle(servletinvocablehandlermethod.java:110)\\n\\tat org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.invokehandlemethod(requestmappinghandleradapter.java:777)\\n\\tat org.springframework.web.servlet.mvc.method.annotation.requestmappinghandleradapter.handleinternal(requestmappinghandleradapter.java:706)\\n\\tat org.springframework.web.servlet.mvc.method.abstracthandlermethodadapter.handle(abstracthandlermethodadapter.java:85)\\n\\tat org.springframework.web.servlet.dispatcherservlet.dodispatch(dispatcherservlet.java:943)\\n\\tat org.springframework.web.servlet.dispatcherservlet.doservice(dispatcherservlet.java:877)\\n\\tat org.springframework.web.servlet.frameworkservlet.processrequest(frameworkservlet.java:966)\\n\\tat org.springframework.web.servlet.frameworkservlet.doget(frameworkservlet.java:857)\\n\\tat javax.servlet.http.httpservlet.service(httpservlet.java:735)\\n\\tat org.springframework.web.servlet.frameworkservlet.service(frameworkservlet.java:842)\\n\\tat javax.servlet.http.httpservlet.service(httpservlet.java:848)\\n\\tat org.eclipse.jetty.servlet.servletholder.handle(servletholder.java:684)\\n\\tat org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1496)\\n\\tat org.springframework.security.web.filterchainproxy.dofilterinternal(filterchainproxy.java:186)\\n\\tat org.springframework.security.web.filterchainproxy.dofilter(filterchainproxy.java:160)\\n\\tat org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1467)\\n\\tat org.eclipse.jetty.servlet.servlethandler.dohandle(servlethandler.java:499)\\n\\tat org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:137)\\n\\tat org.eclipse.jetty.security.securityhandler.handle(securityhandler.java:557)\\n\\tat org.eclipse.jetty.server.session.sessionhandler.dohandle(sessionhandler.java:231)\\n\\tat org.eclipse.jetty.server.handler.contexthandler.dohandle(contexthandler.java:1086)\\n\\tat org.eclipse.jetty.servlet.servlethandler.doscope(servlethandler.java:428)\\n\\tat org.eclipse.jetty.server.session.sessionhandler.doscope(sessionhandler.java:193)\\n\\tat org.eclipse.jetty.server.handler.contexthandler.doscope(contexthandler.java:1020)\\n\\tat org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:135)\\n\\tat org.eclipse.jetty.server.handler.handlerwrapper.handle(handlerwrapper.java:116)\\n\\tat org.eclipse.jetty.server.server.handle(server.java:370)\\n\\tat org.eclipse.jetty.server.abstracthttpconnection.handlerequest(abstracthttpconnection.java:494)\\n\\tat org.eclipse.jetty.server.abstracthttpconnection.headercomplete(abstracthttpconnection.java:971)\\n\\tat org.eclipse.jetty.server.abstracthttpconnection$requesthandler.headercomplete(abstracthttpconnection.java:1033)\\n\\tat org.eclipse.jetty.http.httpparser.parsenext(httpparser.java:644)\\n\\tat org.eclipse.jetty.http.httpparser.parseavailable(httpparser.java:235)\\n\\tat org.eclipse.jetty.server.asynchttpconnection.handle(asynchttpconnection.java:82)\\n\\tat org.eclipse.jetty.io.nio.selectchannelendpoint.handle(selectchannelendpoint.java:667)\\n\\tat org.eclipse.jetty.io.nio.selectchannelendpoint$1.run(selectchannelendpoint.java:52)\\n\\tat org.eclipse.jetty.util.thread.queuedthreadpool.runjob(queuedthreadpool.java:608)\\n\\tat org.eclipse.jetty.util.thread.queuedthreadpool$3.run(queuedthreadpool.java:543)\\n\\tat java.lang.thread.run(thread.java:744)\\n""error_type":"javax.management.instancenotfoundexception""error":"javax.management.instancenotfoundexception : no mbean with pattern xd.str4:module=myfile.1component=*name=output found for reading attributes""status":404} {code} this reponse results in jsonexception in the containerscontroller because it\'s missing \'value\' property. the module id is somewhat problematic in the request: {{xd.str4:module=log.*}} index is {{\\*}} but should be index within the stream also node type (source/sink/processor) is missing. therefore stream {{mail | mail}} is suffering from the same problem. would be nice to have some sort of a bulk request to query more than one module for input/output message rates such that i could get all message rates for modules in the stream.") OR\nIF (User story is similar to "add functionality to provision ec2 instance and mount ebs * the application should ** create a spring application context. ** should take a command line parameter --config that will point to a property file with key/value pairs specified below. by default the file xd-ec2.properties will be looked for on the classpath ** associate ebs shared volume for each machine instance * packaging ** use gradle application plugin to generate a bin directory with a script to start the application. seehttp://www.gradle.org/docs/current/userguide/application_plugin.html ** the config file xd-ec2.properties should be in a directory (ideally a \'config\' directory parallel to \'bin\' and will be loaded by the application by default - loading via the cp is probably the easiest way. ** create a pojo to easily reference these properties vs. using a raw java properties object. how to verify it works * integration testing ** create junit based tests. jclouds itself has extensive testing can look at those for structure. ** verify what you created has been installed. ** verify ports are open instance information ** ebs of 50gb base for each instance. * report successful and failed instances. key-value pairs in configuration file properties may include: * cluster-name= a name describing the cluster you are creating * aws-access-keys= the access key assigned to you by admin * aws-secret-key= the secret key assigned to you by admin * private-key-file= the private key file assigned to you by admin. used for ssh-ing into * multi-node=true/false if true then installer will run the number of nodes as enumerated in the number-nodes property value. if false the installer will start a single node server * number-nodes=the number of nodes(containers) to deploy for this cluster. value is an integer > 0 * machine-size=the size of machines to be assigned for admin and nodes. small medium large * redis-port=6379 * rabbit-port=5279 * xd-dist-url=the url to download the xd to install. for example: http://blahblahblah.zip * ami = the ami image to use for your cluster. for example: ami-dfadsfdadf") OR\nIF (User story is similar to "return the list of jobs from spring-batch-admin the current xd jobcontroller that returns a list of jobs has quite a different api signature than what is in spring-batch-admin. to simplify the ui development a new controller jobadmincontroller will be created that lives under the request path /jobs/admin. the goal is to return a the current json structure of spring-batch-admin /jobs/ request and make only minimal changes to implementations of controllers as found . see #1 in the doc (link to json output doc for spring batch). *implementation suggestions* there will need to be some springmvc setup that will enable the current style of spring-batch-admin controller requests to co-exist with the existing xd controllers e.g. the use of .json for json marshalling etc. this may in fact be the bulk of time spend in this first story to integration spring-batch-admin style controllers into xd. a new controller named jobadmincontroller that in the spring-xd-dirt project in the package org.springframework.xd.dirt.rest. the jobadmincontroller will not need to follow the same hateoas style as the other controllers at this time. the current controller in spring batch admin looks like this {code} @requestmapping(value = "/jobs" method = requestmethod.get) public void jobs(modelmap model @requestparam(defaultvalue = "0") int startjob @requestparam(defaultvalue = "20") int pagesize) { int total = jobservice.countjobs() tableutils.addpagination(model total startjob pagesize "job") collection<string> names = jobservice.listjobs(startjob pagesize) list<jobinfo> jobs = new arraylist<jobinfo>() for (string name : names) { int count = 0 try { count = jobservice.countjobexecutionsforjob(name) } catch (nosuchjobexception e) { // shouldn\'t happen } boolean launchable = jobservice.islaunchable(name) boolean incrementable = jobservice.isincrementable(name) jobs.add(new jobinfo(name count null launchable incrementable)) } model.addattribute("jobs" jobs) } {code} something like {code} @requestmapping(value = "/jobs/admin/jobs" method = requestmethod.get) public void jobs(modelmap model @requestparam(defaultvalue = "0") int startjob @requestparam(defaultvalue = "20") int pagesize) { // we do *not* have to query the spring batch admin jobservice ? at this time but // instead use the jobdeployer to get information about jobs launched by spring xd iterable<jobdefinition> jobdefinitions = dobdeployer.findall() // copy these over to a list<jobinfo> as best as possible copy name over. // not sure how description is getting added to the json // pari } {code} *how to verify it works* a sample job needs to be in the modules/job directory. jobcommandtests/abstractjobintegrationtest seems to have what is need to stage a job for")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "add accepted type logic to module a module can declare one ore more payload types it will accept. this will inform the runtime re. automatic payload conversion. this can be done in the module xml configuration and processed by streamplugin") OR\nIF (User story is similar to "use dot as the composed module option separator following merge of https://github.com/spring-projects/spring-xd/pull/601 use dot as the separator for a composed module option. need change to the parser to accept dots") OR\nIF (User story is similar to "need to create a persistent-job-registry in order to hook up the to get access to all the jobs available the job registry has to be shared. currently the only implmentation is is the mapjobregistry. ==== testability. ==== the admin will need to be see all jobs created by its containers.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to isolate the hadoop tests in a different project so that the dirt project doesn\'t have to depend upon thus eliminating the incorrect cp file generation in eclipse.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to upgrade {{receptor-client}} to comply with latest {{receptor}} api changes so i can sync-up and take advantage of the recent improvements.") OR\nIF (User story is similar to "as a developer i\'d like to add {{undeployed}} status for yarn spi so i can represent the correct status instead of the current {{unknown}} state.")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to document performance benchmark results along with the infrastructure specifics so i can publish the blog for customers/users to use it as a reference while setting up spring xd cluster.") OR\nIF (User story is similar to "as a developer i\'d like to build isolated boot-based {{modulerunner}} for use in container-managed environments so i can run xd without the hard requirement for running _xd-containers_.") OR\nIF (User story is similar to "as a pm i\'d like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf. benchmarks and ref. architectures so that it\'s easy for anyone to quickly get up and running on xd.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "encapsulate list of moduledeploymentrequests within a parsed stream result object currently the parser returns a list<moduledeploymentrequest> and the deployer works with that list directly. we need a higher level parser result (e.g. deployablestream - or probably a better name after some thought) that can encapsulate that list while also enabling metadata to be added. that metadata may be helpful for composite module information as well as the module dependencies of a given stream (including any composed modules within that stream).") OR\nIF (User story is similar to "add remote partitioning to hdfsjdbc job h2. narrative as a developer i need to be able to process the importing of files in parallel via the hdfsjdbc batch job. h2. acceptance criteria # be able to provide a list of files to the job and have them be read in parallel based on the number of slaves deployed. # use {{multiresourcepartitioner}} to create on partition per incoming file.") OR\nIF (User story is similar to "add remote partitioning to filejdbc job h2. narrative as a developer i need to be able to process the importing of files in parallel via the filejdbc batch job. h2. acceptance criteria # be able to provide a list of files to the job and have them be read in parallel based on the number of slaves deployed. # use {{multiresourcepartitioner}} to create on partition per incoming file.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "add "http get" command to shell this will allow for some easy demonstration of how \'hateos\' works via links in our rest api. there are probably some quite useful commands here that could be used from the spring data rest shell longer term but a good place to take a look at now. goal is to show how metrics such as counters are accessible w/o having to switch tabs to use wget. the pretty printing of the returned json is an important feature to help understand the response this functionality can be taken from/reused from the spring data rest shell") OR\nIF (User story is similar to "update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location. launcher.xml can make use of the system property xd.pipeprotocol inside an import statement. this determines which version of the xd infrastructure to load for example what channelregistry implementation local or redis based or specific message listener containers. file name conventions should be used so if the option passed in from the command line is --pipeprotocol localchannel then the xml filename looked for has the \'protocol\' suffix applied e.g. localchannelprotocol and is loaded via the classpath. redis and local will not be the only options other implementations will be provided in the future e.g. rabbit and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).") OR\nIF (User story is similar to "provide user friendly messages when dealing with invalid gemfire sink xd:>stream create --name testgemfire --definition "http --port=8887 | gemfire" 16:20:28503 warn spring shell client.resttemplate:524 - post request for "http://localhost:8080/streams" resulted in 500 (internal server error) invoking error handler command failed org.springframework.xd.rest.client.impl.springxdexception: org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name \'region\' defined in null: could not resolve placeholder \'regionname\' in string value "${regionname}"")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to use spel expressions inline at the stream definition level so i can operate on the payload consistently while using any ootb including the custom modules.") OR\nIF (User story is similar to "as a user i need a "production-ready\' docker image so that i can use that as a baseline to deploy xd with the following setup. * ubuntu os * full xd jar * java 7.x") OR\nIF (User story is similar to "as a tester i\'d like to add test coverage for "complex objects" such protocol buffers any object with nested variables or a tree of objects so that i can evaluate and document the performance characteristics.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "ssl config for rabbitmessagebus connections is ignored") OR\nIF (User story is similar to "test against spring boot snapshot build") OR\nIF (User story is similar to "add kafka-based implementation for abstractsinglenodestreamdeploymentintegrationtests")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create ci plan for xd ec2 deployment * use the cleanup app from xd-1243 to stop previous ci runs of xd on ec2. * build xd-ec2 deployer from github. * use xd-ec2 deployer to deploy the ci xd-instance * should produce artifact that contains the url * admin server of the xd cluster. * container servers of the xd cluster") OR\nIF (User story is similar to "shell integration with xd on yarn we should provide a better shell integration when xd is run on yarn. 1. yarn kill --id tab completion 2. yarn submit more options like app name 3. yarn list filter by app states etc 4. admin config server tab completion for running xd apps on yarn") OR\nIF (User story is similar to "add a new source module to capture video frame from camera or video files this is a source module for video ingestion: the modules captures video frames from a camera or from a video file. for camera the frames are grabbed from the rtsp video stream. this module will generate message with the frame image (encoded with jpeg) as the payload.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "the hdfs sink should support writing pojos to hdfs using avro serialization writing pojos using cdk data (avro) we should support both partitioned and un-partitioned. this story addresses only un-partitioned. document limitations in terms of which java types are supported and not supported by the avro serialization") OR\nIF (User story is similar to "refactor tests with filesink|filesource to use eventually() matcher some tests (esp. moduleclasspathtests.testmodulewithclasspathafterserverstarted) seem to fail because of a race condition. add a hamcrest matcher that knows how to read the content of a filesink|source and refactor those to read like e.g. assertthat(filesink eventually(hascontent("foo)))") OR\nIF (User story is similar to "upgrade to 3.1.1 of the gradle artifactory plugin this addresses the plugin issue https://www.jfrog.com/jira/browse/gap-172 to disable spring-xd/pom.xml")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "support bus producer properties for dynamic producers pass module properties from stream plugin to {{messagebusawarechannelresolver}}. disallow partitioning properties.") OR\nIF (User story is similar to "add watch to stream deployment paths {{deploymentsupervisor}} will be responsible for maintaining the state data for each stream. when a stream is deployed a watch should be created so that the supervisor can recalculate the state of a stream as modules are added/removed.") OR\nIF (User story is similar to "rename packages that is applicable for both stream/job determine a better package name for the following packages once we have a common model that applies to both stream/job: `org.springframework.xd.dirt.stream` `org.springframework.xd.dirt.stream.zookeeper`")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "export of data from hdfs to mongodb based on a single process spring batch job etl of data from hdfs to mongodb.") OR\nIF (User story is similar to "rest-client should not force usage of joda time the rest-client project should not impose joda to the user.") OR\nIF (User story is similar to "payload conversion will need to migrated to m6 as soon as m6 is available currently uses m5 dependency.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to study the taxi trips based on a stream of trip reports from new york city so that i can evaluate event-based systems in the context of real-time analytics using spring xd. [challenge details|http://www.debs2015.org/call-grand-challenge.html]") OR\nIF (User story is similar to "as a developer i\'d like to handle module options via pure boot property source management so i can leverage boot\'s module [metadata|http://docs.spring.io/spring-boot/docs/current-snapshot/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core spring xd runtime cp.") OR\nIF (User story is similar to "as a user i\'d like to have a rest api to point and push an archive that includes custom module definitions and configurations so that i don\'t have to manually move and set it up. *scope of this spike:* * assess customer requirement brainstorm and document options * socialize with the team to collect feedback * identify phases * create new stories")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "end point to retrieve a list of all xd artifacts of all kinds any kind of sophisticated artifact retrieval mechanism in xd will need to grab more than one kind of artifact at once. for example if i want to see all taps streams triggers and jobs (ie- everything) i need to make 4 http requests. i can imagine dashboards that need to display information on artifacts of multiple kinds. there will also need to be a way to pass a query to return a sub-set of artifacts but that should be designed separately.") OR\nIF (User story is similar to "composing modules ignores output/input type specified in definition when composing two or more modules together if any output or input type is specified between modules it is ignored. i created a stream with definition: {code} mysourcemodule --outputtype=application/json | myprocessormodule {code} that worked fine as expected. when i composed this definition as a composed module i got errors stating that the processors message handler had no handler method for the object the source module emitted. the process was only configured to accept json as string. i simply had to create a second handler method but if i didnt own the module this could be an issue.") OR\nIF (User story is similar to "stream partitioning metadata should allow updating at runtime - dynamically / anytime in a running system some times the algorithm for partitioning the data might overload a given server with work. when that happens we might need to "rebalance" the partitioned work / data to achieve a even balance of stream throughput across servers in a given compute group. we can think of this dynamic rebalancing behavior as an extension of a failure use case. in the failure scenario we need to re-partition the stream to other servers in the group. we should allow third parties to plug-in to help with this capability. as an example gemfire will report the new partitioning meta-data when this type failure / rebalance happens.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "redisaggregatecounterrepository doesn\'t give proper results back both luke\'s original code and my refactored pr[1] (which uses same code snippet) seem to behave strangely. stored values seem fine but the getcounts() method seems phony. to test: 1) stream create foo --definition "time|log" 2) tap create bar --definition "tap@foo | aggregatecounter" 3) curl -h "application/json" http://localhost:8080/metrics/aggregate-counters/bar this gives default bucketing (hourly) but chances are that they are empty.") OR\nIF (User story is similar to "xd requires long duration tests in order to identify potential problems that may occur if xd is running for multiple hours we need to create a long duration test regime. create an environment from which we can run both singlenode and a simple cluster (1 admin 2 container) for 24+ hours. * create 2 simple streams * http|file * file|log * send data to http source 2 times a second for 24 hours * this test should execute checkprocs every 5 minutes to capture and record the status of the xd> * record memory usage and system load.") OR\nIF (User story is similar to "jmx shouldn\'t register taps or streams if the creation fails there\'s a lifecycle problem when a tap creation fails (e.g. because the dsl syntax is wrong). subsequent attempts to create the tap will fail with an error: [{"links":[]"logref":"messagehandlingexception""message":"org.springframework.context.applicationcontextexception: failed to start bean \'org.springframework.integration.monitor.integrationmbeanexporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2\' nested exception is org.springframework.jmx.export.unabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=nullchannel sends=0 receives=0]] with key \'xd.tap1:type=messagechannelname=nullchannelindex=1module=log\' nested exception is javax.management.instancealreadyexistsexception: xd.tap1:type=messagechannelname=nullchannelindex=1module=log"}] disabling jmx solves the issue. reproduce create a bad stream definition name \'bad\' try to recreate with the same name but correct stream definitions. the system will report that the stream already exists.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create a scriptprocessor module that allows the execution of a groovy (potentially jrubyjython) based si service activator this will enable arbitrary processing logic to be used in a processing step. see http://blog.springsource.org/2011/12/08/spring-integration-scripting-support-part-1/ <int:service-activator ...> <script:script lang="groovy" location="file:scripts/groovy/myscript.groovy"> </int:service-activator> would be the essence of the module. probably \'lang\' gets detected from the file extension.") OR\nIF (User story is similar to "deleting a job and then re-adding a new definition with the same name fails using single-node deployment of spring xd 1.0 ga we needed to redefine several batch jobs. we deleted the jobs ("job destroy all"). when attempting to re-add we received an error that a job with the name already exists. performing "job list" confirms the jobs were gone. to workaround i needed to terminate the instance (server) of spring xd and restart it. since this was the single-node deployment without a live stream of data coming in this was okay but would have been a major problem if bouncing the spring xd server was not acceptable (i.e. live data being actively received).") OR\nIF (User story is similar to "modify acceptance tests to give a pause time for deployment different than default kafka deployments take nearly 4 times as long as other transports because of the creation of the topic an partitions. currently all test use the same wait time whether it is for waiting for connections or file writes. so to get a ci build for kafka build would take a long period of time. the goal of the story is to allow deployments to have a different pause_time to give kafka bus the extra time it needs but not affect the timeout for other stages of the tests.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to create a example to demonstrate jdbc to hdfs data movement.") OR\nIF (User story is similar to "as a developer i\'d like to brainstorm and investigate various techniques around installation of xd modules from a maven repo so i could define the module {{artifactid}} from cli to have the module downloaded from the repo and installed to a running spring xd runtime.") OR\nIF (User story is similar to "as a user i\'d like to use the java receptor client so i can interact with diego runtime using the java receptor rest apis.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "avoid duplication when loading streams for deployment see: containerlistener.loadstream() and streamlistener.onchildadded(). both require the stream definition as well as stream deployment manifest.") OR\nIF (User story is similar to "modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopdistro=phd1") OR\nIF (User story is similar to "complete camera ready debs submission complete and submit debs 2015 paper as described here: http://www.debs2015.org/camera-ready-instructions.html")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create doc section about quotes handling document the different "onion layers" that come in play with regard to quoting and escaping (shell xd-parser spel expressions in some cases) and provide practical examples to common scenarios") OR\nIF (User story is similar to "add service activator processor would be nice to have a serviceactivator processor available so that if one had an existing spring bean they could simply describe the bean id and method name - without going through the full complexity of creating a processing module.") OR\nIF (User story is similar to "create shell integration test fixture for jdbc related sink would be nice to have some kind of regression testing on the jdbc sink as it becomes more prominent in xd. use of an in memory db where we expose eg a jdbctemplate to assert state")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "hdfs sink partition path causing writes to be slower in certain cases i have not tested this on m7 but i believe it is the case with latest release as well. stream definition 1: stream create logingestion --definition "rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10m --idletimeout=10000 --fileuuid=true --directory=/data/loganalysis --partitionpath=path(payload.split(\'\\u0001\')[1]dateformat(\'yyyy/mm/dd/hh\'payload.split(\'\\u0001\')[0]\'yyyymmddhhmmss\'))" we noticed this was causing writes to be slower stream definition 2: stream create logingestion --definition "rabbit --queues=demo --host=<rabbitmq-broker> | script --location=linemerge.groovy | hdfs --rollover=10m --idletimeout=10000 --fileuuid=true --directory=/data/loganalysis " but this definition caused the writes to be much faster. please note this was just a one time test i did and not reproduced multiple times. janne also seems to have reproduced this in another use case. thanks girish") OR\nIF (User story is similar to "accessing xd-admin urls in the browser return xml and not json here is an example: the following request for streams: http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams returns: this xml file does not appear to have any style information associated with it. the document tree is shown below. <errors xmlns:atom="http://www.w3.org/2005/atom"> <error logref="httpmessagenotwritableexception"> <message> could not marshal [pagedresource { content: [links: [<http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams/ticktock>rel="self"]] metadata: metadata { number: 0 total pages: 1 total elements: 1 size: 20 } links: [] }]: null nested exception is javax.xml.bind.marshalexception - with linked exception: [com.sun.istack.saxexception2: unable to marshal type "org.springframework.xd.rest.client.domain.streamdefinitionresource" as an element because it is not known to this context.] </message> </error> </errors>") OR\nIF (User story is similar to "update document for the distributed runtime based on rc1 changes this should be included on the wiki providing a thorough overview of how the distributed runtime works under-the-hood including details of the various zookeeper nodes and associated watchers etc. for example it should describe the role of *any* admin as a provider of the rest api as well as the specific roles allocated to the single *leader* admin. it should describe module recovery after container failure as well as some description of various failure scenarios (crashed jvm network partition etc) and how the recovery should be expected to occur (e.g. in some cases it will be nearly immediate and in other cases it will be after a timed out connection). intentional container shutdown should be included in that discussion as well. at many points this doc could link back to items that we also need to add to the main user guide such as the description of containermatcher as the strategy for an admin to determine which container(s) should deploy a given module since that containermatcher is used not only for the initial deployment but also any redeployment that may be necessary.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to use spel expressions inline at the stream definition level so i can operate on the payload consistently while using any ootb including the custom modules.") OR\nIF (User story is similar to "as a developer i\'d like to have a simplified ux around parameters for gpdb so i don\'t have to escape each parameter. the scope is also to test the sqoop job with sqlserver and gpdb to identify the ux differences.") OR\nIF (User story is similar to "as a tester i\'d like to add test coverage for "complex objects" such protocol buffers any object with nested variables or a tree of objects so that i can evaluate and document the performance characteristics.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to define security definitions so that i can configure entity (rest api) specific group/role access policies.") OR\nIF (User story is similar to "as a developer i\'d like to fix the offset management with kafka _source_ module so that i can efficiently perform fetch operation from the given offsets.") OR\nIF (User story is similar to "as a user i want to be able to control the partition allocation for the kafka source modules when a stream is deployed so that i can colocate with other data sources.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to create a stream such as _generator | perf-meter_ so that i can ingest 1m messages of 1000 bytes and one thread using xd\'s \'singlenode\' container and measure performance characteristics.") OR\nIF (User story is similar to "as a user i\'d like to have a _generator_ source module so that i can create a number of messages of a specified size (similar to rabbit\'s perftest utility). example: generator --nummsgs 10000 --msgsize 1024 --numthreads 1") OR\nIF (User story is similar to "as a s-c-s developer i\'d like to investigate the right approach to include external library as dependency (ex: mysql) so i can decide better handling of libraries which needs loaded and available in root cp at the runtime.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "documentation for reactor-ip source has conflicting information according to the documentation at: http://docs.spring.io/spring-xd/docs/current/reference/html/#reactor-ip one of the options available for this source is {{transport}}. it\'s listed as having no default but the sample definition doesn\'t provide it yet appears to default to {{tcp}}. the two should match up. it might also be useful if the possible values for {{transport}} were listed (i assume {{tcp}} and {{udp}})") OR\nIF (User story is similar to "first deploy/launch of pig job that includes yarn-site.xml file fails deploying and launching a pig job that contains a yarn-site.xml config file fails on the first deploy after xd starts up. this happens consistently. the error is: error: could not find or load main class org.apache.hadoop.mapreduce.v2.app.mrappmaster which indicates that the yarn-site.xml file never made it to the classpath. un-deploying and re-deploying the job seems to fix the problem.") OR\nIF (User story is similar to "gauge & rich gauge fail to write results to redis for singlenode steps to reproduce: stream create --name test --definition "http --port=9090 | log" stream create --name simplegauge --definition "tap:stream:test > gauge" http post --target http://localhost:9090 --data "10" redis-cli get gauges.simplegauge [the result] redis 127.0.0.1:6379> get gauges.simplegauge (nil) note: it worked with admin/container but failed only on xd-singlenode.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "make rabbitmessagebus rabbitmq config properties optional when the bus is used outside of the xd container (e.g. spring-bus) the inheritance from spring boot configuration is broken (no application.yml or servers.yml on the cp). make the bus properties optional (add ":")") OR\nIF (User story is similar to "create rest endpoint for validation of a job/stream definition have a rest endpoint that would run validation of a definition (without actually attempting the creation let alone deployment) and return a structured representation of validation errors. this to benefit the web ui") OR\nIF (User story is similar to "review dsl updated story points to 14 since 5 of us just participated in a 2 hour call and we still need to discuss "topology" support after some dev spikes later this week")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "creating a tap throws an exception creating a tap throws an exception. in local mode: cannot resolve reference to bean \'redisconnectionfactory\' while setting constructor argument nested exception is org.springframework.beans.factory.nosuchbeandefinitionexception: no bean named \'redisconnectionfactory\' is defined but also fails when using redis.") OR\nIF (User story is similar to "move decision logic for directbinding out of bus to deployer as the decision for directbinding may become more complicated (see eg xd-2946) move the *decision* part out of the bus leaving only the *application* there (leveraging a pre-computed property such as directbind=true). the computation of that property is to be moved at the deployer level") OR\nIF (User story is similar to "resolve classloading issues for custom hadoop based batch jobs there are several issues making it hard to impossible to create batch jobs that use pig hive hbase or other technologies supported by spring for apache hadoop project. we need to make the corresponding dependencies available on the hadoop classpath.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to setup a performance testing infrastructure (rackspace) so i can start benching kafka baselines and continue with xd use-cases.") OR\nIF (User story is similar to "as a developer i\'d like to migrate module deployment from the "repository" abstraction (used for stream/job definitions) so i can create it as a pluggable runtime spi.") OR\nIF (User story is similar to "as a user i should be able to leverage native _websocket_ sink so that i can take the advantage of full-duplex communications channels over a single tcp connection.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "upgrade lettuce to 2.3.2") OR\nIF (User story is similar to "upgrade curator to 2.5.0") OR\nIF (User story is similar to "upgrade to reactor 2.0.1")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to use spel expressions inline at the stream definition level so i can operate on the payload consistently while using any ootb including the custom modules.") OR\nIF (User story is similar to "as a developer i\'d like to add support to _flush_ offsets intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer.") OR\nIF (User story is similar to "as a developer i\'d like to study the state management requirements so i can brainstorm and identify the design to natively add _stateful_ stream processing support in xd.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "create tcp sink module based off si tcp inbound adapter. this will allow for event fowarding.") OR\nIF (User story is similar to "update hdfs sink documentation to reflect new functionality introduced in xd-990 and xd-991") OR\nIF (User story is similar to "documentation for use of conversion service and creating custom processing modules that use the tuple data structure.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "spike: research request/reply support to kafka message bus the scope is to research the available options to provide request/reply support for kafka. * document findings * pocs previous desc: the bindrequestor and bindreplier methods of the message bus need to be implemented.") OR\nIF (User story is similar to "upgrade sdr to get rid of temporary no-op serializer spring data redis 1.1 m2 added the ability to use redistemplate with binary data. we should switch to that instead of the no-op serializer we were forced to implement previously.") OR\nIF (User story is similar to "jdbchdfstests sporadically fail acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged xd-2309. additional tests were added but used fixed timeouts. will replace them with waitforjob.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create documentation section for the shell create a new section in the docs regaring shell usage in particular how to represent single and double quotes. include some discussion of basic commands to manipulate streams jobs and list modules. how to pass in a file that can be executed when the shell starts up. also point to spring-shell ref docs for extensibility in terms of adding custom commands.") OR\nIF (User story is similar to "provide a way to customize the isolation level of the jobrepository the gemfire xd database cannot be used to store the spring xd metadata because the former doesn\'t support the default spring batch transaction isolation level isolation_serializable. there looks to be no way to configure the spring xd\'s internal spring batch jobrepository with another isolation level. the jobrepository instance is getting created with default settings by the spring batch\'es {{simplebatchconfiguration}} and there are no custom {{batchconfigurer}}s available to change the default settings of the jobrepository.") OR\nIF (User story is similar to "support completion proposals of processors after a named channel due to the way the heuristics for module type guessing work we can\'t currently support completions of the like: "queue:foo > s<tab>" that would yield valid processor names we need to add non-determinism (list of types instead of single type) to the type guessing heuristic")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "replace beandefinitionaddingbeanpostprocessor with ordered plugins this will allow us to control the order of plugins and use plugin(s) to manage the common module context replacing beandefinitionaddingbeanpostprocesser") OR\nIF (User story is similar to "move spel propertyaccessors to module parent context when int-3133 is resolved spel {{propertyaccessor}} s are inherited from parent contexts. instead of adding the {{jsonpropertyaccessor}} to each module\'s context add it to the parent instead.") OR\nIF (User story is similar to "move bus cleaner util method from busutils since `spark-streaming` uses `busutils` we need to move the bus cleaner util method that builds rest template so that spark streaming doesn\'t depend on `httpclient`")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "enhance "module upload" to support exploded dirs (on the shell side) would be nice to have the shell zip the contents of a directory if not already in zipped form. this way the development cycle (if one decided to use upload) is quicker and edits can be done in place.") OR\nIF (User story is similar to "create doc section about quotes handling document the different "onion layers" that come in play with regard to quoting and escaping (shell xd-parser spel expressions in some cases) and provide practical examples to common scenarios") OR\nIF (User story is similar to "batch hashtag count throws exception when launched 1) update instructions to mention --hadoopdistro for both singlenode and shell. else demo will not work. 2) pom needs to be updated to use 1.2.1 at the least. 3) i can see where hdfs is writing the results 4) throws npe stacktrace is attached.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.") OR\nIF (User story is similar to "as a developer i\'d like to benchmark a stream with and without {{jmx}} enabled so i can test in isolation and document the differences in performance.") OR\nIF (User story is similar to "as a developer i\'d like to document the kryo optimization guidelines so the end-users can refer to it while tuning to improve performance.")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics. *notes:* * spring-amqp {{rabbitadmin}} now has a {{getqueueproperties()}} method which returns the number of consumers so it may be possible to use it for this purpose. * consider the possibility of _producers_ and/or _queues_ still containing data * consider the scenario even after the topics/queues are cleaned-up what to do with fanout exchange? *some further thoughts* * consider using the upcoming spring amqp rest api {{rabbitmanagementtemplate}} if the timing is not right we could temporarily invoke the rabbit rest api directly. * should be optional perhaps via {{stream destroy foo --clean}} * should this be done by the admin? or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange since we undeploy left->right everything can be cleaned up on the consumer side. * third option would be new methods on the bus {{cleanconsumer}} etc invoked by the {{streamplugin}} * down side of doing it on the admin is that he wouldn\'t necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so we\'d need the admin url(s) for the cluster.") OR\nIF (User story is similar to "as a spring xd user i\'d like to persist module (aka: {{cf apps}}) metrics directly so i can relay that information via rest-apis and not depend on the current coupling of {{xd-container}}\'s. currently sboot\'s {{export()}} api allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). this could be something to explore as part of this scope.") OR\nIF (User story is similar to "as a s-c-s developer i\'d like to setup a ci workflow to build bundle and upload the {{module-launcher}} image to dockerhub so i don\'t have to worry about having a local-private docker registry for development/testing. it could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] dockerhub location.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have a flexible rxjava module so that it can as a processor.") OR\nIF (User story is similar to "as a developer i\'d like to split up spring-xd dependencies to more fine-grained so i can get the ones "below the line" down to spring-bus-* instead of spring-xd-* bundle.") OR\nIF (User story is similar to "as a developer i\'d like to move \'serialization codec\' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add parameter information to application definition a moduledefinition contains parameters which need to be passed to the cloudfoundry application. currently these are put directly into the application\'s environment. this issue will verify they are correctly named.") OR\nIF (User story is similar to "build.gradle doesn\'t handle a small handful of libraries trying to build spring-xd for the first resulted in lots of errors inside sts (i had an empty .m2 repo).") OR\nIF (User story is similar to "shell: add named channel list command user shall have the ability to get a listing of available named channels (order by name ascending) from the shell * add support to controllers * add tests")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "support the ability for a user to create composite modules that can accept parameters parser creates a module compose command that allows a user to create a module of other modules. this composed module can accept parameters.") OR\nIF (User story is similar to "add ability to copy job from http site to containers download zipped job modules from a http site and deploy them to modules on the admin & containers before container is started.") OR\nIF (User story is similar to "xd-container and xd-admin should log to a file out of the box we should have an externally editable log4j config file in a conf dir and the default should log to a file (presumably in a logs dir)")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "provide ability to disable tab completion for specific module options not all module options are born equal. some are more important/useful than others and having the more "expert" ones show up e.g. in tab completion is very noisy (esp. given how jline2 currently presents the whole stream definition typed so far when doing completion as opposed to just the last bit)") OR\nIF (User story is similar to "hdfs sink should provide rollovertime option not only idletiemout when using hdfs sink with ildetimeout and rollover options in stream definition we have noticed that idletimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file. proposed option: rollovertimeout timeout after file will be automatically closed link: #xd-2413") OR\nIF (User story is similar to "add support to start apps in yarn automatically by type as an s-c-d developer i\'d like to add support to negotiate with the resourcemanager rest-apis to deploy modules by groups. so i can build instrumentation to start the app instances automatically. perhaps also take into account of the app specifics such as {{apptype=clouddata}} and {{appname=spring-cloud-data-yarn-app}}.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-s user i\'d like to have my modules add/update it\'s current state to eureka so i can use the repository to discover the current sate of the module as needed.") OR\nIF (User story is similar to "as a user i\'d like to have a config parameter preferably in _servers.yml_ file so that i can enable/disable message rates in the cluster view.") OR\nIF (User story is similar to "as a user i\'d like to have the ability to visually explore xd\'s cluster view so that i\'m aware where the components are deployed and how they are connected within the topology.")\nThen \'2\'',
    'User story is "{case}".\nIF (User story is similar to "modules need to validate their parameters at create time. we need to fail fast.") OR\nIF (User story is similar to "job executions without deployed job (deleted) shall not be restartable") OR\nIF (User story is similar to "add support for creating fixed delay/ fixed rate triggers")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "add the dependencies required to use #xpath in streams thanks to gary i found this little gem of documentation to be able to use xpath expression in xd. only hiccup is that i had to also add the spring-xml.jar to the classpath (otherwise it is missing xpathexception class). http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload") OR\nIF (User story is similar to "do you have plan to support spark? do you have plans to support spark? in version 1.0 ga spring xd has supported hadoop but it has not supported the brand new big data calculation platform spark. do you have plans to support spark in the future?") OR\nIF (User story is similar to "update doc about trigger changes trigger has been changed to be one single modules taking params (as opposed to 3 before) update doc at https://github.com/spring-projects/spring-xd/wiki/batch-jobs also arguably the module could be advertised as a source itself (it is only mentioned in the context of batch)")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "ui - setup sauce labs integration we should have a facility to easily test the e2e protractor tests against a variety of common browsers including ie. sauce labs seems to be the service to use.") OR\nIF (User story is similar to "map column names with underscore to camelcase style keys for jdbc sink we need to add support for matching column names with underscores like "user_name" and map them to camel case style keys like "username" in the jdbcmessagepayloadtransformer.") OR\nIF (User story is similar to "add a jobexecution dto object related to xd-779. * we need the ability to provide json serializable jobexecution information. * change from using javaserialization back to returning objects")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "enforce consistent naming across cli options and command/template/operations method names e.g. see comment on pr #390: https://github.com/spring-projects/spring-xd/pull/390/files#r7563787 in that case it\'s "delete" in one place and "destroy" in another. there are other cases as well.") OR\nIF (User story is similar to "vary consumers size (db-4) using a single producer message size of 1000 bytes pretch of 100. send 1m messages and increase or decrease so that a given test iteration takes about 2 minutes. vary the number of consumers. measure the msg/sec rate and calculate the data transfer rate in mb/sec. *number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50 during the measurements look at the rabbitmq admin ui and see if the queue is backing up.") OR\nIF (User story is similar to "vary consumers size (ecb-4) using a single producer message size of 1000 bytes pretch of 100. send 1m messages and increase or decrease so that a given test iteration takes about 2 minutes. vary the number of consumers. measure the msg/sec rate and calculate the data transfer rate in mb/sec. *number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50 during the measurements look at the rabbitmq admin ui and see if the queue is backing up.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to benchmark rabbit performance so that i can use the results as reference to setup xd cluster.") OR\nIF (User story is similar to "as a user i\'d like to have the option to _stop_ an existing sqoop job so that i can clean-up resources at the time of completion.") OR\nIF (User story is similar to "as a user i\'d like to have the option to setup _batching_ so that i can ingest data in batches as opposed to payload-at-a-time.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a module developer i would like the jsonstringtotupleconverter in the spring cloud streams project to maintain the types provided in the json string and not convert everything to a string representation.") OR\nIF (User story is similar to "as a user i\'d like to have a landing page with higher-order links for sources processors sinks and jobs so i can jump to right section from one place.") OR\nIF (User story is similar to "as a temporary work around to fix xd-1935 make producible media type to \'application/json\' for job executions get request endpoints.")\nThen \'1\'',
    'User story is "{case}".\nIF (User story is similar to "ensure dsm matrix is diagonal") OR\nIF (User story is similar to "add command for tap creation") OR\nIF (User story is similar to "add batchmbeanexporter for batch modules")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "update https://github.com/spring-guides/gs-spring-xd/ for new release") OR\nIF (User story is similar to "create one xd-yarn shell script that encompases the functionality of seperate shell scripts") OR\nIF (User story is similar to "change springsource references in pom.xml to spring/spring.io this is currently in the m6 pom: <organization> <name>springsource</name> <url>http://springsource.org</url> </organization>")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "custom modules can\'t be found wen using xd.custommodule.home on windows xd can not find the custom modules directory after setting the xd.custommodule.home in the windows environment deployment * xd-singlenode (embedded zookeeper) * java 8 * windows 8 or windows server 2012 r2 steps to reproduce: 1) start xd-singlenode 2) start shell 3) build either the payload-conversion or rss-feed-source from the spring-xd-samples 4) use the shell to execute a module upload for the custom module (rss-feed-source payload-conversion) 5) verify it uploaded xd:>module info processor:mytupleprocessor 6) stop xd single node 7) from the command line execute set xd.custommodule.home=[path to your custom modules] i.e. c:\\project\\spring-xd-1.1.0.release\\xd\\custom-modules 8) restart xd-singlenode 9) execute module info processor:mytupleprocessor 10) you will get the following error {noformat} command failed org.springframework.xd.rest.client.impl.springxdexception: could not find module with name \'mytupleprocessor\' and type \'processor\' {noformat}") OR\nIF (User story is similar to "installer needs to launch a single node xd instance * create a deployer class has methods ** runninginstance deploysinglenode *** takes into account machine size as specified in properties file ** void destroyallinstances() *** or whatever jclouds returns from the destroy call ** ctor gets passed in the root boostrapping credentials. * install script steps ** setup xd_home variable ** make sure privileges are set to ubuntu not root. ** start up redis and rabbit using ports as specified in xd-ec2.properties ** use port watch to make sure they started ** start singlenode after configuration. ** display hostname of singlenode server ** report successful and failed startup ** hit root of xd-admin to see if there is a response on 9393 * integration testing ** verify that config files have been setup ** verify xd has been started ** verify xd can process a basic http post") OR\nIF (User story is similar to "implement common set of controller methods save : save a xyzdefinition - method used to be \'create\' delete : delete a xyzdefinition - method used to be called \'destroy\' deploy : deploy a xyzdefinition undeploy : undeploy a xyzdefinition list : list a xyzdefinition returns pagedresources<xyzdefinitionresource> display : get specific information about a xyzdefinition create other stories for each controller and include in this weeks sprint")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to fix the offset management with kafka _source_ module so that i can efficiently perform fetch operation from the given offsets.") OR\nIF (User story is similar to "as a developer i\'d like to migrate the current master branch ci builds to ec2 instances so i can manage them all in one-place reliably.") OR\nIF (User story is similar to "as a user i\'d like to define security definitions so that i can configure entity (rest api) specific group/role access policies.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add job rdbms config in ambari plugin spring xd ambari plugin only supports hdb as job db. hdb is not good in production environment. it will be great if we can specify rdb in spring xd installation/config process.") OR\nIF (User story is similar to "obtain username and password credentials for cloudfoundry as part of moving to a bespoke restoperations application we will need credentials to access cloudfoundry. these will need to be supplied from the new xd admin app at runtime.") OR\nIF (User story is similar to "add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the xd classpath this is needed for the use of the webhdfs:// scheme to talk to hdfs over http.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i want spring xd to pre-allocate a set of partitions between the kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesnt take place.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to add support for having different binder types for module\'s channels so i can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.") OR\nIF (User story is similar to "as a user i want spring xds message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesnt happen when a container crashes and/or its redeployed.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (e.g. during deployment of streams/jobs) ideally i would like to have this addressed on the server-side as well. it would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system. we could then use those to notify connected ui clients.") OR\nIF (User story is similar to "as a performance tester i\'d like to rerun baseline benchmarks with batching enabled on rabbit so that i can compare the results with previous performance snapshots. note: - batchingenabled = true - batchingsize = 100 (default) we could also vary default size to compute and record at granular level.") OR\nIF (User story is similar to "as a user i\'d like to have a redis based _aggregation_ over field-value counters so that i can continuously write the aggregation in redis as we ingest more data. *scope:* * port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/old---aggregate-field-value-counters]. * identify gaps * update reference documentation")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to host/read python script (file) from hdfs so i can use the shell processor in xd (on cf) to delegate data science functionality to py runtime and receive the feedback back in xd.") OR\nIF (User story is similar to "as a developer i\'d like to have a central place to manage external properties for applications across all the environments so i can provide server and client-side support for externalized configuration for xd-admin and xd-container servers.") OR\nIF (User story is similar to "as a follow up to xd-2877 experiment with the removal of the list of modules from basedefinition and reparse as needed. branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to bench test cases around {{tuplebuilder}} so i can identify the bottlenecks and tune for performance optimizations.") OR\nIF (User story is similar to "as a developer i\'d like to build _spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.") OR\nIF (User story is similar to "as a user i\'d like to have the option to write into _file roll_ sink so that i can store events on the local file system.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add ability to copy job from http site to containers download zipped job modules from a http site and deploy them to modules on the admin & containers before container is started.") OR\nIF (User story is similar to "rabbit source and sink mappedrequestheaders should include all headers by default currently it is necessary to specify mappedrequestheaders=* on the rabbit sink otherwise no headers are mapped to amqp. this should be the default behavior.") OR\nIF (User story is similar to "modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopdistro=phd1")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have a flexible rxjava module so that it can as a processor.") OR\nIF (User story is similar to "as a developer i\'d like to split up spring-xd dependencies to more fine-grained so i can get the ones "below the line" down to spring-bus-* instead of spring-xd-* bundle.") OR\nIF (User story is similar to "as a developer i\'d like to move \'serialization codec\' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "improve resilience of route creation/removal the cf implementation requires that a route be created for each new app. this works fine on the happy path but is brittle. for example it will fail if the route required already exists.") OR\nIF (User story is similar to "moduleconfigurationexception should not report http 500 see discussion at https://github.com/spring-projects/spring-xd/pull/1537#issuecomment-99583179 this is likely a client error so should be in the 4xx family. this requires customization of restcontrolleradvice") OR\nIF (User story is similar to "redis sink: better handling of module options/profile activation please see the discussion here: https://github.com/spring-projects/spring-xd/pull/1188#discussion_r18788216")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "expose shutdown operation over http this will allow for a simple way to shutdown the server via an http call. support for security is a separate story. the end goal is to have some shell scripts distributed that can issue http requests to shutdown the xd-admin and xd-container servers. the newest version of jolokia has the ability to boostrap itself inside an application context vs. requiring a java agent. i suspect using the application context approach will provide us with more flexibility (e.g. property replacement etc) but not sure.") OR\nIF (User story is similar to "improvements to executions tab 1. add quick filter 2. the table should have columns for name | instance | execution id getting the name might require a bit of extra work given some limitations with json serialization and cycles in the current object returned from spring batch. 3. the restart action should appear only if the job is restartable and the status was failed.") OR\nIF (User story is similar to "improve module options support note from pr #365 - which has been merged - providing the initial level of support... pending issues (to be addressed in another pr?): - [x] complex case - [x] default values for complex case when option is not surfaced back to the module (eg "suffix" in our canonical example) - [ ] plugin provided options and values - [ ] descriptive defaults instead of actual defaults (e.g. \\<use stream name\\>) - [ ] jsr303 validation")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "getting stuck on hive error. in hadoop while creating table in hive i am getting stuck in below error 15/04/21 12:35:34 info log.perflogger: <perflog method=driver.run from=org.apache.hadoop.hive.ql.driver> 15/04/21 12:35:34 info log.perflogger: <perflog method=timetosubmit from=org.apache.hadoop.hive.ql.driver> 15/04/21 12:35:34 info log.perflogger: <perflog method=acquirereadwritelocks from=org.apache.hadoop.hive.ql.driver> 15/04/21 12:35:34 info lockmgr.dummytxnmanager: creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.zookeeper.zookeeperhivelockmanager 15/04/21 12:35:34 info zookeeper.zookeeper: initiating client connection connectstring=dkhc3013.dcsg.com:2181dkhc3010.dcsg.com:2181dkhc3011.dcsg.com:2181 sessiontimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.zookeeperhivelockmanager$dummywatcher@5b9e1cd4 15/04/21 12:35:34 debug lockmgr.dummytxnmanager: adding /incoming/mkt/gcdb.etl_master_account_pref to list of lock inputs 15/04/21 12:35:34 debug lockmgr.dummytxnmanager: adding database:mkt_incoming to list of lock outputs after restart the zookeeper service i am able to successfully run the query but after some time again facing the same issue/error i am stuck on the same error. is there any solution to overcome this issue or any tuning i can do for resolve this issue. please suggest on this.") OR\nIF (User story is similar to "spring xd ec2 needs to setup cluster that uses static resources. h1. summary user wants the ability to deploy an ec2 cluster where the admin & containers use a pre existing zk ensemble rabbit and redis instance that are deployed on different machines. h2. current functionality currently spring-xd-ec2 sets up its containers & admin server to use a zk rabbit and redis that are provisioned and collocated with the admin server. h2. detail the following properties will be added to the spring-xd-ec2.properties # *spring_zk_client_connect* - contains a comma delimited list of zk hosts:ports for a ensemble. the application will check to see if the port is open on at least of the servers in the list if not deployment will fail. default is adminserver_host:2181. # *spring_rabbitmq_addresses* - contains a comma delimited list of hosts:ports for a rabbit cluster. the application will check to see if the port is open on at least of the servers in the list if not deployment will fail. default is adminserver_host:5672. # *spring_redis* - contains a host:port for a redis instance. the application will check to see if the port is open if not deployment will fail. default is adminserver_host:5672. # *ec2_zone* - user can specify the zone to which the containers and admin will be deployed. if not present aws will decide which zone to deploy the cluster.") OR\nIF (User story is similar to "merge container and containermetadata as well as their "repositories" the two classes in question are: * org.springframework.xd.dirt.cluster.container * org.springframework.xd.dirt.container.containermetadata the former is currently used by the admin when making decisions about module deployment. that latter was a replacement for runtimecontainerinforentity as we migrated the various redis/inmemory repositories to use the data that is now available in zookeeper instead. the containerrepository is currently used by the admin leader and the containermetadatarepository is used by the rest endpoint that supports the xd-shell\'s \'runtime containers\' command. perhaps those can also be merged. in any case if not addressed by a larger refactoring the containerrepository should probably support an iterable return rather than an iterator. having finders (e.g. for attribute key/values such as "group"=="foo") might be convenient for various module deployment strategies.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "come up with a consistent link consumption scheme on the rest client side see discussion at https://github.com/spring-cloud/spring-cloud-data/pull/37#discussion_r36849117 also relevant: http://docs.spring.io/spring-hateoas/docs/current/reference/html/#client") OR\nIF (User story is similar to "allow for late-binding of module options defaults this is about computing the value to support expressions such as ${xd.stream.name} as a default. initial discussion suggested to leverage the work done in xd-1175 by having a custom @latevalue (or @deploytimevalue etc) be resolved at deployment time") OR\nIF (User story is similar to "user wants to package and deploy an xd application install a boot uberjar containing custom modules plus stream and job definitions and possibly specific configuration. this potentially includes the ability to export and import all deployable resources defined in an xd environment.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to troubleshoot the performance issues with rabbit as message bus implementation so i can isolate the bottleneck and fix as appropriate.") OR\nIF (User story is similar to "as a continuation we would like to further investigate spark develop poc and identify the best appropriate design and implementation for xd.") OR\nIF (User story is similar to "as a field engineer i\'d like to have a comparison of spark streaming examples in spring xd so that it is easy to relate from implementation standpoint.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "upgrade lettuce to 2.3.2") OR\nIF (User story is similar to "upgrade curator to 2.5.0") OR\nIF (User story is similar to "upgrade to reactor 2.0.1")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "refactor src/test/resources in dirt * in the testmodules.source ** rename source-config to packaged-source ** rename source-config to packaged-source-no-lib * all xml files should be prefixed with test. i.e. testsource testsink * make sure all tests pass with new configuration") OR\nIF (User story is similar to "automatic support for --fooexpression style options it would be nice if either one of the two options would come "for free" when you\'re authoring a module. currently it has been a pain including handling exclusivity of options at the module options level. also it would be nice if xd/s-c-s provided ease of creation of xxexpression style options (ie not having the author have to deal with expressionparser etc)") OR\nIF (User story is similar to "add definition of serialversionuid to twitter classes add serialversionuid to the objects in package org.springframework.integration.x.twitter: * xdentities * xdurlentity * xdhashtagentity * xdmentionentity * xdmediaentity * xdtickersymbolentity * xdtweet the absence creates warnings during compile time.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "move bus cleaner util method from busutils since `spark-streaming` uses `busutils` we need to move the bus cleaner util method that builds rest template so that spark streaming doesn\'t depend on `httpclient`") OR\nIF (User story is similar to "address already in use for tomcat/hsqldb should fail completly currently process is left running and if logs / sysout are not monitored you have no clue") OR\nIF (User story is similar to "processortest.testfailedsink needs to use http as its test source also check the jmx output to see that the filter rejected the entry.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "add support for pivotal hd 2.1 (xd 1.0.2 release) *xd 1.0.2 release + phd 2.1 upgrade - action items:* * update to shdp 2.0.3 * add hadoop 2.5 (hadoop25) * change phd 2.x from phd20 to phd21 * test phd 2.0 with phd21 * document that both phd 2.1 and phd 2.0 is supported with phd21") OR\nIF (User story is similar to "the hdfs sink should support writing pojos to hdfs using avro serialization writing pojos using cdk data (avro) we should support both partitioned and un-partitioned. this story addresses only un-partitioned. document limitations in terms of which java types are supported and not supported by the avro serialization") OR\nIF (User story is similar to "update spring-data-hadoop dependency and add new hadoop distros update to spring for apache hadoop 2.0 rc3 add support for new hadoop distros: - pivotal hd 2.0 (phd20) - hortonworks hdp 2.1 (hdp21) - cloudera cdh5 (cdh5)")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create a perfsink module create a sink that can capture the results of the messages sent and log the number of messages received per a configured interval in seconds.") OR\nIF (User story is similar to "replace \'anonymous\' node in xd module bean names enhance bean naming strategy or provide a value for the property that binds to this") OR\nIF (User story is similar to "add authentication information to twittersearch source doc since the changes for xd-202 twittersearch requires authentication. need to update the docs to reflect this.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to bench test cases around {{tuplebuilder}} so i can identify the bottlenecks and tune for performance optimizations.") OR\nIF (User story is similar to "as a developer i\'d like to build _spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.") OR\nIF (User story is similar to "as a user i\'d like to have the option to write into _file roll_ sink so that i can store events on the local file system.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to start multiple instances of {{xd-container}}\'s through the rpm scripts so i can easily spin-up instances on the same node/vm.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to add support to add external libraries so i can consume such dependencies for modules in an uniform way.") OR\nIF (User story is similar to "as a user i\'d like to refer to documentation in wiki so that i can setup and configure kafka as a message bus as recommended.")\nThen \'2\'',
    'User story is "{case}".\nIF (User story is similar to "tcp-client source module throws classnotfoundexception *version:* xd: 1.1 m1 *problem:* trying to use tcp-client source module and observing an exception while deploying the stream. *stream definition:* {code:xml} curl --data name=dummy-firehose --data definition=\'tcp-client --decoder=lf --port=8080 | log\' --data deploy=true http://localhost:9393/streams/definitions {"name":"dummy-firehose""status":null"definition":"tcp-client --decoder=lf --port=8080 | log""_links":{"self":{"href":"http://localhost:9393/streams/dummy-firehose"}}} {code} the same curl command works fine against xd 1.0.1 release.") OR\nIF (User story is similar to "allow mixins of moduleoptionsmetadata a lot of modules have similar options. moreover job modules often have options that belong to at least two domains (eg jdbc + hdfs). i think that by using flattenedcompositemoduleoptionsmetadata we could come up with a way to combine several options pojos into one. something like: public class jdbchdfsoptionsmetadata { @optionsmixin private jdbcoptionsmetadata jdbc @optionsmixin private hdfsoptionsmetadata hdfs } this would expose eg "driverclass" as well as "rolloversize" as top level options. values could be actually injected into the fields so that eg custom validation could occur (default validation for the mixin class would occur by default)") OR\nIF (User story is similar to "jobs are not completely removed from jobstore deploy type: admin/container on ec2 (rabbit transport) sha: 8fba31d [steps to reproduce] 1) using rabbit 3.3 above create a user that does not have privileges to write to / * sudo rabbitmqctl add_user joe password * (omit this step) sudo rabbitmqctl set_permissions -p / joe ".*" ".*" ".*" 2) set the rabbitmq user name and password * export spring_rabbitmq_username=acctest * export spring_rabbitmq_password=acctest23 3) start container. 4) create stream or job "foo" 5) error will occur 6) delete stream or job "foo" 7) stop container 8) set privilege * sudo rabbitmqctl set_permissions -p / joe ".*" ".*" ".*" 9) start container 10) create stream or job "foo" 11) system will report that foo exists.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to separate mocks vs. real repository coupling from the test infrastructure so it is easy to test against thin layer of dependencies.") OR\nIF (User story is similar to "as a developer i\'d like to investigate channel performance issues in si 4.2 so i can determine the bottlenecks and take corrective actions to improve overall channel performance.") OR\nIF (User story is similar to "as a developer i\'d like to migrate the current master branch ci builds to ec2 instances so i can manage them all in one-place reliably.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "provide user friendly messages when dealing with invalid gemfire sink xd:>stream create --name testgemfire --definition "http --port=8887 | gemfire" 16:20:28503 warn spring shell client.resttemplate:524 - post request for "http://localhost:8080/streams" resulted in 500 (internal server error) invoking error handler command failed org.springframework.xd.rest.client.impl.springxdexception: org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name \'region\' defined in null: could not resolve placeholder \'regionname\' in string value "${regionname}"") OR\nIF (User story is similar to "when there are no wiretap listeners don\'t publish messages being able to listen to a stream at any point has a significant performance impact. the reason for the impact is the message needs to be "serialized + transported + deserialized" to other members even if there is no one listening. this "serialized + transported + deserialized" processes happens for each step in a flow - source | process | sink. recommend creating some kind of protocol for wiretaps that allows members to know if there is someone listening in the grid so they will emit the data. likewise we need to deregister the listener if the wiretap is deleted.") OR\nIF (User story is similar to "xd yarn deployment requires the ability to set permsize when deploying xd using java 7 the user must be able to set the permsize to a value larger than the default. the reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source & sink more than 2 times stream deployment begins to fail. the only exception that was captured was the following: {noformat} exception in thread "ec2test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor" exception: java.lang.outofmemoryerror thrown from the uncaughtexceptionhandler in thread "ec2test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor {noformat} logs are not available at this time.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-d developer i\'d like to create foundation to support _processor_ as ootb modules so i can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.") OR\nIF (User story is similar to "as a user i\'d like to access sqoop logs so that i can troubleshoot or evaluate the errors or current state respectively. we will have to identify how to capture the sqoop logs and stream them to our logging mechanism.") OR\nIF (User story is similar to "as a s-c-d user i\'d like to have {{runtime info}} as shell command so i can use this to list the details about the module such as {{host}} {{port}} and the like.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "change springsource references in pom.xml to spring/spring.io this is currently in the m6 pom: <organization> <name>springsource</name> <url>http://springsource.org</url> </organization>") OR\nIF (User story is similar to "document router processor module for an example see comments here: https://jira.springsource.org/browse/xd-671") OR\nIF (User story is similar to "create gradle task to check that all projects have descriptions this keeps coming up as an issue that prevents us from publishing to maven central.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "have resourcemoduleregistry transparently proxy a remote root thru filesystem archivemoduleregistry and the use of boot archives inherently relies on java.io.file have resourcemoduleregistry extend/compose archivemr to transparently download and cache (remote) jars that may be located in a (non-file:) location. the staging area should be customizable but some subdir of java.io.tmpdir sounds like a sensible default") OR\nIF (User story is similar to "flatten out ephemeral nodes flatten out ephemeral nodes written by containers when deploying modules. for instance instead of {{.../streams/moduletype/modulelabel/container}} use {{.../streams/moduletype.modulelabel.container}}. this change allows us to derive state for a stream/job without having to traverse multiple layers of znodes. this is a big deal because: * each level of children requires a network call * curator can only cache one level of children") OR\nIF (User story is similar to "suppress deliverymode header in rabbitmq source related to xd-2567 which fixed this problem but only in the bus. {quote} 2016-02-19t18:25:24-0500 1.2.1.release warn simpleasynctaskexecutor-1 support.defaultamqpheadermapper - skipping header \'amqp_deliverymode\' since it is not of expected type [class org.springframework.amqp.core.messagedeliverymode] it is [class org.springframework.amqp.core.messagedeliverymode] {quote}")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "replace spring-xd-messagebus-* dependencies with scs xd 2.0 will not have direct dependency on the s-c-s binder (as mb has been renamed). the message bus code is obsolete/orphaned in xd 2.0 but some is required to support current integration tests. we can look at pruning it some more but complete removal likely depends on integrating the s-c-s enabled admin spi. mb will remain in xd 1.x.") OR\nIF (User story is similar to "xd distributed tests are broken there are test failures running xd distributed tests. it looks like all the test failures are related to npe on deploymentproperties format: java.lang.nullpointerexception org.springframework.xd.rest.domain.support.deploymentpropertiesformat.formatdeploymentproperties(deploymentpropertiesformat.java:72) org.springframework.xd.rest.client.impl.jobtemplate.deploy(jobtemplate.java:71) org.springframework.xd.distributed.test.jobstatetests.testjobstatetransition(jobstatetests.java:83)") OR\nIF (User story is similar to "jdk 1.8 compile warning for containerconfiguration the following warning appears when compiling with jdk 8: {panel} /users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/singlenodeapplication.java:67: warning: auxiliary class containerconfiguration in /users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/containerserverapplication.java should not be accessed from outside its own source file .child(containerconfiguration.class)}} {panel} can this be turned into a static inner class?")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "allow user to configure tests with di with the addition of sinks and sources that require connections with external entities (hadoop jms jdbc ...) the environment setup is getting unwieldy. * integrate springjunit4classrunner.class into acceptance tests. * retrieve environment variables via dependency injection from application.properties. * utilize profiles for --local single node --local cluster --ec2 single node --ec2 cluster") OR\nIF (User story is similar to "the ability to route within streams a flow or a processor component may require routing semantics. currently the stream assumes a single input and output for each module. a flow may support multiple outputs - switch routing that is - recipient list is not currently supported (another subtask?). we need to support semantics like: a |[output.foo:coutput.bar:ddefault:e]") OR\nIF (User story is similar to "user wants ability to test sources examples: 1. be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml pass in some property file for parameters to be replaced and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality. 2. test for as many source types as is \'reasonable\' e.g. mqtt/tcp testing might be harder than say rabbitmq. 3. test that sending json results in media-type header is set to json 4. test that sending pojo " pojo 5. test that sending tuple " tuple 6. test that sending raw bytes " raw bytes")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "ensure job definitions are escaped in ui if using the definition <aaa || bbb> where the definition starts with a "<" and ends with a ">" the definition for the composed job does not appear on the definition page.") OR\nIF (User story is similar to "container and single node do not update their associated log after the container/singlenode is up and running the application does not update the singlenode.log or containernode.log. create a stream "time|log". you will see the timestamp in your console but it will not be in the log.") OR\nIF (User story is similar to "add caching to moduleoptionsmetadataresolver will likely involve having the module identity (type+name) be part of the optionsmetadata identity/cache key")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "remove org. in hsqldb dependency") OR\nIF (User story is similar to "update rpm and brew recipes") OR\nIF (User story is similar to "redissink to support in-memory store")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to remove hadoop dependencies from root classpath so we don\'t have to incur the penalty of classloading unnecessary libraries at the startup time. the goal is to at least try and decouple for situations when hdfs is not used for module registry.") OR\nIF (User story is similar to "as a user i need the ability to configure docker xd containers so that i can link to external services such as _rabbit redis zookeeper hadoop mongo etc_. includes pointers to: * linking/binding attributes * environment variables") OR\nIF (User story is similar to "as a user i\'d like to have a _generator_ source module so that i can create a number of messages of a specified size (similar to rabbit\'s perftest utility). example: generator --nummsgs 10000 --msgsize 1024 --numthreads 1")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "return full modulestatus information remove all stubs and check all required information is returned accurately.") OR\nIF (User story is similar to "provide .settings formatting rules so that they\'re shared thinking about using the official springsource rules as a template") OR\nIF (User story is similar to "add ci job in bamboo to run xd integration tests ci job will run integration tests that are tagged for ci build.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "spike: research request/reply support to kafka message bus the scope is to research the available options to provide request/reply support for kafka. * document findings * pocs previous desc: the bindrequestor and bindreplier methods of the message bus need to be implemented.") OR\nIF (User story is similar to "spark streaming module executor use getmessagebuilderfactory(beanfactory) we need to use getmessagebuilderfactory(beanfactory) to initialize messagebuilder in spark streaming module executor. please see the discussion: https://github.com/spring-projects/spring-xd/pull/1454/files#r24367825") OR\nIF (User story is similar to "integrate code coverage reports into the ci process not sure if this is best done via sonar our sonar build plan the nightly one or the frequent one off master... open question is if we want to fail a build do to code coverage levels.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "filejdbc job throws exception during acceptance tests currently the testfilejdbcjobmultipleinvocations fails on line 156 stating data is different in table that what is expected. currently this is failing on the single admin/container deployment using redis as a transport. also seeing the following exception in the attached log: {noformat} 2.0.0.snap error xdbus.job:ec2job3.0.requests-1 step.abstractstep - encountered an error executing step step1 in job ec2job3 org.springframework.batch.item.itemstreamexception: failed to initialize the reader ... caused by: java.lang.illegalstateexception: input resource must exist (reader is in \'strict\' mode): url [file:/tmp/xd/output/filejdbctest/filejdbctest1.out] {noformat} the file is should be present and data present for the test. at least according to the checker on ec2 and local deployments.") OR\nIF (User story is similar to "bind producer before consumer {quote} here is the full exception: org.springframework.messaging.messagedeliveryexception: dispatcher has no subscribers for channel \'resourceconfiguredmodule [name=filter type=processor group=request-rate index=0 @58b0f318]:use-expressiondefaultadminsinglenodehsqldbserver:9393.output\'. nested exception is org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers and here is that stream: topic:httpstartstop > filter --expression=payload.gethttpstartstop().getpeertype().name().equals(\'client\') | requestrateaggregator | appmetricssplitter | router --expression=\'topic:app-request-rate-\'+#jsonpath(payload\'$.appid\') [2:59 pm] gary russell: @markfisher @ilayaperumalgopinathan @patrickperalta this looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. the tap is started before the tap stream is deployed. but it\'s not clear to me how the filter module could be deployed/bound as a consumer before the requestrateaggregator [3:08 pm] gary russell: i see the problem: abstractmessagebusbinderplugin.bindconsumerandproducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @davidturanski {quote}") OR\nIF (User story is similar to "accessing xd-admin urls in the browser return xml and not json here is an example: the following request for streams: http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams returns: this xml file does not appear to have any style information associated with it. the document tree is shown below. <errors xmlns:atom="http://www.w3.org/2005/atom"> <error logref="httpmessagenotwritableexception"> <message> could not marshal [pagedresource { content: [links: [<http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams/ticktock>rel="self"]] metadata: metadata { number: 0 total pages: 1 total elements: 1 size: 20 } links: [] }]: null nested exception is javax.xml.bind.marshalexception - with linked exception: [com.sun.istack.saxexception2: unable to marshal type "org.springframework.xd.rest.client.domain.streamdefinitionresource" as an element because it is not known to this context.] </message> </error> </errors>")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to setup a performance testing infrastructure (rackspace) so i can start benching kafka baselines and continue with xd use-cases.") OR\nIF (User story is similar to "as a developer i\'d like to migrate module deployment from the "repository" abstraction (used for stream/job definitions) so i can create it as a pluggable runtime spi.") OR\nIF (User story is similar to "as a user i should be able to leverage native _websocket_ sink so that i can take the advantage of full-duplex communications channels over a single tcp connection.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "ensure dsm matrix is diagonal") OR\nIF (User story is similar to "add command for tap creation") OR\nIF (User story is similar to "add batchmbeanexporter for batch modules")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to create a example to demonstrate jdbc to hdfs data movement.") OR\nIF (User story is similar to "as a developer i\'d like to brainstorm and investigate various techniques around installation of xd modules from a maven repo so i could define the module {{artifactid}} from cli to have the module downloaded from the repo and installed to a running spring xd runtime.") OR\nIF (User story is similar to "as a user i\'d like to use the java receptor client so i can interact with diego runtime using the java receptor rest apis.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to migrate the current master branch ci builds to ec2 instances so i can manage them all in one-place reliably.") OR\nIF (User story is similar to "as a developer i\'d like to fix the offset management with kafka _source_ module so that i can efficiently perform fetch operation from the given offsets.") OR\nIF (User story is similar to "as a user i\'d like to define security definitions so that i can configure entity (rest api) specific group/role access policies.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "consider using the conversionservice to convert incoming message payload to reactor based processor\'s input type. in {noformat} broadcastermessagehandler.handlemessageinternal {noformat} the call {code:java} } else if (classutils.isassignable(inputtype message.getpayload().getclass())) { //todo handle type conversion of payload to input type if possible ringbufferprocessor.onnext(message.getpayload()) {code} could try to invoke a conversion service") OR\nIF (User story is similar to "moduleconfigurationexception should not report http 500 see discussion at https://github.com/spring-projects/spring-xd/pull/1537#issuecomment-99583179 this is likely a client error so should be in the 4xx family. this requires customization of restcontrolleradvice") OR\nIF (User story is similar to "more dsl work: using and policing & for job step lists the new parser supports | for connecting regular modules and & for connecting job steps. the modules in the ast that were connected with & are tagged but nothing is currently using that information (it doesnt get into the module deployment request). we need to think about using this data: policing the modules that are being deployed to ensure they are job steps for example.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a build manager i\'d like to setup ci infrastructure so that i can run integration tests in windows os automatically as we commit-trigger new builds. *scope:* * use the environment where bamboo is running * gain access to powershell * setup services (redis rabbit etc.) * kick-off ci task") OR\nIF (User story is similar to "as a spring xd user i\'d like to persist module (aka: {{cf apps}}) metrics directly so i can relay that information via rest-apis and not depend on the current coupling of {{xd-container}}\'s. currently sboot\'s {{export()}} api allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). this could be something to explore as part of this scope.") OR\nIF (User story is similar to "as a user i\'d like to have a common shared location so that i can place the dependent jar\'s that are required by 2 or more custom modules. *current recommendation:* * place the dependent jar under xd/lib folder * if it necessary to support different versions of jar\'s then bundle it in custom module to get around the _classloader_ problem if a older/newer version exist in xd/lib")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "create ci for xd-ec2 project automated test will use directly use the deployer class * asserts on basic info of runninginstance ** check that ebs was mounted ** that application was unzipped ** redis and rabbit are running via port checks * http requests on admin port for ** root path ** list of modules * @afterclass that will look for the cluster name and terminate all instances look at live tag in jclouds tests for some additional tactics") OR\nIF (User story is similar to "vary consumer size (ec-db-4) using a single producer message size of 1000 bytes pretch of 100. send 1m messages and increase or decrease so that a given test iteration takes about 2 minutes. vary the number of consumers. measure the msg/sec rate and calculate the data transfer rate in mb/sec. *number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50 during the measurements look at the rabbitmq admin ui and see if the queue is backing up.") OR\nIF (User story is similar to "better approach to handle module execution framework currently when the module doesn\'t need to go through message bus binding the module interface provides \'shouldbind()` method to return false. the shouldbind() is being used in other place where moduletypeconversionplugin is excluded for spark streaming modules. we need a better approach to refactor this. also see the discussion here: https://github.com/spring-projects/spring-xd/pull/1438#discussion_r24150937")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create shell command for restarting a specific job instance") OR\nIF (User story is similar to "add dependencies needed for running a job using hbase") OR\nIF (User story is similar to "create ci process for xd build bamboo based")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to benchmark rabbit performance so that i can use the results as reference to setup xd cluster.") OR\nIF (User story is similar to "as a user i\'d like to have the option to _stop_ an existing sqoop job so that i can clean-up resources at the time of completion.") OR\nIF (User story is similar to "as a user i\'d like to have the option to setup _batching_ so that i can ingest data in batches as opposed to payload-at-a-time.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring-cloud-data developer i\'d like to use an in-memory stream definition repository so i don\'t have to spin up a store obviously this will not persist between application executions but it will be useful for a simplified development experience.") OR\nIF (User story is similar to "as a spring xd developer i\'d like to refactor current controller with spi calls so i can invoke the respective admin spi implementation based on the deployment. *controllers to refactor* * containerscontroller * streamscontroller * modulescontroller * jobscontroller") OR\nIF (User story is similar to "as a user i\'d like to have the option to specify system properties that will be passed in to the sqoop job which runs in it\'s own java process. this is needed for defining memory usage and also for defining some options for various connector implementations.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "ui: user should be able to filter the list of executions on the execution tab on clicking the executions tab user should see the list of all batch job executions. there should be options to filter job executions by few criteria such as by job name execution time etc.") OR\nIF (User story is similar to "cleanup hsqldb data directory used by tests after each test completion currently the "data" directory created by the hsqldb process during the tests run is not cleaned up and may cause issues. we should delete the "data" directory after each test completion.") OR\nIF (User story is similar to "add support to upload custom modules as an s-c-d user i\'d like to upload custom modules using shell/rest-api so i can contribute modules and create streaming/batch pipelines.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "list runtime modules by wrong containerid should throw exception with pr#340 listing of runtime modules with a non-existent containerid will display empty table. instead we can throw exception saying container doesn\'t exist.") OR\nIF (User story is similar to "remove jmxenabled as a cmdline option and enable jmx by default after some discussion and voting we decided to remove "jmxenabled" as a command line option and have jmx enabled by default. this can be disabled from xd-config.yml externally.") OR\nIF (User story is similar to "fix failing script integration test see https://build.spring.io/browse/xd-scripts-723")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "redisaggregatecounterrepository doesn\'t give proper results back both luke\'s original code and my refactored pr[1] (which uses same code snippet) seem to behave strangely. stored values seem fine but the getcounts() method seems phony. to test: 1) stream create foo --definition "time|log" 2) tap create bar --definition "tap@foo | aggregatecounter" 3) curl -h "application/json" http://localhost:8080/metrics/aggregate-counters/bar this gives default bucketing (hourly) but chances are that they are empty.") OR\nIF (User story is similar to "improve type handling for jdbc sink the jdbc sink is currently limited to handling the entire payload as a string and converting a single json object to row data. we should improve that and support the following input types: - linkedcaseinsensitivemap (single row) - list<linkedcaseinsensitivemap> (multiple rows as a batch insert) - json string {"id":74488"name":"foo""year":"2014"} (single row) - json array [{"id":74488"name":"foo""year":"2014"}{"id":74489"name":"bar""year":"2014"}] (multiple rows as a batch insert) - none of the above use payload.tostring() the above matches what the new jdbc source puts out (depending on outputtype used)") OR\nIF (User story is similar to "further decouple message bus deps (test scope) commit https://github.com/spring-projects/spring-xd/commit/8d28b2786acbdea1617d7e903b805e5af5369b90 removed messagebus implementations from the main dirt classpath but used a trick to have tests working (basically mb classes *are* on the cp when in test scope). this story is about adding more gradle projects that support classpath isolation when running tests (and also when authoring a mb implementation). this would avoid false positives such as https://github.com/spring-projects/spring-xd/pull/1340 were lacking jars go unnoticed")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "enhance tuplecodec performance profile tuplecodec and implement performance optimizations") OR\nIF (User story is similar to "update docker versions update the current docker images to 1.1.0 release") OR\nIF (User story is similar to "the state of a task or job should be recorded such that it can be monitored by a user the state of a task or job should be recorded such that it can be monitored by a user.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "profile byte array on in-memory and kafka transport identify and report hotspots while running the load-generator source and the throughput sink on : # singlenode -> in memory transport # singlenode -> kafka transport # admin/container -> kafka transport") OR\nIF (User story is similar to "modularize xd ui from https://jira.springsource.org/browse/xd-1231 we understand the importance of modularizing client side javascript code. this story tracks modularization of xd ui.") OR\nIF (User story is similar to "add spring xd build plan for java 8 to bamboo this is issue depends on xd-761 https://build.springsource.org/browse/xd-jdk8")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring xd developer i\'d like to move {{cassandra}} module from xd to s-c-s repo so i can use it as {{sink}} to build streaming pipeline.") OR\nIF (User story is similar to "as a spring-bus lead i\'d like to review the current spring-bus architecture and the design specs so i can address any foundation level gaps.") OR\nIF (User story is similar to "as a user i\'d like to have the option of _solr_ sink so that i can perform full-text indexing and search through solr backend server.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "create shell command for restarting a specific job instance") OR\nIF (User story is similar to "add dependencies needed for running a job using hbase") OR\nIF (User story is similar to "create ci process for xd build bamboo based")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring xd developer i\'d like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective spi ({{receptor}} or {{cloudcontroller}}) implementations.") OR\nIF (User story is similar to "as a user i want to be able to provide security credentials to the xd shell so that i can interact with an xd admin server that is secured via basic auth technical implementation: add ---password and --username to the admin config command.") OR\nIF (User story is similar to "as a s-c-s user i\'d like to have the option to use more than one binder connection factory so i can mix and match where i consume and publish data. more details [here|https://github.com/spring-cloud/spring-cloud-stream/issues/140].")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to create separate repo for cf spi so i don\'t have to bundle all spi variants under one admin project.") OR\nIF (User story is similar to "as a developer i\'d like to create separate repo for k8s spi so i don\'t have to bundle all spi variants under one admin project.") OR\nIF (User story is similar to "as a developer i\'d like to create separate repo for mesos spi so i don\'t have to bundle all spi variants under one admin project.")\nThen \'3\'',
    'User story is "{case}".\nIF (User story is similar to "create tcp sink module based off si tcp inbound adapter. this will allow for event fowarding.") OR\nIF (User story is similar to "update hdfs sink documentation to reflect new functionality introduced in xd-990 and xd-991") OR\nIF (User story is similar to "documentation for use of conversion service and creating custom processing modules that use the tuple data structure.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "fix error handling in jdbchdfs job the jdbchdfs job keeps the output stream open in case of error writing to hdfs. we should improve this and close it plus throw an exception. we should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.") OR\nIF (User story is similar to "modify rest controller to obtain stream/job state see the [design document|https://docs.google.com/a/gopivotal.com/document/d/1kwtoh_xef1wmklzq8azaiuhbzwilpcdi8g9_hap8fgc/edit#heading=h.2rk74f16ow4i] for more details. the rest controller needs to be modified to obtain stream/job state once it is available in zookeeper. this depends on xd-1847.") OR\nIF (User story is similar to "error message for "missing job description" needs to be updated when using the rest interface to create a job with an empty description used to generate the following exception "definition can not be empty". now generates "xd112e:(pos 0): unexpectedly ran out of input^". the correct error should be "definition cannot be blank or null"")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to create a example to demonstrate jdbc to hdfs data movement.") OR\nIF (User story is similar to "as a developer i\'d like to brainstorm and investigate various techniques around installation of xd modules from a maven repo so i could define the module {{artifactid}} from cli to have the module downloaded from the repo and installed to a running spring xd runtime.") OR\nIF (User story is similar to "as a user i\'d like to use the java receptor client so i can interact with diego runtime using the java receptor rest apis.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "admin leader should watch zookeeper for stream deployment requests the stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed. when a stream is deployed the leader will consult its container cache and write the modules to the various /xd/deployments child nodes (see xd-1400).") OR\nIF (User story is similar to "make transport serialization configurable the refactoring done for m6 prevents overriding "codec" bean configured for messagebus. since mb is now in sharedservercontext that context can only be altered by a custom orderedcontextinitializer for example. there is currently no mechanism provided by the bootstrapcontext for dynamically loading a user\'s orderedcontextinitializer.") OR\nIF (User story is similar to "ui: refactor schedule and launch screen under deployments the current screen layout is problematic in cases where there are many deployments. having a dedicated page for launching or scheduling jobs may be desirable. alternatively a light-box-based approach may be possible but i personally don\'t favor that.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring-cloud-data developer i\'d like to use an in-memory stream definition repository so i don\'t have to spin up a store obviously this will not persist between application executions but it will be useful for a simplified development experience.") OR\nIF (User story is similar to "as a s-c-s user i\'d like to have the modules self-register itself with {{eureka}} whenever they\'re installed so i can also discover the same modules using spring xd admin spi and reuse them to create data pipelines.") OR\nIF (User story is similar to "as a user i need a \'sandbox\' docker image so that i can get started to experiment xd deployment with the following setup: * ubuntu os * full xd jar * java 7.x * redis * rabbitmq")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to bench test cases around {{tuplebuilder}} so i can identify the bottlenecks and tune for performance optimizations.") OR\nIF (User story is similar to "as a developer i\'d like to build _spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.") OR\nIF (User story is similar to "as a user i\'d like to have the option to write into _file roll_ sink so that i can store events on the local file system.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a module developer i would like the jsonstringtotupleconverter in the spring cloud streams project to maintain the types provided in the json string and not convert everything to a string representation.") OR\nIF (User story is similar to "as a temporary work around to fix xd-1935 make producible media type to \'application/json\' for job executions get request endpoints.") OR\nIF (User story is similar to "as a user i\'d like to have a landing page with higher-order links for sources processors sinks and jobs so i can jump to right section from one place.")\nThen \'1\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to add support to _flush_ offsets intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer.") OR\nIF (User story is similar to "as a developer i\'d like to resolve remaining gaps wrt ci pipelines for data flow and the family so i can continuously evaluate functionalities on every commit.") OR\nIF (User story is similar to "as a developer i\'d like to study the state management requirements so i can brainstorm and identify the design to natively add _stateful_ stream processing support in xd.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "ip address used as default data when creating paths invoking {{paths.ensurepath}} is creating a default value of the host ip address instead of the expected "empty" value.") OR\nIF (User story is similar to "rename packages that is applicable for both stream/job determine a better package name for the following packages once we have a common model that applies to both stream/job: `org.springframework.xd.dirt.stream` `org.springframework.xd.dirt.stream.zookeeper`") OR\nIF (User story is similar to "add http port command line option to adminmain currently streamserver has setport but no way for end user to set it.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to setup a performance testing infrastructure (rackspace) so i can start benching kafka baselines and continue with xd use-cases.") OR\nIF (User story is similar to "as a developer i\'d like to migrate module deployment from the "repository" abstraction (used for stream/job definitions) so i can create it as a pluggable runtime spi.") OR\nIF (User story is similar to "as a user i should be able to leverage native _websocket_ sink so that i can take the advantage of full-duplex communications channels over a single tcp connection.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to use ambari plugin so that i can provision manage and monitor spring xd cluster using the same tool i use for hadoop clusters.") OR\nIF (User story is similar to "as a developer i\'d like to design and document the approach towards deploying stream in a single container so i can have all modules within a stream colocated.") OR\nIF (User story is similar to "as a user i\'d like to have the option of _batching_ for the rabbit _sink_ so that i can write data in batches as opposed to one-at-a-time.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "the moduleoptions in modulemetadata should contain type information when querying the *modulemetadatarepository* the *moduleoptions* in class *modulemetadata* are currently only provided as *properties*. this is a problem in cases where i need to determine the type of the property. for instance security sensitive properties should not be exposed verbatim but rather be masked. right now it seems impossible (easily) to determine whether a property is e.g. of type: *org.springframework.xd.module.options.types.password*") OR\nIF (User story is similar to "fix gradle build inconsistencies and leftovers the build has some inconsistencies that should be taken care of. amongst the one i know: * the ui project is always getting cleaned for no apparent reason (there might have been one before) thus triggering a rebuild of everything downstream most notably dirt * the exec" task is not used anymore * lots of projects are getting the boot plugin applied to them. i\'m not sure 100% what that plugin does but we don\'t need the repackage bit for example.") OR\nIF (User story is similar to "document how to create a custom input/output module for existing si channel adapters document how to take an existing input/output channel adapters in spring integration and add them as a xd source/sink module. should be as end-user focused step by step guide as possible. consider including a getting started gradle/pom.xml")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a s-c-d developer i\'d like to produce ref. documentation for s-c-d architecture so i could define 1.x and 2.x deployment differences.") OR\nIF (User story is similar to "as a developer i\'d like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to invoke rest apis via shell so i can validate {{streamcontroller}} operations.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "inject moduledefinitionrepository into modulescontroller currently modulescontroller creates the moduledefinitionrepository instance with moduleregistry. instead we should inject the moduledefinitionrepository into modulescontroller directly.") OR\nIF (User story is similar to "enhance tuplecodec performance profile tuplecodec and implement performance optimizations") OR\nIF (User story is similar to "the hdfs store library should support compression when writing text need to support writing text in compressed format should initially support: - bzip2 - lzo")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "in ec2 deployment allow users to set download jars into the lib/xd directory in cases where the deployment requires jars that can not be included with the distribution the user should be able to pull a jar from a http site and place it in lib/xd. the use case is that when we removed the mysql jar from the distribution the ci tests could not start the xd instances on ec2 without it. it was suggested that we use the postgresql instead but decided to continue the use of mysql for acceptance tests.") OR\nIF (User story is similar to "improve module options support note from pr #365 - which has been merged - providing the initial level of support... pending issues (to be addressed in another pr?): - [x] complex case - [x] default values for complex case when option is not surfaced back to the module (eg "suffix" in our canonical example) - [ ] plugin provided options and values - [ ] descriptive defaults instead of actual defaults (e.g. \\<use stream name\\>) - [ ] jsr303 validation") OR\nIF (User story is similar to "localmessagebus pubsub needs a bounded task exectutor since 1.1 {{pubsub}} channels in the {{localmessagebus}} run on a {{cachedthreadpoolexecutor}}. for high volume environments where back-pressure might occur on a {{topic:}} thread we could overwhelm the system with threads. add a local bus configuration to limit the thread pool used for pubsubs and queue tasks where there are no threads available. it would be a bus-wide setting.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have a flexible rxjava module so that it can as a processor.") OR\nIF (User story is similar to "as a developer i\'d like to split up spring-xd dependencies to more fine-grained so i can get the ones "below the line" down to spring-bus-* instead of spring-xd-* bundle.") OR\nIF (User story is similar to "as a developer i\'d like to move \'serialization codec\' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to setup a performance testing infrastructure (rackspace) so i can start benching kafka baselines and continue with xd use-cases.") OR\nIF (User story is similar to "as a developer i\'d like to migrate module deployment from the "repository" abstraction (used for stream/job definitions) so i can create it as a pluggable runtime spi.") OR\nIF (User story is similar to "as a user i should be able to leverage native _websocket_ sink so that i can take the advantage of full-duplex communications channels over a single tcp connection.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add create() and deploy() methods to jobdeployer see https://docs.google.com/a/gopivotal.com/drawings/d/1kcnbvsprbjgc10itf9cskwst8wgcjgg3wgzfkqlcazu/edit create the deployer if it doesn\'t exist.") OR\nIF (User story is similar to "add create() and deploy() methods to streamscontroller see https://docs.google.com/a/gopivotal.com/drawings/d/1kcnbvsprbjgc10itf9cskwst8wgcjgg3wgzfkqlcazu/edit create optionally deploys") OR\nIF (User story is similar to "decouple messagebus dependencies *refactoring scope:* (_spring-xd-dirt_) * message bus dependencies the goal is to decouple them from startup phase to further enhance initialization time.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "move $xd_home/modules/processor/scripts out of the way since the refactoring of the module registry that does not "look inside" a module it can\'t know that the scripts directory is not a module. everything that is a direct child of source processor sink job should be a module archive. everything else supporting that should be moved out e.g. in modules/common") OR\nIF (User story is similar to "no way to set \'makeunique\' false when creating job in ui the resulting definition starts with --makeunique=true even if the makeunique checkbox is unchecked. i can check and uncheck the box and the --make unique parameter isn\'t included. since the default for this parameter is true the end result is the same. there doesn\'t seem to be a way to set --makeunique=false.") OR\nIF (User story is similar to "the use of labelled modules and taps needs more explanation https://github.com/spring-projects/spring-xd/wiki/taps mentions this but the explanation needs more elaboration and example e.g. mystream -> "http | flibble: transform --expression=payload.touppercase() | file" "tap:stream:mystream.flibble > transform --expression=payload.replaceall(\'a\'\'.\') | log")")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a developer i\'d like to setup a performance testing infrastructure (rackspace) so i can start benching kafka baselines and continue with xd use-cases.") OR\nIF (User story is similar to "as a developer i\'d like to migrate module deployment from the "repository" abstraction (used for stream/job definitions) so i can create it as a pluggable runtime spi.") OR\nIF (User story is similar to "as a user i should be able to leverage native _websocket_ sink so that i can take the advantage of full-duplex communications channels over a single tcp connection.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "add the dependencies required to use #xpath in streams thanks to gary i found this little gem of documentation to be able to use xpath expression in xd. only hiccup is that i had to also add the spring-xml.jar to the classpath (otherwise it is missing xpathexception class). http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload") OR\nIF (User story is similar to "the ability to route within streams a flow or a processor component may require routing semantics. currently the stream assumes a single input and output for each module. a flow may support multiple outputs - switch routing that is - recipient list is not currently supported (another subtask?). we need to support semantics like: a |[output.foo:coutput.bar:ddefault:e]") OR\nIF (User story is similar to "change inconditionnal thread.sleep() calls in tests to smarter incremental pauses there are a lot of thread.sleep() calls with delays chosen in the 1-2 seconds range. change to a while loop with smaller pauses until a timeout is reached and give up. this applies to verification code (e.g. verifying that a counter has expected value) as well as file setup or http being ready to accept requests etc")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "creating a tap with same name as existing streams results in infinite loop see http://stackoverflow.com/questions/17157068/counter-analytics-in-springxd the underlying issue is stream creation with a name already taken though") OR\nIF (User story is similar to "create ootb batch job that uses the hadoop shell to copy multiple files from hdfs to a local directory this is the inverse of xd-986 and will require creating a custom tasklet but with the input/output reversd.") OR\nIF (User story is similar to "admin leader should watch container nodes in zookeeper this will require a zookeeperconnection in adminserverapplication based on singlenode vs. distributed (via profiles see: containerserverapplication for an example). then a pathchildrencache should be established for the /xd/containers node.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "bind producer before consumer {quote} here is the full exception: org.springframework.messaging.messagedeliveryexception: dispatcher has no subscribers for channel \'resourceconfiguredmodule [name=filter type=processor group=request-rate index=0 @58b0f318]:use-expressiondefaultadminsinglenodehsqldbserver:9393.output\'. nested exception is org.springframework.integration.messagedispatchingexception: dispatcher has no subscribers and here is that stream: topic:httpstartstop > filter --expression=payload.gethttpstartstop().getpeertype().name().equals(\'client\') | requestrateaggregator | appmetricssplitter | router --expression=\'topic:app-request-rate-\'+#jsonpath(payload\'$.appid\') [2:59 pm] gary russell: @markfisher @ilayaperumalgopinathan @patrickperalta this looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. the tap is started before the tap stream is deployed. but it\'s not clear to me how the filter module could be deployed/bound as a consumer before the requestrateaggregator [3:08 pm] gary russell: i see the problem: abstractmessagebusbinderplugin.bindconsumerandproducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @davidturanski {quote}") OR\nIF (User story is similar to "configuration conflict when using "--transport" "local" "--store" "redis" "--disablejmx" "true" "--analytics" "redis" results in both in-memory and redis based definitions of richgaugeservice - can\'t satisfy autowiring because there are two candidates. had to change --analytics=memory to get the application context to load.") OR\nIF (User story is similar to "sqoop command should not require jdbc parameters based on the ootb sqoop.xml definition on github we are required to provide the jdbc.url jdbc.username and jdbc.password as a parameter definition. {code} <bean id="sqooptasklet" class="org.springframework.xd.sqoop.sqooptasklet"> <property name="arguments"> <list> <value>${command}</value> <value>${args}</value> <value>jdbc.url=${url}</value> <value>jdbc.username=${username}</value> <value>jdbc.password=${password}</value> <value>fs.defaultfs=${fsuri}</value> ... {code} this is causing a problem if we define the the sqoop connection parameters within the args list. we are using the --password-file option in the args list and need to specify the connection info via the --connect option with the --username within the args list. our job definition is: {code} job create bdl_lookup --definition "bdl-load --command=import --args=\'--connect=jdbc:oracle:thin:@<hostname>:1821/<dbname> --username=<user> --password-file=/user/workspace/secure-files/gdw.password --table=masterdata.w_lookup_d --target-dir=/<targetfolder/lookup_d -m 1\' " {code} this results to an deployment: {code} 2015-05-07 11:40:51586 1.2.0.m1 info deploymentsupervisor-0 zk.zkjobdeploymenthandler - deployment status for job \'bdl_lookup\': deploymentstatus{state=failederror(s)=org.springframework.beans.factory.beandefinitionstoreexception: invalid bean definition with name \'sqooptasklet\' defined in class path resource [config/bdl-load.xml]: could not resolve placeholder \'url\' in string value "jdbc.url=${url}" nested exception is java.lang.illegalargumentexception: could not resolve placeholder \'url\' in string value "jdbc.url=${url}" {code} if we skip the jdbc connection info from the module.xml file similar to: {code} <bean id="sqooptasklet" class="org.springframework.xd.sqoop.sqooptasklet"> <property name="arguments"> <list> <value>${command}</value> <value>${args}</value> <!-- comment out jdbc info <value>jdbc.url=${url}</value> <value>jdbc.username=${username}</value> <value>jdbc.password=${password}</value> --> <value>fs.defaultfs=${fsuri}</value> ... {code} custom module deploys fine but get a we get a nullpointerexception in the container logs: {code} 2015-05-07 11:46:04450 1.2.0.m1 error inbound.job:bdl_lookup-redis:queue-inbound-channel-adapter1 step.abstractstep - encountered an error executing step sqooptask in job bdl_lookup java.lang.nullpointerexception org.springframework.xd.sqoop.sqooptasklet.createcommand(sqooptasklet.java:91) org.springframework.batch.step.tasklet.x.abstractprocessbuildertasklet.execute(abstractprocessbuildertasklet.java:107) org.springframework.batch.core.step.tasklet.taskletstep$chunktransactioncallback.dointransaction(taskletstep.java:406) org.springframework.batch.core.step.tasklet.taskletstep$chunktransactioncallback.dointransaction(taskletstep.java:330) org.springframework.transaction.support.transactiontemplate.execute(transactiontemplate.java:133) org.springframework.batch.core.step.tasklet.taskletstep$2.doinchunkcontext(taskletstep.java:271) org.springframework.batch.core.scope.context.stepcontextrepeatcallback.doiniteration(stepcontextrepeatcallback.java:77) {code}")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i want spring xds message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesnt happen when a container crashes and/or its redeployed.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to add support for having different binder types for module\'s channels so i can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.") OR\nIF (User story is similar to "as a user i want spring xd to pre-allocate a set of partitions between the kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesnt take place.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "expose a getter for a module unique id inside a stream definition following merge of https://github.com/spring-projects/spring-xd/pull/601 expose a unique id under which a module is known inside a stream. that id (which defaults to the module name) is what should be used as the qualifier for an option name inside a composed module ie {noformat} module compose foo --definition "f1: filter | filter" ==> f1.expression and filter.expression are available {noformat}") OR\nIF (User story is similar to "basic support for plugin contributed module options metadata pending a better approach and extension point (see xd-1050) provide a way to factor out common recurring options for modules: * inputtype * outputtype * job parameters") OR\nIF (User story is similar to "ui: improve the filtering capabilities of jobs that are executing/have executed * show only the jobs that you have created vs. those of others. (requires security - e.g. xd-1616) - probably a separate issue * show only jobs that are in a specific status/state running vs. other states. * show only jobs for the past x number of days. * show only jobs whose name matches a simple string e.g. useranalysis")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "testers need ability to wait for a file to be created in xd directory user\'s need ability to wait for user specified time in millis for a file to be created in the xd directory. if file is not created in allotted time then return false else return true. also check to see if a file exists in the xd directory.") OR\nIF (User story is similar to "refactor exception handling and update javadocs for acceptance test [add javadocs to] * streamutils * httptest * mqtttest * jmssource [exception handling] streamutils stream method should throw illegalstateexception instead of a checked exception. xdec2validation assertreceived assertvalid should throw illegalstateexception instead of a checked exception") OR\nIF (User story is similar to "update sink\'s file section to use shell commands instead of curl see http://static.springsource.org/spring-xd/docs/1.0.0.m1/reference/html/#file_sinks")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "spring-xd-module-parent creates resources outside of target folder custom modules that use {code} <groupid>org.springframework.xd</groupid> <artifactid>spring-xd-module-parent</artifactid> <version>1.1.0.release</version> {code} as a parent will get a "lib" directory created in the module root source directory. this forces us to add additional ignores in version control system. following maven convention all build files should be created under "target" folder so "lib" folder should be created as "target/lib".") OR\nIF (User story is similar to "create google doc with instructions on managing ec2 instances * logging into your xd account for example: https://946513944028.signin.aws.amazon.com/console * discuss how to terminate running instances. ** users can terminate all instances using the ui on the ec2 admin page * usage monitoring via cloudwatch * investigate what metadata in each instance is required so that cloudwatch can track") OR\nIF (User story is similar to "have resourcemoduleregistry transparently proxy a remote root thru filesystem archivemoduleregistry and the use of boot archives inherently relies on java.io.file have resourcemoduleregistry extend/compose archivemr to transparently download and cache (remote) jars that may be located in a (non-file:) location. the staging area should be customizable but some subdir of java.io.tmpdir sounds like a sensible default")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a spring xd user i want to have the ability to customize the encoders and decoders used by the kafka source sink and bus so that i can customize data formats and choose the most appropriate strategy") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to experiment how do we resolve and then add module dependent jar\'s to boot loader so i have an approach to handle external libraries required by ootb modules.") OR\nIF (User story is similar to "as a developer i\'d like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that i can use this module to ingest data from mongo.")\nThen \'5\'',
    'User story is "{case}".\nIF (User story is similar to "duplicate mbean names with router sink for some reason the integration {{mbeanexporterhelper}} is not preventing the standard context {{mbeanexporter}} from exporting the {{abstractmessagerouter}}. this should be suppressed (when an imbe is present) because it\'s annotated {{@integrationmanagedresource}}. causes {{instancealreadyexistsexception}}. workaround in the stack overflow answer. http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0 could be an si issue but investigation needed. however we should probably include the stream/job name in all mbeans for the stream (as is done for the integration exporter).") OR\nIF (User story is similar to "add support for dynamic routing it should be possible to create streams like the following which rely upon named channel support and dynamic routing capabilities: {code} http | somerouter :x > xtransformer | hdfs :y > ytransformer | hdfs {code} the \'somerouter\' processor could return "x" or "y" which determines the downstream path for each message. this should be implemented in such a way that any developer adding a router module would only need to deal with existing spring integration semantics (in this case only considering the return of "x" or "y" - whether it be spel or a pojo method invocation). perhaps in the plugin that modifies a module context we could simply add a new channelresolver implementation (by adding that channelresolver as a bean and/or a beanpostprocessor that configures that as the resolver for any router if necessary). that channelresolver would have a reference to the channelregistry so that the router actually sends its messages to those shared channels. the shared channels themselves would have been created as long as a valid downstream flow has been defined.") OR\nIF (User story is similar to "jobdeployer hides root exceptions on failure when deploying jobs the following code (line 103) hides the root cause of deployment failure: if (exceptionclassname.equals(bean_creation_exception) || exceptionclassname.equals(bean_definition_exeption)) { throw new missingrequireddefinitionexception(definition.getname() cause.getmessage()) } for example: org.springframework.xd.dirt.stream.missingrequireddefinitionexception: error creating bean with name \'datasourceinitializer\' defined in file [/users/luke/work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: cannot resolve reference to bean \'databasepopulator\' while setting bean property \'databasepopulator\' nested exception is org.springframework.beans.factory.beancreationexception: error creating bean with name \'databasepopulator\' defined in file [/users/luke/work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: initialization of bean failed nested exception is java.lang.nullpointerexception org.springframework.xd.dirt.stream.jobdeployer.deploy(jobdeployer.java:103) org.springframework.xd.dirt.stream.jobdeployer.deploy(jobdeployer.java:67) org.springframework.xd.dirt.rest.xdcontroller.save(xdcontroller.java:242)")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i need a document covering our recommendations for deploying a xd cluster using mesos with the marathon framework.") OR\nIF (User story is similar to "as a developer i\'d like to bench rabbit on rackspace infrastructure so i can have a sense on how it scales as we add more _xd-container_ nodes.") OR\nIF (User story is similar to "as a field engineer i\'d like to have a comparison of storm examples in spring xd so that it is easy to relate from implementation standpoint.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "as a user i\'d like to have a separate _yml_ file to list the deployment manifest properties so that i don\'t have to include as part of the stream definition.") OR\nIF (User story is similar to "as a spring xd user i\'d like to have ipython notebook integration so i can perform interactive data computations in real-time.") OR\nIF (User story is similar to "as a s-c-d developer i\'d like to refactor cc spi deployer with cf java-client so i can improve the overall design and performance.")\nThen \'8\'',
    'User story is "{case}".\nIF (User story is similar to "clean up publishing to maven repositories of empty module projects see the various module.xyz directories here https://repo.spring.io/libs-snapshot/org/springframework/xd/") OR\nIF (User story is similar to "simple ootb job for testing similar to {{time | log}} we should ship a simple batch job that appends a timestamp to a file. this will make it much easier to validate job functionality especially in automated tests.") OR\nIF (User story is similar to "request to create a repo for spring xd performance testing it would be nice if we have a git repo for spring xd performance testing. this would enable us to have a common repository (rather than inside spring-xd as a subproject) for all performance related code specific to any module message middleware etc.")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "add spring-xd-hadoop distro specific sub-projects we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (pivotal hd) to pull in transitive dependencies for correct hadoop distro") OR\nIF (User story is similar to "rename "node" references to "container" this applies to a few places (when addressing the issue a search should be done to uncover any others) e.g.: containerserverapplication: public static final string node_profile = "node" *options classes: "the transport to use for data messages (from node to node)" "the transport to use for control messages (between admin and nodes)"") OR\nIF (User story is similar to "upgrade groovy version to 2.2.2 currently xd hast "testcompile" dependency to use org.codehaus.groovy:groovy-all:2.2.1. the spring-integration-groovy uses "2.2.2" and it is what spring io platform uses as well. to keep it all same we can change this "testcompile" dependency to use "2.2.2"")\nThen \'0\'',
    'User story is "{case}".\nIF (User story is similar to "create a splitter module the splitter functionality in spring integration should be exposed to xd as a processing module. the splitter should use a spel expression to specify how to split the message up. *implementation suggestions* this should be a simple xml based module definition that has input/output channels and has the spel expression parameterized. the default value of the spel expression should result in the message not being split. *how to check it works* the current file or tail input source can be used to split up the text in a file into words. the tail module should be checked to see how many lines of text it will read into memory at once. the file module node with the file-to-string transformer will only work for small files as it keep the whole file in memory. if there is a big memory inefficiency in using the tail file input source create a new story to investigate how to have a file based input source that creates a message per line of text or something that is will not result in excessive memory usage.") OR\nIF (User story is similar to "reorganize toc for manual here is a strawman {noformat} getting started (rather meaty compared to other top level sections maybe have a section - running in singlenode) * running in distributed mode * running on yarn *application configuration message bus configuration monitoring and management technical documentation architecture distributed runtime (remove \'xd\' prefix) interactive shell batch jobs streams modules tuples sources processors analytics sinks taps type conversion deployment (better name?) best practices (new section) admin ui dsl reference rest api samples {noformat}") OR\nIF (User story is similar to "add a processor for restful webservices offers the functionality to make http request to a web service. i.e. outbound http gateway. example implementations: stream create --name foo --definition "trigger |rest --reply-timeout=1 --url=http://earthquake.usgs.gov/earthquakes/feed/geojson/all/day|log" stream create --name foos --definition "trigger --payload=lat=34.0567006&lon=-84.34368810000001&site=all&smap=1&searchresult=roswell%2c%20ga%2030076%2c%20usa#.uktzawsg1dd | rest --url=http://forecast.weather.gov/mapclick.php? |log"")\nThen \'0\'']

adherence_to_knowledge_limits = [
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
]

correct_outside_knowledge_domain_flags = [
    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1
]

adherence_to_similarity_threshold_flags = [0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

adherence_to_similarity_distance_threshold_flags = [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

acceptability_scores = [5.0, 5.0, 5.0, 2.00763640237451, 5.0, 2.00763640237451, 2.0141894644677456, 2.0010715005239854, 5.0, 5.0, 9.366666666666665, 2.027260197269242, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.027260197269242, 9.365851515617448, 5.0, 5.0, 5.0, 5.0, 9.366654387040366, 9.366654387040366, 2.0010715005239854, 2.00763640237451, 5.0, 5.0, 2.0010715005239854, 5.0, 5.0, 2.0010715005239854, 2.082615430012371, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 9.365851515617448, 5.0, 5.0, 2.0010715005239854, 2.00763640237451, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0010715005239854, 5.0, 5.0, 5.0, 5.0, 2.00763640237451, 9.366654387040366, 2.0010715005239854, 2.082615430012371, 5.0, 5.0, 5.0, 5.0, 2.00763640237451, 5.0, 2.0010715005239854, 5.0, 5.0, 5.0, 5.0, 2.997129241540277, 5.0, 5.0, 5.0, 2.00763640237451, 5.0, 9.366654387040366, 2.997129241540277, 5.0, 2.00763640237451, 5.0, 5.0, 5.0, 5.0, 2.0141894644677456, 5.0, 2.0010715005239854, 5.0, 5.0, 5.0, 5.0, 5.0, 9.366654387040366, 5.0, 5.0, 5.0, 2.0010715005239854, 2.0141894644677456, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 9.365851515617448, 5.0, 2.082615430012371, 5.0, 5.0, 2.00763640237451, 9.366654387040366, 5.0, 2.00763640237451, 5.0, 5.0, 5.0, 9.366654387040366, 2.00763640237451, 5.0, 5.0, 5.0, 5.0, 4.2925247902364605, 5.0, 2.0010715005239854, 9.366654387040366, 5.0, 2.020730718804219, 2.082615430012371, 5.0, 5.0, 5.0, 5.0, 2.0141894644677456, 5.0, 5.0, 5.0, 2.00763640237451, 5.0, 5.0, 2.00763640237451, 2.027260197269242, 5.0, 2.0010715005239854, 2.00763640237451, 2.020730718804219, 5.0, 2.00763640237451, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]

meaningfulness_scores = [0.0025981372594833375, 0.0, 0.0, 0.002546021044254303, 0.002659110128879547, 0.0, 0.0, 0.0, 0.0, 0.0026489895582199096, 0.0, 0.002668280601501465, 0.0, 0.0, 0.002684904634952545, 0.0027219223976135253, 0.0, 0.0, 0.0, 0.0, 0.002707873582839966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027448394894599914, 0.0025343307852745056, 0.0, 0.002562638223171234, 0.0025899940729141235, 0.0, 0.002636750340461731, 0.0, 0.0, 0.0025257080793380736, 0.0, 0.0, 0.0, 0.0026489895582199096, 0.00532198041677475, 0.0025096893310546874, 0.0025645855069160463, 0.0026646888256072997, 0.0025653076171875, 0.0, 0.0025872209668159484, 0.0, 0.0, 0.002609410881996155, 0.0, 0.0, 0.005330062508583069, 0.0, 0.0, 0.0, 0.002684904634952545, 0.0, 0.0, 0.0, 0.0025872209668159484, 0.0025366705656051634, 0.002612212896347046, 0.0, 0.0, 0.002637907862663269, 0.005391097664833069, 0.0, 0.0025872209668159484, 0.0025483563542366026, 0.005315346717834473, 0.00525034636259079, 0.0, 0.0025389936566352846, 0.002621608078479767, 0.005275791585445404, 0.0027448394894599914, 0.0, 0.002534658908843994, 0.0025739973783493043, 0.0027219223976135253, 0.0025819450616836547, 0.002575223445892334, 0.005350415706634522, 0.0, 0.0025981369614601134, 0.0025129005312919616, 0.0, 0.0, 0.0, 0.002546021044254303, 0.0, 0.0026115593314170837, 0.0, 0.005452757477760315, 0.002572680413722992, 0.0, 0.0027448394894599914, 0.0, 0.0, 0.00278689444065094, 0.0, 0.002659110128879547, 0.0, 0.0, 0.0, 0.0, 0.00265636682510376, 0.002572680413722992, 0.002615472078323364, 0.0, 0.0025235626101493837, 0.0, 0.002599307596683502, 0.0, 0.0, 0.0, 0.002582089304924011, 0.0, 0.0, 0.0, 0.002542269229888916, 0.0026453113555908203, 0.0, 0.005391097664833069, 0.0, 0.002684904634952545, 0.0025343307852745056, 0.0053562051057815556, 0.005264536142349243, 0.0, 0.0, 0.0025981369614601134, 0.002574804127216339, 0.0, 0.0026751741766929626, 0.0, 0.0, 0.002506960928440094, 0.002675923407077789, 0.0, 0.0, 0.0, 0.0025483563542366026, 0.0, 0.002684904634952545, 0.002679663598537445, 0.0027018997073173525, 0.002572680413722992, 0.0025129008293151857, 0.002562638223171234, 0.0, 0.005391097664833069, 0.0025399303436279296, 0.0, 0.0026624906063079834, 0.0, 0.0, 0.0027448394894599914, 0.005391097664833069, 0.0, 0.0, 0.005391097664833069, 0.0, 0.0, 0.0, 0.0026873469352722166, 0.0, 0.005295108556747436, 0.0, 0.0, 0.0, 0.002751592993736267, 0.002621346712112427, 0.0, 0.0, 0.0]

explanation_accuracy_decisions = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

explanation_accuracy_scores = [
    1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 8.333333333333332, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 8.333333333333332, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 8.333333333333332, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672, 1.6666666666666672
]

faithfulness_scores = [0.0, 0.75, 0.75, 0.4, 0.3333333333333333, 0.0, 0.4, 0.4, 0.3333333333333333, 0.0, 0.0, 0.8, 0.2, 0.0, 0.75, 0.8, 0.25, 0.16666666666666666, 0.0, 0.0, 0.3333333333333333, 0.75, 0.6666666666666666, 0.0, 0.2, 0, 0.25, 0.0, 0.3333333333333333, 0.2857142857142857, 0.16666666666666666, 0.3333333333333333, 0.6, 0.25, 0.3333333333333333, 0.4, 0.3333333333333333, 0.16666666666666666, 0.2857142857142857, 0.2, 0.25, 0.2857142857142857, 0.2, 0.4, 0.0, 0.3333333333333333, 0.14285714285714285, 0.5, 1.0, 0.16666666666666666, 0.3333333333333333, 0.25, 0.0, 0.4, 0.3333333333333333, 0.2857142857142857, 0.3333333333333333, 0.4, 0.6666666666666666, 0.4, 0.2, 0.3333333333333333, 0.0, 0.6666666666666666, 0.14285714285714285, 0.0, 0.4, 1.0, 0.2, 0.3333333333333333, 0.6, 0.4, 0.3333333333333333, 0.6, 0.2, 0.0, 0.3333333333333333, 0.14285714285714285, 0.6, 0.25, 0.5, 0.3333333333333333, 0.25, 0.2, 0.14285714285714285, 0.0, 0.16666666666666666, 0.0, 0.4, 0.25, 0.4, 0.25, 0.6666666666666666, 0.16666666666666666, 0.0, 0.2, 0.16666666666666666, 0.0, 0.2, 0.2, 0.4, 0.4, 0.5, 0, 0.0, 0.16666666666666666, 0.6, 0.0, 0.0, 0.25, 0.3333333333333333, 0.0, 0.5, 0.6, 0.0, 0.3333333333333333, 0.2857142857142857, 0.0, 0.16666666666666666, 0.0, 0.6, 0.4, 0.5, 0.5, 0.42857142857142855, 0.75, 0.5, 0.4, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.75, 0.4, 0.0, 0.2, 0.0, 0.3333333333333333, 1.0, 0.0, 0.2, 0.0, 0.3333333333333333, 0.5, 0.2, 0.16666666666666666, 0.2, 0.4, 0.16666666666666666, 0.6, 0.0, 0.75, 0.2, 0.25, 0.3333333333333333, 0.16666666666666666, 0.6, 0.0, 0.6, 0.0, 0.16666666666666666, 0.6666666666666666, 0.2, 0.3333333333333333, 0.25, 0.25, 0.2857142857142857, 0.2, 0.0, 0.5, 0.5, 0.4, 0.25, 0.0, 0.0, 0.25]

import csv
with open("temp_output.csv", "r+", encoding="utf8") as csvfile:
    writer =  csv.writer(csvfile)

    row = "testing_labels,testing_cases,explanations,adherence_to_knowledge_limits,correct_outside_knowledge_domain_flags,adherence_to_similarity_threshold_flags,adherence_to_similarity_distance_threshold_flags,acceptability_scores,meaningfulness_scores,explanation_accuracy_decisions,explanation_accuracy_scores,faithfulness_scores"

    columns = [c.strip() for c in row.strip(', ').split(',')]
    writer.writerow(columns)
    for i, case in enumerate(testing_cases[0]):
        explanation = explanations[i]
        explanation = explanation.replace('\n', ' ')
        row = f"{testing_labels[i]},{case},{explanation},{adherence_to_knowledge_limits[i]},{correct_outside_knowledge_domain_flags[i]},{adherence_to_similarity_threshold_flags[i]},{adherence_to_similarity_distance_threshold_flags[i]},{acceptability_scores[i]},{meaningfulness_scores[i]},{explanation_accuracy_decisions[i]},{explanation_accuracy_scores[i]},{faithfulness_scores[i]}"

        columns = [c.strip() for c in row.strip(', ').split(',')]
        writer.writerow(columns)
