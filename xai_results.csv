id;x_test;y_test;y_pred;explanations;meaningfulness;acceptability;faithfulness;explanation_accuracy_scores;explanation_accuracy_decisions;okd;similarity_threshold;adherence_to_knowledge_limits
0;Stream Destroy fails if stream deploy failed (From Eric) Deploying using the following stream fails (probably because of issues around quoting): `stream create foo --definition time | filter --expression=payload.contains('0') | log --deploy` When you try to destroy the stream the destroy fails which shouldn't happen whether the stream was valid or not.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Stream destroy fails if stream deploy failed (from eric) deploying using the following stream fails (probably because of issues around quoting): `stream create foo --definition time | filter --expression=payloadcontains('0') | log --deploy` when you try to destroy the stream the destroy fails which shouldn't happen whether the stream was valid or not and the most similar text Taps avoid transport hop taps currently source modules simply bridge tapped modules tap topic directly conversion first tap modules input channel note - ensure destroy works currently tap destroyed simple fact module longer module well need special handling tap adapter does not exceed the minimum threshold of 75%.;0.02;8.62;1.0;8.33;1;1;0;0
1;As a developer I'd like to port {{gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to port {{gauge}} module from xd to s-c-s repo so i can use it as {{sink}} module to build streaming pipeline is a user story, and is worth 5 story points. This was predicted because it is most similar to the text User id like refer pig sample use reference integrate pig jobs and similar to the text Scd user id like add rest support stream commands maneuver streaming pipeline backed and similar to the text Scd developer id like explore options bootstrap setup lattice based infrastructure scds bare metal deployment (and these texts are all user stories with a worth of 5 story points).;0.02;7.13;1.0;8.24;1;1;1;1
2;A a boot ConfigurationPropertiesModuleOptionsResolver This allows incremental adoption of boot @ConfigurationProperties as a way of being recognized as XD options;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text A a boot configurationpropertiesmoduleoptionsresolver this allows incremental adoption of boot @configurationproperties as a way of being recognized as xd options was most similar to the text Container remove shared module context separate context main container context becomes shared context modules and similar to the text Add ssl attachments mail sink add ssl attachments mail sink module see and similar to the text User required specify control channel addition user does specify rabbit control channel story allow user specify rabbit control channel (and these texts are not user stories).;0.04;2.0;1.0;1.67;0;1;1;1
3;Add install script for Redis This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gz The install script does the following: - Check the platform OS & arch - unzip the tar compile the sources;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add install script for redis this assumes the redis source tar is available under $rootdir/redis/redis-2613targz the install script does the following: - check the platform os & arch - unzip the tar compile the sources is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like create new use measure highly serialized payload measure performance differences and similar to the text User id like option track history get visibility stream name module name etc added part message header and similar to the text Performance tester id like rerun baseline benchmarks compression rabbit compare results performance snapshots (and these texts are all user stories with a worth of 3 story points).;0.01;2.03;1.0;1.67;0;0;1;0
4;As a s-c-s-m developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline. See also XD-2250;4;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-s-m developer i'd like to move {{jdbc}} module from xd to s-c-s repo so i can use it as {{sink}} to build streaming pipeline see also xd-2250 is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like update installed spring cluster multiple instances servers setup ha and similar to the text Developer id like continue poc identify scope risks overall design spi and similar to the text Qa id like include acceptance test coverage shell sink module validate functionality part every ci build (and these texts are all user stories with a worth of 5 story points).;0.07;4.48;1.0;7.9;1;1;1;1
5;As a s-c-d developer I'd like to move {{rabbit}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to move {{rabbit}} module from xd to s-c-s repo so i can use it as {{sink}} to build streaming pipeline is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;5.83;1.0;8.33;1;1;1;1
6;XD should run offline Trying to run XD offline results in an error in redis.xml because the cloudfoundry schema file is missing. We need to add the cf-runtime jar to the classpath to resolve this.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Xd should run offline trying to run xd offline results in an error in redisxml because the cloudfoundry schema file is missing we need to add the cf-runtime jar to the classpath to resolve this is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
7;add file source and sink modules;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add file source and sink modules was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;8.62;1.0;8.33;1;1;1;1
8;Wrong Jetty Util on classpath for WebHdfs We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jar Need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Wrong jetty util on classpath for webhdfs we currently include jetty-util-6126jar but we need to add correct jar for different distributions - phd uses jetty-util-7610v20130312jar need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro was most similar to the text Replace jps calls get pids container log replace execution jps retrieve pid containers acceptance tests and similar to the text Document ability use flows streams test document eg http file and similar to the text Revert specific support 12 thanks need specific class anymore (and these texts are not user stories).;0.02;2.2;1.0;1.67;0;1;1;1
9;Upgrade to Spring Boot 1.1 SNAPSHOT;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Upgrade to spring boot 11 snapshot was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;2.9;1.0;1.67;0;1;1;1
10;As a user I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have the option to write into _kafka_ sink so that i can publish mass data into kafka broker is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;8.55;1.0;8.33;1;1;1;1
11;Update to spring-data-hadoop 1.0.1.RELEASE This might mean we should adjust our hadoopDistro options to the ones supported in the new release - hadoop12 (default) cdh4 hdp13 phd1 and hadoop21;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update to spring-data-hadoop 101release this might mean we should adjust our hadoopdistro options to the ones supported in the new release - hadoop12 (default) cdh4 hdp13 phd1 and hadoop21 was most similar to the text Fix sonar build weird annotation dependency problem worked around compile sonar complains one solution add jackson 2 sonar manage and similar to the text Need set small commit level acceptance tests default commit level jobs 1000 vs original 100 tests sporadically fail need set tests small value and similar to the text Add docs job item processor brief introduction topic linking relevant spring batch documentation (and these texts are not user stories).;0.02;8.28;1.0;8.33;1;1;1;1
12;Fix package tangle between org.springframework.xd.dirt.plugins.job and org.springframework.xd.dirt.job;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Fix package tangle between orgspringframeworkxddirtpluginsjob and orgspringframeworkxddirtjob is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies and similar to the text Developer want abstraction support multiple binder types future and similar to the text User id like parameterize options generate code fly needed (and these texts are all user stories with a worth of 5 story points).;0.02;8.16;1.0;8.33;1;0;1;0
13;Allow sending to multiple named channels at once Currently it’s possible to do this via {code} source | router --expression=''queue:queue1queue:queue2'' {code} but this involves an additional hop to the message bus for the pipe between the source and router. It would be better if this was supported directly with the existing named channel syntax to remove this pipe ie {code} source > queue:queue1queue:queue2 {code} This would be useful as a possible solution in the scenario described in XD-3613 as an alternative to using topics on the Redis message bus which don’t support having multiple instances of the same consumer.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Allow sending to multiple named channels at once currently it’s possible to do this via {code} source | router --expression=''queue:queue1queue:queue2'' {code} but this involves an additional hop to the message bus for the pipe between the source and router it would be better if this was supported directly with the existing named channel syntax to remove this pipe ie {code} source > queue:queue1queue:queue2 {code} this would be useful as a possible solution in the scenario described in xd-3613 as an alternative to using topics on the redis message bus which don’t support having multiple instances of the same consumer was most similar to the text Investigate fall values running yarn support using configuration modules atm current code was committed time improvements handling module configuration switch include bean definitions remove configuration classes see add support configuration another short term hack put prefix value used and similar to the text Add named channel api need abstraction place retrieve messages named channel right implementation agnostic way quite useful integration tests streams eg focussed tests resorting nonessential sinks sources etc - eg code router code and similar to the text Elk - log like experiment elk stack combination extract end-to-end real-time insights structured unstructured data source possibly provide integration endpoints components features search analyze real-time scrub parse enrich data visualization website (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
14;As a developer I’d like override the partition function within my source or processor module so I can send the data to a specific partition.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i’d like override the partition function within my source or processor module so i can send the data to a specific partition is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option disable db requirement setup use dirt stream processing requirement and similar to the text Developer id like partitions scale containers bring running reestablish dynamic partitions and similar to the text User id like use java receptor client interact using java receptor rest apis (and these texts are all user stories with a worth of 8 story points).;0.12;8.48;1.0;8.33;1;1;1;1
15;As a user I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources.;3;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed i can clean-up resources was most similar to the text Remove jar build directory - need remove and similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job and similar to the text Update build script use correct version based (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
16;Ensure that each controller's list() returns PagedResources;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Ensure that each controller's list() returns pagedresources was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;7.13;0.0;1.67;0;1;1;1
17;Gemfire cache closed when a gemfire module is undeployed Need to investigate why this is happening normally setting {code:xml} <gfe:client-cache close=false/> {code} prevents the (singleton) cache from closing when the application context is closed.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Gemfire cache closed when a gemfire module is undeployed need to investigate why this is happening normally setting {code:xml} <gfe:client-cache close=false/> {code} prevents the (singleton) cache from closing when the application context is closed was most similar to the text Update sources section use shell commands instead curl see and similar to the text Create reusable responsive ui layout render tabular view create reusable responsive ui layout render returned rest endpoint part try bootstrap 300 use responsive styles offered and similar to the text Add job integration tests using implementations uses problem was discovered manual integration test was executed minimum run implementations (and these texts are not user stories).;0.04;2.0;1.0;1.67;0;1;1;1
18;Update spring-xd-extension-reactor dependency Currently the reactorEnv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project. This enables boot's ReactorAutoConfiguration to initialize the reactor environment we have the reactor setup configured for both admin and container server applications. Since reactor environment is not being used by container and only used by the reactor-syslog module we can move the reactorEnv bean definition in reactor-syslog module. There is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update spring-xd-extension-reactor dependency currently the reactorenv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project this enables boot's reactorautoconfiguration to initialize the reactor environment we have the reactor setup configured for both admin and container server applications since reactor environment is not being used by container and only used by the reactor-syslog module we can move the reactorenv bean definition in reactor-syslog module there is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed was most similar to the text Remove currently gets added dependency need remove 10 fir pig jobs version remain though and similar to the text Enable grouping modules deployment example code b c code b c modules deployed together composite module 2 options maybe handle one defining type simply bridges channels bs output cs input example second option deploy together node modules using and similar to the text Add required jars needed use scheme talk hdfs http (and these texts are not user stories).;0.01;2.03;1.0;1.67;0;1;1;1
19;As a s-c-s developer I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.;3;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-s developer i'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so i can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Developer id like port module scs use sink module build streaming pipeline and similar to the text Spring user need listen jms topic ingest messages process messages currently module allows queues and similar to the text User id like ability visually explore cluster view aware components deployed connected within topology (and these texts are all user stories with a worth of 2 story points).;0.04;5.83;1.0;8.33;1;1;1;1
20;As a QA I'd like to include acceptance test coverage for _aggregate-counter_ sink module so that I can validate the functionality as part of every CI build.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a qa i'd like to include acceptance test coverage for _aggregate-counter_ sink module so that i can validate the functionality as part of every ci build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.01;8.62;1.0;8.33;1;1;1;1
21;Add tab completion for named channels (i.e. queue:xyz >) Tab completion doesn't currently list/support queue as a source. For example if typing the following stream: stream create b --definition queue:bar > transform --expression=payload+'-bar' | log --deploy Tab completion doesn't recognize or suggest queue or anything after it until after the first bar |. The same applies to named channels queue as a sink.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add tab completion for named channels (ie queue:xyz >) tab completion doesn't currently list/support queue as a source for example if typing the following stream: stream create b --definition queue:bar > transform --expression=payload+'-bar' | log --deploy tab completion doesn't recognize or suggest queue or anything after it until after the first bar | the same applies to named channels queue as a sink was most similar to the text Sample app process analyze network packets create example application demonstrates processing stream network packets potential scenario detection ongoing cyber attacks scanning tls packets abuse ssl vulnerability heart bleed library help and similar to the text Tap connection listener close tap path children cache disconnect currently implements closes taps child event child event recreates tap previously still hanging better close cache disconnect and similar to the text Unable destroy stream using http source destroying stream contains http source exception thrown even though stream destroyed resources ie port still use currently setup set true running system http needs time release port recommendation set false instead true (and these texts are not user stories).;0.06;2.04;1.0;1.67;0;1;1;1
22;Add http port command line option to AdminMain Currently StreamServer has setPort but no way for end user to set it.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add http port command line option to adminmain currently streamserver has setport but no way for end user to set it is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.02;2.03;1.0;1.67;0;0;1;0
23;Add @XmlRootElement to all REST resources Some REST resources lack an @XmlRootElement annotation. This causes a JAXB marshalling error when trying to access the API with an Accept header of xml (which is the default in most browsers) This is a preliminary to XD-1800 (which is much more involved) only to fix ugly exception;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add @xmlrootelement to all rest resources some rest resources lack an @xmlrootelement annotation this causes a jaxb marshalling error when trying to access the api with an accept header of xml (which is the default in most browsers) this is a preliminary to xd-1800 (which is much more involved) only to fix ugly exception was most similar to the text Shell distribution zip missing libraries distribution zip include directory libraries get following exception starting shell exception thread main and similar to the text Create repository narrative need persistent way register job definitions beyond map registry implementation spring batch acceptance able register find job definitions registry registry backed persistent and similar to the text Fix tangle container event references referenced stopped (and these texts are not user stories).;0.04;2.02;1.0;1.67;0;1;1;1
24;Spike to model the cluster nodes. Each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them. The deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group. The project https://github.com/spring-projects/spring-data-grid is the start of this model.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Spike to model the cluster nodes each node in the cluster advertises itself and the admin node listens to these ads and creates groups out of them the deployment of jobs and stream processing can then be deployed onto a specific group and specific nodes within the group the project https://githubcom/spring-projects/spring-data-grid is the start of this model was most similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases and similar to the text Fix tangle container event references referenced stopped and similar to the text Kafka tests assume offset 0 testing queue partitions content read assumed start offset 0 incorrect topics may exist already especially ci environment (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
25;As a Spring XD developer I'd like to port {{http-client}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd developer i'd like to port {{http-client}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline was most similar to the text Parameterize source add support tcp source currently hard-coded use udp port need parameterize port provide option use tcp and similar to the text Add single threaded executor service eliminate any race conditions deployments containers cluster and similar to the text Fix startup messages started container documentation (and these texts are not user stories).;0.04;3.01;1.0;1.67;0;1;1;1
26;Admin leader election issue when using different management port When the admin is started with the different management port (default is the same as that of admin http port) then the leadership is requested when the management context is setup. The leadership election should happen only using the Admin server application context. With this the following exception is thrown when deployment requests are handled: 2015-03-24 21:48:26340 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000004 org.springframework.xd.dirt.server.admin.deployment.DeploymentException: testStream org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164) org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83) org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109) org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117) org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115) org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:73) org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43) org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678) org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712) org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65) org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) java.util.concurrent.FutureTask.run(FutureTask.java:262) java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null. org.springframework.util.Assert.notNull(Assert.java:112) org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81) org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161) ... 17 more;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Admin leader election issue when using different management port when the admin is started with the different management port (default is the same as that of admin http port) then the leadership is requested when the management context is setup the leadership election should happen only using the admin server application context with this the following exception is thrown when deployment requests are handled: 2015-03-24 21:48:26340 120snap error deploymentsupervisor-0 queuedistributedqueue - exception processing queue item: queue-0000000004 orgspringframeworkxddirtserveradmindeploymentdeploymentexception: teststream orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployresource(abstractinstancepersistingdeployerjava:164) orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeploy(abstractinstancepersistingdeployerjava:83) orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployall(abstractinstancepersistingdeployerjava:109) orgspringframeworkxddirtstreamabstractinstancepersistingdeployerdeleteall(abstractinstancepersistingdeployerjava:117) orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerprocessdeploymentmessage(deploymentmessageconsumerjava:115) orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerconsumemessage(deploymentmessageconsumerjava:73) orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerconsumemessage(deploymentmessageconsumerjava:43) orgapachecuratorframeworkrecipesqueuedistributedqueueprocessmessagebytes(distributedqueuejava:678) orgapachecuratorframeworkrecipesqueuedistributedqueueprocessnormally(distributedqueuejava:712) orgapachecuratorframeworkrecipesqueuedistributedqueueaccess$300(distributedqueuejava:65) orgapachecuratorframeworkrecipesqueuedistributedqueue$5run(distributedqueuejava:629) javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) javautilconcurrentfuturetaskrun(futuretaskjava:262) javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskaccess$201(scheduledthreadpoolexecutorjava:178) javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskrun(scheduledthreadpoolexecutorjava:292) javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) javalangthreadrun(threadjava:745) caused by: javalangillegalargumentexception: module deployment request path cache shouldn't be null orgspringframeworkutilassertnotnull(assertjava:112) orgspringframeworkxddirtserveradmindeploymentzkzkdeploymenthandlerundeploy(zkdeploymenthandlerjava:81) orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployresource(abstractinstancepersistingdeployerjava:161)  17 more and the most similar text User id like shell automatically configure environment setup really work shell anywhere cluster best was able build file deploy already knows admin code cat admin server fs code run starting code file admin server successfully targeted fs script required seconds execute code does not exceed the minimum threshold of 75%.;0.09;2.03;1.0;1.67;0;0;0;0
27;As a Spring XD on CF user I'd like to use {{cloudController}} implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics. *Possible APIs:* {code} ModuleStatus getStatus(ModuleDescriptor descriptor) Collection<ModuleDescriptor> listModules() Map<ModuleDescriptor.Key ModuleStatus> {code};5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd on cf user i'd like to use {{cloudcontroller}} implementation of admin spi every time i deploy spring xd modules so i can leverage the spi to query for module status and health metrics *possible apis:* {code} modulestatus getstatus(moduledescriptor descriptor) collection<moduledescriptor> listmodules() map<moduledescriptorkey modulestatus> {code} was most similar to the text Fix batch job throws exception code resolve resource location pattern class path resource resolved url does exist code solved using file prefix maybe update docs and similar to the text Enable grouping modules deployment example code b c code b c modules deployed together composite module 2 options maybe handle one defining type simply bridges channels bs output cs input example second option deploy together node modules using and similar to the text Ui user able view graphical representation job may broken multiple issues provide generic approach render batch jobs graphically second especially components - provide renderings batch components - see (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
28;Enable FtpHdfsTest FtpHdfsTest was added in https://github.com/spring-projects/spring-xd/pull/1005 but excluded since it will require some changes to run on ec2 including setting up an ftpServer on ec2 with appropriate security etc.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Enable ftphdfstest ftphdfstest was added in https://githubcom/spring-projects/spring-xd/pull/1005 but excluded since it will require some changes to run on ec2 including setting up an ftpserver on ec2 with appropriate security etc is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics and similar to the text Scs developer id like investigate right approach include external library dependency ex mysql decide better handling libraries needs loaded available root cp (and these texts are all user stories with a worth of 8 story points).;0.02;8.48;1.0;8.33;1;0;1;0
29;Normalize and refactor component packaging decomposition Normalize and refactor as needed functionality currently included in - spring-integration-core (LocalChannelRegistry) - spring-integration-module (Module types upon which Flow are built) - xd-module (Depend Module types common to DIRT and Spring Integration) - spring-integration-flow (Flow specific types namespace support etc);0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Normalize and refactor component packaging decomposition normalize and refactor as needed functionality currently included in - spring-integration-core (localchannelregistry) - spring-integration-module (module types upon which flow are built) - xd-module (depend module types common to dirt and spring integration) - spring-integration-flow (flow specific types namespace support etc) is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Scd developer id like add support deploy yarn app hdfs automatically orchestrate overall deployment leveraging manifest deploy assets and similar to the text User id like option store custom module hdfs rely ha feature reliably read reinstall failure scenarios and similar to the text User id like option store custom module hdfs rely ha feature reliably read reinstall failure scenarios (and these texts are all user stories with a worth of 3 story points).;0.03;2.0;1.0;1.67;0;0;1;0
30;Type Conversion across modules This story will need to be broken down further. The current code mixes together the type conversion that happens within a single JVM (for data that is passed on a local transport between modules) and serialization/deserialization between JVMs. This should be separated. There was a suggestion that we could perhaps use typed data channels in SI as a means implement the type conversion between modules. The media-type conversion support in Spring 4 is another part of this solution.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Type conversion across modules this story will need to be broken down further the current code mixes together the type conversion that happens within a single jvm (for data that is passed on a local transport between modules) and serialization/deserialization between jvms this should be separated there was a suggestion that we could perhaps use typed data channels in si as a means implement the type conversion between modules the media-type conversion support in spring 4 is another part of this solution and the most similar text Fix job allow setting running job non apache installation - yarn app fails error find load main class - need able set any use pivotal hd does not exceed the minimum threshold of 75%.;0.02;2.0;1.0;1.67;0;1;0;0
31;Parameter parsing does not work if an argument contains '--'. Parameter parsing does not work if an argument contains '--'. For example: {code} ... | transform --expression=42 | transform --expression=--payload |... {code} Also I was surprised that this worked.. {code} | transform --expression=new StringBuilder(payload).reverse() | {code} ... but this didn't... {code} | transform --expression='new StringBuilder(payload).reverse()' | {code} I think we need to tokenize the argument (with ' if contains spaces) and remove any surrounding '...' from the result. This means if someone wants a SpEL literal they would have to use something like {code}--expression=''Hello world!''{code} resulting in a SpEL literal 'Hello world!';0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Parameter parsing does not work if an argument contains '--' parameter parsing does not work if an argument contains '--' for example: {code}  | transform --expression=42 | transform --expression=--payload | {code} also i was surprised that this worked {code} | transform --expression=new stringbuilder(payload)reverse() | {code}  but this didn't {code} | transform --expression='new stringbuilder(payload)reverse()' | {code} i think we need to tokenize the argument (with ' if contains spaces) and remove any surrounding '' from the result this means if someone wants a spel literal they would have to use something like {code}--expression=''hello world!''{code} resulting in a spel literal 'hello world!' and the most similar text User trying access uri get fails forbidden error role view access details another url error does not exceed the minimum threshold of 75%.;0.07;2.06;1.0;1.67;0;0;0;0
32;Define developer facing interfaces for Reactor Stream processors What is the core interface contract users will be exposed to when creating a processor module that uses Reactor's Stream API. Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Define developer facing interfaces for reactor stream processors what is the core interface contract users will be exposed to when creating a processor module that uses reactor's stream api some consideration for error handling should be considered as it maybe outside normal exception throwing signatures was most similar to the text Move ftp support x package batch package commit support ftp added bunch x classes belong dirt proper though added extension style project jobs module depend and similar to the text Fix tangle container event references referenced stopped and similar to the text Nodes connect admin using transport has happened once node fails whatever reason restarted does receive requests admin server file handle count based rabbit transport chasing yet felt needed recorded (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
33;Create separate commands for --all shell commands Commands like stream deploy have changed over time to allow passing a --all option. So it's either {{stream deploy foo}} or {{stream deploy --all}}. This has a number of drawbacks given that these are the only 2 alternatives: - Implementation code is cumbersome - None of the options can be marked mandatory yet one of them is required. This has to be checked in the command code itself - TAB completion is less powerful as the shell doesn't know if we want the first or the second form. Consider splitting those commands into two distinct commands one as before and one literally named {{stream deploy all}}.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Create separate commands for --all shell commands commands like stream deploy have changed over time to allow passing a --all option so it's either {{stream deploy foo}} or {{stream deploy --all}} this has a number of drawbacks given that these are the only 2 alternatives: - implementation code is cumbersome - none of the options can be marked mandatory yet one of them is required this has to be checked in the command code itself - tab completion is less powerful as the shell doesn't know if we want the first or the second form consider splitting those commands into two distinct commands one as before and one literally named {{stream deploy all}} and the most similar text Document append support writes empty file hdfs testing cluster throws exception attached file hdfs empty steps recreate using 1 job create definition deploy 2 stream create definition file deploy 3 use excel create 3 column spreadsheet save csv 4 copy csv directory does not exceed the minimum threshold of 75%.;0.05;2.0;1.0;1.67;0;1;0;0
34;Change composed module behavior to black box Composed Module currently behave as white boxes. As soon as a module is composed (say http | filter) then all options of the children modules are available (as e.g. http.port and filter.expression in the example above). Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable). Possible syntaxes : 1) {code} module compose foo --definition http --port=${myport:1234} | filter {code} 2) {code} module compose foo --definition http | filter --expose port {code} 2.1) in case of ambiguity (simulated in this particular example): {code} module compose foo --definition http | filter --expose http.port {code} 2.2) for specifying a default: {code} module compose foo --definition http | filter --expose port=1234 {code} 3) allow both 1) and 2) using 1) mainly for cases where we don't map 1 to 1 with the underlying option e.g.: {code} filter --expression=${expr}+'foo' {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Change composed module behavior to black box composed module currently behave as white boxes as soon as a module is composed (say http | filter) then all options of the children modules are available (as eg httpport and filterexpression in the example above) change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name) hardcoding of values would be retained (and possibly overridable) possible syntaxes : 1) {code} module compose foo --definition http --port=${myport:1234} | filter {code} 2) {code} module compose foo --definition http | filter --expose port {code} 21) in case of ambiguity (simulated in this particular example): {code} module compose foo --definition http | filter --expose httpport {code} 22) for specifying a default: {code} module compose foo --definition http | filter --expose port=1234 {code} 3) allow both 1) and 2) using 1) mainly for cases where we don't map 1 to 1 with the underlying option eg: {code} filter --expression=${expr}+'foo' {code} was most similar to the text Document append support writes empty file hdfs testing cluster throws exception attached file hdfs empty steps recreate using 1 job create definition deploy 2 stream create definition file deploy 3 use excel create 3 column spreadsheet save csv 4 copy csv directory and similar to the text Source module throws version 11 m1 problem trying use source module observing exception deploying stream stream definition curl data data log data code curl command works fine 101 release and similar to the text Unnecessary format enforcement module short description functional justification validation modules really necessary enforce short description must start capitol letter end period seems bit unnecessary opinionated 1 errors field error object info field rejected value snip codes arguments codes arguments default message default message short description must start capital letter end dot (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
35;stream list should show undeployed rather than blank if a stream is not deployed;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Stream list should show undeployed rather than blank if a stream is not deployed was most similar to the text Server transport option transport and similar to the text Provide python module handle io implementing python shell processor and similar to the text Port throughput modules migrate throughput scs (and these texts are not user stories).;0.03;4.94;1.0;8.33;1;1;1;1
36;Fix error handling in jdbchdfs job The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception. We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Fix error handling in jdbchdfs job the jdbchdfs job keeps the output stream open in case of error writing to hdfs we should improve this and close it plus throw an exception we should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer was most similar to the text Improve use current job does take advantage features available write hdfs spring implementations partitioning update job use similar hdfs sink inside new implementation and similar to the text Fix tangle container event references referenced stopped and similar to the text Create batch job uses shell copy multiple files hdfs local directory inverse require custom inputoutput (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
37;Module Launcher properties improvments Improve Spring Cloud Stream module launcher/resolver properties: 1) Support comma separated remoteRepositories 2) Classify/group the properties;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Module launcher properties improvments improve spring cloud stream module launcher/resolver properties: 1) support comma separated remoterepositories 2) classify/group the properties is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like create new use measure highly serialized payload measure performance differences and similar to the text User id like option track history get visibility stream name module name etc added part message header and similar to the text Performance tester id like rerun baseline benchmarks compression rabbit compare results performance snapshots (and these texts are all user stories with a worth of 3 story points).;0.02;3.01;1.0;1.67;0;0;1;0
38;Support oracle jdbc configuration for XD batch job repository Currently hsqldb postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Support oracle jdbc configuration for xd batch job repository currently hsqldb postgres and mysql job repositories are supported we need to add configurable oracle jdbc settings is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules (and these texts are all user stories with a worth of 8 story points).;0.1;2.06;1.0;1.67;0;0;1;0
39;As a user I'd like to have a Redis based _aggregation_ over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data. *Scope:* * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters]. * Identify gaps * Update reference documentation;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have a redis based _aggregation_ over field-value counters so that i can continuously write the aggregation in redis as we ingest more data *scope:* * port specs from [previous implementation|https://githubcom/spring-projects/spring-xd/wiki/old---aggregate-field-value-counters] * identify gaps * update reference documentation is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like rest api point push archive includes custom module definitions configurations manually move set scope spike assess customer requirement brainstorm document options socialize team collect feedback identify phases create new stories and similar to the text Developer id like build data pipeline using kafka message demonstrate capabilities use case consider log aggregation lambda architecture avoid code duplication eliminate tight coupling logic kafka used reliable reprocessing and similar to the text User id like option define access control list acls define access controls resource user privileges resource spike scope review customer use cases come design specs identify best approach fits identify scope dsl ui document next steps phases (and these texts are all user stories with a worth of 8 story points).;0.03;2.0;1.0;1.67;0;1;1;1
40;twittersearch stream returns duplicate tweets The twittersearch source module picks up the same tweet in successive iterations of the REST request. The reason for this is that the since_id value being set at the end of each iteration is the last item in the list of tweets but not the latest value of tweet id. Steps to reproduce: Created a stream using below definition stream create --name twittersearchspring --definition twittersearch --consumerKey=<key> --consumerSecret=<secret> --query='spring' | tweet-transformer | file --deploy tweet-transformer referred here is used from the spring-xd-samples repo and is logging the tweet ID being transformed https://github.com/spring-projects/spring-xd-samples/tree/master/tweet-transformer-processor Below is the log __________ 2015-04-14 15:47:22154 1.1.0.RELEASE INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'twittersearchspring': DeploymentStatus{state=deployed} 2015-04-14 15:47:22158 1.1.0.RELEASE INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Stream Stream{name='twittersearchspring'} deployment attempt complete 2015-04-14 15:47:24301 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:24312 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:24315 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:24318 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:24320 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:24325 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:24340 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:24342 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:24343 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:24344 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884737307549696 2015-04-14 15:47:24346 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884734723702784 2015-04-14 15:47:24348 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884730059771905 2015-04-14 15:47:24356 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884729225125888 2015-04-14 15:47:24358 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884725802405888 2015-04-14 15:47:24359 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884724938481665 2015-04-14 15:47:26465 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884724938481665 2015-04-14 15:47:26865 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:26867 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:26869 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:26871 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:26872 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:26878 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:26880 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:26882 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:26884 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:26886 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:26887 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:26889 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:26890 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:26900 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:26903 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:29004 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884739387719680 2015-04-14 15:47:29369 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884782945611776 2015-04-14 15:47:29371 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884781305663488 2015-04-14 15:47:29374 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884779506311169 2015-04-14 15:47:29376 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884775895072768 2015-04-14 15:47:29377 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771893739520 2015-04-14 15:47:29379 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771717578753 2015-04-14 15:47:29384 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884769138081792 2015-04-14 15:47:29386 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:29388 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:29389 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:29390 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:29391 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:29395 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:29399 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:29401 1.1.0.RELEASE INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:31502 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884752591544320 __________ Notice that tweet ID 587884752591544320 is picked up in second iteration as well although it was picked in the first. The issue can be fixed in the doSendLine method of TwitterSearchChannelAdapter.java where this.sinceId is being set to the last value of id. Instead the statuses map can be sorted on ID and the highest ID can be set for sinceId.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Twittersearch stream returns duplicate tweets the twittersearch source module picks up the same tweet in successive iterations of the rest request the reason for this is that the since_id value being set at the end of each iteration is the last item in the list of tweets but not the latest value of tweet id steps to reproduce: created a stream using below definition stream create --name twittersearchspring --definition twittersearch --consumerkey=<key> --consumersecret=<secret> --query='spring' | tweet-transformer | file --deploy tweet-transformer referred here is used from the spring-xd-samples repo and is logging the tweet id being transformed https://githubcom/spring-projects/spring-xd-samples/tree/master/tweet-transformer-processor below is the log __________ 2015-04-14 15:47:22154 110release info deploymentsupervisor-0 serverstreamdeploymentlistener - deployment status for stream 'twittersearchspring': deploymentstatus{state=deployed} 2015-04-14 15:47:22158 110release info deploymentsupervisor-0 serverstreamdeploymentlistener - stream stream{name='twittersearchspring'} deployment attempt complete 2015-04-14 15:47:24301 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884756488032256 2015-04-14 15:47:24312 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884752591544320 2015-04-14 15:47:24315 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884752536911873 2015-04-14 15:47:24318 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884751219986432 2015-04-14 15:47:24320 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884750620258305 2015-04-14 15:47:24325 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884749974147072 2015-04-14 15:47:24340 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884743338917888 2015-04-14 15:47:24342 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884741493272577 2015-04-14 15:47:24343 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884739387719680 2015-04-14 15:47:24344 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884737307549696 2015-04-14 15:47:24346 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884734723702784 2015-04-14 15:47:24348 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884730059771905 2015-04-14 15:47:24356 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884729225125888 2015-04-14 15:47:24358 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884725802405888 2015-04-14 15:47:24359 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884724938481665 2015-04-14 15:47:26465 110release debug twittersource-1-1 twittertwittersearchchanneladapter - search uri:https://apitwittercom/11/search/tweetsjson?q=spring&since_id=587884724938481665 2015-04-14 15:47:26865 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884766608916481 2015-04-14 15:47:26867 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884766072025089 2015-04-14 15:47:26869 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884765707116544 2015-04-14 15:47:26871 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884764394299392 2015-04-14 15:47:26872 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884761366003712 2015-04-14 15:47:26878 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884759381966849 2015-04-14 15:47:26880 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884756488032256 2015-04-14 15:47:26882 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884752591544320 2015-04-14 15:47:26884 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884752536911873 2015-04-14 15:47:26886 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884751219986432 2015-04-14 15:47:26887 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884750620258305 2015-04-14 15:47:26889 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884749974147072 2015-04-14 15:47:26890 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884743338917888 2015-04-14 15:47:26900 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884741493272577 2015-04-14 15:47:26903 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884739387719680 2015-04-14 15:47:29004 110release debug twittersource-1-1 twittertwittersearchchanneladapter - search uri:https://apitwittercom/11/search/tweetsjson?q=spring&since_id=587884739387719680 2015-04-14 15:47:29369 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884782945611776 2015-04-14 15:47:29371 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884781305663488 2015-04-14 15:47:29374 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884779506311169 2015-04-14 15:47:29376 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884775895072768 2015-04-14 15:47:29377 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884771893739520 2015-04-14 15:47:29379 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884771717578753 2015-04-14 15:47:29384 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884769138081792 2015-04-14 15:47:29386 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884766608916481 2015-04-14 15:47:29388 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884766072025089 2015-04-14 15:47:29389 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884765707116544 2015-04-14 15:47:29390 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884764394299392 2015-04-14 15:47:29391 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884761366003712 2015-04-14 15:47:29395 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884759381966849 2015-04-14 15:47:29399 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884756488032256 2015-04-14 15:47:29401 110release info twittersource-1-1 transformertweettransformer - transforming tweet with id : 587884752591544320 2015-04-14 15:47:31502 110release debug twittersource-1-1 twittertwittersearchchanneladapter - search uri:https://apitwittercom/11/search/tweetsjson?q=spring&since_id=587884752591544320 __________ notice that tweet id 587884752591544320 is picked up in second iteration as well although it was picked in the first the issue can be fixed in the dosendline method of twittersearchchanneladapterjava where thissinceid is being set to the last value of id instead the statuses map can be sorted on id and the highest id can be set for sinceid and the most similar text Assess sinks close client cache os - mac deployment type - sha - required software - sample server description destroying 3 streams sink 4th fail error connection number clients 4 exceeded limit 3 allowed default evaluation license steps reproduce shell execute following 4 times stream create name stocks definition http deploy stream destroy stocks does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
41;Add spring-xd-exec directory to Git repo Without the directory Spring XD cannot be imported into STS using its own Gradle support.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add spring-xd-exec directory to git repo without the directory spring xd cannot be imported into sts using its own gradle support is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
42;As a developer I'd like to remove Hadoop dependencies from root classpath so we don't have to incur the penalty of classloading unnecessary libraries at the startup time. The goal is to at least try and decouple for situations when HDFS is not used for module registry.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to remove hadoop dependencies from root classpath so we don't have to incur the penalty of classloading unnecessary libraries at the startup time the goal is to at least try and decouple for situations when hdfs is not used for module registry is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text Developer id like new dsl parser easily detect incorrect values ui example mail log log parsed separately ui does current parser endpoint barf second stream know first stream and similar to the text User id like r processor efficiently perform data computations statistical context streaming pipeline investigate right approach fits spring model r java libraries (and these texts are all user stories with a worth of 8 story points).;0.07;2.0;1.0;1.67;0;1;1;1
43;Container does not fail if sharing same ports on same machine with another container. * SHA baddfc24b08286a78392d5f565742c9bab5adfea * EC2 Environment ** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology h2. The test scenario # Can be duplicated with single server ZK ensemble # Start Container on a EC2 instance. Wait till it joins cluster # Start 2nd container on same EC2 instance. h2. Observed Behavior. # Container 1 starts normally # Container 2 reports that failed to bind to address. (shown in attached stack trace) ## But does not terminate ## Shown as valid container when executing runtime containers command. xd:>runtime containers Container Id Host IP Address PID Groups Custom Attributes 0c88a300-9469-4f21-a256-7733259b13c7 ip-10-70-11-185 10.70.11.185 2061 256c35b7-c9f4-43ba-81dd-e1bfff0fb7c1 ip-10-70-9-57 10.70.9.57 3604 31fedc48-2762-4c45-8075-1dce64af5391 ip-10-110-186-48 *10.110.186.48* 2396 GROUPA 524bb933-a8b5-4014-a0b5-06d4fa8b30c2 ip-10-2-209-174 10.2.209.174 2123 e993026e-e2ac-4d16-9890-0786149d7b75 ip-10-110-186-48 *10.110.186.48* 2524 GROUPA f9437b15-1ee2-4827-99d4-e7957f9abdf2 ip-10-70-9-153 10.70.9.153 2366 GROUP0;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Container does not fail if sharing same ports on same machine with another container * sha baddfc24b08286a78392d5f565742c9bab5adfea * ec2 environment ** look at zookeeper ec2 deployment test topologypng for a view of the topology h2 the test scenario # can be duplicated with single server zk ensemble # start container on a ec2 instance wait till it joins cluster # start 2nd container on same ec2 instance h2 observed behavior # container 1 starts normally # container 2 reports that failed to bind to address (shown in attached stack trace) ## but does not terminate ## shown as valid container when executing runtime containers command xd:>runtime containers container id host ip address pid groups custom attributes 0c88a300-9469-4f21-a256-7733259b13c7 ip-10-70-11-185 107011185 2061 256c35b7-c9f4-43ba-81dd-e1bfff0fb7c1 ip-10-70-9-57 1070957 3604 31fedc48-2762-4c45-8075-1dce64af5391 ip-10-110-186-48 *1011018648* 2396 groupa 524bb933-a8b5-4014-a0b5-06d4fa8b30c2 ip-10-2-209-174 102209174 2123 e993026e-e2ac-4d16-9890-0786149d7b75 ip-10-110-186-48 *1011018648* 2524 groupa f9437b15-1ee2-4827-99d4-e7957f9abdf2 ip-10-70-9-153 10709153 2366 group0 and the most similar text Throughput stream any processor one goal micro benchmark compare throughput difference two types streams 1 source sink 2 source processor sink test used source sink processor tests performed single node container direct binding turned streams 1 throughput stream create definition stream deploy properties system get following numbers throughput items elapsed time 2 throughput code available stream create definition stream deploy properties system throughput reduces less throughput items elapsed time shows 50 cpu time following thread daemon class object event list consumer consumer long boolean long boolean does not exceed the minimum threshold of 75%.;0.04;8.62;1.0;8.33;1;1;0;0
44;Create aggregator module that uses an embedded database stored in the local filesystem Similar to XD-1100. SI has the jdbc based message store. <int-jdbc:message-store id=messageStore data-source=dataSource table-prefix=MY_INT_/> The configuration of this aggregator would be configured so that it uses an embedded database hsqldb or H2 depending if there is any real perf benefit to one or the other and store the data on the local file system.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create aggregator module that uses an embedded database stored in the local filesystem similar to xd-1100 si has the jdbc based message store <int-jdbc:message-store id=messagestore data-source=datasource table-prefix=my_int_/> the configuration of this aggregator would be configured so that it uses an embedded database hsqldb or h2 depending if there is any real perf benefit to one or the other and store the data on the local file system was most similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Needs bounded task 11 channels run high volume environments might occur topic thread overwhelm system threads add local configuration limit thread pool used queue tasks threads available setting and similar to the text Assess sinks close client cache os - mac deployment type - sha - required software - sample server description destroying 3 streams sink 4th fail error connection number clients 4 exceeded limit 3 allowed default evaluation license steps reproduce shell execute following 4 times stream create name stocks definition http deploy stream destroy stocks (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
45;As a developer I want to be able to connect to multiple external systems for the same binding type so that I can read data from a system and write it to another.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i want to be able to connect to multiple external systems for the same binding type so that i can read data from a system and write it to another is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.02;8.48;1.0;8.33;1;1;1;1
46;UI - Launch a job with parameters Use a modal dialog to specify runtime parameters. There should be a little text are that gives hints as to the spring batch parameter key/value conventions e.g. for type. Might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number. 4 columns key value type identifying and an 'add parameter' button that adds a new row. This would appear as a modal dialog box polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Ui - launch a job with parameters use a modal dialog to specify runtime parameters there should be a little text are that gives hints as to the spring batch parameter key/value conventions eg for type might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number 4 columns key value type identifying and an 'add parameter' button that adds a new row this would appear as a modal dialog box polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown was most similar to the text Issue trying use http trying send json object get following error even though opened requests allow load header present requested resource origin therefore allowed access spring profiles transport local ui and similar to the text Add named channel api need abstraction place retrieve messages named channel right implementation agnostic way quite useful integration tests streams eg focussed tests resorting nonessential sinks sources etc - eg code router code and similar to the text Investigate fall values running yarn support using configuration modules atm current code was committed time improvements handling module configuration switch include bean definitions remove configuration classes see add support configuration another short term hack put prefix value used (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
47;add create() and deploy() methods to JobDeployer see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit Create the deployer if it doesn't exist.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add create() and deploy() methods to jobdeployer see https://docsgooglecom/a/gopivotalcom/drawings/d/1kcnbvsprbjgc10itf9cskwst8wgcjgg3wgzfkqlcazu/edit create the deployer if it doesn't exist is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Data scientist id like option process data using processor take advantage streaming machine learning abstractions implemented top and similar to the text Qa id like include acceptance test coverage batch job validate functionality part every ci build and similar to the text Developer id like add support explicit partition count configuration use option cleverly route payload intended consumer module (and these texts are all user stories with a worth of 5 story points).;0.05;5.64;1.0;8.33;1;0;1;0
48;Add support for specifying an undeploy-condition for stream definitions In some scenarios like when performing exploratory data-analysis on streaming data one often create a stream keep it running for some time (or until some condition is met) and then stop the stream and start to investigate the collected data. It would be cool to be able to specify some undeploy condition like e.g. a timeout after x minutes no. of events collected a specific counter past a given threshold file-size greater then x etc.;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Add support for specifying an undeploy-condition for stream definitions in some scenarios like when performing exploratory data-analysis on streaming data one often create a stream keep it running for some time (or until some condition is met) and then stop the stream and start to investigate the collected data it would be cool to be able to specify some undeploy condition like eg a timeout after x minutes no of events collected a specific counter past a given threshold file-size greater then x etc and the most similar text User id like option extend default message handling behavior http override settings control default message size notes adapter currently has hard-coded limit expose property overrides related does not exceed the minimum threshold of 75%.;0.02;2.2;1.0;1.67;0;0;0;0
49;As a user I'd like to parameterize Merge Options so I can incrementally consume the delta with the help of megastore.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to parameterize merge options so i can incrementally consume the delta with the help of megastore is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;1;1;1
50;Shell should display error messages returned from the server For example using tcpdump I can see both an exception and message information: 'HTTP/1.1 500 Internal Server Error Server: Apache-Coyote/1.1 Content-Type: application/jsoncharset=UTF-8 Transfer-Encoding: chunked Date: Fri 12 Jul 2013 13:38:26 GMT Connection: close 275 [{links:[]logref:MessageHandlingExceptionmessage:org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=nullChannel sends=0 receives=0]] with key 'xd.tap1:type=MessageChannelname=nullChannelindex=1module=log' nested exception is javax.management.InstanceAlreadyExistsException: xd.tap1:type=MessageChannelname=nullChannelindex=1module=log}] However the client only shows: http://localhost:8080:>tap create --name tap1 --definition tap@test1.file | log --deploy true 14:38:26113 WARN Spring Shell client.RestTemplate:524 - POST request for http://localhost:8080/taps resulted in 500 (Internal Server Error) invoking error handler Error creating tap 'tap1' The error doesn't seem to be logged in the XD Admin server either so the information is effectively lost.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Shell should display error messages returned from the server for example using tcpdump i can see both an exception and message information: 'http/11 500 internal server error server: apache-coyote/11 content-type: application/jsoncharset=utf-8 transfer-encoding: chunked date: fri 12 jul 2013 13:38:26 gmt connection: close 275 [{links:[]logref:messagehandlingexceptionmessage:orgspringframeworkcontextapplicationcontextexception: failed to start bean 'orgspringframeworkintegrationmonitorintegrationmbeanexporter#0#92e27d20-4c48-4131-866c-91b6cb642ca2' nested exception is orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=nullchannel sends=0 receives=0]] with key 'xdtap1:type=messagechannelname=nullchannelindex=1module=log' nested exception is javaxmanagementinstancealreadyexistsexception: xdtap1:type=messagechannelname=nullchannelindex=1module=log}] however the client only shows: http://localhost:8080:>tap create --name tap1 --definition tap@test1file | log --deploy true 14:38:26113 warn spring shell clientresttemplate:524 - post request for http://localhost:8080/taps resulted in 500 (internal server error) invoking error handler error creating tap 'tap1' the error doesn't seem to be logged in the xd admin server either so the information is effectively lost and the most similar text Hdfs sink partition path causing writes slower certain cases tested believe case latest release well stream definition 1 stream create definition rabbit script hdfs noticed was causing writes slower stream definition 2 stream create definition rabbit script hdfs definition writes much faster please note was one time test multiple times also seems another use case thanks does not exceed the minimum threshold of 75%.;0.01;3.01;1.0;1.67;0;1;0;0
51;wordcount failed to run in cloudera VM 5.7 I download the spring XD example projects and run through the steps acccording the README file for the project. I tried to change the hadoop-site.xml server.yml and wordcount.xml files but I failed get the . I am blocked by this issue. Thank you very much in advance for help. Best Regards.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Wordcount failed to run in cloudera vm 57 i download the spring xd example projects and run through the steps acccording the readme file for the project i tried to change the hadoop-sitexml serveryml and wordcountxml files but i failed get the  i am blocked by this issue thank you very much in advance for help best regards is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like rest api point push archive includes custom module definitions configurations manually move set scope spike assess customer requirement brainstorm document options socialize team collect feedback identify phases create new stories and similar to the text Developer id like build data pipeline using kafka message demonstrate capabilities use case consider log aggregation lambda architecture avoid code duplication eliminate tight coupling logic kafka used reliable reprocessing and similar to the text User id like option define access control list acls define access controls resource user privileges resource spike scope review customer use cases come design specs identify best approach fits identify scope dsl ui document next steps phases (and these texts are all user stories with a worth of 8 story points).;0.01;2.41;1.0;1.67;0;0;1;0
52;Create tests for Stream/Job deployments path data verification Based on the discussion here: https://github.com/spring-projects/spring-xd/pull/852#issuecomment-43356579 we would like to have tests created for verifying the Stream/Job deployments path data;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create tests for stream/job deployments path data verification based on the discussion here: https://githubcom/spring-projects/spring-xd/pull/852#issuecomment-43356579 we would like to have tests created for verifying the stream/job deployments path data was most similar to the text Tap name existing streams results infinite loop see underlying issue stream creation name already taken though and similar to the text Create batch job uses shell copy multiple files hdfs local directory inverse require custom inputoutput and similar to the text Additional rest endpoint working security see following error admin ui get forbidden (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
53;As a user I'd like to have the ability to configure ACLs so that I can restrict access to resources accessed via DSL Shell. *Examples:* * Who can create streams? * Who can destroy the streams? * Who can view the streams? ??(defaults to all)??;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have the ability to configure acls so that i can restrict access to resources accessed via dsl shell *examples:* * who can create streams? * who can destroy the streams? * who can view the streams? ??(defaults to all)?? was most similar to the text Need set small commit level acceptance tests default commit level jobs 1000 vs original 100 tests sporadically fail need set tests small value and similar to the text Add docs job item processor brief introduction topic linking relevant spring batch documentation and similar to the text Response code http source use case need http source module return instead 200 currently returned may codes useful able return simple additional option module allow configured (and these texts are not user stories).;0.04;7.13;1.0;8.24;1;1;1;1
54;As a developer I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to create ec2 ami with the necessary packages so that i can run the kafka perf tests is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;1;1;1
55;Clarify API or syntax for managing deployment parameters Suppose we have 3 environements of Spring XD : - Dev environment - Test environment - Prod environement ( Suppose whe develop the script bellow: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=/tmp/toto stream2 = http | filter --expression=payload.contains('titi') | file --dir=/tmp/titi ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// When we need to deploy the script in Test and Prod environements we must modify dir option of file sink. This is very easy when there is not a lot of options and when we have a small factory team. But in a big factory environment this will be problematic. In order to industrialize deployment it would be convenient to implement in DSL a directory interface API or something equivalent like below: Suppose we call this directory interface XDDI ... like XD Directory Interface :-) The script can be like that: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=XDDI('totoKey') stream2 = http | filter --expression=payload.contains('titi') | file --dir=XDDI('titiKey') ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// The XDDI keys are defined in a centralized directory interface (admin console or XDDI.properties) The XDDI keys/values in Dev environment: ///////////////////////////////////// totoKey=/tmp/toto titiKey=/tmp/titi ///////////////////////////////////// The XDDI keys/values in Test environment: ////////////////////////////////////////// totoKey=/tartempion/toto titiKey=/petaouchnok/titi ///////////////////////////////////////// The XDDI keys/values in Prod environment: ///////////////////////////////////////////////////// totoKey=/vavoirlabasijysuis/toto titiKey=/vavoirlabasijysuis/titi ///////////////////////////////////////////////////// When the script is deployed in Test or Prod environement if the script contain a key that is not defined in centralized directory the deployment fail. This will reduce errors risks in a big factory environnement (several hundred parameters and signifiant team turnover).;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Clarify api or syntax for managing deployment parameters suppose we have 3 environements of spring xd : - dev environment - test environment - prod environement ( suppose whe develop the script bellow: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payloadcontains('toto') | file --dir=/tmp/toto stream2 = http | filter --expression=payloadcontains('titi') | file --dir=/tmp/titi ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// when we need to deploy the script in test and prod environements we must modify dir option of file sink this is very easy when there is not a lot of options and when we have a small factory team but in a big factory environment this will be problematic in order to industrialize deployment it would be convenient to implement in dsl a directory interface api or something equivalent like below: suppose we call this directory interface xddi  like xd directory interface :-) the script can be like that: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payloadcontains('toto') | file --dir=xddi('totokey') stream2 = http | filter --expression=payloadcontains('titi') | file --dir=xddi('titikey') ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// the xddi keys are defined in a centralized directory interface (admin console or xddiproperties) the xddi keys/values in dev environment: ///////////////////////////////////// totokey=/tmp/toto titikey=/tmp/titi ///////////////////////////////////// the xddi keys/values in test environment: ////////////////////////////////////////// totokey=/tartempion/toto titikey=/petaouchnok/titi ///////////////////////////////////////// the xddi keys/values in prod environment: ///////////////////////////////////////////////////// totokey=/vavoirlabasijysuis/toto titikey=/vavoirlabasijysuis/titi ///////////////////////////////////////////////////// when the script is deployed in test or prod environement if the script contain a key that is not defined in centralized directory the deployment fail this will reduce errors risks in a big factory environnement (several hundred parameters and signifiant team turnover) and the most similar text Large number required options jdbc sink definition id like use following command define stream spring test environment code stream create name test definition http jdbc code add following options definition make work otherwise get exceptions failed deploy code code given empty anyway seems like necessary notes like needs null stream creation fails cant find file environment even though wont run anyway does not exceed the minimum threshold of 75%.;0.15;2.0;1.0;1.67;0;1;0;0
56;Add Accepted Media Type Support to Tap Currently the initial tap module accepted media types are not retrieved from the module when creating the tap.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add accepted media type support to tap currently the initial tap module accepted media types are not retrieved from the module when creating the tap is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like create separate yarn spi bundle spi variants one admin project and similar to the text Developer id like design document approach deploying stream single container modules within stream and similar to the text Scd user id like add rest support stream commands maneuver streaming pipeline backed (and these texts are all user stories with a worth of 5 story points).;0.04;4.94;1.0;8.33;1;0;1;0
57;Install XD admin instance on EC2 *Update the Deployer class to add the following methods * ** RunningInstance deployAdminServer * The install script steps: ** Using XD-977 install distribution ** Setup XD_HOME variable ** start up redis and rabbit using ports as specified in xd-ec2.properties on admin server ** Create configurator directory ** Copy the configurator to containers ** Use port watch to make sure they started ** start admin server ** use port watch to make sure the admin started on 9393 ** Report if admin server started. If it didn't start abort install. ** Report public DNS name of admin-server * Integration Testing ** Verify XD admin has been started *** Create a basic stream (trigger>log)and make sure we get a success code from xd admin was received. *** Query the redis to see if the stream was created.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Install xd admin instance on ec2 *update the deployer class to add the following methods * ** runninginstance deployadminserver * the install script steps: ** using xd-977 install distribution ** setup xd_home variable ** start up redis and rabbit using ports as specified in xd-ec2properties on admin server ** create configurator directory ** copy the configurator to containers ** use port watch to make sure they started ** start admin server ** use port watch to make sure the admin started on 9393 ** report if admin server started if it didn't start abort install ** report public dns name of admin-server * integration testing ** verify xd admin has been started *** create a basic stream (trigger>log)and make sure we get a success code from xd admin was received *** query the redis to see if the stream was created and the most similar text Source displays incorrect information using hdfs sink deploying stream hdfs sink jdbc source displays incorrect information jdbc source issue occurs 1 containers deployed source deployed one container sink deployed another container checked rest endpoints seem show correct information test case say 2 containers source sink deployed container show correct information stream used testing purposes follows - stream create definition jdbc employer employee hdfs deploy attach issue has also reported using source hdfs sink thanks does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
58;As a developer I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo so I could define the module {{artifactId}} from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i'd like to brainstorm and investigate various techniques around installation of xd modules from a maven repo so i could define the module {{artifactid}} from cli to have the module downloaded from the repo and installed to a running spring xd runtime was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Verify platform compatibility versions dependencies need make sure dependency using spring io platform dependencies one scenario dependency missing and similar to the text Update sinks file section use shell commands instead curl see (and these texts are not user stories).;0.03;8.62;1.0;8.33;1;1;1;1
59;Add support to restart job composition As an XD user I'd like have support restart an existing composed job so I could re-launch it at will.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add support to restart job composition as an xd user i'd like have support restart an existing composed job so i could re-launch it at will was most similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job and similar to the text User wants ability create mock source send preset message processes and similar to the text Add docs simple stream curl x delete (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
60;As a s-c-d developer I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader so we could use this as a reference while porting modules with external dependencies.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to complete documentation and test-cases on resolving and adding jar's to boot loader so we could use this as a reference while porting modules with external dependencies is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.09;8.4;1.0;8.33;1;1;1;1
61;Switch to use Jedis driver for Redis The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn't had any update activity for several months. Jedis is actively maintained. We might also want to investigate Redisson which is a fork of Lettuce - https://github.com/mrniko/redisson;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Switch to use jedis driver for redis the spring data team recommends using the jedis driver since the lettuce driver hasn't had any update activity for several months jedis is actively maintained we might also want to investigate redisson which is a fork of lettuce - https://githubcom/mrniko/redisson is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Scs developer id like setup ci workflow build bundle upload image worry docker registry nice image uploaded existing location and similar to the text User id like option hdfs sink use temporary like instead write using filename specified directly useful use writes sink fails file open new option user explicitly rename file and similar to the text User id like ability data database systems restricted current approach dependent jdbc drivers spike scope identify integration options collaborate determine design document outcome design specs (and these texts are all user stories with a worth of 5 story points).;0.03;7.13;1.0;8.24;1;0;1;0
62;Standardize Date/Time/TimeZone handling We should we centrally standardize on date/time formats so that we don't create inconsistencies and follow ISO 8601 internally. Internally we should only work with UTC (or make that the default config option). Ultimately whatever the user sees is just a formatting concern.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Standardize date/time/timezone handling we should we centrally standardize on date/time formats so that we don't create inconsistencies and follow iso 8601 internally internally we should only work with utc (or make that the default config option) ultimately whatever the user sees is just a formatting concern is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics and similar to the text Scs developer id like investigate right approach include external library dependency ex mysql decide better handling libraries needs loaded available root cp (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
63;As a follow-up to Kafka message bus support we would like to rerun the failing tests after upgrading to new [consumer|https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design] rewrite. [Response from Kafka support|http://mail-archives.apache.org/mod_mbox/kafka-users/201410.mbox/%3CCAHwHRrWZmLr94eHX1z5i36BYz%2B%3DCisx7GcbW1_Nn7ooNJcShMw%40mail.gmail.com%3E].;3;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a follow-up to kafka message bus support we would like to rerun the failing tests after upgrading to new [consumer|https://cwikiapacheorg/confluence/display/kafka/kafka+09+consumer+rewrite+design] rewrite [response from kafka support|http://mail-archivesapacheorg/mod_mbox/kafka-users/201410mbox/%3ccahwhrrwzmlr94ehx1z5i36byz%2b%3dcisx7gcbw1_nn7oonjcshmw%40mailgmailcom%3e] was most similar to the text Processor module does load classes custom module package processor module failing load castor classes module code works fine eclipse dirt based test cases attaching code email jar built has jars need folder code worked fine put custom jars application jar spoke confirm broken need and similar to the text Streams sending job queue issue look stream definition gets deployed state even corresponding job job any job cant deployed goes hung state example stream definition stream create name definition file deploy and similar to the text Duplicate server definition referred setting option defined exposed modules also use define duplicate definition adds component module seem needed also currently flag generic used well module separate flag enable modules separate definition necessary (and these texts are not user stories).;0.01;2.01;1.0;1.67;0;1;1;1
64;REST: Make the Job Execution REST endpoint pagination-aware Implement pagination for: http://localhost:9393/jobs/executions;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Rest: make the job execution rest endpoint pagination-aware implement pagination for: http://localhost:9393/jobs/executions is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like separate file list deployment manifest properties include part stream definition and similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint and similar to the text Developer id like troubleshoot performance issues rabbit message implementation isolate bottleneck fix appropriate (and these texts are all user stories with a worth of 8 story points).;0.03;8.62;1.0;8.33;1;0;1;0
65;Add command for listing streams;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add command for listing streams was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;3.24;1.0;1.67;0;1;1;1
66;As a user I'd like to use the _Mail_ sink to connect to secured IMAP and/or SMTP mail servers. Currently the sink doesn't support TLS. _Mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html]. {code:xml} <util:properties id=javaMailProperties> <prop key=mail.imap.socketFactory.class>javax.net.ssl.SSLSocketFactory</prop> <prop key=mail.imap.socketFactory.fallback>false</prop> <prop key=mail.store.protocol>imaps</prop> <prop key=mail.debug>false</prop> </util:properties> {code} [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html];1;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text As a user i'd like to use the _mail_ sink to connect to secured imap and/or smtp mail servers currently the sink doesn't support tls _mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute [ref example|http://docsspringio/spring-integration/docs/latest-ga/reference/html/mailhtml] {code:xml} <util:properties id=javamailproperties> <prop key=mailimapsocketfactoryclass>javaxnetsslsslsocketfactory</prop> <prop key=mailimapsocketfactoryfallback>false</prop> <prop key=mailstoreprotocol>imaps</prop> <prop key=maildebug>false</prop> </util:properties> {code} [list of all java-mail properties|https://javamailjavanet/nonav/docs/api/com/sun/mail/smtp/package-summaryhtml] and the most similar text Expose job parameters currently way accessing batch admin filled using grab job executions database database queries uses does include stored different table think require change batch admin order properly expose parameters does not exceed the minimum threshold of 75%.;0.02;2.2;1.0;1.67;0;1;0;0
67;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to refer to documentation in wiki so that i can setup and configure kafka as a message bus as recommended is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;5.39;1.0;8.33;1;1;1;1
68;Admin UI deploys job with wrong module count When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1. More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties];0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Admin ui deploys job with wrong module count when deploying a job through admin ui with a count of 0 the module is actually deployed with count 1 more info here: [http://stackoverflowcom/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties] was most similar to the text Create shell integration test fixture jdbc related sink nice kind regression testing jdbc sink becomes prominent use memory db expose eg assert state and similar to the text Create repository narrative need persistent way register job definitions beyond map registry implementation spring batch acceptance able register find job definitions registry registry backed persistent and similar to the text Verify platform compatibility versions dependencies need make sure dependency using spring io platform dependencies one scenario dependency missing (and these texts are not user stories).;0.04;8.55;1.0;8.33;1;1;1;1
69;Refactor Task parsing Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules). This results in a lot of duplication. This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Refactor task parsing currently the dsl parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules) this results in a lot of duplication this should be refactored to remove duplication and remove explicit references to either streams or tasks in common code is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics and similar to the text Scs developer id like investigate right approach include external library dependency ex mysql decide better handling libraries needs loaded available root cp (and these texts are all user stories with a worth of 8 story points).;0.02;2.0;1.0;1.67;0;0;1;0
70;Improve E2E Test Coverage;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Improve e2e test coverage was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;2.51;1.0;1.67;0;1;1;1
71;Use unique queue names in shell tests There seems to be some cross talk among the shell integration tests. It looks like the same singlenode application might get shared among the test classes when they run in parallel. Using unique queue names across the tests seem to fix the issue for now.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Use unique queue names in shell tests there seems to be some cross talk among the shell integration tests it looks like the same singlenode application might get shared among the test classes when they run in parallel using unique queue names across the tests seem to fix the issue for now was most similar to the text Disable collection object conversion provides collection object conversion produce first item target type matches results unfortunate side effect list return tuple misleading case preferable treat error argument tuple and similar to the text Response code http source use case need http source module return instead 200 currently returned may codes useful able return simple additional option module allow configured and similar to the text Dead letter queues stream hi use module also creates queues policy first queue has thanks (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
72;As a Spring XD user I'd like to persist module (aka: {{cf apps}}) metrics directly so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s. Currently SBoot's {{export()}} API allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). This could be something to explore as part of this scope.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd user i'd like to persist module (aka: {{cf apps}}) metrics directly so i can relay that information via rest-apis and not depend on the current coupling of {{xd-container}}'s currently sboot's {{export()}} api allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}) this could be something to explore as part of this scope was most similar to the text Allow user configure tests addition sinks sources require connections external entities jms jdbc environment setup getting unwieldy integrate acceptance tests retrieve environment variables dependency injection utilize profiles local single node local cluster single node cluster and similar to the text Create benchmarking application demonstrate high performance message processing application live repository stream documented run benchmark made easy execute use generate traffic order saturate stream and similar to the text New libraries experiment like experiment open source libraries enrich spring service offerings epic remains anchor point following categories respective experimentation outcomes documented stories measure based alerts log machine learning graph computation (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
73;RedisSink to support in-memory store;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Redissink to support in-memory store was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;3.24;0.0;1.67;0;1;1;1
74;As a Spring XD developer I'd like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd developer i'd like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective spi ({{receptor}} or {{cloudcontroller}}) implementations was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Integrate code coverage reports ci process sure best done sonar sonar build plan nightly one frequent one master open question want fail build code coverage levels and similar to the text Remove main dirt driver present dirts present modules though blocked shortcoming described (and these texts are not user stories).;0.05;8.16;1.0;8.33;1;1;1;1
75;Create final distribution zip across multiple projects The final directory structure should look like <install-dir>/xd <install-dir>/redis <install-dir>/gemfire inside the XD directory /xd/bin - which has xd-container and xd-admin scripts /xd/lib inside the gemfire directory /gemfire/bin - has the gemfire-server script /gemfire/lib inside the redis directory is /redis/redis-latest-v.x.y.z.tar /redis/README /readis/install-redis - script that does the basic 4 commands to install redis. There should be a gradle task that runs after the distZip task that will take the contents of different project directories script diretories and 'redis-binary' directories and creates the final layout for the distribution.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Create final distribution zip across multiple projects the final directory structure should look like <install-dir>/xd <install-dir>/redis <install-dir>/gemfire inside the xd directory /xd/bin - which has xd-container and xd-admin scripts /xd/lib inside the gemfire directory /gemfire/bin - has the gemfire-server script /gemfire/lib inside the redis directory is /redis/redis-latest-vxyztar /redis/readme /readis/install-redis - script that does the basic 4 commands to install redis there should be a gradle task that runs after the distzip task that will take the contents of different project directories script diretories and 'redis-binary' directories and creates the final layout for the distribution and the most similar text User id like option define access control list acls define access controls resource user privileges resource spike scope review customer use cases come design specs identify best approach fits identify scope dsl ui document next steps phases does not exceed the minimum threshold of 75%.;0.1;2.0;1.0;1.67;0;0;0;0
76;Move BatchJobExecutionsByJobName to BatchJobsController from BatchJobExecutionsController We need to move the BatchJobExecutionsByJobName method to BatchJobsController as that seems appropriate;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Move batchjobexecutionsbyjobname to batchjobscontroller from batchjobexecutionscontroller we need to move the batchjobexecutionsbyjobname method to batchjobscontroller as that seems appropriate is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like review improve performance characteristics and similar to the text Developer id like upgrade spring 13 release and similar to the text Spring user id like create streaming pipelines take advantage latest specs streaming (and these texts are all user stories with a worth of 3 story points).;0.02;5.39;1.0;8.33;1;0;1;0
77;As a developer I'd like to clean-up compiler and javadoc warnings from the build so we don't see the warnings in build sysout.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to clean-up compiler and javadoc warnings from the build so we don't see the warnings in build sysout is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text User id like parameterize options generate code fly needed and similar to the text Developer id like revisit existing design identify known limitations gaps (and these texts are all user stories with a worth of 5 story points).;0.02;8.55;1.0;8.33;1;1;1;1
78;SqoopTasklet not using hadoop configuration Hey Guys I'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log). Could please you guys help me to solve this problem? Thanks in advance. Regards;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Sqooptasklet not using hadoop configuration hey guys i'm trying to use a sqooptasklet but for some reason it is not getting the hadoop configuration in the attached sqoop job configuration using the sqooprunner class directly works without problems but the sqooptasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenodelog) could please you guys help me to solve this problem? thanks in advance regards is a user story, and is worth 1 story points. This was predicted because it is most similar to the text User id like option basic provide user name password making request technical implementation functionality spring boot matter adding spring boot security starter dependency project controlled using spring boot property default property false and similar to the text Developer id like upgrade ga release leverage latest improvements breaking backwards compatibility uses boot 13 versions drop older hive support avoid breaking changes instead use has backported any improvements need well move spring versions recent ones and similar to the text User want able provide implementation enrich jdbc data use case requires add field delete flag field records get written hdfs implement extend override method change default implementation otherwise write processor add fields tuples tuples immutable recreate tuples additional fields processor large load big overhead love know any technique implement use case (and these texts are all user stories with a worth of 1 story points).;0.01;2.0;1.0;1.67;0;0;1;0
79;As a developer I'd like to add documentation on escape quotes so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to add documentation on escape quotes so when someone using sqoop job can double escape {{\\\\n}} instead of sending quotes {{'\n'}} to successfully submit the job is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Developer id like migrate module deployment repository abstraction used definitions create spi (and these texts are all user stories with a worth of 8 story points).;0.08;8.62;1.0;8.33;1;1;1;1
80;Change jmxDisabled option to jmxEnabled and do not enable by default also the current behavior is broken it checks if the property is set but does not actually check whether it's true or false;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Change jmxdisabled option to jmxenabled and do not enable by default also the current behavior is broken it checks if the property is set but does not actually check whether it's true or false is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.08;5.83;1.0;8.33;1;0;1;0
81;As a user I'd like to use the latest release of {{gemfire}} sink so I can create a streaming pipeline to land data in gemfire.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to use the latest release of {{gemfire}} sink so i can create a streaming pipeline to land data in gemfire is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option configure default access control endpoints grant access admin viewer roles and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text User id like option write file roll sink store events local file system (and these texts are all user stories with a worth of 8 story points).;0.03;4.94;1.0;8.33;1;1;1;1
82;Clean shutdown of redis in xd-admin A ctrl-c of xd-admin results in exception messages about disconnecting from redis. 14:16:07327 ERROR task-scheduler-1 handler.LoggingHandler:136 - org.springframework.data.redis.RedisSystemException: Redis command interrupted nested exception is com.lambdaworks.redis.RedisCommandInterruptedException: Command interrupted;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Clean shutdown of redis in xd-admin a ctrl-c of xd-admin results in exception messages about disconnecting from redis 14:16:07327 error task-scheduler-1 handlerlogginghandler:136 - orgspringframeworkdataredisredissystemexception: redis command interrupted nested exception is comlambdaworksredisrediscommandinterruptedexception: command interrupted is a user story, and is worth 1 story points. This was predicted because it is most similar to the text User id like api documentation links section within ideal version dynamically every release and similar to the text User trying compose job one definition however getting following error message misinterpreted code create salsa definition successfully job salsa create foo definition salsa salsa successfully job foo create definition salsa command failed find module name salsa type job code and similar to the text Scs developer id like create auto configuration binder automatically configure spring application based dependencies (and these texts are all user stories with a worth of 1 story points).;0.05;8.62;1.0;8.33;1;0;1;0
83;Unable to delete composed module After creating a composed module I am unable to delete it. [Steps to reproduce] xd:>module compose doo --definition filter --expression=payload.contains('doo') | file Successfully created module 'doo' with type sink xd:>module module compose module delete module display module info module list xd:>module delete --name doo --type sink java.lang.StringIndexOutOfBoundsException: Failed to convert 'doo' to type QualifiedModuleName for option 'name' String index out of range: -1 xd:>;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Unable to delete composed module after creating a composed module i am unable to delete it [steps to reproduce] xd:>module compose doo --definition filter --expression=payloadcontains('doo') | file successfully created module 'doo' with type sink xd:>module module compose module delete module display module info module list xd:>module delete --name doo --type sink javalangstringindexoutofboundsexception: failed to convert 'doo' to type qualifiedmodulename for option 'name' string index out of range: -1 xd:> was most similar to the text Rename node references container applies places addressing issue search done uncover any eg public static final string node options classes transport use data messages node node transport use control messages admin nodes and similar to the text Implement spark streaming driver application controlled module instance include management modules stream spark streaming application stopped etc deploying number module instances result multiple receiver tasks bind using consumer side partitioning metadata and similar to the text Job definition restart service single node mode job definition restart service single node mode step service single node batch module job based batch module service expect result job definition displayed job list actual result job list empty job definitions missed (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
84;add twitter search source module;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add twitter search source module was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;2.41;1.0;1.67;0;1;1;1
85;Modules need to validate their parameters at create time. We need to fail fast.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Modules need to validate their parameters at create time we need to fail fast was most similar to the text Create integration test script jms create script sanity check jms and similar to the text Remove retry tcp sink supports retry longer necessary retry advice tcp sink and similar to the text Display command options nice options display command (and these texts are not user stories).;0.07;6.58;1.0;8.33;1;1;1;1
86;Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Publish spring xd final distribution zip as part of bamboo artifactory plugin currently bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives' we need to have a way to set the final distribution archive as one of the gradle 'configurations' in our buildgradle and refer it inside bamboo artifacts was most similar to the text Improve use current job does take advantage features available write hdfs spring implementations partitioning update job use similar hdfs sink inside new implementation and similar to the text Fix tangle container event references referenced stopped and similar to the text Fix anchor links work wiki docs part issue likely build script also add link checker ci build (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
87;Make the parser aware of message conversion configuration Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example: {noformat:nopanel=true} source --outputType=my.Foo | sink --inputType=some.other.Bar is likely invalid since XD doesn't know how to convert Foo->Bar. {noformat};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Make the parser aware of message conversion configuration enhance the stream parser to take message conversion into account in order to validate or automatically configure converters for example: {noformat:nopanel=true} source --outputtype=myfoo | sink --inputtype=someotherbar is likely invalid since xd doesn't know how to convert foo->bar {noformat} was most similar to the text Automate execution part daily build one easy way use authentication scheme described bamboo mask property name contains password may want create dedicated user though and similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases and similar to the text Dispatcher has subscriber error posting message stream has observed intermittently transport sending message valid stream sure recreate yet error - error sending message dispatcher has subscribers channel (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
88;Script to generate reference documentation from wiki and include in .zip distribution;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Script to generate reference documentation from wiki and include in zip distribution is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like upgrade spring 13 release and similar to the text Developer id like review improve performance characteristics and similar to the text Spring user id like create streaming pipelines take advantage latest specs streaming (and these texts are all user stories with a worth of 3 story points).;0.02;2.9;1.0;1.67;0;0;1;0
89;Update getting started documentation to use xd-singlenode start script. With the new option of starting without requiring redis the getting started documentation should reflect this easier way to start processing data.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update getting started documentation to use xd-singlenode start script with the new option of starting without requiring redis the getting started documentation should reflect this easier way to start processing data is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like use stream definition repository spin store obviously persist application executions useful simplified development experience and similar to the text User id like option specify system properties passed job runs java process needed defining memory usage also defining options connector implementations and similar to the text Spring developer id like current controller spi calls invoke respective admin spi implementation based deployment controllers (and these texts are all user stories with a worth of 5 story points).;0.03;7.7;1.0;8.33;1;0;1;0
90;As a user I'd like to have the option of _Cassandra_ sink so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.;3;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have the option of _cassandra_ sink so i can leverage the nosql database to write high volumes of variable data segments in high velocity was most similar to the text Handle responses currently handle single page response cc spi list requests potentially multiple ones and similar to the text Add agent depending run mode war vs jvm agent vs jvm probably needs support spring profiles and similar to the text Add steams page show job triggers streams page needs added ui least show job triggers scheduling jobs (and these texts are not user stories).;0.03;2.04;1.0;1.67;0;1;1;1
91;configuration conflict when using --transport local --store redis --disableJmx true --analytics redis results in both in-memory and redis based definitions of RichGaugeService - can't satisfy autowiring because there are two candidates. Had to change --analytics=memory to get the application context to load.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Configuration conflict when using --transport local --store redis --disablejmx true --analytics redis results in both in-memory and redis based definitions of richgaugeservice - can't satisfy autowiring because there are two candidates had to change --analytics=memory to get the application context to load was most similar to the text Add property polled sources polled message sources return one message per poll default polling say file directory many files files emitted once per user need configure limit number messages emitted per poll and similar to the text Leakage modules call was added inherit active profiles sadly added property sources side effect note jdbc module defaults rely bug and similar to the text Scs samples use samples module options classes use pure approach making sure metadata written appropriate still referenced obviously cant work provide equivalent (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
92;ClasspathEnvironmentProvider should support packaged Spring XD modules Custom Spring XD modules are packaged into a JAR file with 3rd party libraries packaged into {{lib}} folder. Let's say we have a {{my-job}} custom job module packaged as JAR and deployed with {{module upload}} shell command. It wants to use {{org.springframework.xd.sqoop.SqoopTasklet}} provided by {{spring-xd-extension-sqoop}} library. Unfortunately {{org.springframework.batch.step.tasklet.x.ClasspathEnvironmentProvider}} will only add {{my-job.jar}} to {{SqoopRunner}} classpath (code in {{ClasspathEnvironmentProvider#createClassPath()}} method). {{ClasspathEnvironmentProvider}} should add all 3rd party JARs packaged in custom job module to classpath. This works with {{sqoop}} module shipped with Spring XD because it's deployed as exploded module under $XD_HOME/modules/job. In such case {{ClasspathEnvironmentProvider}} correctly adds all JARs from $XD_HOME/modules/job/sqoop/lib to classpath.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Classpathenvironmentprovider should support packaged spring xd modules custom spring xd modules are packaged into a jar file with 3rd party libraries packaged into {{lib}} folder let's say we have a {{my-job}} custom job module packaged as jar and deployed with {{module upload}} shell command it wants to use {{orgspringframeworkxdsqoopsqooptasklet}} provided by {{spring-xd-extension-sqoop}} library unfortunately {{orgspringframeworkbatchsteptaskletxclasspathenvironmentprovider}} will only add {{my-jobjar}} to {{sqooprunner}} classpath (code in {{classpathenvironmentprovider#createclasspath()}} method) {{classpathenvironmentprovider}} should add all 3rd party jars packaged in custom job module to classpath this works with {{sqoop}} module shipped with spring xd because it's deployed as exploded module under $xd_home/modules/job in such case {{classpathenvironmentprovider}} correctly adds all jars from $xd_home/modules/job/sqoop/lib to classpath and the most similar text Give proper results back lukes original code uses code snippet seem behave strangely stored values seem fine method seems phony test 1 stream create foo definition 2 tap create bar definition 3 curl h gives default bucketing hourly chances empty does not exceed the minimum threshold of 75%.;0.06;2.0;1.0;1.67;0;1;0;0
93;As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to refer to documentation in wiki so that i can setup and configure kafka as a source or a sink as recommended is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;7.7;1.0;8.33;1;1;1;1
94;DIRT Runtime that deploys an application context across multiple nodes using redis.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Dirt runtime that deploys an application context across multiple nodes using redis is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
95;Package Tangle Introduced by XD-790 https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Package tangle introduced by xd-790 https://sonarspringsourceorg/drilldown/measures/7173?metric=package_tangle_index&rids%5b%5d=7717 is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.1;4.48;0.0;1.67;0;0;1;0
96;Add support for offline module resolution h2. Narrarive As a developer I need to be able to test modules without pushing them to a remote maven repository. I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add support for offline module resolution h2 narrarive as a developer i need to be able to test modules without pushing them to a remote maven repository i should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams is a user story, and is worth 1 story points. This was predicted because it is most similar to the text Build manager id like schedule ci builds windows verify scope isolate remaining test failures experiment new ami images solid infrastructure fix failing tests and similar to the text User id like see date logs troubleshoot issues occurred specific day time property needs adjusted and similar to the text User id like refer wiki create job partitions turn expects columns explicitly included job definition also beneficial call-out sql metadata options mutually exclusive following logic needs documented use columns using partition column boolean return return true code (and these texts are all user stories with a worth of 1 story points).;0.04;2.0;1.0;1.67;0;0;1;0
97;As a Spring XD developer I'd like to have a permanent location of SPI implementations so I could use the common repo every time I contribute or enhance the test coverage.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to have a permanent location of spi implementations so i could use the common repo every time i contribute or enhance the test coverage is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.08;4.94;1.0;8.33;1;1;1;1
98;singlestep-partition-support needs to allow grid size to be configurable h3. Narrative As a developer I need to be able to configure a partitioned job's grid size so that the correct number of partitions are created (the current code is hard coded to 1 for the grid size). h3. Acceptance Criteria # Expose the gridSize attribute of the {{MessageChannelPartitionHandler}} as an option. h3. Assumptions # Existing OOTB jobs should not be impacted by this given they don't use the grid size.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Singlestep-partition-support needs to allow grid size to be configurable h3 narrative as a developer i need to be able to configure a partitioned job's grid size so that the correct number of partitions are created (the current code is hard coded to 1 for the grid size) h3 acceptance criteria # expose the gridsize attribute of the {{messagechannelpartitionhandler}} as an option h3 assumptions # existing ootb jobs should not be impacted by this given they don't use the grid size was most similar to the text Composed modules cant duplicate processors code compose foo definition time code produces - first transform applied twice and similar to the text Failure stream invalid stream repository implementations reproduce 1 create bad stream definition name bad try recreate name correct stream definitions system report stream already exists and similar to the text Update sinks log section use shell commands instead curl see (and these texts are not user stories).;0.08;2.0;1.0;1.67;0;1;1;1
99;As a developer I'd like to port {{Log}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to port {{log}} module from xd to s-c-s repo so i can use it as {{sink}} modules to build streaming pipeline is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint and similar to the text Scd developer id like cc spi deployer cf improve overall design performance and similar to the text User able leverage native sink aggregate search analyze data insights (and these texts are all user stories with a worth of 8 story points).;0.02;5.64;1.0;8.33;1;1;1;1
100;As a result of fixing XD-2015 we still cannot execute: {code} grunt test:e2e {code} Basically running the tests AND the server together in one process fails. We see the following error: *Fatal error: socket hang up*. If we separate the protractor execution into 2 separate steps the tests pass: {code} grunt serve (one console window) grunt protractor:run (second console window) {code} In the *grunt serve* window you can still observe *Fatal error: socket hang up* being printed out but the tests execute successfully.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a result of fixing xd-2015 we still cannot execute: {code} grunt test:e2e {code} basically running the tests and the server together in one process fails we see the following error: *fatal error: socket hang up* if we separate the protractor execution into 2 separate steps the tests pass: {code} grunt serve (one console window) grunt protractor:run (second console window) {code} in the *grunt serve* window you can still observe *fatal error: socket hang up* being printed out but the tests execute successfully was most similar to the text Add named channel api need abstraction place retrieve messages named channel right implementation agnostic way quite useful integration tests streams eg focussed tests resorting nonessential sinks sources etc - eg code router code and similar to the text New libraries experiment like experiment open source libraries enrich spring service offerings epic remains anchor point following categories respective experimentation outcomes documented stories measure based alerts log machine learning graph computation and similar to the text Allow user configure tests addition sinks sources require connections external entities jms jdbc environment setup getting unwieldy integrate acceptance tests retrieve environment variables dependency injection utilize profiles local single node local cluster single node cluster (and these texts are not user stories).;0.07;2.0;1.0;1.67;0;1;1;1
101;Re-add Spark job acceptance test with spark standalone cluster The spark app test on spark standalone cluster is currently commented out: https://github.com/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/SparkAppTests.java#L74 We need to add it back once the cluster is setup on acceptance test environment.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Re-add spark job acceptance test with spark standalone cluster the spark app test on spark standalone cluster is currently commented out: https://githubcom/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/sparkapptestsjava#l74 we need to add it back once the cluster is setup on acceptance test environment was most similar to the text Introduce admin ui consider moving encourage dependency injection ui javascript code see and similar to the text Options ignored defines values following parameters values hence manually added stream definition addresses password cf and similar to the text Create directory structures move existing ui code spring repository create directory structure best benefits ui development copying ui files build tasks ui run inside embedded servlet container story (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
102;As a user I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesn’t take place.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i want spring xd to pre-allocate a set of partitions between the kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesn’t take place is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.09;8.62;1.0;8.33;1;1;1;1
103;As a user I'd like to also have the capability to upload the custom module through maven/gradle targets so I can automate the installation of custom module fragments.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to also have the capability to upload the custom module through maven/gradle targets so i can automate the installation of custom module fragments was most similar to the text Add property sources spring environment bean extremely nice property sources available spring environment bean module use and similar to the text Add ability copy job http site containers download zipped job modules http site deploy modules admin containers container started and similar to the text Rabbit source sink include headers default currently necessary specify rabbit sink otherwise headers mapped default behavior (and these texts are not user stories).;0.05;2.09;1.0;1.67;0;1;1;1
104;Add value-expression to gauges See http://stackoverflow.com/questions/30112430/payload-filters-transforms-rich-gauges/30115234 for the use case. It should be possible to extract both a numeric value and a gauge name from the message.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add value-expression to gauges see http://stackoverflowcom/questions/30112430/payload-filters-transforms-rich-gauges/30115234 for the use case it should be possible to extract both a numeric value and a gauge name from the message was most similar to the text Investigate using txs pipeline q adapter perf improvements investigate using transactions pipelining improve performance inbound outbound channel adapters testing 11 m2 and similar to the text Documentation jms source jms added list also corresponding section shows basic usage and similar to the text Create batch job uses shell copy multiple files hdfs local directory inverse require custom inputoutput (and these texts are not user stories).;0.01;8.15;1.0;8.33;1;1;1;1
105;Update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location. launcher.xml can make use of the system property xd.pipeProtocol inside an import statement. This determines which version of the XD infrastructure to load for example what ChannelRegistry implementation Local or Redis based or specific message listener containers. File name conventions should be used so if the option passed in from the command line is --pipeProtocol localChannel then the XML filename looked for has the 'Protocol' suffix applied e.g. localChannelProtocol and is loaded via the classpath. Redis and Local will not be the only options other implementations will be provided in the future e.g. Rabbit and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update launcherxml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location launcherxml can make use of the system property xdpipeprotocol inside an import statement this determines which version of the xd infrastructure to load for example what channelregistry implementation local or redis based or specific message listener containers file name conventions should be used so if the option passed in from the command line is --pipeprotocol localchannel then the xml filename looked for has the 'protocol' suffix applied eg localchannelprotocol and is loaded via the classpath redis and local will not be the only options other implementations will be provided in the future eg rabbit and the user may be able to provide their own implementations of these infrastructure classes (an advanced task) was most similar to the text Allow lot modules similar options moreover job modules often options belong least two domains eg jdbc hdfs think using come way combine several options pojos one like public class private jdbc private hdfs expose eg well top level options values actually injected fields eg custom validation occur default validation class occur default and similar to the text Create design document implementation strategy support message conversion conversion based headers similar way springs work mime types also map available converters extensible common defaults json xml etc likely want add content types also eg tuples likely logic configuration methods extending converter map belong common across implementations ie logic regardless transport used and similar to the text Add options supporting compression message added support compression expose configuration options enable configure compression message note options may specific brokers require additional functionality issue address adding additional functionality make feature set common possible across msg implementations expose makes sense current code base example kafka supports lets pick subset topics compressed (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
106;Not able to connect a pubsub channel to spark streaming module If a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel) then it doesn't bind to it. For instance if I have a stream ingest with a definition http | log and want to create another stream as tap:stream:ingest > spark-processor | count then this stream doesn't work.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Not able to connect a pubsub channel to spark streaming module if a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel) then it doesn't bind to it for instance if i have a stream ingest with a definition http | log and want to create another stream as tap:stream:ingest > spark-processor | count then this stream doesn't work was most similar to the text Create shell integration test fixture jdbc related sink nice kind regression testing jdbc sink becomes prominent use memory db expose eg assert state and similar to the text Create repository narrative need persistent way register job definitions beyond map registry implementation spring batch acceptance able register find job definitions registry registry backed persistent and similar to the text Use descriptive texts module options defaults need way tell user option determined bindings module info command references read use stream name example (and these texts are not user stories).;0.13;4.38;1.0;6.41;1;1;1;1
107;Shell processor is not thread safe Multiple threads invoke the shell processor result in I/O errors and/or data corruption. send() and receive() should be synchronized.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Shell processor is not thread safe multiple threads invoke the shell processor result in i/o errors and/or data corruption send() and receive() should be synchronized is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like upgrade kafkas si ga release sync latest bits scope backport kafka changes si kafka upgrade ga release and similar to the text User like option write data hive sink query manage large distributed storage and similar to the text Scd developer id like enhance integration test coverage yarn spi continuously evaluate functionalities ci pipeline (and these texts are all user stories with a worth of 5 story points).;0.02;4.94;1.0;1.67;0;0;1;0
108;As a user I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput. *Example:* http --batchInterval=10 | log;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have _microbatching_ capability so that i can ingest based on batch intervals for enhanced performance throughput *example:* http --batchinterval=10 | log is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.03;8.55;1.0;8.33;1;1;1;1
109;Refactor Exception Handling and update JavaDocs for acceptance test [Add JavaDocs to] * StreamUtils * HttpTest * MqttTest * JmsSource [Exception Handling] StreamUtils stream method should throw IllegalStateException instead of a checked exception. XDEc2Validation assertReceived assertValid should throw IllegalStateException instead of a checked exception;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Refactor exception handling and update javadocs for acceptance test [add javadocs to] * streamutils * httptest * mqtttest * jmssource [exception handling] streamutils stream method should throw illegalstateexception instead of a checked exception xdec2validation assertreceived assertvalid should throw illegalstateexception instead of a checked exception was most similar to the text Hdfs sink support number rollover options strategy roll files allows user choose 1 size file 2 number file 3 idle timeout value exceeded close file and similar to the text Update getting started chapter use shell commands instead curl see and similar to the text Source modules use standardize vs value accept property standard name like interval (and these texts are not user stories).;0.02;8.06;1.0;8.33;1;1;1;1
110;gemfire-json-server multiple PdxTypes Types I am using SpringXD to ingest tweets to a gemfire-json-server sink. I am running into an issue where the json documents get defined as a pdx type twice. See the reweet_count field below. This causes problems later when using OQL to access this data. Incompatible types. What are the recommended ways to resolve this? The field type should account for the largest possible value which is unknown because it is twitter. This would likely be a int or long. I was asked to log this as a SXD JIRA issue but I am not sure if the problem is in SXD or GemFire. [info 2015/04/25 06:51:28.767 CST <twitterSource-1-1> tid=0x53] Defining: PdxType[ dsid=0typenum=1 name=__GEMFIRE_JSON fields=[ id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1 from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1 created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2 text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3 language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4 retweet_count:short:5:4:idx0(relativeOffset)=-3:idx1(vlfOffsetIndex)=-1 retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]] [info 2015/04/25 06:51:29.307 CST <twitterSource-1-1> tid=0x53] Defining: PdxType[ dsid=0typenum=2 name=__GEMFIRE_JSON fields=[ id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1 from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1 created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2 text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3 language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4 retweet_count:byte:5:4:idx0(relativeOffset)=-2:idx1(vlfOffsetIndex)=-1 retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]];0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Gemfire-json-server multiple pdxtypes types i am using springxd to ingest tweets to a gemfire-json-server sink i am running into an issue where the json documents get defined as a pdx type twice see the reweet_count field below this causes problems later when using oql to access this data incompatible types what are the recommended ways to resolve this? the field type should account for the largest possible value which is unknown because it is twitter this would likely be a int or long i was asked to log this as a sxd jira issue but i am not sure if the problem is in sxd or gemfire [info 2015/04/25 06:51:28767 cst <twittersource-1-1> tid=0x53] defining: pdxtype[ dsid=0typenum=1 name=__gemfire_json fields=[ id:string:0:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=-1 from_user:string:1:1:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=1 created_at:string:2:2:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=2 text:string:3:3:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=3 language_code:string:4:4:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=4 retweet_count:short:5:4:idx0(relativeoffset)=-3:idx1(vlfoffsetindex)=-1 retweet:boolean:6:4:idx0(relativeoffset)=-1:idx1(vlfoffsetindex)=-1]] [info 2015/04/25 06:51:29307 cst <twittersource-1-1> tid=0x53] defining: pdxtype[ dsid=0typenum=2 name=__gemfire_json fields=[ id:string:0:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=-1 from_user:string:1:1:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=1 created_at:string:2:2:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=2 text:string:3:3:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=3 language_code:string:4:4:idx0(relativeoffset)=0:idx1(vlfoffsetindex)=4 retweet_count:byte:5:4:idx0(relativeoffset)=-2:idx1(vlfoffsetindex)=-1 retweet:boolean:6:4:idx0(relativeoffset)=-1:idx1(vlfoffsetindex)=-1]] and the most similar text Hdfs sink partition path causing writes slower certain cases tested believe case latest release well stream definition 1 stream create definition rabbit script hdfs noticed was causing writes slower stream definition 2 stream create definition rabbit script hdfs definition writes much faster please note was one time test multiple times also seems another use case thanks does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
111;Add log config file to gemfire in final distro The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts but the separate gemfire app doesn't.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add log config file to gemfire in final distro the changes for xd-144 mean that log4j files are no longer in the library jars the admin server already has a logging configuration which should be activated by the startup scripts but the separate gemfire app doesn't was most similar to the text Kafka tests assume offset 0 testing queue partitions content read assumed start offset 0 incorrect topics may exist already especially ci environment and similar to the text Add aliases concept module options use composed modules following merge allow module option known several names elect short name composed module options ambiguity and similar to the text Replace usage raw curl shell command post http data documentation eg target data 10 believe also help avoid ugly syntax quotes json example (and these texts are not user stories).;0.04;8.62;1.0;8.33;1;1;1;1
112;As a user I want Spring XD’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i want spring xd’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.11;4.48;1.0;7.9;1;1;1;1
113;Add JMS source module;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add jms source module was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;2.9;1.0;1.67;0;1;1;1
114;As a user I'm trying to list streams (>20) in admin-ui to use the pagination however I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_. Version: 1.1.0 SNAPSHOT (master build) Distributed: 1 admin and 2 containers *Steps to reproduce:* 1) Deploy the following streams. stream create foo1 --definition time | log --deploy stream create foo2 --definition time | log --deploy stream create foo3 --definition time | log --deploy stream create foo4 --definition time | log --deploy stream create foo5 --definition time | log --deploy stream create foo6 --definition time | log --deploy stream create foo7 --definition time | log --deploy stream create foo8 --definition time | log --deploy stream create foo9 --definition time | log --deploy stream create foo10 --definition time | log --deploy stream create foo11 --definition time | log --deploy stream create foo12 --definition time | log --deploy stream create foo13 --definition time | log --deploy stream create foo14 --definition time | log --deploy stream create foo15 --definition time | log --deploy stream create foo16 --definition time | log --deploy stream create foo17 --definition time | log --deploy stream create foo18 --definition time | log --deploy stream create foo19 --definition time | log --deploy stream create foo20 --definition time | log --deploy stream create foo21 --definition time | log --deploy stream create foo22 --definition time | log --deploy 2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs. *Error:* 16:55:19107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a request java.lang.IllegalStateException: Not all instances were looked at org.springframework.util.Assert.state(Assert.java:385) org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207) org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178) org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63);1;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text As a user i'm trying to list streams (>20) in admin-ui to use the pagination however i ended up with blank page and the server-side errored with _javalangillegalstateexception_ version: 110 snapshot (master build) distributed: 1 admin and 2 containers *steps to reproduce:* 1) deploy the following streams stream create foo1 --definition time | log --deploy stream create foo2 --definition time | log --deploy stream create foo3 --definition time | log --deploy stream create foo4 --definition time | log --deploy stream create foo5 --definition time | log --deploy stream create foo6 --definition time | log --deploy stream create foo7 --definition time | log --deploy stream create foo8 --definition time | log --deploy stream create foo9 --definition time | log --deploy stream create foo10 --definition time | log --deploy stream create foo11 --definition time | log --deploy stream create foo12 --definition time | log --deploy stream create foo13 --definition time | log --deploy stream create foo14 --definition time | log --deploy stream create foo15 --definition time | log --deploy stream create foo16 --definition time | log --deploy stream create foo17 --definition time | log --deploy stream create foo18 --definition time | log --deploy stream create foo19 --definition time | log --deploy stream create foo20 --definition time | log --deploy stream create foo21 --definition time | log --deploy stream create foo22 --definition time | log --deploy 2) go to streams tab in admin-ui to get a blank page and the following exception in admin logs *error:* 16:55:19107 110snap error http-nio-9393-exec-2 restrestcontrolleradvice - caught exception while handling a request javalangillegalstateexception: not all instances were looked at orgspringframeworkutilassertstate(assertjava:385) orgspringframeworkxddirtrestxdcontrollerenhancewithdeployments(xdcontrollerjava:207) orgspringframeworkxddirtrestxdcontrollerlistvalues(xdcontrollerjava:178) orgspringframeworkxddirtreststreamscontrollerlist(streamscontrollerjava:63) and the most similar text Bind producer consumer quote full exception dispatcher has subscribers channel nested exception dispatcher has subscribers stream filter router pm gary russell looks like another fixed fix timing problem taps using tap started tap stream deployed clear filter module consumer pm gary russell see problem binds consumer producer - wrong order passive component filter cc quote does not exceed the minimum threshold of 75%.;0.03;2.0;1.0;1.67;0;1;0;0
115;In XD shell an incomplete command will be executed as the full command When using the XD shell a user can enter the first character of a command and it will be accepted as the full command. for example e <return/> will exit the shell The following commands below show how a user can target a new cluster and then get a job execution list by using the first character of the command. server-unknown:>a c s http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 Successfully targeted http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 xd:>j e l Id Job Name Start Time Step Execution Count Execution Status Deployment Status Definition Status -- ----------------------------------------- ----------------------- -------------------- ---------------- ----------------- ----------------- 28 tsle2145f21d-5b0b-49df-b9cc-a3fe65c49ecc 2014-12-18 11:08:47000 2 COMPLETED Undeployed Destroyed 27 ec2Job3 2014-12-18 11:07:13000 2 COMPLETED Undeployed Destroyed 26 ec2Job3;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text In xd shell an incomplete command will be executed as the full command when using the xd shell a user can enter the first character of a command and it will be accepted as the full command for example e <return/> will exit the shell the following commands below show how a user can target a new cluster and then get a job execution list by using the first character of the command server-unknown:>a c s http://ec2-54-90-166-140compute-1amazonawscom:9393 successfully targeted http://ec2-54-90-166-140compute-1amazonawscom:9393 xd:>j e l id job name start time step execution count execution status deployment status definition status -- ----------------------------------------- ----------------------- -------------------- ---------------- ----------------- ----------------- 28 tsle2145f21d-5b0b-49df-b9cc-a3fe65c49ecc 2014-12-18 11:08:47000 2 completed undeployed destroyed 27 ec2job3 2014-12-18 11:07:13000 2 completed undeployed destroyed 26 ec2job3 was most similar to the text Create general structure based wiki spring guide adopt syntax useful pdf feature rich standard flavored loosely following conventions generate docs wiki project key element adoption use format rendering engine used see guidance and similar to the text Reactor environment improvements use profile similar include environment conditionally currently also one thing keep mind talked properties file configured et al way eg event loop large thread pool size 50 threads maybe even two input output might want change strictly default environment bean specific maybe add namespace element environment and similar to the text Unnecessary format enforcement module short description functional justification validation modules really necessary enforce short description must start capitol letter end period seems bit unnecessary opinionated 1 errors field error object info field rejected value snip codes arguments codes arguments default message default message short description must start capital letter end dot (and these texts are not user stories).;0.02;3.01;1.0;1.67;0;1;1;1
116;As a user I'd like to have a _generator_ source module so that I can create a number of messages of a specified size (similar to Rabbit's PerfTest utility). Example: generator --numMsgs 10000 --msgSize 1024 --numThreads 1;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have a _generator_ source module so that i can create a number of messages of a specified size (similar to rabbit's perftest utility) example: generator --nummsgs 10000 --msgsize 1024 --numthreads 1 is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scs developer id like investigate right approach include external library dependency ex mysql decide better handling libraries needs loaded available root cp and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics and similar to the text Developer id like central place manage external properties applications across environments provide server support externalized configuration servers (and these texts are all user stories with a worth of 8 story points).;0.04;8.06;1.0;8.33;1;1;1;1
117;Fix XD config initializer for ZK connection string Spring Boot 1.1.1 has the following change: https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4 where an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external zk-properties property source always preceding over the application configuration properties.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Fix xd config initializer for zk connection string spring boot 111 has the following change: https://githubcom/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4 where an external property source precedence would get re-ordered after the application configuration properties this change affects spring xd config initializer which expects an external zk-properties property source always preceding over the application configuration properties was most similar to the text Support compatible formats currently emits native twitter json uses social emits spring social tweet types makes difficult replace twitter sources reuse stream definitions requires coordination ss 110 si 40 ga releases note think good idea continue support native twitter json keep option default tweet types and similar to the text Update documentation related transport eg need update section maybe remove mentions control replace any mentions transport cmd line arg property and similar to the text Dsl work hooking stream directory following stream parsing stream resolution stage chases references fills parameterization lookup streams done interface currently parser implements really job stream directory parser implementation know stream deletions example may still resolve streams longer exist (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
118;hdfs sink loses messages/data when container killed Scenario running a rabbit | hdfs stream and killing the xd-container while stream is running. Looks like the messages get's acked before the data is flushed to hdfs. This results in some data lost due to data either in tmp file or cached in the dfs client. Reference: VESC-387;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Hdfs sink loses messages/data when container killed scenario running a rabbit | hdfs stream and killing the xd-container while stream is running looks like the messages get's acked before the data is flushed to hdfs this results in some data lost due to data either in tmp file or cached in the dfs client reference: vesc-387 was most similar to the text Add source module parameters include optional binding key pattern connection info host port also defaults default port likely fallback file directory and similar to the text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available and similar to the text Ui user able view graphical representation job may broken multiple issues provide generic approach render batch jobs graphically second especially components - provide renderings batch components - see (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
119;Support for registering custom Kryo Serializers This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement however initial benchmarks show that custom serializers are about 10% more performant than Serializable.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Support for registering custom kryo serializers this is an enhancement to kryoclassregistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance currently xd will support pojos that implement the kryo serializable interface to gain a 2x performance improvement however initial benchmarks show that custom serializers are about 10% more performant than serializable was most similar to the text Incorrect message used reason message bound incorrect transport different set container log info main - transport rabbit info - test and similar to the text Add source module parameters include optional binding key pattern connection info host port also defaults default port likely fallback file directory and similar to the text Fix tangle container event references referenced stopped (and these texts are not user stories).;0.1;2.0;1.0;1.67;0;1;1;1
120;As a developer I'd like to create a _gpload_ tasklet so I can ingest data from various sources into GPDB in an efficient manner.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to create a _gpload_ tasklet so i can ingest data from various sources into gpdb in an efficient manner is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;3.24;1.0;1.67;0;1;1;1
121;Update Master Environment for 2.0 CI Acceptance Tests;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update master environment for 20 ci acceptance tests is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
122;As a developer I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module so that I can take advantage of the native Kafka partitioning and message ordering support.;3;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i want to be able to set a partitioning key for the kafka bus even when there is a single downstream module so that i can take advantage of the native kafka partitioning and message ordering support was most similar to the text Support spark streaming specific module options currently module options spark streaming modules use start adding new module options specific modules better expose specific classes help implementing developers and similar to the text Add required jars needed use scheme talk hdfs http and similar to the text Support higher level structure complex module registry see discussion (and these texts are not user stories).;0.09;8.4;1.0;8.33;1;1;1;1
123;Update to spring-data-hadoop 2.0.0.M5 Update to spring-data-hadoop 2.0.0.M5 when it is released and remove the temporary DatasetTemplateAllowingNulls in spring-xd-hadoop We should also review the supported hadoop distros - think we should support anything that is current/stable: - hadoop12 - hadoop22 - phd1 (PHD 1.1) - hdp13 - hdp20 - cdh4;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update to spring-data-hadoop 200m5 update to spring-data-hadoop 200m5 when it is released and remove the temporary datasettemplateallowingnulls in spring-xd-hadoop we should also review the supported hadoop distros - think we should support anything that is current/stable: - hadoop12 - hadoop22 - phd1 (phd 11) - hdp13 - hdp20 - cdh4 was most similar to the text Connection pool settings need section define beginning - code spring code any changes made earlier section defines either removed separate section and similar to the text Exclude final includes need additional jars modules extensions and similar to the text Apart sanity checks much ties actual using resource abstraction work allow loading modules constrained environments file hdfs http (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
124;Package Shell binary next to xd-admin and xd-container The shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now. If we follow how redis/mongo distribut the shell it sits side by side with the other binaries;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Package shell binary next to xd-admin and xd-container the shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now if we follow how redis/mongo distribut the shell it sits side by side with the other binaries is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like central place manage external properties applications across environments provide server support externalized configuration servers and similar to the text Follow experiment removal list modules needed branch and similar to the text Developer id like simplified ux around parameters escape parameter scope also test job identify ux differences (and these texts are all user stories with a worth of 8 story points).;0.01;8.62;1.0;8.33;1;0;1;0
125;Acceptance Tests fail to map some EC2 internal IPs to External IPs The acceptance tests interrogate the XD-Admin for the containers that are available. When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal. [Defect] The acceptance tests only handled the most common suffix of .ec2.internal. Thus some CI Acceptance tests will fail because because the container's IPs were not properly mapped. Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues. FYI EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal. The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Acceptance tests fail to map some ec2 internal ips to external ips the acceptance tests interrogate the xd-admin for the containers that are available when on ec2 the admin only returns the internal ec2 addresses without the associated suffix of ec2internal or compute-1internal [defect] the acceptance tests only handled the most common suffix of ec2internal thus some ci acceptance tests will fail because because the container's ips were not properly mapped thus the acceptance tests should map internal to external ip without regard to the suffixes ec2 issues fyi ec2 issues addresses in 2 different formats: ip-xxx-xxx-xxx-xxxec2internal or domu-xx-xx-xx-xx-xx-xxcompute-1internal the code only able to handle ip-xxx-xxx-xxx-xxxec2internal and the most similar text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available does not exceed the minimum threshold of 75%.;0.04;6.52;1.0;8.33;1;1;0;0
126;Spring flo issue with unexpected char In Flo when creating a stream if you use asterisk you get an error. See the image attached.;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Spring flo issue with unexpected char in flo when creating a stream if you use asterisk you get an error see the image attached is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Developer id like port module scs use sink module build streaming pipeline and similar to the text Spring user need listen jms topic ingest messages process messages currently module allows queues and similar to the text User id like ability visually explore cluster view aware components deployed connected within topology (and these texts are all user stories with a worth of 2 story points).;0.01;3.24;1.0;1.67;0;0;1;0
127;As a user I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka. Consider: * Kafka as message bus * Kafka as source;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have a sample app (github project) so that i can use it as a reference while provisioning spring xd cluster with kafka consider: * kafka as message bus * kafka as source was most similar to the text Rest api dsl completion allow extension rest api dsl completion currently returns prevents future backwards compatible extension change completion has eg text property and similar to the text Remove rename refactoring methods used merging relevant functionality rename consistent and similar to the text Add required jars needed use scheme talk hdfs http (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
128;Custom job with RabbitMq dependencies Hi I've develop a custom Job which have to publish message on RabbitMq when it's finished. To develop this module I'veto include this libraries: * com.rabbitmq:amqp-client:jar * org.springframework.amqp:spring-rabbit:jar * org.springframework.amqp:spring-amqp:jar My job use this writer: org.springframework.batch.item.amqp.AmqpItemWriter I've this error log: {noformat} support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode] {noformat} This is typically due to a library loaded several times. What is the solution to resolve this? I'd like to use the same libraries has RabbitMq Source/Sink or the transport bus. Does module classloader isolated from others? Thanks Mickaël;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Custom job with rabbitmq dependencies hi i've develop a custom job which have to publish message on rabbitmq when it's finished to develop this module i'veto include this libraries: * comrabbitmq:amqp-client:jar * orgspringframeworkamqp:spring-rabbit:jar * orgspringframeworkamqp:spring-amqp:jar my job use this writer: orgspringframeworkbatchitemamqpamqpitemwriter i've this error log: {noformat} supportdefaultamqpheadermapper - skipping header 'amqp_deliverymode' since it is not of expected type [class orgspringframeworkamqpcoremessagedeliverymode] it is [class orgspringframeworkamqpcoremessagedeliverymode] {noformat} this is typically due to a library loaded several times what is the solution to resolve this? i'd like to use the same libraries has rabbitmq source/sink or the transport bus does module classloader isolated from others? thanks mickaël and the most similar text Rest returns one job has error bug deployments rest endpoint reproduce deploy batch job success example does necessary libraries causes result retrieve list deployments list anymore using rest endpoint report job name exist message entirely extremely misleading think still return entire list rather mark job error also returning found misleading well does not exceed the minimum threshold of 75%.;0.02;6.52;1.0;8.33;1;1;0;0
129;As a developer I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to review the current sonar violations so that i can fix the relevant and update the irrelevant ones as invalid is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.06;8.16;1.0;8.33;1;1;1;1
130;Create localChannelProtocol.xml that will load all the SI specific implementations to suppor the XD container runtime and administration;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create localchannelprotocolxml that will load all the si specific implementations to suppor the xd container runtime and administration is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.03;3.24;1.0;1.67;0;0;1;0
131;More DSL work: using and policing & for job step lists The new parser supports | for connecting regular modules and & for connecting job steps. The modules in the ast that were connected with & are tagged but nothing is currently using that information (it doesnt get into the module deployment request). We need to think about using this data: policing the modules that are being deployed to ensure they are job steps for example.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text More dsl work: using and policing & for job step lists the new parser supports | for connecting regular modules and & for connecting job steps the modules in the ast that were connected with & are tagged but nothing is currently using that information (it doesnt get into the module deployment request) we need to think about using this data: policing the modules that are being deployed to ensure they are job steps for example was most similar to the text Modules gives error cli modules command failed running distributed mode transport rabbit rabbit and similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases and similar to the text Automate execution part daily build one easy way use authentication scheme described bamboo mask property name contains password may want create dedicated user though (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
132;Batch Wordcount Sample to use File Source;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Batch wordcount sample to use file source is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
133;IllegalStateException when shutting down container {noformat} 13:23:57643 INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log' moduleLabel = 'log' group = 'paymenttap' sourceChannelName = 'tap:job:payment' sinkChannelName = [null] sinkChannelName = [null] index = 0 type = sink parameters = map[[empty]] children = list[[empty]]] 13:23:57643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exception java.lang.IllegalStateException: instance must be started before calling this method at com.google.common.base.Preconditions.checkState(Preconditions.java:176) at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344) at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292) at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257) at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711) at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67) at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) {noformat} Sequence of events: * Stream module ZK path is removed * Event is raised * ZK connection is closed * Event handler causes module undeployment which includes unregistration of tap * Since connection is closed exception is thrown;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Illegalstateexception when shutting down container {noformat} 13:23:57643 info main-eventthread servercontainerregistrar - undeploying module [moduledescriptor@1c736092 modulename = 'log' modulelabel = 'log' group = 'paymenttap' sourcechannelname = 'tap:job:payment' sinkchannelname = [null] sinkchannelname = [null] index = 0 type = sink parameters = map[[empty]] children = list[[empty]]] 13:23:57643 error main-eventthread impscuratorframeworkimpl - watcher exception javalangillegalstateexception: instance must be started before calling this method at comgooglecommonbasepreconditionscheckstate(preconditionsjava:176) at orgapachecuratorframeworkimpscuratorframeworkimpldelete(curatorframeworkimpljava:344) at orgspringframeworkxddirtservercontainerregistrarunregistertap(containerregistrarjava:292) at orgspringframeworkxddirtservercontainerregistrarundeploymodule(containerregistrarjava:257) at orgspringframeworkxddirtservercontainerregistrar$streammodulewatcherprocess(containerregistrarjava:711) at orgapachecuratorframeworkimpsnamespacewatcherprocess(namespacewatcherjava:67) at orgapachezookeeperclientcnxn$eventthreadprocessevent(clientcnxnjava:522) at orgapachezookeeperclientcnxn$eventthreadrun(clientcnxnjava:498) {noformat} sequence of events: * stream module zk path is removed * event is raised * zk connection is closed * event handler causes module undeployment which includes unregistration of tap * since connection is closed exception is thrown and the most similar text Add support dynamic routing possible create streams like following rely named channel support dynamic routing capabilities code http x hdfs hdfs code processor return x determines downstream path message implemented way any developer adding router module need deal existing spring integration semantics case return x - pojo method invocation modifies module context simply add new implementation adding bean configures resolver any router necessary reference router actually sends messages shared channels shared channels long valid downstream flow has defined does not exceed the minimum threshold of 75%.;0.02;2.0;1.0;1.67;0;1;0;0
134;As a developer I'm adding new overrides to {{server.yml}} file however the overridden properties do not reflect even after the restart of server.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'm adding new overrides to {{serveryml}} file however the overridden properties do not reflect even after the restart of server is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like use server modules centrally manage external properties and similar to the text Spring user id like notebook integration perform interactive data computations and similar to the text Developer id like troubleshoot performance issues rabbit message implementation isolate bottleneck fix appropriate (and these texts are all user stories with a worth of 8 story points).;0.02;5.64;1.0;8.33;1;1;1;1
135;As a developer I'd like to add support to _flush_ state intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to add support to _flush_ state intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.02;2.07;1.0;1.67;0;1;1;1
136;Documentation for gauge taps Put on the guide as a section in an 'input-stream' wiki page.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Documentation for gauge taps put on the guide as a section in an 'input-stream' wiki page is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;8.48;1.0;8.33;1;0;1;0
137;In-memory implementation of aggregate counter;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text In-memory implementation of aggregate counter was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;5.83;0.0;1.67;0;1;1;1
138;Create a rabbit sink module and documentation https://github.com/springsource/spring-xd/wiki/Sinks should have 'rabbit' added to the list and also the corresponding section that shows some basic usage.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create a rabbit sink module and documentation https://githubcom/springsource/spring-xd/wiki/sinks should have 'rabbit' added to the list and also the corresponding section that shows some basic usage was most similar to the text Use dot composed module option separator following merge use dot separator composed module option need change parser accept dots and similar to the text Remove unnecessary usage following merge investigate calling sites any similar api remove needed and similar to the text Remove main dirt driver present dirts present modules though blocked shortcoming described (and these texts are not user stories).;0.02;8.28;1.0;8.33;1;1;1;1
139;As a user I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to refer to documentation so that i can build the custom module based on recommended standards and patterns is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;8.55;1.0;8.33;1;1;1;1
140;Export of data from HDFS to a relational database Based on a single process running a Spring Batch job support the ETL of data from HDFS to a RDBMS;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Export of data from hdfs to a relational database based on a single process running a spring batch job support the etl of data from hdfs to a rdbms was most similar to the text Remove expiry keys based repositories code based repositories related expiry behavior move common shared helper class base class and similar to the text Source log info keep mind pbkac part please review see get work and similar to the text Needs use http test source also check output see filter rejected entry (and these texts are not user stories).;0.02;7.13;1.0;8.24;1;1;1;1
141;As a user I would like to specify the default output channel when the channel name resolution doesn't occur. In cases where I won't prefer to lose the data and like to investigate the messages from errorChannel or that sort.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i would like to specify the default output channel when the channel name resolution doesn't occur in cases where i won't prefer to lose the data and like to investigate the messages from errorchannel or that sort was most similar to the text Custom user configuration file jobs allow users submit configuration file part job definition configuration file contain job definition parameters well customer parameters reference thanks and similar to the text Add required jars needed use scheme talk hdfs http and similar to the text Support higher level structure complex module registry see discussion (and these texts are not user stories).;0.08;2.05;1.0;1.67;0;1;1;1
142;Spring XD very poor performance when using redis as transport When using redis as transport bus there is a problem when using many streams and taps. Basically the maxTotal parameter of org.apache.commons.pool2.GenericObjectPool default is 8. After some streams are deployed it starts to occur concurrency problems hence the number of inbound redis channel adapters is larger than that number. A more detailed explanation is in stackoverflow: http://stackoverflow.com/questions/25851660/spring-xd-very-poor-performance-when-using-redis-as-transport;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Spring xd very poor performance when using redis as transport when using redis as transport bus there is a problem when using many streams and taps basically the maxtotal parameter of orgapachecommonspool2genericobjectpool default is 8 after some streams are deployed it starts to occur concurrency problems hence the number of inbound redis channel adapters is larger than that number a more detailed explanation is in stackoverflow: http://stackoverflowcom/questions/25851660/spring-xd-very-poor-performance-when-using-redis-as-transport was most similar to the text Need support test properties user wishes run acceptance tests local machine instance way establish container admin server artifact has subdirectory user able set file and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Fix module properties use dot property name prevents user value stream definition also defaults repeated xml properties level (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
143;Add SmartLifecycle to ChannelBindingAdapter Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add smartlifecycle to channelbindingadapter make channelbindingadapter implement smartlifecycle so that it gets started with the highest precedence and before any other message producing bean was most similar to the text Ability send files attachment mail sink id mail sink has ability send files attachment ie add attribute and similar to the text Home use set set use otherwise point two different paths and similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
144;Test integration with jboss queue message I am new to Spring XD I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e stream create --name TEST-LOG --definition jms | file --deploy. I am trying to configure the spring-xd-1.0.0.M6\xd\modules\common\jms-jbossmq-infrastructure-context.xml to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Test integration with jboss queue message i am new to spring xd i want to read the jboss queue message and then want to write it into text file by using stream create comment ie stream create --name test-log --definition jms | file --deploy i am trying to configure the spring-xd-100m6\xd\modules\common\jms-jbossmq-infrastructure-contextxml to invoke the jboss queue and read the queue message can you help me to do the configuration and resolve my objective? was most similar to the text Consider using convert incoming message payload reactor based processors input type call handle type conversion payload input type possible code try invoke conversion service and similar to the text Modules gives error cli modules command failed running distributed mode transport rabbit rabbit and similar to the text Spike research mechanism job management current implementation job management entirely based message exchange message request reply scenario creates challenges comes using certain types transports well crashes effect option using different job coordination strategy relies distributed computing coordination mechanism (and these texts are not user stories).;0.06;2.0;1.0;1.67;0;1;1;1
145;Investigate increased size of XD distribution.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Investigate increased size of xd distribution was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;8.62;1.0;8.33;1;1;1;1
146;Documentation for data partitioning and all Rabbit Bus properties;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Documentation for data partitioning and all rabbit bus properties is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
147;Spike: Research request/reply support to Kafka Message Bus The scope is to research the available options to provide request/reply support for Kafka. * Document findings * POCs Previous Desc: The bindRequestor and bindReplier methods of the message bus need to be implemented.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Spike: research request/reply support to kafka message bus the scope is to research the available options to provide request/reply support for kafka * document findings * pocs previous desc: the bindrequestor and bindreplier methods of the message bus need to be implemented was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Decouple make dl public class handle deployment related events remove dl eventually use and similar to the text Build script creates executable server artifact application good starting point main server host si based modules ingestion example (and these texts are not user stories).;0.06;8.16;1.0;8.33;1;1;1;1
148;Document partitioning through deployment properties As an s-c-d user I'd like to have documentation on deployment manifest so I could refer to the relevant bits on {{partitions}}. I'd like to understand how streams withe;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Document partitioning through deployment properties as an s-c-d user i'd like to have documentation on deployment manifest so i could refer to the relevant bits on {{partitions}} i'd like to understand how streams withe was most similar to the text Fix rest endpoint security security container admin server wont able fetch message rates deployed modules container rest endpoint needs fixed and similar to the text Pom generation creates correct dependency list moved different version boot platform and similar to the text Organize modules consistently using per module even strictly necessary modules use scheme care taken case import (and these texts are not user stories).;0.09;8.62;1.0;1.67;0;1;1;1
149;Exception when accessing CDH4 namenode Get exception when accessing cdh4 from shell - java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses. com.google.protobuf.GeneratedMessage.getUnknownFields most likely due to protobuf-java-2.5.0.jar being on the main classpath now Full stack trace: {code} trisberg@carbon:~/Test$ ./spring-xd-1.0.0.BUILD-SNAPSHOT/shell/bin/xd-shell --hadoopDistro cdh4 16:55:22680 WARN main conf.Configuration:824 - fs.default.name is deprecated. Instead use fs.defaultFS _____ __ _______ / ___| (-) \ \ / / _ \ \ `--. _ __ _ __ _ _ __ __ _ \ V /| | | | `--. \ '_ \| '__| | '_ \ / _` | / ^ \| | | | /\__/ / |_) | | | | | | | (_| | / / \ \ |/ / \____/| .__/|_| |_|_| |_|\__ | \/ \/___/ | | __/ | |_| |___/ eXtreme Data 1.0.0.BUILD-SNAPSHOT | Admin Server Target: http://localhost:9393 Welcome to the Spring XD shell. For assistance hit TAB or type help. xd:>hadoop config fs --namenode hdfs://cdh4:8020 xd:>hadoop fs ls / Hadoop configuration changed re-initializing shell... 16:55:28853 WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable -ls: Fatal internal error java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses. com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180) org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:30108) com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49) org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.constructRpcRequest(ProtobufRpcEngine.java:149) org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:193) com.sun.proxy.$Proxy43.getFileInfo(Unknown Source) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164) org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83) com.sun.proxy.$Proxy43.getFileInfo(Unknown Source) org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:629) org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1545) org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:819) org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1646) org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1592) org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1567) org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:271) org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224) org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207) org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190) org.apache.hadoop.fs.shell.Command.run(Command.java:154) org.apache.hadoop.fs.FsShell.run(FsShell.java:254) org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412) org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407) org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:196) org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64) org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48) org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127) org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:530) org.springframework.shell.core.JLineShell.run(JLineShell.java:178) java.lang.Thread.run(Thread.java:744) {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Exception when accessing cdh4 namenode get exception when accessing cdh4 from shell - javalangunsupportedoperationexception: this is supposed to be overridden by subclasses comgoogleprotobufgeneratedmessagegetunknownfields most likely due to protobuf-java-250jar being on the main classpath now full stack trace: {code} trisberg@carbon:~/test$ /spring-xd-100build-snapshot/shell/bin/xd-shell --hadoopdistro cdh4 16:55:22680 warn main confconfiguration:824 - fsdefaultname is deprecated instead use fsdefaultfs _____ __ _______ / ___| (-) \ \ / / _ \ \ `-- _ __ _ __ _ _ __ __ _ \ v /| | | | `-- \ '_ \| '__| | '_ \ / _` | / ^ \| | | | /\__/ / |_) | | | | | | | (_| | / / \ \ |/ / \____/| __/|_| |_|_| |_|\__ | \/ \/___/ | | __/ | |_| |___/ extreme data 100build-snapshot | admin server target: http://localhost:9393 welcome to the spring xd shell for assistance hit tab or type help xd:>hadoop config fs --namenode hdfs://cdh4:8020 xd:>hadoop fs ls / hadoop configuration changed re-initializing shell 16:55:28853 warn spring shell utilnativecodeloader:62 - unable to load native-hadoop library for your platform using builtin-java classes where applicable -ls: fatal internal error javalangunsupportedoperationexception: this is supposed to be overridden by subclasses comgoogleprotobufgeneratedmessagegetunknownfields(generatedmessagejava:180) orgapachehadoophdfsprotocolprotoclientnamenodeprotocolprotos$getfileinforequestprotogetserializedsize(clientnamenodeprotocolprotosjava:30108) comgoogleprotobufabstractmessagelitetobytestring(abstractmessagelitejava:49) orgapachehadoopipcprotobufrpcengine$invokerconstructrpcrequest(protobufrpcenginejava:149) orgapachehadoopipcprotobufrpcengine$invokerinvoke(protobufrpcenginejava:193) comsunproxy$proxy43getfileinfo(unknown source) sunreflectnativemethodaccessorimplinvoke0(native method) sunreflectnativemethodaccessorimplinvoke(nativemethodaccessorimpljava:57) sunreflectdelegatingmethodaccessorimplinvoke(delegatingmethodaccessorimpljava:43) javalangreflectmethodinvoke(methodjava:606) orgapachehadoopioretryretryinvocationhandlerinvokemethod(retryinvocationhandlerjava:164) orgapachehadoopioretryretryinvocationhandlerinvoke(retryinvocationhandlerjava:83) comsunproxy$proxy43getfileinfo(unknown source) orgapachehadoophdfsprotocolpbclientnamenodeprotocoltranslatorpbgetfileinfo(clientnamenodeprotocoltranslatorpbjava:629) orgapachehadoophdfsdfsclientgetfileinfo(dfsclientjava:1545) orgapachehadoophdfsdistributedfilesystemgetfilestatus(distributedfilesystemjava:819) orgapachehadoopfsfilesystemglobstatusinternal(filesystemjava:1646) orgapachehadoopfsfilesystemglobstatus(filesystemjava:1592) orgapachehadoopfsfilesystemglobstatus(filesystemjava:1567) orgapachehadoopfsshellpathdataexpandasglob(pathdatajava:271) orgapachehadoopfsshellcommandexpandargument(commandjava:224) orgapachehadoopfsshellcommandexpandarguments(commandjava:207) orgapachehadoopfsshellcommandprocessrawarguments(commandjava:190) orgapachehadoopfsshellcommandrun(commandjava:154) orgapachehadoopfsfsshellrun(fsshelljava:254) orgspringframeworkxdshellhadoopfsshellcommandsrun(fsshellcommandsjava:412) orgspringframeworkxdshellhadoopfsshellcommandsruncommand(fsshellcommandsjava:407) orgspringframeworkxdshellhadoopfsshellcommandsls(fsshellcommandsjava:110) sunreflectnativemethodaccessorimplinvoke0(native method) sunreflectnativemethodaccessorimplinvoke(nativemethodaccessorimpljava:57) sunreflectdelegatingmethodaccessorimplinvoke(delegatingmethodaccessorimpljava:43) javalangreflectmethodinvoke(methodjava:606) orgspringframeworkutilreflectionutilsinvokemethod(reflectionutilsjava:196) orgspringframeworkshellcoresimpleexecutionstrategyinvoke(simpleexecutionstrategyjava:64) orgspringframeworkshellcoresimpleexecutionstrategyexecute(simpleexecutionstrategyjava:48) orgspringframeworkshellcoreabstractshellexecutecommand(abstractshelljava:127) orgspringframeworkshellcorejlineshellpromptloop(jlineshelljava:530) orgspringframeworkshellcorejlineshellrun(jlineshelljava:178) javalangthreadrun(threadjava:744) {code} and the most similar text Modules fail deploy yarn 1 admin 1 container modules fail deploy following exception modules require environment variable set yarn deployment offending resource url nested exception file directory configuration problem error groovy script file directory offending resource url nested exception file directory method method method 29 file directory method 79 does not exceed the minimum threshold of 75%.;0.08;2.0;1.0;1.67;0;1;0;0
150;Add Spring Cloud Config to SPI Module Parent Enable spring cloud config for all modules * Add spring cloud config client to pom dependencies. * Add bootstrap.yml to scs project;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add spring cloud config to spi module parent enable spring cloud config for all modules * add spring cloud config client to pom dependencies * add bootstrapyml to scs project is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively (and these texts are all user stories with a worth of 8 story points).;0.01;8.48;1.0;8.33;1;0;1;0
151;Create Boot Starters for Modules Create various boot starter projects for module developers. This should include templates for source processor sink and job and ideally different options for each. For example a processor configured with XML SI Java DSL or SI Java DSL with lambdas.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create boot starters for modules create various boot starter projects for module developers this should include templates for source processor sink and job and ideally different options for each for example a processor configured with xml si java dsl or si java dsl with lambdas was most similar to the text Verify platform compatibility versions dependencies need make sure dependency using spring io platform dependencies one scenario dependency missing and similar to the text Add documentation functionality based processors see issue docs include examples show use standard based splitter transformer filters expressions and similar to the text Fix tangle container event references referenced stopped (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
152;Improve Shell Connection Diagnostics When a problem occurs connecting to admin we just get {{Unable to contact Data Flow Admin}} even if the connection is successful and some problem occurs when interpreting the result. The exception is eaten. Log an error including the exception. Currently investigating an NPE in DataFlowTemplate @ line 77.;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Improve shell connection diagnostics when a problem occurs connecting to admin we just get {{unable to contact data flow admin}} even if the connection is successful and some problem occurs when interpreting the result the exception is eaten log an error including the exception currently investigating an npe in dataflowtemplate @ line 77 is a user story, and is worth 1 story points. This was predicted because it is most similar to the text Build manager id like schedule ci builds windows verify scope isolate remaining test failures experiment new ami images solid infrastructure fix failing tests and similar to the text User id like see date logs troubleshoot issues occurred specific day time property needs adjusted and similar to the text User id like refer wiki create job partitions turn expects columns explicitly included job definition also beneficial call-out sql metadata options mutually exclusive following logic needs documented use columns using partition column boolean return return true code (and these texts are all user stories with a worth of 1 story points).;0.01;2.0;1.0;1.67;0;0;1;0
153;Job as a Source h2. Narrative As an XD developer I need to be able to use a batch job to stream data as a source. h2. Acceptance Criteria # Implement the ability for a job to be defined as a source in the DSL # Add the configurations for the batch infrastructure transparently to the user # Add the ability to specify if the job is stateful (picks up where it left off if it stops or restarts at the beginning).;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Job as a source h2 narrative as an xd developer i need to be able to use a batch job to stream data as a source h2 acceptance criteria # implement the ability for a job to be defined as a source in the dsl # add the configurations for the batch infrastructure transparently to the user # add the ability to specify if the job is stateful (picks up where it left off if it stops or restarts at the beginning) was most similar to the text Update use test dependent external system success times service running slower test expects test fails unnecessarily once merged utilize feature wait result file stream written wait time twitter extended 1 min make search string tests fail consistently present and similar to the text Implement spark streaming driver application controlled module instance include management modules stream spark streaming application stopped etc deploying number module instances result multiple receiver tasks bind using consumer side partitioning metadata and similar to the text Add acceptance test job stage uses distributed mode see stages one jobs run parallel like tests across rabbit transport occur parallel (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
154;Change SpringSource references in pom.xml to Spring/spring.io This is currently in the M6 pom: <organization> <name>SpringSource</name> <url>http://springsource.org</url> </organization>;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Change springsource references in pomxml to spring/springio this is currently in the m6 pom: <organization> <name>springsource</name> <url>http://springsourceorg</url> </organization> is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like separate mocks vs real repository coupling test infrastructure easy test thin layer dependencies and similar to the text User id like option write file roll sink store events local file system and similar to the text User need document covering recommendations deploying cluster using marathon framework (and these texts are all user stories with a worth of 8 story points).;0.03;4.94;1.0;8.33;1;0;1;0
155;Add Spring Retry to Rabbit Message Bus Log and purge bad messages;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add spring retry to rabbit message bus log and purge bad messages is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;3.01;1.0;1.67;0;0;1;0
156;No indication of failure in shell when deploying job referencing nonexistent trigger I see the following output on the shell if I create a job and reference a non-existent trigger. There's a big stack trace in the server log but nothing on the shell side indicating failure. A subsequent jobs list also shows the job. The same thing happens if I deploy an undeployed Job after deleting its associated Trigger. $ job create --name helloWorldJob --definition myjob --trigger=nonexistenttrigger Successfully created and deployed job 'helloWorldJob';0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text No indication of failure in shell when deploying job referencing nonexistent trigger i see the following output on the shell if i create a job and reference a non-existent trigger there's a big stack trace in the server log but nothing on the shell side indicating failure a subsequent jobs list also shows the job the same thing happens if i deploy an undeployed job after deleting its associated trigger $ job create --name helloworldjob --definition myjob --trigger=nonexistenttrigger successfully created and deployed job 'helloworldjob' was most similar to the text Issue trying use http trying send json object get following error even though opened requests allow load header present requested resource origin therefore allowed access spring profiles transport local ui and similar to the text Thrown using empty string inside expression reproduce using single quotes around expression code stream create test definition http transform log deploy true code following two alternatives work fine though code using trim single space stream create test definition http transform trim log deploy true using single quotes spaces expression stream create test definition http transform log deploy true code and similar to the text Binder configuration use currently references rabbit configuration classes trigger trigger based presence another jar has meat configuration typically boot moreover adding new binding eg kafka stub module testing require crack open (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
157;Provide JMS as a supported MessageBus implementation;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Provide jms as a supported messagebus implementation was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;6.58;1.0;8.33;1;1;1;1
158;HdfsTest picks up data from a previous run. If a stream foo has messages in its queue when it is destroyed and another stream named foo is created of similar structure those messages will be delivered to sink. This is seen when twitterstream runs prior to hdfssink test. The twitters stream data is written to hdfs instead of the trigger data that was intended. The solution is to give hdfstest its own unique name instead of the default ec2test3 name.;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Hdfstest picks up data from a previous run if a stream foo has messages in its queue when it is destroyed and another stream named foo is created of similar structure those messages will be delivered to sink this is seen when twitterstream runs prior to hdfssink test the twitters stream data is written to hdfs instead of the trigger data that was intended the solution is to give hdfstest its own unique name instead of the default ec2test3 name is a user story, and is worth 1 story points. This was predicted because it is most similar to the text User trying access uri get fails forbidden error role view access details another url error and similar to the text Developer id like upgrade ga release leverage latest improvements breaking backwards compatibility uses boot 13 versions drop older hive support avoid breaking changes instead use has backported any improvements need well move spring versions recent ones and similar to the text User id like option basic provide user name password making request technical implementation functionality spring boot matter adding spring boot security starter dependency project controlled using spring boot property default property false (and these texts are all user stories with a worth of 1 story points).;0.03;6.52;1.0;8.33;1;0;1;0
159;STS - Spring XD Imported with Compilation Error Cannot import Spring XD into STS without compilation errors in class: *org.springframework.xd.dirt.rest.ModulesController#list* Error is in: {code} return assembler.toResource(page detailed ? detailedAssembler: simpleAssembler) {code} {code} The method toResource(Page<ModuleDefinition> Link) in the type PagedResourcesAssembler<ModuleDefinition> is not applicable for the arguments (Page<ModuleDefinition> (detailed ? detailedAssembler : simpleAssembler)) {code} Seems to be an STS specific issue.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Sts - spring xd imported with compilation error cannot import spring xd into sts without compilation errors in class: *orgspringframeworkxddirtrestmodulescontroller#list* error is in: {code} return assemblertoresource(page detailed ? detailedassembler: simpleassembler) {code} {code} the method toresource(page<moduledefinition> link) in the type pagedresourcesassembler<moduledefinition> is not applicable for the arguments (page<moduledefinition> (detailed ? detailedassembler : simpleassembler)) {code} seems to be an sts specific issue is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study taxi trips based stream trip reports new york city evaluate systems context real-time analytics using spring challenge and similar to the text Developer id like build data pipeline using kafka message demonstrate capabilities use case consider log aggregation lambda architecture avoid code duplication eliminate tight coupling logic kafka used reliable reprocessing and similar to the text User id like rest api point push archive includes custom module definitions configurations manually move set scope spike assess customer requirement brainstorm document options socialize team collect feedback identify phases create new stories (and these texts are all user stories with a worth of 8 story points).;0.03;2.01;1.0;1.67;0;0;1;0
160;Create tcp/udp load generator script for XD performance testing Create a load generator script which can generate messages at specific 1) Rate 2) Payload 3) Concurrency to a specific tcp/udp port where a syslog adapter is listening.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create tcp/udp load generator script for xd performance testing create a load generator script which can generate messages at specific 1) rate 2) payload 3) concurrency to a specific tcp/udp port where a syslog adapter is listening is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Scs user id like investigate possibility scs modules service discovery use spring running cf discover orchestrate modules streams (and these texts are all user stories with a worth of 8 story points).;0.06;8.62;1.0;8.33;1;0;1;0
161;Detect Module Properties for Non-existent Modules stream create foo --definition=bar | baz stream deploy foo --properties=module.qux.fiz;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Detect module properties for non-existent modules stream create foo --definition=bar | baz stream deploy foo --properties=modulequxfiz is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like migrate module deployment repository abstraction used definitions create spi and similar to the text Spring user id like use cluster message create streams batch pipelines and similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster (and these texts are all user stories with a worth of 8 story points).;0.01;3.01;1.0;1.67;0;0;1;0
162;As a s-c-d user I'd like to have {{runtime info}} as shell command so I can use this to list the details about the module such as {{host}} {{port}} and the like.;4;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d user i'd like to have {{runtime info}} as shell command so i can use this to list the details about the module such as {{host}} {{port}} and the like is a user story, and is worth 5 story points. This was predicted because it is most similar to the text User id like refer pig sample use reference integrate pig jobs and similar to the text Scd user id like add rest support stream commands maneuver streaming pipeline backed and similar to the text Scd developer id like explore options bootstrap setup lattice based infrastructure scds bare metal deployment (and these texts are all user stories with a worth of 5 story points).;0.03;8.48;1.0;8.33;1;1;1;1
163;XD should use same hadoop security keys as Spring for Apache Hadoop For kerberos and other security related settings we use keys like 'spring.hadoop.userPrincipal' mentioned in https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos. However when we added boot config props to shdp we used a sub keys like 'spring.hadoop.security.userPrincipal'. It'd be good if we'd fix these to be same in both XD and SHDP not to cause confusion.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Xd should use same hadoop security keys as spring for apache hadoop for kerberos and other security related settings we use keys like 'springhadoopuserprincipal' mentioned in https://githubcom/spring-projects/spring-xd/wiki/hadoop-kerberos however when we added boot config props to shdp we used a sub keys like 'springhadoopsecurityuserprincipal' it'd be good if we'd fix these to be same in both xd and shdp not to cause confusion was most similar to the text Create repository narrative need persistent way register job definitions beyond map registry implementation spring batch acceptance able register find job definitions registry registry backed persistent and similar to the text Module option validation happening anymore seems option validation spring happening anymore stream creation time eg stream create foo definition http log and similar to the text Verify platform compatibility versions dependencies need make sure dependency using spring io platform dependencies one scenario dependency missing (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
164;Tasks Launcher should be able to record status to a central repository Need infrastructure to capture the state from the environment (lattice local) running the task. Task Launcher needs ability to map the task state as it is reported from the cloud environment (lattice local) to the enumerated state as specified [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly]. The state information needs to be recorded in the task_execution table enumerated [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Tasks launcher should be able to record status to a central repository need infrastructure to capture the state from the environment (lattice local) running the task task launcher needs ability to map the task state as it is reported from the cloud environment (lattice local) to the enumerated state as specified [#here|https://docsgooglecom/document/d/1ttmqmiwsuefewyysafk8ji4z9ni-5f1vfeaiwhuzsgg/edit#heading=h2ec94f2he9ly] the state information needs to be recorded in the task_execution table enumerated [#here|https://docsgooglecom/document/d/1ttmqmiwsuefewyysafk8ji4z9ni-5f1vfeaiwhuzsgg/edit#heading=h2ec94f2he9ly] was most similar to the text Allow user configure tests addition sinks sources require connections external entities jms jdbc environment setup getting unwieldy integrate acceptance tests retrieve environment variables dependency injection utilize profiles local single node local cluster single node cluster and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Needs bounded task 11 channels run high volume environments might occur topic thread overwhelm system threads add local configuration limit thread pool used queue tasks threads available setting (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
165;As a s-c-d developer I'd like to enhance unit test coverage for {{Lattice}} SPI so I can continuously evaluate functionalities via CI pipeline.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to enhance unit test coverage for {{lattice}} spi so i can continuously evaluate functionalities via ci pipeline is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.03;8.06;1.0;8.33;1;1;1;1
166;As a PM I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a pm i'd like to have test coverage for both kafka source and sink modules so that we can assert its functionality as part of the ci builds is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint and similar to the text Scd developer id like cc spi deployer cf improve overall design performance and similar to the text User able leverage native sink aggregate search analyze data insights (and these texts are all user stories with a worth of 8 story points).;0.1;4.48;1.0;7.9;1;1;1;1
167;Modularize angular app modules based on the functionality When adding streams page to the UI (from XD-1667) it is necessary to modularize the angular app modules based on the functionality/components (job stream auth etc.). As we expand into more components and use cases in the UI this definitely makes it easier to concentrate on specific modules based on the functionality.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Modularize angular app modules based on the functionality when adding streams page to the ui (from xd-1667) it is necessary to modularize the angular app modules based on the functionality/components (job stream auth etc) as we expand into more components and use cases in the ui this definitely makes it easier to concentrate on specific modules based on the functionality was most similar to the text Rpm upgrades wipeout installation operator id like upgrade latest releases spring yet lose older installation copy reuse previously used configurations and similar to the text Kafka tests assume offset 0 testing queue partitions content read assumed start offset 0 incorrect topics may exist already especially ci environment and similar to the text Replace usage raw curl shell command post http data documentation eg target data 10 believe also help avoid ugly syntax quotes json example (and these texts are not user stories).;0.12;8.62;1.0;8.33;1;1;1;1
168;BackPort script.xml Bug Fix An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master it needs to be backported to 1.0.x. {{s/$\{location\}/$\{script\}/}} https://gopivotal-com.socialcast.com/messages/22909482;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Backport scriptxml bug fix an additional commit (https://githubcom/spring-projects/spring-xd/commit/db1f585) for xd-2230 was applied only to master it needs to be backported to 10x {{s/$\{location\}/$\{script\}/}} https://gopivotal-comsocialcastcom/messages/22909482 is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Build master id like fix local targets outstanding build issues evaluate publish builds works expected and similar to the text Performance tester id like rerun baseline benchmarks batching rabbit compare results performance snapshots note - true - 100 default also vary default size compute record granular level and similar to the text User id like option hdfs sink leverage open source distributed authentication system data writes (and these texts are all user stories with a worth of 3 story points).;0.02;8.62;1.0;8.33;1;0;1;0
169;As a Spring XD developer I'd like to move {{mqtt}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to move {{mqtt}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Spring developer id like move cassandra module scs use sink build streaming pipeline and similar to the text Lead id like review current architecture design specs address any foundation level gaps and similar to the text User id like option sink perform indexing search server (and these texts are all user stories with a worth of 5 story points).;0.1;8.4;1.0;8.33;1;1;1;1
170;As a user I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'm trying to create a composed job with >20 steps/transitions using rabbit as the message bus and it doesn't complete successfully is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.01;4.48;1.0;7.9;1;1;1;1
171;JAR version mismatches Looks like there are some version mismatch issues with the build/packaging of the XD components. Looking in xd/lib I see the following which looks suspicious: mqtt-client-0.2.1.jar mqtt-client-1.0.jar jackson-core-asl-1.9.13.jar jackson-mapper-asl-1.9.12.jar spring-integration-core-3.0.0.M3.jar spring-integration-http-2.2.5.RELEASE.jar spring-data-commons-1.6.0.M1.jar spring-data-commons-core-1.4.0.RELEASE.jar;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Jar version mismatches looks like there are some version mismatch issues with the build/packaging of the xd components looking in xd/lib i see the following which looks suspicious: mqtt-client-021jar mqtt-client-10jar jackson-core-asl-1913jar jackson-mapper-asl-1912jar spring-integration-core-300m3jar spring-integration-http-225releasejar spring-data-commons-160m1jar spring-data-commons-core-140releasejar was most similar to the text Hdfs sink support file naming strategy distinguish file currently written completed files file process written customized suffix added name eg temp once file closed suffix removed another value - default value dependent serialization format used customized and similar to the text Ship relevant modules files current build ships found modules directory build artifacts build idea iml files restrict build include lib moment and similar to the text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
172;Channel Registry;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Channel registry was most similar to the text Upgrade 22 and similar to the text Update reactor and similar to the text Upgrade curator (and these texts are not user stories).;0.03;2.9;0.0;1.67;0;1;1;1
173;Accessing Admin REST APIs on CF returns unexpected results As an s-c-d user I'm trying to access {{admin}} REST endpoints running on CF but I'm getting SSL authentication errors.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Accessing admin rest apis on cf returns unexpected results as an s-c-d user i'm trying to access {{admin}} rest endpoints running on cf but i'm getting ssl authentication errors is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.05;2.09;1.0;1.67;0;0;1;0
174;Add Redis binaries for Windows Presently Spring XD does not ship Windows binaries for Redis. However Microsoft is actively working [1] on supporting Redis on Windows. You can download Windows Redis binaries from: https://github.com/MSOpenTech/redis/tree/2.6/bin/release [1] http://blogs.msdn.com/b/interoperability/archive/2013/04/22/redis-on-windows-stable-and-reliable.aspx;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Add redis binaries for windows presently spring xd does not ship windows binaries for redis however microsoft is actively working [1] on supporting redis on windows you can download windows redis binaries from: https://githubcom/msopentech/redis/tree/26/bin/release [1] http://blogsmsdncom/b/interoperability/archive/2013/04/22/redis-on-windows-stable-and-reliableaspx and the most similar text Document review rest api rest api needs finalized documented ga release api reviewed rest experts does not exceed the minimum threshold of 75%.;0.06;2.02;1.0;1.67;0;1;0;0
175;The HDFS Sink should support writing POJOs to HDFS using Parquet Writing POJOs using Kite SDK;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text The hdfs sink should support writing pojos to hdfs using parquet writing pojos using kite sdk is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text User id like parameterize options generate code fly needed and similar to the text Developer id like revisit existing design identify known limitations gaps (and these texts are all user stories with a worth of 5 story points).;0.02;8.4;1.0;8.33;1;0;1;0
176;As a user I'm trying to load Job - Modules page in admin-ui but I'm seeing exceptions in console and the page wouldn't load. {code} Failed to convert value of type 'java.lang.String' to required type 'org.springframework.cloud.dataflow.core.ArtifactType' nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @org.springframework.web.bind.annotation.RequestParam org.springframework.cloud.dataflow.core.ArtifactType for value 'job' nested exception is java.lang.IllegalArgumentException: No enum constant org.springframework.cloud.dataflow.core.ArtifactType.job {code};2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'm trying to load job - modules page in admin-ui but i'm seeing exceptions in console and the page wouldn't load {code} failed to convert value of type 'javalangstring' to required type 'orgspringframeworkclouddataflowcoreartifacttype' nested exception is orgspringframeworkcoreconvertconversionfailedexception: failed to convert from type javalangstring to type @orgspringframeworkwebbindannotationrequestparam orgspringframeworkclouddataflowcoreartifacttype for value 'job' nested exception is javalangillegalargumentexception: no enum constant orgspringframeworkclouddataflowcoreartifacttypejob {code} was most similar to the text Improvements modules tab 1 get listing job modules 2 remove version action column 3 text say definitions available modules ui forthcoming link command line 4 association spring box module names description 5 add button display xml file defines job module and similar to the text Support compatible formats currently emits native twitter json uses social emits spring social tweet types makes difficult replace twitter sources reuse stream definitions requires coordination ss 110 si 40 ga releases note think good idea continue support native twitter json keep option default tweet types and similar to the text Documentation source has conflicting information according documentation one options available source transport listed default sample definition provide yet appears default tcp two match might also useful possible values transport listed assume tcp udp (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
177;End point to retrieve a list of all XD artifacts of all kinds Any kind of sophisticated artifact retrieval mechanism in XD will need to grab more than one kind of artifact at once. For example if I want to see all taps streams triggers and jobs (ie- everything) I need to make 4 http requests. I can imagine dashboards that need to display information on artifacts of multiple kinds. There will also need to be a way to pass a query to return a sub-set of artifacts but that should be designed separately.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text End point to retrieve a list of all xd artifacts of all kinds any kind of sophisticated artifact retrieval mechanism in xd will need to grab more than one kind of artifact at once for example if i want to see all taps streams triggers and jobs (ie- everything) i need to make 4 http requests i can imagine dashboards that need to display information on artifacts of multiple kinds there will also need to be a way to pass a query to return a sub-set of artifacts but that should be designed separately and the most similar text Issue trying use http trying send json object get following error even though opened requests allow load header present requested resource origin therefore allowed access spring profiles transport local ui does not exceed the minimum threshold of 75%.;0.03;2.0;1.0;1.67;0;1;0;0
178;spring-xd services randomly report failure after correct shutdown On multiple occasions we have seen that {{spring-xd-container}} and {{spring-xd-admin}} services can exit reporting {{FAILED}} state however most of the times the Java process is correctly terminated. {code} $ sudo service spring-xd-container stop Stopping xd-container: [FAILED] $ ps uax | grep [x]d-container $ {code} and in the container logs: {code} [info 2015/04/28 09:42:15.167 EDT <Distributed system shutdown hook> tid=0x88] VM is exiting - shutting down distributed system [info 2015/04/28 09:42:15.168 EDT <Distributed system shutdown hook> tid=0x88] GemFireCache[id = 2029162775 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:34 EDT 2015 se [info 2015/04/28 09:42:15.171 EDT <Distributed system shutdown hook> tid=0x53] VM is exiting - shutting down distributed system [info 2015/04/28 09:42:15.171 EDT <Distributed system shutdown hook> tid=0x53] GemFireCache[id = 389249684 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:14 EDT 2015 ser [info 2015/04/28 09:42:15.177 EDT <Distributed system shutdown hook> tid=0x77] VM is exiting - shutting down distributed system [info 2015/04/28 09:42:15.179 EDT <Distributed system shutdown hook> tid=0x77] GemFireCache[id = 1768828050 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:27 EDT 2015 se [info 2015/04/28 09:42:15.181 EDT <Distributed system shutdown hook> tid=0x63] VM is exiting - shutting down distributed system [info 2015/04/28 09:42:15.199 EDT <Distributed system shutdown hook> tid=0x63] GemFireCache[id = 548938309 isClosing = true isShutDownAll = false closingGatewayHubsByShutdownAll = false created = Mon Apr 27 10:59:19 EDT 2015 serv 2015-04-28 09:42:15410 1.1.1.RELEASE DEBUG xdbus.queue:radius-1 transform.RadiusMsgTransformer - Transformed message: GenericMessage [payload=FACILITY=22 SEVERITY=5 TIMESTAMP=Tue Apr 28 09:42:15 EDT 2015 HOST=hopisepsnprd01 Messa [info 2015/04/28 09:42:15.626 EDT <Distributed system shutdown hook> tid=0x53] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen [info 2015/04/28 09:42:15.630 EDT <Distributed system shutdown hook> tid=0x77] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen [info 2015/04/28 09:42:15.621 EDT <Distributed system shutdown hook> tid=0x88] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen [info 2015/04/28 09:42:15.662 EDT <Distributed system shutdown hook> tid=0x63] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen 2015-04-28 09:42:15854 1.1.1.RELEASE WARN Thread-4 support.DisposableBeanAdapter - Invocation of destroy method failed on bean with name 'client-pool': java.lang.IllegalStateException: Pool could not be destroyed because it is still [config 2015/04/28 09:42:15.857 EDT <Thread-4> tid=0x12] Destroying connection pool client-pool [config 2015/04/28 09:42:15.897 EDT <Thread-4> tid=0x12] Destroying connection pool client-pool [config 2015/04/28 09:42:15.898 EDT <Distributed system shutdown hook> tid=0x53] Destroying connection pool client-pool [config 2015/04/28 09:42:15.908 EDT <Distributed system shutdown hook> tid=0x88] Destroying connection pool client-pool {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Spring-xd services randomly report failure after correct shutdown on multiple occasions we have seen that {{spring-xd-container}} and {{spring-xd-admin}} services can exit reporting {{failed}} state however most of the times the java process is correctly terminated {code} $ sudo service spring-xd-container stop stopping xd-container: [failed] $ ps uax | grep [x]d-container $ {code} and in the container logs: {code} [info 2015/04/28 09:42:15167 edt <distributed system shutdown hook> tid=0x88] vm is exiting - shutting down distributed system [info 2015/04/28 09:42:15168 edt <distributed system shutdown hook> tid=0x88] gemfirecache[id = 2029162775 isclosing = true isshutdownall = false closinggatewayhubsbyshutdownall = false created = mon apr 27 10:59:34 edt 2015 se [info 2015/04/28 09:42:15171 edt <distributed system shutdown hook> tid=0x53] vm is exiting - shutting down distributed system [info 2015/04/28 09:42:15171 edt <distributed system shutdown hook> tid=0x53] gemfirecache[id = 389249684 isclosing = true isshutdownall = false closinggatewayhubsbyshutdownall = false created = mon apr 27 10:59:14 edt 2015 ser [info 2015/04/28 09:42:15177 edt <distributed system shutdown hook> tid=0x77] vm is exiting - shutting down distributed system [info 2015/04/28 09:42:15179 edt <distributed system shutdown hook> tid=0x77] gemfirecache[id = 1768828050 isclosing = true isshutdownall = false closinggatewayhubsbyshutdownall = false created = mon apr 27 10:59:27 edt 2015 se [info 2015/04/28 09:42:15181 edt <distributed system shutdown hook> tid=0x63] vm is exiting - shutting down distributed system [info 2015/04/28 09:42:15199 edt <distributed system shutdown hook> tid=0x63] gemfirecache[id = 548938309 isclosing = true isshutdownall = false closinggatewayhubsbyshutdownall = false created = mon apr 27 10:59:19 edt 2015 serv 2015-04-28 09:42:15410 111release debug xdbusqueue:radius-1 transformradiusmsgtransformer - transformed message: genericmessage [payload=facility=22 severity=5 timestamp=tue apr 28 09:42:15 edt 2015 host=hopisepsnprd01 messa [info 2015/04/28 09:42:15626 edt <distributed system shutdown hook> tid=0x53] resetting original memorypoolmxbean heap threshold bytes 0 on pool ps old gen [info 2015/04/28 09:42:15630 edt <distributed system shutdown hook> tid=0x77] resetting original memorypoolmxbean heap threshold bytes 0 on pool ps old gen [info 2015/04/28 09:42:15621 edt <distributed system shutdown hook> tid=0x88] resetting original memorypoolmxbean heap threshold bytes 0 on pool ps old gen [info 2015/04/28 09:42:15662 edt <distributed system shutdown hook> tid=0x63] resetting original memorypoolmxbean heap threshold bytes 0 on pool ps old gen 2015-04-28 09:42:15854 111release warn thread-4 supportdisposablebeanadapter - invocation of destroy method failed on bean with name 'client-pool': javalangillegalstateexception: pool could not be destroyed because it is still [config 2015/04/28 09:42:15857 edt <thread-4> tid=0x12] destroying connection pool client-pool [config 2015/04/28 09:42:15897 edt <thread-4> tid=0x12] destroying connection pool client-pool [config 2015/04/28 09:42:15898 edt <distributed system shutdown hook> tid=0x53] destroying connection pool client-pool [config 2015/04/28 09:42:15908 edt <distributed system shutdown hook> tid=0x88] destroying connection pool client-pool {code} and the most similar text Bind producer consumer quote full exception dispatcher has subscribers channel nested exception dispatcher has subscribers stream filter router pm gary russell looks like another fixed fix timing problem taps using tap started tap stream deployed clear filter module consumer pm gary russell see problem binds consumer producer - wrong order passive component filter cc quote does not exceed the minimum threshold of 75%.;0.03;2.0;1.0;1.67;0;1;0;0
179;Test coverage for RuntimeModuleDeploymentPropertiesProvider There are more calculations done at the RuntimeModuleDeploymentPropertiesProvider implementations and would be good to have some tests to cover them.;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Test coverage for runtimemoduledeploymentpropertiesprovider there are more calculations done at the runtimemoduledeploymentpropertiesprovider implementations and would be good to have some tests to cover them is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Users able execute sql processor job statement and similar to the text Developer id like add load sink module measure received throughput and similar to the text User id like option ack messages guarantee sent successful (and these texts are all user stories with a worth of 3 story points).;0.02;4.48;1.0;7.9;1;0;1;0
180;UI - Setup Sauce Labs Integration We should have a facility to easily test the E2E Protractor tests against a variety of common browsers including IE. Sauce Labs seems to be the service to use.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Ui - setup sauce labs integration we should have a facility to easily test the e2e protractor tests against a variety of common browsers including ie sauce labs seems to be the service to use was most similar to the text Investigate throwing exception condition leads exception does seem like ever occur namely bpp processing job deployment job was already deployed container and similar to the text Add object related need ability provide json information change using back returning objects and similar to the text Fix module properties use dot property name prevents user value stream definition also defaults repeated xml properties level (and these texts are not user stories).;0.03;2.09;1.0;1.67;0;1;1;1
181;Update Source Syslog section to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#syslog;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update source syslog section to use shell commands instead of curl see http://staticspringsourceorg/spring-xd/docs/100m1/reference/html/#syslog was most similar to the text Update processors transform section use shell commands instead curl see and similar to the text Need set small commit level acceptance tests default commit level jobs 1000 vs original 100 tests sporadically fail need set tests small value and similar to the text Add docs job item processor brief introduction topic linking relevant spring batch documentation (and these texts are not user stories).;0.02;7.13;1.0;8.24;1;1;1;1
182;Users need the ability to provision an XD cluster on EC2 via command line tool. we need the ability to run an XD cluster to get a handle on general issues and missing features based on running the system in a 'true' clustered environment. We don’t need to make this an end-user facing feature in the short term e.g. set a few keys in the shell and then install via a shell command.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Users need the ability to provision an xd cluster on ec2 via command line tool we need the ability to run an xd cluster to get a handle on general issues and missing features based on running the system in a 'true' clustered environment we don’t need to make this an end-user facing feature in the short term eg set a few keys in the shell and then install via a shell command was most similar to the text Make requirement md5 hash files custom module registry post 12 upgrade custom modules longer show copying jars directory instead use module upload command install modules md5 file required details and similar to the text Update use test dependent external system success times service running slower test expects test fails unnecessarily once merged utilize feature wait result file stream written wait time twitter extended 1 min make search string tests fail consistently present and similar to the text Write initial stream deployment state currently stream deployed event thread blocks deployment requests answered timed any deployment errors log stack trace instead addition need write results deployment request initial thought go panel panel data state json map fields state optional (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
183;As a developer I'd like to add {{undeployed}} status for YARN SPI so I can represent the correct status instead of the current {{unknown}} state.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to add {{undeployed}} status for yarn spi so i can represent the correct status instead of the current {{unknown}} state is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like custom module built hosted hdfs deploy module newly containers and similar to the text User id like separate file list deployment manifest properties include part stream definition and similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint (and these texts are all user stories with a worth of 8 story points).;0.06;8.62;1.0;8.33;1;1;1;1
184;Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes: 1) Remove assertReceived. Since the number of messages is indeterminate 2) Change file sink that captures the results to append mode. Because each message will overwrite the previous messages result.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update twittersearchtest to handle the latest release of twittersearch the changes to twittersearch means that it will send multiple messages during the duration of the test to support these changes: 1) remove assertreceived since the number of messages is indeterminate 2) change file sink that captures the results to append mode because each message will overwrite the previous messages result was most similar to the text Investigate intermittent failure test often fails running inside reproduce inside eclipse already tried fixing using different key space avail one explanation runs tests concurrently understanding does and similar to the text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available and similar to the text Provide way debug http source http source does provide debug logging see information http headers requests particular non ok response returned effect suspect due need configure logging system (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
185;Add Kafka-based implementation for AbstractSingleNodeStreamDeploymentIntegrationTests;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add kafka-based implementation for abstractsinglenodestreamdeploymentintegrationtests was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;8.48;1.0;8.33;1;1;1;1
186;As a user I need a production-ready' Docker Image so that I can use that as a baseline to deploy XD with the following setup. * Ubuntu OS * Full XD Jar * Java 7.x;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i need a production-ready' docker image so that i can use that as a baseline to deploy xd with the following setup * ubuntu os * full xd jar * java 7x was most similar to the text Document pool properties add properties commented show default values eg 8 0 8 1 and similar to the text Create script node script launch admin along module container part implementation also remove embedded options admin container scripts and similar to the text Add tests looks like bit technical debt additionally single test class yet however looks tricky (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
187;Extend aggregate counter to dynamically aggregate by field values in addition to time. This would be a combination of the existing aggregate counter and field value counter functionality. For example if the stream data was for car purchases some fields might be colour make and model. When analysing the aggregate data I dont just want to know how many were sold on Monday but how many of each make or how many of each colour or how many of a particular colour make AND model. This would allow a dashboard type client to 'drill down' into each dimension or combination of dimensions (in real time without executing batch queries against the raw data) Ideally the aggregate counter would be specified as stream create --name mytap --definition tap:mystream > aggregatecounter --name=mycount --fieldNames=colourmakemodel The keys would be dynamically created according to the field values in each record (ie in a similar way to the field value counter you would not need to predefine field values) and keys would be created for all combinations of the fields specified eg the record { colour:silver make:VW model : Golf } would increment the following key counters (in addtion to the existing time buckets) <existing base counter - ie all fields for this time bucket> colour:black make:VW model:Golf colour:black.make:VW colour:black.model:Golf make:VW.model:Golf colour:black.make:VW.model:Golf ie the actual keys would look something like aggregatecounters.mycount.make:VW.model:Golf.201307 etc This may seem like it would generate a lot of key combinations but in practice the data generated will still be massively less than the raw data and keys will only be created if that combination occurs in a time period. Also some fields may be dependent on each other (such as make and model in the above example) so the amount of possibilites for those composite keys would be a lot less that the number of one times the number of the other.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Extend aggregate counter to dynamically aggregate by field values in addition to time this would be a combination of the existing aggregate counter and field value counter functionality for example if the stream data was for car purchases some fields might be colour make and model when analysing the aggregate data i dont just want to know how many were sold on monday but how many of each make or how many of each colour or how many of a particular colour make and model this would allow a dashboard type client to 'drill down' into each dimension or combination of dimensions (in real time without executing batch queries against the raw data) ideally the aggregate counter would be specified as stream create --name mytap --definition tap:mystream > aggregatecounter --name=mycount --fieldnames=colourmakemodel the keys would be dynamically created according to the field values in each record (ie in a similar way to the field value counter you would not need to predefine field values) and keys would be created for all combinations of the fields specified eg the record { colour:silver make:vw model : golf } would increment the following key counters (in addtion to the existing time buckets) <existing base counter - ie all fields for this time bucket> colour:black make:vw model:golf colour:blackmake:vw colour:blackmodel:golf make:vwmodel:golf colour:blackmake:vwmodel:golf ie the actual keys would look something like aggregatecountersmycountmake:vwmodel:golf201307 etc this may seem like it would generate a lot of key combinations but in practice the data generated will still be massively less than the raw data and keys will only be created if that combination occurs in a time period also some fields may be dependent on each other (such as make and model in the above example) so the amount of possibilites for those composite keys would be a lot less that the number of one times the number of the other and the most similar text Assess sinks close client cache os - mac deployment type - sha - required software - sample server description destroying 3 streams sink 4th fail error connection number clients 4 exceeded limit 3 allowed default evaluation license steps reproduce shell execute following 4 times stream create name stocks definition http deploy stream destroy stocks does not exceed the minimum threshold of 75%.;0.04;8.62;1.0;8.33;1;1;0;0
188;Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopDistro=phd1;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use we need to modify startup script to use hadoop 112 as default or phd1 when specified with --hadoopdistro=phd1 is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User able leverage native sink take advantage full-duplex communications channels single tcp connection and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.01;8.62;0.0;1.67;0;0;1;0
189;Problem using twittersearch when system where container is running has two network interfaces. Problem using twittersearch when the system where the XD container is running has two network interfaces. With the following config: eth0 local network resolves `hostname` eth1 internet network I get an error deploying the stream: {code} 12:08:22965 WARN twitterSource-1-1 client.RestTemplate - GET request for https://stream.twitter.com/1.1/statuses/sample.json resulted in 401 (Authorization Required) invoking error handler 12:08:22972 ERROR twitterSource-1-1 twitter.TwitterStreamChannelAdapter - Twitter authentication failed: 401 Authorization Required {code} If I flip the network interfaces to be: eth0 internet network resolves `hostname` eth1 local network then it seems to work.;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Problem using twittersearch when system where container is running has two network interfaces problem using twittersearch when the system where the xd container is running has two network interfaces with the following config: eth0 local network resolves `hostname` eth1 internet network i get an error deploying the stream: {code} 12:08:22965 warn twittersource-1-1 clientresttemplate - get request for https://streamtwittercom/11/statuses/samplejson resulted in 401 (authorization required) invoking error handler 12:08:22972 error twittersource-1-1 twittertwitterstreamchanneladapter - twitter authentication failed: 401 authorization required {code} if i flip the network interfaces to be: eth0 internet network resolves `hostname` eth1 local network then it seems to work is a user story, and is worth 2 story points. This was predicted because it is most similar to the text User able shutdown container admin ui following stream definition deployed code stream create definition jdbc employer employee hdfs deploy code details and similar to the text Scd developer id like add support dependency resolution two modules use different version jars ex direct binding two modules include different versions spring data capability resolve include right bits and similar to the text Developer id like move project reactor based core use sink write (and these texts are all user stories with a worth of 2 story points).;0.09;2.0;1.0;1.67;0;0;1;0
190;Rename xd-config.yml to servers.yml and add modules/modules.yml to spring-xd-yarn Make changes to XD on YARN config that correspond to XD-1499 changes;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Rename xd-configyml to serversyml and add modules/modulesyml to spring-xd-yarn make changes to xd on yarn config that correspond to xd-1499 changes is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like design document approach deploying stream single container modules within stream and similar to the text Developer id like create separate yarn spi bundle spi variants one admin project and similar to the text Developer id like use provision manage monitor spring cluster using tool use clusters (and these texts are all user stories with a worth of 5 story points).;0.05;8.62;1.0;8.33;1;0;1;0
191;Change module option type from Class to String This better aligns with boot. Moreover using Class was a bad design choice (one can always get a Class from a String [modulo knowing which CL to use] while to converse is not always easy [CL not being available]);0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Change module option type from class to string this better aligns with boot moreover using class was a bad design choice (one can always get a class from a string [modulo knowing which cl to use] while to converse is not always easy [cl not being available]) was most similar to the text Ui shell remove any usage rest endpoints using json notation accessing rest endpoint using json file extension causes maintenance issues authorization rules necessary remove any usage admin ui shell time json endpoint deprecated removed ultimately and similar to the text Rename node references container applies places addressing issue search done uncover any eg public static final string node options classes transport use data messages node node transport use control messages admin nodes and similar to the text Dead letter queues stream hi use module also creates queues policy first queue has thanks (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
192;As a developer I'd like to bench Rabbit on rackspace infrastructure so I can have a sense on how it scales as we add more _xd-container_ nodes.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to bench rabbit on rackspace infrastructure so i can have a sense on how it scales as we add more _xd-container_ nodes is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;4.48;1.0;7.9;1;1;1;1
193;Switch CAPITAL_LETTERS to system.property style in application config;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Switch capital_letters to systemproperty style in application config was most similar to the text Ui - container list - module properties - escape passwords and similar to the text User wants able know triggers job and similar to the text Failing intermittent reported (and these texts are not user stories).;0.02;6.15;0.0;1.67;0;1;1;1
194;KafkaSourceSinkTests to use embedded Kafka server Test is failing since Kafka isn't installed on the CI server. Using an embedded server will make the testing more robust vs. needing an external server.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Kafkasourcesinktests to use embedded kafka server test is failing since kafka isn't installed on the ci server using an embedded server will make the testing more robust vs needing an external server was most similar to the text User needs ability pause resume triggers pause means trigger wait fire job pause removed does apply misfire behavior and similar to the text Incompatible use causes throw operation exception replacing code allows used and similar to the text Handle stop method cleanly server needs stop cleanly stopping admin server container server also tests require main server needs handle server shutdown appropriately (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
195;As a user I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to implement the core interface contract so that i can create a processor module that uses rxjava api is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.03;2.9;1.0;1.67;0;1;1;1
196;As a user I'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics. *Notes:* * Spring-AMQP {{RabbitAdmin}} now has a {{getQueueProperties()}} method which returns the number of consumers so it may be possible to use it for this purpose. * Consider the possibility of _producers_ and/or _queues_ still containing data * Consider the scenario even after the topics/queues are cleaned-up what to do with fanout exchange? *Some Further Thoughts* * Consider using the upcoming Spring AMQP REST API {{RabbitManagementTemplate}} if the timing is not right we could temporarily invoke the rabbit REST API directly. * Should be optional perhaps via {{stream destroy foo --clean}} * Should this be done by the admin? Or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange since we undeploy left->right everything can be cleaned up on the consumer side. * Third option would be new methods on the bus {{cleanConsumer}} etc invoked by the {{StreamPlugin}} * Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so we'd need the admin url(s) for the cluster.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text As a user i'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics *notes:* * spring-amqp {{rabbitadmin}} now has a {{getqueueproperties()}} method which returns the number of consumers so it may be possible to use it for this purpose * consider the possibility of _producers_ and/or _queues_ still containing data * consider the scenario even after the topics/queues are cleaned-up what to do with fanout exchange? *some further thoughts* * consider using the upcoming spring amqp rest api {{rabbitmanagementtemplate}} if the timing is not right we could temporarily invoke the rabbit rest api directly * should be optional perhaps via {{stream destroy foo --clean}} * should this be done by the admin? or via a new plugin handling module undeployments - in the rabbit case undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange since we undeploy left->right everything can be cleaned up on the consumer side * third option would be new methods on the bus {{cleanconsumer}} etc invoked by the {{streamplugin}} * down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so we'd need the admin url(s) for the cluster and the most similar text Problem tapping source channels follow bug fixed ability use tap pipe tap used source channel also work deploy fashion source channels directly connected subsequent module creation pass-through tap instance necessary test shows syntax work current information fails code public void throws http transform filter foo fails bean already registered does match required type tap transform fails empty null tap foo transform code suspect part problem initially lies code around builds module deployment requests ast parsed input dsl string source channel was originally specified tap ast knowledge appear getting used does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
197;Document Monitoring & Management Features This section should discuss what is exposed via JMX how you can view it in JConsole and how you can view it over http via Jolikia. in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream that indicate the number of messages processed per section.;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Document monitoring & management features this section should discuss what is exposed via jmx how you can view it in jconsole and how you can view it over http via jolikia in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream that indicate the number of messages processed per section is a user story, and is worth 1 story points. This was predicted because it is most similar to the text Build manager id like schedule ci builds windows verify scope isolate remaining test failures experiment new ami images solid infrastructure fix failing tests and similar to the text User id like see date logs troubleshoot issues occurred specific day time property needs adjusted and similar to the text User id like refer wiki create job partitions turn expects columns explicitly included job definition also beneficial call-out sql metadata options mutually exclusive following logic needs documented use columns using partition column boolean return return true code (and these texts are all user stories with a worth of 1 story points).;0.04;8.62;1.0;8.33;1;0;1;0
198;Misleading error message when trying to restart a job exec Disregard the missing date that is caused by another problem. Here is the setup: {noformat} xd:>job execution list Id Job Name Start Time Step Execution Count Status -- -------- -------------------------------- -------------------- --------- 13 foo Europe/Paris 0 STARTING 12 foo 2014-02-12 15:39:46 Europe/Paris 1 FAILED 11 foo 2014-02-12 15:39:29 Europe/Paris 1 COMPLETED 10 foo 2014-02-12 15:38:36 Europe/Paris 1 COMPLETED 9 foo 2014-02-12 15:38:21 Europe/Paris 1 COMPLETED 8 foo Europe/Paris 0 STARTING 7 foo 2014-02-12 15:25:41 Europe/Paris 1 COMPLETED 6 foo 2014-02-12 15:25:04 Europe/Paris 1 FAILED 5 foo 2014-02-12 15:14:32 Europe/Paris 1 FAILED 4 foo 2014-02-12 15:14:13 Europe/Paris 1 FAILED 3 foo 2014-02-12 15:13:54 Europe/Paris 1 FAILED 2 foo 2014-02-12 15:13:18 Europe/Paris 1 FAILED 1 foo 2014-02-12 15:12:58 Europe/Paris 1 FAILED 0 foo 2014-02-12 15:11:44 Europe/Paris 1 FAILED xd:>job execution restart --id 12 Command failed org.springframework.xd.rest.client.impl.SpringXDException: Job Execution 12 is already running. {noformat} while the server exception is a bit better: {noformat} Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobInstance: id=11 version=0 Job=[foo] org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:120) {noformat} I'd argue we should not speak in terms of execution ids if possible but rather in terms of job names;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Misleading error message when trying to restart a job exec disregard the missing date that is caused by another problem here is the setup: {noformat} xd:>job execution list id job name start time step execution count status -- -------- -------------------------------- -------------------- --------- 13 foo europe/paris 0 starting 12 foo 2014-02-12 15:39:46 europe/paris 1 failed 11 foo 2014-02-12 15:39:29 europe/paris 1 completed 10 foo 2014-02-12 15:38:36 europe/paris 1 completed 9 foo 2014-02-12 15:38:21 europe/paris 1 completed 8 foo europe/paris 0 starting 7 foo 2014-02-12 15:25:41 europe/paris 1 completed 6 foo 2014-02-12 15:25:04 europe/paris 1 failed 5 foo 2014-02-12 15:14:32 europe/paris 1 failed 4 foo 2014-02-12 15:14:13 europe/paris 1 failed 3 foo 2014-02-12 15:13:54 europe/paris 1 failed 2 foo 2014-02-12 15:13:18 europe/paris 1 failed 1 foo 2014-02-12 15:12:58 europe/paris 1 failed 0 foo 2014-02-12 15:11:44 europe/paris 1 failed xd:>job execution restart --id 12 command failed orgspringframeworkxdrestclientimplspringxdexception: job execution 12 is already running {noformat} while the server exception is a bit better: {noformat} caused by: orgspringframeworkbatchcorerepositoryjobexecutionalreadyrunningexception: a job execution for this job is already running: jobinstance: id=11 version=0 job=[foo] orgspringframeworkbatchcorerepositorysupportsimplejobrepositorycreatejobexecution(simplejobrepositoryjava:120) {noformat} i'd argue we should not speak in terms of execution ids if possible but rather in terms of job names and the most similar text Bind producer consumer quote full exception dispatcher has subscribers channel nested exception dispatcher has subscribers stream filter router pm gary russell looks like another fixed fix timing problem taps using tap started tap stream deployed clear filter module consumer pm gary russell see problem binds consumer producer - wrong order passive component filter cc quote does not exceed the minimum threshold of 75%.;0.07;8.16;1.0;8.33;1;1;0;0
199;Container nodes should write attributes to ZooKeeper The /xd/containers node is the parent where each Container will write an ephemeral child node. The node name should be the Container's ID and the node data should be the Container's attributes (host pid and much more to be added later). When a Container shuts down cleanly it should eagerly delete the ephemeral node so that watchers are notified immediately. For any other case (including a network partition) the ephemeral node will disappear after the timeout elapses.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Container nodes should write attributes to zookeeper the /xd/containers node is the parent where each container will write an ephemeral child node the node name should be the container's id and the node data should be the container's attributes (host pid and much more to be added later) when a container shuts down cleanly it should eagerly delete the ephemeral node so that watchers are notified immediately for any other case (including a network partition) the ephemeral node will disappear after the timeout elapses and the most similar text Logging listener container narrow error see however was set error last year reduce log noise prefer elevate least warn address noise issue spring does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
200;Final review of REST API structure document for streams taps and jobs Get closure on open discussion points for REST API wrt to streams taps and jobs.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Final review of rest api structure document for streams taps and jobs get closure on open discussion points for rest api wrt to streams taps and jobs is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Developer id like migrate module deployment repository abstraction used definitions create spi (and these texts are all user stories with a worth of 8 story points).;0.04;8.62;1.0;8.33;1;0;1;0
201;Using custom classes for module properties leads to ClassNotFoundException Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory. Following exception is thrown: {code}6:26:03064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137) org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193) org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154) org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44) org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127) org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173) org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95) org.springframework.xd.dirt.rest.XDController.save(XDController.java:223) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689) org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83) org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938) org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870) org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961) org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863) javax.servlet.http.HttpServlet.service(HttpServlet.java:646) org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837) javax.servlet.http.HttpServlet.service(HttpServlet.java:727) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186) org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220) org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122) org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501) org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171) org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408) org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070) org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611) org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736) org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) java.lang.Thread.run(Thread.java:745){code} Please see attached patch file this seems to be enough to resolve the problem.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Using custom classes for module properties leads to classnotfoundexception attached is module properties file both custom java classes referenced in the properties are available in the jar file under _spring_xd_home/xd/module/<the-module>/lib_ directory following exception is thrown: {code}6:26:03064 102release error http-nio-9393-exec-4 restrestcontrolleradvice - caught exception while handling a request javalangillegalstateexception: can't find class used for type of option 'binding': comemcitdsrtdspringxdbindingbindingstrategy orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolvermakesimplemoduleoptions(defaultmoduleoptionsmetadataresolverjava:137) orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolverresolvenormalmetadata(defaultmoduleoptionsmetadataresolverjava:193) orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolverresolve(defaultmoduleoptionsmetadataresolverjava:154) orgspringframeworkxdmoduleoptionsdelegatingmoduleoptionsmetadataresolverresolve(delegatingmoduleoptionsmetadataresolverjava:44) orgspringframeworkxdmoduleoptionsenvironmentawaremoduleoptionsmetadataresolverresolve(environmentawaremoduleoptionsmetadataresolverjava:127) orgspringframeworkxddirtstreamxdstreamparserparse(xdstreamparserjava:173) orgspringframeworkxddirtstreamabstractdeployersave(abstractdeployerjava:95) orgspringframeworkxddirtrestxdcontrollersave(xdcontrollerjava:223) sunreflectnativemethodaccessorimplinvoke0(native method) sunreflectnativemethodaccessorimplinvoke(nativemethodaccessorimpljava:57) sunreflectdelegatingmethodaccessorimplinvoke(delegatingmethodaccessorimpljava:43) javalangreflectmethodinvoke(methodjava:606) orgspringframeworkwebmethodsupportinvocablehandlermethodinvoke(invocablehandlermethodjava:215) orgspringframeworkwebmethodsupportinvocablehandlermethodinvokeforrequest(invocablehandlermethodjava:132) orgspringframeworkwebservletmvcmethodannotationservletinvocablehandlermethodinvokeandhandle(servletinvocablehandlermethodjava:104) orgspringframeworkwebservletmvcmethodannotationrequestmappinghandleradapterinvokehandlemethod(requestmappinghandleradapterjava:749) orgspringframeworkwebservletmvcmethodannotationrequestmappinghandleradapterhandleinternal(requestmappinghandleradapterjava:689) orgspringframeworkwebservletmvcmethodabstracthandlermethodadapterhandle(abstracthandlermethodadapterjava:83) orgspringframeworkwebservletdispatcherservletdodispatch(dispatcherservletjava:938) orgspringframeworkwebservletdispatcherservletdoservice(dispatcherservletjava:870) orgspringframeworkwebservletframeworkservletprocessrequest(frameworkservletjava:961) orgspringframeworkwebservletframeworkservletdopost(frameworkservletjava:863) javaxservlethttphttpservletservice(httpservletjava:646) orgspringframeworkwebservletframeworkservletservice(frameworkservletjava:837) javaxservlethttphttpservletservice(httpservletjava:727) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:303) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworkbootactuatetracewebrequesttracefilterdofilterinternal(webrequesttracefilterjava:110) orgspringframeworkwebfilteronceperrequestfilterdofilter(onceperrequestfilterjava:107) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworkbootactuateautoconfigureendpointwebmvcautoconfiguration$applicationcontextheaderfilterdofilterinternal(endpointwebmvcautoconfigurationjava:280) orgspringframeworkwebfilteronceperrequestfilterdofilter(onceperrequestfilterjava:107) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworksecuritywebfilterchainproxydofilterinternal(filterchainproxyjava:186) orgspringframeworksecuritywebfilterchainproxydofilter(filterchainproxyjava:160) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworkwebfilterhiddenhttpmethodfilterdofilterinternal(hiddenhttpmethodfilterjava:77) orgspringframeworkwebfilteronceperrequestfilterdofilter(onceperrequestfilterjava:107) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworkwebfilterhttpputformcontentfilterdofilterinternal(httpputformcontentfilterjava:88) orgspringframeworkwebfilteronceperrequestfilterdofilter(onceperrequestfilterjava:107) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgspringframeworkbootactuateautoconfiguremetricfilterautoconfiguration$metricsfilterdofilterinternal(metricfilterautoconfigurationjava:89) orgspringframeworkwebfilteronceperrequestfilterdofilter(onceperrequestfilterjava:107) orgapachecatalinacoreapplicationfilterchaininternaldofilter(applicationfilterchainjava:241) orgapachecatalinacoreapplicationfilterchaindofilter(applicationfilterchainjava:208) orgapachecatalinacorestandardwrappervalveinvoke(standardwrappervalvejava:220) orgapachecatalinacorestandardcontextvalveinvoke(standardcontextvalvejava:122) orgapachecatalinaauthenticatorauthenticatorbaseinvoke(authenticatorbasejava:501) orgapachecatalinacorestandardhostvalveinvoke(standardhostvalvejava:171) orgapachecatalinavalveserrorreportvalveinvoke(errorreportvalvejava:103) orgapachecatalinacorestandardenginevalveinvoke(standardenginevalvejava:116) orgapachecatalinaconnectorcoyoteadapterservice(coyoteadapterjava:408) orgapachecoyotehttp11abstracthttp11processorprocess(abstracthttp11processorjava:1070) orgapachecoyoteabstractprotocol$abstractconnectionhandlerprocess(abstractprotocoljava:611) orgapachetomcatutilnetnioendpoint$socketprocessordorun(nioendpointjava:1736) orgapachetomcatutilnetnioendpoint$socketprocessorrun(nioendpointjava:1695) javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) orgapachetomcatutilthreadstaskthread$wrappingrunnablerun(taskthreadjava:61) javalangthreadrun(threadjava:745){code} please see attached patch file this seems to be enough to resolve the problem and the most similar text Cant build run app building running app fails trying create first stream configuration ends instead java version se environment build java server vm build mixed mode error code error exception handling request null method warn handler execution resulted exception null code does not exceed the minimum threshold of 75%.;0.01;8.62;1.0;8.33;1;1;0;0
202;Tap Fixture refactoring The Tap fixture does not need to inherit from AbstractModuleFixture Replace moduleName method with moduleToTap. The current tap syntax is: tap:stream:<streamname>.<modulelabel> and not tap:stream:<streamname>.<modulelabel>.<modulename> as currently implemented by the label fixture.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Tap fixture refactoring the tap fixture does not need to inherit from abstractmodulefixture replace modulename method with moduletotap the current tap syntax is: tap:stream:<streamname><modulelabel> and not tap:stream:<streamname><modulelabel><modulename> as currently implemented by the label fixture is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like update installed spring cluster multiple instances servers setup ha and similar to the text User need sandbox docker image get started experiment deployment following setup os full jar java and similar to the text Developer id like decouple execution context job launch avoid cl serialization errors fix needs formally applied spring batch upgrade batch release order inherit functionality hence current workaround needs (and these texts are all user stories with a worth of 5 story points).;0.02;2.0;1.0;1.67;0;0;1;0
203;Create ReactorMessageHandler for Reactor based XD processor/sink modules The module should be flexible to act as a sink as well as a processor. ErrorHandling will be considered as part of another JIRA;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create reactormessagehandler for reactor based xd processor/sink modules the module should be flexible to act as a sink as well as a processor errorhandling will be considered as part of another jira is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Developer id like able clean rabbit binder broker artifacts using rest api rabbit was ported cleaner was ported rest api invoke was ported and similar to the text User id like migrate 10 11 able port custom modules operationalize existing data pipelines also take advantage latest features and similar to the text Scd developer id like make deployer work use shell return quickly also queue deploy operations within yarn tasks (and these texts are all user stories with a worth of 2 story points).;0.03;2.06;1.0;1.67;0;0;1;0
204;As a developer I'd like to refactor stream/job definition repository so I can decouple from module deployment concerns.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to refactor stream/job definition repository so i can decouple from module deployment concerns is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;3.87;1.0;1.67;0;1;1;1
205;Create shell command for getting information on the progress of a given step execution;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create shell command for getting information on the progress of a given step execution is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.03;8.55;1.0;8.33;1;0;1;0
206;Detect Invalid Deployment Properties in the Bus Detect properties the bus doesn't support.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Detect invalid deployment properties in the bus detect properties the bus doesn't support is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc and similar to the text User id like option disable db requirement setup use dirt stream processing requirement (and these texts are all user stories with a worth of 8 story points).;0.05;8.62;1.0;8.33;1;0;1;0
207;As a user I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed so that I can colocate with other data sources.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i want to be able to control the partition allocation for the kafka source modules when a stream is deployed so that i can colocate with other data sources is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.04;8.4;1.0;8.33;1;1;1;1
208;Update Spring Framework to 4.2.4;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update spring framework to 424 was most similar to the text Update spring platform 101 and similar to the text Test and similar to the text Retrieve information counter (and these texts are not user stories).;0.03;2.24;0.0;1.67;0;1;1;1
209;Do not eagerly use repositories in completion's *Strategy;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Do not eagerly use repositories in completion's *strategy was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
210;Add authentication support to the mongo sink;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add authentication support to the mongo sink was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
211;Provide support for XD Runtime on Vagrant;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Provide support for xd runtime on vagrant was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
212;Make Enum Conversions for ModuleOptions more lenient If you have a an option *--mode=textLine* presently the enum MUST be named *textLine*. I think it would improve the user-experience if we allowed users to pass in values such as: * --mode=textLine * --mode=text_line * --mode=TEXT_LINE;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Make enum conversions for moduleoptions more lenient if you have a an option *--mode=textline* presently the enum must be named *textline* i think it would improve the user-experience if we allowed users to pass in values such as: * --mode=textline * --mode=text_line * --mode=text_line is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Scs developer id like investigate right approach port phd provider support hdfs module decide better handling hdfs dependencies needs loaded available root cp and similar to the text Spring user want ability customize encoders decoders used kafka source sink customize data formats choose appropriate strategy and similar to the text User need use module support merge command currently method forces requirement connect password options valid merge option check module type force options assigned arg list preferred (and these texts are all user stories with a worth of 5 story points).;0.01;6.15;1.0;8.33;1;0;1;0
213;As a developer I'd like to move 'serialization codec' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i'd like to move 'serialization codec' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency was most similar to the text Move ephemeral nodes clear separation definition vs information move ephemeral nodes written containers jobs and similar to the text Home wiki page improvements add structure easily find reference guide style nice and similar to the text Response code http source use case need http source module return instead 200 currently returned may codes useful able return simple additional option module allow configured (and these texts are not user stories).;0.08;7.7;1.0;8.33;1;1;1;1
214;XD AdminMain & ContainerMain should check xd.home property from scripts Currently the system property xd.home is set as JVM_OPTS (via SPRING_XD_ADMIN_OPTS) into xd-admin & xd-container scripts. Inside the ContainerMain & AdminMain we need to check if this system property is set and use it. It seems like this check is missing now.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Xd adminmain & containermain should check xdhome property from scripts currently the system property xdhome is set as jvm_opts (via spring_xd_admin_opts) into xd-admin & xd-container scripts inside the containermain & adminmain we need to check if this system property is set and use it it seems like this check is missing now is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like central place manage external properties applications across environments provide server support externalized configuration servers and similar to the text Follow experiment removal list modules needed branch and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.02;6.52;1.0;8.33;1;0;1;0
215;Investigate how to provide a means to share bean defintions across module instances In some cases it maybe useful to share a specific bean instance contributed by a user across multiple module instances. This story is a placeholder to collect requirements and discuss.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Investigate how to provide a means to share bean defintions across module instances in some cases it maybe useful to share a specific bean instance contributed by a user across multiple module instances this story is a placeholder to collect requirements and discuss was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Build script creates executable server artifact application good starting point main server host si based modules ingestion example and similar to the text Decouple make dl public class handle deployment related events remove dl eventually use (and these texts are not user stories).;0.13;3.01;1.0;1.67;0;1;1;1
216;As a developer I'd like to bench test cases around {{TupleBuilder}} so I can identify the bottlenecks and tune for performance optimizations.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to bench test cases around {{tuplebuilder}} so i can identify the bottlenecks and tune for performance optimizations is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;6.15;1.0;8.33;1;1;1;1
217;Update jdbchdfs properties and defaults to better match hdfs sink We should use fileName fileExtension properties and default to /xd/jobname as directory;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update jdbchdfs properties and defaults to better match hdfs sink we should use filename fileextension properties and default to /xd/jobname as directory is a user story, and is worth 3 story points. This was predicted because it is most similar to the text User id like build stream definitions using syntax resolving properties tuple json and similar to the text Pm id like rpm scripts single public users go single location use respective build scripts and similar to the text Cf user id like ability override yarn location change custom module stored (and these texts are all user stories with a worth of 3 story points).;0.02;8.62;1.0;8.33;1;0;1;0
218;As a pre-requisite for XD-2835 and a continuation of XD-2671 split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a pre-requisite for xd-2835 and a continuation of xd-2671 split apart the concepts of repository and deployment this will affect the {{resourcedeployer}} interface and the classes that implement it was most similar to the text Parameterize source add support tcp source currently hard-coded use udp port need parameterize port provide option use tcp and similar to the text User able specify deploy properties jobs clicking deploy job definitions page user able specify deployment manifest module count module etc and similar to the text Change metrics assertions integration tests use smart similar has done eg metrics related sinks use smart timings (and these texts are not user stories).;0.04;8.06;1.0;8.33;1;1;1;1
219;As a developer I'd like to have a maintenance branch so that I can commit MINOR release _(ex: 1.0.2)_ code changes instead of committing to MASTER.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to have a maintenance branch so that i can commit minor release _(ex: 102)_ code changes instead of committing to master is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint and similar to the text Scd developer id like cc spi deployer cf improve overall design performance and similar to the text User able leverage native sink aggregate search analyze data insights (and these texts are all user stories with a worth of 8 story points).;0.02;4.48;1.0;7.9;1;1;1;1
220;Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests. Thus they are no longer needed. The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error. This test (httpbash) was never called from the scripts CI build.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Remove test scripts from xd the acceptance tests cover the entire suite of script tests thus they are no longer needed the only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error this test (httpbash) was never called from the scripts ci build was most similar to the text Update documentation related transport eg need update section maybe remove mentions control replace any mentions transport cmd line arg property and similar to the text Build scripts refer sub projects unique place based change build scripts refer two different places check list sub projects simplify make available one place maintenance and similar to the text Generic source twitters streaming apis capabilities plain particular support option use track well request parameters delimited language etc (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
221;As a user I'd like to retain the data partitioning state so that when I restart the containers I continue to write based on the original partitioning strategy. Currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different _hashCode()_. *Design consideration:* Mine through the container info to derive the partition index instead of relying on _hashCode()_.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to retain the data partitioning state so that when i restart the containers i continue to write based on the original partitioning strategy currently the state is not preserved hence on restarts the definition of partitioning strategy is lost due to different _hashcode()_ *design consideration:* mine through the container info to derive the partition index instead of relying on _hashcode()_ was most similar to the text Add dependencies required use streams thanks gary found little gem documentation able use expression hiccup also add otherwise missing class and similar to the text Change calls tests incremental pauses lot calls delays chosen 12 seconds range change loop smaller pauses timeout reached give applies verification code eg verifying counter has expected value well file setup http ready accept requests etc and similar to the text Routing json arrays create following stream able route json messages send message array working possible stream create name definition rabbit router deploy (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
222;Implement XD_MODULE_CONFIG_LOCATION & NAME The description in the google doc https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharing describes the usage of XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Implement xd_module_config_location & name the description in the google doc https://docsgooglecom/a/gopivotalcom/document/d/12cboa7nyvvkvxdishlj-68m5f78ayxn14ejlrcljyvg/edit?usp=sharing describes the usage of xd_module_config_location and xd_module_config_name is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another (and these texts are all user stories with a worth of 8 story points).;0.02;8.55;1.0;8.33;1;0;1;0
223;Shell integration tests should be able to be run across all transports Automate running integration tests on all supported transports;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Shell integration tests should be able to be run across all transports automate running integration tests on all supported transports is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like migrate wiki project tagged code versioned etc and similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
224;Create a standard way to configure Spring Cloud Data and Stream projects;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create a standard way to configure spring cloud data and stream projects is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.02;8.62;1.0;8.33;1;0;1;0
225;Batch hashtag count throws exception when launched 1) Update Instructions to mention --hadoopDistro for both singlenode and shell. Else demo will not work. 2) Pom needs to be updated to use 1.2.1 at the least. 3) I can see where hdfs is writing the results 4) throws NPE Stacktrace is attached.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Batch hashtag count throws exception when launched 1) update instructions to mention --hadoopdistro for both singlenode and shell else demo will not work 2) pom needs to be updated to use 121 at the least 3) i can see where hdfs is writing the results 4) throws npe stacktrace is attached was most similar to the text Use correct constant based version used keep getting following warning warn spring shell - deprecated instead use switch use value constant based version used and similar to the text Move ftp support x package batch package commit support ftp added bunch x classes belong dirt proper though added extension style project jobs module depend and similar to the text Create receptor related narrative developer need able create batch job uses tasks partition slaves back story new partition handler uses receptor api launch tasks slaves grid size (and these texts are not user stories).;0.01;8.62;1.0;8.33;1;1;1;1
226;Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}. Disallow partitioning properties.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Support bus producer properties for dynamic producers pass module properties from stream plugin to {{messagebusawarechannelresolver}} disallow partitioning properties is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like design document approach deploying stream single container modules within stream and similar to the text Developer id like create separate yarn spi bundle spi variants one admin project and similar to the text Developer id like use provision manage monitor spring cluster using tool use clusters (and these texts are all user stories with a worth of 5 story points).;0.03;8.55;1.0;8.33;1;0;1;0
227;Module (re) deployment failed after ZK Cluster Ensemble lost quorum When simulating a slow network by deploying a Zookeeper with 3 nodes. * Zookeeper 1 (follower)was located at US-East-1 * Zookeeper 2 (follower) was in Sydney * Zookeeper 3 (Leader) was in Sydney XD Admin and containers were running in US-East-1 Zone In this case we simulated a loss of quorum by killing the zookeeper 2 (follower in Sydney). All modules were undeployed. When I restarted the zookeeper 2 all containers and admin recognized the ensemble was up and tried to redeploy the modules but the stream was left in a Failed state. Steps to reproduce: * Deploy Stream http|file * Start Data Flow to stream from JMeter * Terminate ZK Follower in AU * Restart ZK Follower in AU The workaround is to undeploy and deploy the stream.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Module (re) deployment failed after zk cluster ensemble lost quorum when simulating a slow network by deploying a zookeeper with 3 nodes * zookeeper 1 (follower)was located at us-east-1 * zookeeper 2 (follower) was in sydney * zookeeper 3 (leader) was in sydney xd admin and containers were running in us-east-1 zone in this case we simulated a loss of quorum by killing the zookeeper 2 (follower in sydney) all modules were undeployed when i restarted the zookeeper 2 all containers and admin recognized the ensemble was up and tried to redeploy the modules but the stream was left in a failed state steps to reproduce: * deploy stream http|file * start data flow to stream from jmeter * terminate zk follower in au * restart zk follower in au the workaround is to undeploy and deploy the stream and the most similar text Automate copyright header management java files currently missing headers help initial trial revealed - does seem honored may need use year construction like force files current year know legal implications - default source sets encompass files basically means xml well properties files example seem logical add header well think does not exceed the minimum threshold of 75%.;0.01;2.02;1.0;1.67;0;1;0;0
228;Measure baseline performance of RabbitMQ using PerfTest (In-house);0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Measure baseline performance of rabbitmq using perftest (in-house) was most similar to the text Ui - container list - module properties - escape passwords and similar to the text User wants able know triggers job and similar to the text Failing intermittent reported (and these texts are not user stories).;0.03;8.48;1.0;8.33;1;1;1;1
229;add SpEL 'transform' processor It should provide an 'expression' param for SpEL and have a default pass-thru of the payload.;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add spel 'transform' processor it should provide an 'expression' param for spel and have a default pass-thru of the payload is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Developer id like update module docs also include available users learn module and similar to the text Scs user id like store module metadata eureka use repository determine current state and similar to the text Developer id like move branch infrastructure reliably run ci test suites (and these texts are all user stories with a worth of 2 story points).;0.04;3.01;1.0;1.67;0;0;1;0
230;As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Note: 1.1.1 > Benched against 0.8.1 1.2 > Benched against 0.8.2;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i'd like to rerun _baseline_ _tuple_ and _serialized_ payloads so i can compare the differences in performance between 081 and 082 kafka releases note: 111 > benched against 081 12 > benched against 082 was most similar to the text Documentation sources sinks modules define attributes required optional eventually admin server write hand documentation and similar to the text Need check deployment requests check actual deployment requests built correctly module test currently use check and similar to the text Create spring cloud stream task module create job used sample users create spring boot based jobs (and these texts are not user stories).;0.02;2.03;1.0;1.67;0;1;1;1
231;Connection props in rabbit.properties ignored by xd-admin and xd-container I modified rabbit.hostname in rabbit.properties and xd-container still attempted to find Rabbit at localhost with --transport rabbit. Looks like the PPC for xd-container and xd-admin is not pointing to rabbit.properties;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Connection props in rabbitproperties ignored by xd-admin and xd-container i modified rabbithostname in rabbitproperties and xd-container still attempted to find rabbit at localhost with --transport rabbit looks like the ppc for xd-container and xd-admin is not pointing to rabbitproperties is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Developer id like move serialization codec spring si update spring inherit maven dependency and similar to the text Scd developer id like module shell command existing module and similar to the text Scd developer id like enforce external libraries overriding any existing library (and these texts are all user stories with a worth of 2 story points).;0.1;8.55;1.0;8.33;1;0;1;0
232;gemfire source does not offer --host nor --port options;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Gemfire source does not offer --host nor --port options is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.55;1.0;8.33;1;0;1;0
233;Create a Sink and Source for Riak;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create a sink and source for riak was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;3.24;1.0;1.67;0;1;1;1
234;As a s-c-s user I'd like to have {{Gemfire}} message-channel binder so I can use {{Gemfire}} as the messaging middleware for low latency use-cases.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a s-c-s user i'd like to have {{gemfire}} message-channel binder so i can use {{gemfire}} as the messaging middleware for low latency use-cases was most similar to the text Empty parameter sent job launched ui job gets empty pair launching job and similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job and similar to the text Fail sonar ci build any package tangles violated similar show reports (and these texts are not user stories).;0.02;6.15;1.0;1.67;0;1;1;1
235;Fix 'cluster/containers' REST endpoint with security enabled Once the container's management server is secured the admin server needs to know which REST template to use to get the message rates from the deployed modules inside the containers.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Fix 'cluster/containers' rest endpoint with security enabled once the container's management server is secured the admin server needs to know which rest template to use to get the message rates from the deployed modules inside the containers was most similar to the text Fix rest endpoint security once containers management server admin server needs know rest template use get message rates deployed modules inside containers and similar to the text Fix rest endpoint security once containers management server admin server needs know rest template use get message rates deployed modules inside containers and similar to the text Additional rest endpoint working security see following error admin ui get forbidden (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
236;Ensure that branch-specific documentation is pulled and generated;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Ensure that branch-specific documentation is pulled and generated is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
237;Update dependencies in Spring XD Sample Repository;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update dependencies in spring xd sample repository is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.4;0.0;1.67;0;0;1;0
238;Create documentation for how module properties are resolved. The ordering of the lookup should be described in particular detail on how environment variables can overrride properties. Some details will necessarily change based on outcome of current discussion but the overall ordering is going to remain.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create documentation for how module properties are resolved the ordering of the lookup should be described in particular detail on how environment variables can overrride properties some details will necessarily change based on outcome of current discussion but the overall ordering is going to remain was most similar to the text Build script package scripts packaging separate scripts start application generate unwanted scripts removed bin directory distribution zip and similar to the text Create batch job uses shell copy multiple files hdfs local directory inverse require custom inputoutput and similar to the text Leakage modules call was added inherit active profiles sadly added property sources side effect note jdbc module defaults rely bug (and these texts are not user stories).;0.01;2.02;1.0;1.67;0;1;1;1
239;XD admin ZK distributed queue consumer initialization issue The ZK distributed queue consumer is initialized even before the module stream job deployment requests path cache are started. This could lead to issue when the consumer start processing the requests before the cache are initialized. On such scenario the following exception could be thrown: 2015-03-23 21:00:25919 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000002 org.springframework.xd.dirt.server.admin.deployment.DeploymentException: dataSender at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164) at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83) at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109) at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117) at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115) at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:70) at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43) at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678) at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712) at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65) at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null. at org.springframework.util.Assert.notNull(Assert.java:112) at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81) at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161);0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Xd admin zk distributed queue consumer initialization issue the zk distributed queue consumer is initialized even before the module stream job deployment requests path cache are started this could lead to issue when the consumer start processing the requests before the cache are initialized on such scenario the following exception could be thrown: 2015-03-23 21:00:25919 120snap error deploymentsupervisor-0 queuedistributedqueue - exception processing queue item: queue-0000000002 orgspringframeworkxddirtserveradmindeploymentdeploymentexception: datasender at orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployresource(abstractinstancepersistingdeployerjava:164) at orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeploy(abstractinstancepersistingdeployerjava:83) at orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployall(abstractinstancepersistingdeployerjava:109) at orgspringframeworkxddirtstreamabstractinstancepersistingdeployerdeleteall(abstractinstancepersistingdeployerjava:117) at orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerprocessdeploymentmessage(deploymentmessageconsumerjava:115) at orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerconsumemessage(deploymentmessageconsumerjava:70) at orgspringframeworkxddirtserveradmindeploymentzkdeploymentmessageconsumerconsumemessage(deploymentmessageconsumerjava:43) at orgapachecuratorframeworkrecipesqueuedistributedqueueprocessmessagebytes(distributedqueuejava:678) at orgapachecuratorframeworkrecipesqueuedistributedqueueprocessnormally(distributedqueuejava:712) at orgapachecuratorframeworkrecipesqueuedistributedqueueaccess$300(distributedqueuejava:65) at orgapachecuratorframeworkrecipesqueuedistributedqueue$5run(distributedqueuejava:629) at javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) at javautilconcurrentfuturetaskrun(futuretaskjava:262) at javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskaccess$201(scheduledthreadpoolexecutorjava:178) at javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskrun(scheduledthreadpoolexecutorjava:292) at javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) at javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) at javalangthreadrun(threadjava:745) caused by: javalangillegalargumentexception: module deployment request path cache shouldn't be null at orgspringframeworkutilassertnotnull(assertjava:112) at orgspringframeworkxddirtserveradmindeploymentzkzkdeploymenthandlerundeploy(zkdeploymenthandlerjava:81) at orgspringframeworkxddirtstreamabstractinstancepersistingdeployerundeployresource(abstractinstancepersistingdeployerjava:161) and the most similar text Module loading error handling improvement modules loaded container code try module properties properties module null new key module deployment returned null new key null catch exception e new key deploying module e try module path catch e deployment module type sequence number request was detected module path was removed e code problem error thrown need make best effort writing deployment prevent supervisor timing waiting does not exceed the minimum threshold of 75%.;0.03;5.64;1.0;8.33;1;1;0;0
240;Update router sink logic to match new channel syntax for example the following should work: {code} xd:>stream create a1 --definition queue:a > transform --expression=payload+'-a' | log Created new stream 'a1' xd:>stream create b1 --definition queue:b > transform --expression=payload+'-b' | log Created new stream 'b1' xd:>stream create s1 --definition http | router --expression=payload.contains('a')?'queue:a':'queue:b' Created new stream 's1' xd:>http post --data ha > POST (text/plainCharset=UTF-8) http://localhost:9000 ha > 200 OK // log shows: ha-a xd:>http post --data hi > POST (text/plainCharset=UTF-8) http://localhost:9000 hi > 200 OK // log shows: ha-b {code} This needs to be tested against all transports (local redis and rabbit);0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update router sink logic to match new channel syntax for example the following should work: {code} xd:>stream create a1 --definition queue:a > transform --expression=payload+'-a' | log created new stream 'a1' xd:>stream create b1 --definition queue:b > transform --expression=payload+'-b' | log created new stream 'b1' xd:>stream create s1 --definition http | router --expression=payloadcontains('a')?'queue:a':'queue:b' created new stream 's1' xd:>http post --data ha > post (text/plaincharset=utf-8) http://localhost:9000 ha > 200 ok // log shows: ha-a xd:>http post --data hi > post (text/plaincharset=utf-8) http://localhost:9000 hi > 200 ok // log shows: ha-b {code} this needs to be tested against all transports (local redis and rabbit) was most similar to the text New libraries experiment like experiment open source libraries enrich spring service offerings epic remains anchor point following categories respective experimentation outcomes documented stories measure based alerts log machine learning graph computation and similar to the text Stream destroy create ticktock definition time log deploy true warn spring shell - post request resulted 400 bad request error handler command failed already stream named ticktock destroy ticktock warn spring shell - delete request resulted 500 internal server error error handler command failed and similar to the text Allow user configure tests addition sinks sources require connections external entities jms jdbc environment setup getting unwieldy integrate acceptance tests retrieve environment variables dependency injection utilize profiles local single node local cluster single node cluster (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
241;As a Spring XD developer I'd like to port {{http}} module from XD to s-c-s repo so I can use it as {{source}} module in streaming pipeline.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd developer i'd like to port {{http}} module from xd to s-c-s repo so i can use it as {{source}} module in streaming pipeline was most similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job and similar to the text Spike writing hdfs see epic and similar to the text Add unit tests cc spi infrastructure test converter configuration definition objects (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
242;Add support for PHD 2.1 (XD 1.1 M1 Release) *XD 1.1 M1 Release + PHD 2.1 Upgrade - Action Items:* * Update to SHDP 2.1.M2 * Add Hadoop 2.5 (hadoop25) * Remove hadoop22 * Remove PHD 1.0 (phd1) * Change PHD 2.x from phd20 to phd21 * Test PHD 2.0 with phd21;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add support for phd 21 (xd 11 m1 release) *xd 11 m1 release + phd 21 upgrade - action items:* * update to shdp 21m2 * add hadoop 25 (hadoop25) * remove hadoop22 * remove phd 10 (phd1) * change phd 2x from phd20 to phd21 * test phd 20 with phd21 was most similar to the text Remove currently gets added dependency need remove 10 fir pig jobs version remain though and similar to the text Module context true current configuration prevents modules default values evaluate null workaround either - module ppc allows nulls - rid placeholders foo and similar to the text Create reusable responsive ui layout render tabular view create reusable responsive ui layout render returned rest endpoint part try bootstrap 300 use responsive styles offered (and these texts are not user stories).;0.08;2.0;1.0;1.67;0;1;1;1
243;Ensure that when batch jobs are created they are created with the job bean definition id equal to the ‘stream name’ Unlike in spring-batch-admin in SpringXD all the jobs the /modules/jobs directory is not ‘visible’ to query when the server starts. Jobs only become visible to XD’s ‘jobs list’ command once they have been ‘created’. Creating a Job in XD is an opportunity to specify additional values to any property placeholders in the job bean definition. This isn’t part of spring-batch-admin. We will not worry about the creation of job definition in this story. Assume that they have been created already and that the GET for /jobs works as it does now for Spring XD. We should however make sure that there is always a replacement of the job name in the job bean definition to match the ‘--name’ specified in the command line. That is “job create --name myjob --description “thisfunkyjob�? will use ‘myjob to replace <job id=${xd.stream.name} in the file thisfunkyjob.xml *Implementation Suggestions* This should hopefully just be a matter of changing job definition files to follow the naming pattern. <job id=${xd.stream.name} … /> *How to verify it works* 1. Create a JUnit integration style test that has ‘job create --name myjob --defintion “testJob�?’ and then deploy the job. The name ‘myjob’ should appear in the job execution table;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Ensure that when batch jobs are created they are created with the job bean definition id equal to the ‘stream name’ unlike in spring-batch-admin in springxd all the jobs the /modules/jobs directory is not ‘visible’ to query when the server starts jobs only become visible to xd’s ‘jobs list’ command once they have been ‘created’ creating a job in xd is an opportunity to specify additional values to any property placeholders in the job bean definition this isn’t part of spring-batch-admin we will not worry about the creation of job definition in this story assume that they have been created already and that the get for /jobs works as it does now for spring xd we should however make sure that there is always a replacement of the job name in the job bean definition to match the ‘--name’ specified in the command line that is “job create --name myjob --description “thisfunkyjob�? will use ‘myjob to replace <job id=${xdstreamname} in the file thisfunkyjobxml *implementation suggestions* this should hopefully just be a matter of changing job definition files to follow the naming pattern <job id=${xdstreamname} … /> *how to verify it works* 1 create a junit integration style test that has ‘job create --name myjob --defintion “testjob�?’ and then deploy the job the name ‘myjob’ should appear in the job execution table and the most similar text Fix doc formatting issues noticed issues reviewing documentation sidebar longer was really nice somehow section giving error quote warning line invalid style paragraph appendix warning line include file found quote notice different appendix does not exceed the minimum threshold of 75%.;0.01;2.03;1.0;1.67;0;1;0;0
244;As a tester I'd like to add test coverage for complex objects such protocol buffers any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a tester i'd like to add test coverage for complex objects such protocol buffers any object with nested variables or a tree of objects so that i can evaluate and document the performance characteristics was most similar to the text User needs ability pause resume triggers pause means trigger wait fire job pause removed does apply misfire behavior and similar to the text Fix section headers reference see title and similar to the text Document pool properties add properties commented show default values eg 8 0 8 1 (and these texts are not user stories).;0.02;8.15;1.0;8.33;1;1;1;1
245;As a PM I'd like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf. benchmarks and ref. architectures so that it's easy for anyone to quickly get up and running on XD.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a pm i'd like to have a static _gh_pages_ to organize the collateral such as samples tutorials links perf benchmarks and ref architectures so that it's easy for anyone to quickly get up and running on xd is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.03;3.87;1.0;1.67;0;1;1;1
246;As a user I would like to use fsUri = file:// to use Hadoop LocalFileSystem instead of a running cluster. In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job. The quickest way to solve this was to change the fsUri to file://. and it should have just worked. This will work alright for singlenode setups for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing.;1;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i would like to use fsuri = file:// to use hadoop localfilesystem instead of a running cluster in my use case my data scientist team requested to provide me a local csv of data that is being loaded using jdbchdfs job the quickest way to solve this was to change the fsuri to file:// and it should have just worked this will work alright for singlenode setups for multiple containers hosted on multiple machines will split the file across different machines - but then i believe it is fair to assume that the developer must know what he is doing was most similar to the text Vary consumers size using single producer message size 1000 bytes 100 send messages increase decrease given test iteration takes 2 minutes vary number consumers measure rate calculate data transfer rate number consumers 1 2 4 6 10 50 measurements look admin ui see queue backing and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Needs bounded task 11 channels run high volume environments might occur topic thread overwhelm system threads add local configuration limit thread pool used queue tasks threads available setting (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
247;Add documentation for JDBC to HDFS batch job Add docs to section https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#pre-packaged-batch-jobs;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add documentation for jdbc to hdfs batch job add docs to section https://githubcom/spring-projects/spring-xd/wiki/batch-jobs#pre-packaged-batch-jobs was most similar to the text Batch basic fails launch job rabbit data transport deployed batch basic instructions prescribe tests work data transport however job does deploy using rabbit does launch and similar to the text Configuration message concurrent consumers configuration option concurrent consumers help improve performance message consumption consumer modules ordering incoming messages matter and similar to the text Use dot composed module option separator following merge use dot separator composed module option need change parser accept dots (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
248;Allow --path=... configuration in HTTP channel adapter Currently each HTTP stream channel uses its own port which is a limitation if we want to use large numbers of HTTP streams with fine granularity. It would be nice to (additionally) use URI paths to identify HTTP channels allowing to re-use a single HTTP port for multiple channels in XD. Example usage: stream create --name s1 --definition http --port=9495 --path=/foo | log --deploy For a PoC implementation see: https://github.com/spring-projects/spring-xd/pull/1538;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Allow --path= configuration in http channel adapter currently each http stream channel uses its own port which is a limitation if we want to use large numbers of http streams with fine granularity it would be nice to (additionally) use uri paths to identify http channels allowing to re-use a single http port for multiple channels in xd example usage: stream create --name s1 --definition http --port=9495 --path=/foo | log --deploy for a poc implementation see: https://githubcom/spring-projects/spring-xd/pull/1538 was most similar to the text Integration tests fail boot 12 upgrade many tests fail code find template location class path resource templates please add templates check groovy configuration set code somehow need disable check using property suggested and similar to the text Add acceptance test job stage uses distributed mode see stages one jobs run parallel like tests across rabbit transport occur parallel and similar to the text Processor module does load classes custom module package processor module failing load castor classes module code works fine eclipse dirt based test cases attaching code email jar built has jars need folder code worked fine put custom jars application jar spoke confirm broken need (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
249;Enable configuration of replication factor on the Kafka message bus The field exists and it is referred to in application.yml but it does not have a setter and the bus will always use the configured default which is 1.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Enable configuration of replication factor on the kafka message bus the field exists and it is referred to in applicationyml but it does not have a setter and the bus will always use the configured default which is 1 was most similar to the text Add server info banner admin currently has shiny banner container has importantly does say port listening transport used etc and similar to the text Fix rest endpoint security security container admin server wont able fetch message rates deployed modules container rest endpoint needs fixed and similar to the text Job definition parameter issues parameter job definition set master step job has partition definition set individual partition steps master steps fails default timeout (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
250;Context Deserialize Doesn't Use Parent First Classloader If a class is added to a batch execution context that is located in an isolated context an exception will be thrown when that object is deserialized. It appears the serialize doesn't use the ParentFirstClassloader during deserialization.;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Context deserialize doesn't use parent first classloader if a class is added to a batch execution context that is located in an isolated context an exception will be thrown when that object is deserialized it appears the serialize doesn't use the parentfirstclassloader during deserialization is a user story, and is worth 1 story points. This was predicted because it is most similar to the text User id like guidance create custom modules align development practices recommended approach update scope task create example demonstrate document capability and similar to the text User logged get error trying job creation create job shell successfully trying workflow results error well see logs error and similar to the text User id like option change default implement db choice tied default specifications refer details (and these texts are all user stories with a worth of 1 story points).;0.01;6.15;1.0;8.33;1;0;1;0
251;Create bridge processor See https://github.com/spring-cloud/spring-cloud-dataflow/issues/128 This is needed to support channel > channel type constructs;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create bridge processor see https://githubcom/spring-cloud/spring-cloud-dataflow/issues/128 this is needed to support channel > channel type constructs was most similar to the text Fix rest endpoint security security container admin server wont able fetch message rates deployed modules container rest endpoint needs fixed and similar to the text Disable setting set false contexts getting destroyed properly cases prevents running successfully and similar to the text Eliminate package tangle see (and these texts are not user stories).;0.02;8.16;1.0;8.33;1;1;1;1
252;Allow aggregate-counter to increment by some value of the message Currently the aggregate counter only adds +1 to the individual values even though support is there to add any increment. This ticket is about surfacing a SpEL expression on the message to choose the increment;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Allow aggregate-counter to increment by some value of the message currently the aggregate counter only adds +1 to the individual values even though support is there to add any increment this ticket is about surfacing a spel expression on the message to choose the increment was most similar to the text Interaction issue modules see discussion and similar to the text Create rest api stopping job executions adopted functionality spring batch admin include test framework style tests delete - stop job executions and similar to the text Documentation aggregate counter rest api include query parameters query parameters resolution documented along specify time string (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
253;Jolokia based aggregator for cluster monitoring;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Jolokia based aggregator for cluster monitoring was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.06;8.62;1.0;8.33;1;1;1;1
254;Retrieve information for a Field Value Counter TODO as part of this (see XD-537): * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO) * Have REST controllers depend on XRepository in all cases;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Retrieve information for a field value counter todo as part of this (see xd-537): * get rid of so-called service layer in analytics project (doesn't do much right now and logic would better live in the 'handler' imo) * have rest controllers depend on xrepository in all cases was most similar to the text Automate execution part daily build one easy way use authentication scheme described bamboo mask property name contains password may want create dedicated user though and similar to the text Logging listener container narrow error see however was set error last year reduce log noise prefer elevate least warn address noise issue spring and similar to the text Fix batch job throws exception code resolve resource location pattern class path resource resolved url does exist code solved using file prefix maybe update docs (and these texts are not user stories).;0.01;8.4;1.0;8.33;1;1;1;1
255;Add bash based scripts of simple module create to src/main/scripts;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add bash based scripts of simple module create to src/main/scripts was most similar to the text Add spring batch sample spring samples and similar to the text Add integration tests job need add integration tests job and similar to the text Generate doc module options generate fragments modules options way date (and these texts are not user stories).;0.03;2.37;1.0;1.67;0;1;1;1
256;Investigate JobExecutions page list performance Investigate Job Executions list page load timing based on number of job executions to load. The investigation can be of the following steps: 1) Return all the size restrictions to retrieve the number of job executions. 2) Setup 5 10 100 500 1000 number of job executions and measure the page load timings. Based on this we can address the paging support mentioned in XD-1864.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Investigate jobexecutions page list performance investigate job executions list page load timing based on number of job executions to load the investigation can be of the following steps: 1) return all the size restrictions to retrieve the number of job executions 2) setup 5 10 100 500 1000 number of job executions and measure the page load timings based on this we can address the paging support mentioned in xd-1864 was most similar to the text Create batch job export processing multiple files hdfs read multiple files hdfs data converted tuple data structure no-op groovy script write data collection converter need developed sample job documented and similar to the text Make job notification channels currently job notification channels direct channels need make channels allowing automatic job listeners registration allow us create named channel syntax like log log and similar to the text Fix tangle container event references referenced stopped (and these texts are not user stories).;0.03;5.83;1.0;8.33;1;1;1;1
257;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to move {{kafka}} module from xd to s-c-s repo so i can use it as {{sink}} to build streaming pipeline is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;1;1;1
258;As a build manager I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. *Location for 1.1.0 RELEASE:* http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a build manager i'd like to have spring xd rpms published in springio repository so that users can directly download the bits without having to go through appsuite repo or the eula *location for 110 release:* http://repospringio/libs-release-local/org/springframework/xd/spring-xd/110release/ is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use use environments run scope complete remaining deployment properties work and similar to the text User id like ability configure acls restrict access resources accessed admin ui examples create streams destroy streams view streams defaults and similar to the text Developer someone easily deploy spark streaming module developed using (and these texts are all user stories with a worth of 8 story points).;0.05;6.15;1.0;8.33;1;1;1;1
259;As a developer I'd like to upgrade to {{0.6.0}} release of Lattice so I can demonstrate data flow on the latest Lattice improvements.;4;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to upgrade to {{060}} release of lattice so i can demonstrate data flow on the latest lattice improvements is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Users able execute sql processor job statement and similar to the text Developer id like add load sink module measure received throughput and similar to the text User id like option ack messages guarantee sent successful (and these texts are all user stories with a worth of 3 story points).;0.02;6.58;1.0;8.33;1;1;1;1
260;Job in unknown state after run long sqooptasklet Hello guys I hope you are doing good. I found a problem when I try run long sqoop imports (4 hours or more). For some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems. 2015-10-17T03:04:03-0400 1.2.0.RELEASE ERROR SimpleAsyncTaskExecutor-4 step.AbstractStep - Encountered an error saving batch meta data for step import-logs in job ingestion-flow. This job is now in an unknown state and should not be restarted. Please see attached log file for more details. Could you please let me know if you need other details to find what is the problem? Thanks in advance Héctor;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Job in unknown state after run long sqooptasklet hello guys i hope you are doing good i found a problem when i try run long sqoop imports (4 hours or more) for some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems 2015-10-17t03:04:03-0400 120release error simpleasynctaskexecutor-4 stepabstractstep - encountered an error saving batch meta data for step import-logs in job ingestion-flow this job is now in an unknown state and should not be restarted please see attached log file for more details could you please let me know if you need other details to find what is the problem? thanks in advance héctor was most similar to the text Unnecessary format enforcement module short description functional justification validation modules really necessary enforce short description must start capitol letter end period seems bit unnecessary opinionated 1 errors field error object info field rejected value snip codes arguments codes arguments default message default message short description must start capital letter end dot and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases (and these texts are not user stories).;0.04;2.0;1.0;1.67;0;1;1;1
261;As a QA I'd like to include acceptance test coverage for _aggregator_ processor module so that I can validate the functionality as part of every CI build.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a qa i'd like to include acceptance test coverage for _aggregator_ processor module so that i can validate the functionality as part of every ci build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.09;2.01;1.0;1.67;0;1;1;1
262;Design the foundation to port XD modules to s-c-s As an s-c-s developer I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules so I can use it as the base and start migrating the modules.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Design the foundation to port xd modules to s-c-s as an s-c-s developer i'd like to brainstorm and design the foundation to port xd modules as s-c-s modules so i can use it as the base and start migrating the modules was most similar to the text Parser able handle parameter name hyphen embedded right treats new parameter start fails and similar to the text Make spring java 8 issues causing build fail java 8 and similar to the text Create documentation batch db migration update documentation related database migration changes (and these texts are not user stories).;0.02;8.4;1.0;8.33;1;1;1;1
263;Allow processor script variables to be passed as module parameters Currently if we want to bind values to script variables we need to put them in a properties file like so: xd:> stream create --name groovyprocessortest --definition http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log Ideally it should be: xd:> stream create --name groovyprocessortest --definition http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Allow processor script variables to be passed as module parameters currently if we want to bind values to script variables we need to put them in a properties file like so: xd:> stream create --name groovyprocessortest --definition http --port=9006 | script --location=custom-processorgroovy --properties-location=custom-processorproperties | log ideally it should be: xd:> stream create --name groovyprocessortest --definition http --port=9006 | script --location=custom-processorgroovy --foo=bar --baz=boo | log was most similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases and similar to the text Automate execution part daily build one easy way use authentication scheme described bamboo mask property name contains password may want create dedicated user though and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks (and these texts are not user stories).;0.06;2.0;1.0;1.67;0;1;1;1
264;As a developer I'd like to have an OOTB MVC-aware HTTP module (with embedded tomcat) so I can use this module to leverage spring-mvc and spring-security features instead of rewriting them within the existing HTTP source module. * Adds richer support for content-type in the HTTP Source module. See [~jbrisbin] comments: https://github.com/spring-projects/spring-xd/pull/879. * Adds full header mapping in the source (see comments) * See SO request: http://stackoverflow.com/questions/29353471/spring-xd-as-a-rest-endpoint;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text As a developer i'd like to have an ootb mvc-aware http module (with embedded tomcat) so i can use this module to leverage spring-mvc and spring-security features instead of rewriting them within the existing http source module * adds richer support for content-type in the http source module see [~jbrisbin] comments: https://githubcom/spring-projects/spring-xd/pull/879 * adds full header mapping in the source (see comments) * see so request: http://stackoverflowcom/questions/29353471/spring-xd-as-a-rest-endpoint and the most similar text Jdbc sink broken - looks like options booted jdbc sink broken simple time jdbc results bad sql grammar insert test payload values nested exception user lacks privilege object found test looks like options clobbered does not exceed the minimum threshold of 75%.;0.09;2.05;1.0;1.67;0;1;0;0
265;http module leaks threads Attempts to create/use/undeploy a stream involving the http module will result in an OOME stating that VM could not create native thread. Other modules should be checked as well. {noformat} java.lang.Thread.run(Thread.java:724) Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0' nested exception is java.lang.OutOfMemoryError: unable to create new native thread org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176) org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51) org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346) org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149) org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:91) org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1180) org.springframework.xd.module.core.SimpleModule.start(SimpleModule.java:273) org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:251) org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:239) org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:179) org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:150) org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) ... 80 more Caused by: java.lang.OutOfMemoryError: unable to create new native thread java.lang.Thread.$$YJP$$start0(Native Method) java.lang.Thread.start0(Thread.java) java.lang.Thread.start(Thread.java:693) java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949) java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1371) org.jboss.netty.util.internal.DeadLockProofWorker.start(DeadLockProofWorker.java:38) org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:343) org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95) org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:53) org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45) org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:45) org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:28) org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(AbstractNioWorkerPool.java:99) org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:69) org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39) org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33) org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149) org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131) org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:115) org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.doStart(NettyHttpInboundChannelAdapter.java:114) org.springframework.integration.endpoint.AbstractEndpoint.start(AbstractEndpoint.java:84) org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173) ... 91 more {noformat};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Http module leaks threads attempts to create/use/undeploy a stream involving the http module will result in an oome stating that vm could not create native thread other modules should be checked as well {noformat} javalangthreadrun(threadjava:724) caused by: orgspringframeworkcontextapplicationcontextexception: failed to start bean 'orgspringframeworkintegrationxhttpnettyhttpinboundchanneladapter#0' nested exception is javalangoutofmemoryerror: unable to create new native thread orgspringframeworkcontextsupportdefaultlifecycleprocessordostart(defaultlifecycleprocessorjava:176) orgspringframeworkcontextsupportdefaultlifecycleprocessoraccess$200(defaultlifecycleprocessorjava:51) orgspringframeworkcontextsupportdefaultlifecycleprocessor$lifecyclegroupstart(defaultlifecycleprocessorjava:346) orgspringframeworkcontextsupportdefaultlifecycleprocessorstartbeans(defaultlifecycleprocessorjava:149) orgspringframeworkcontextsupportdefaultlifecycleprocessorstart(defaultlifecycleprocessorjava:91) orgspringframeworkcontextsupportabstractapplicationcontextstart(abstractapplicationcontextjava:1180) orgspringframeworkxdmodulecoresimplemodulestart(simplemodulejava:273) orgspringframeworkxddirtmodulemoduledeployerdeploy(moduledeployerjava:251) orgspringframeworkxddirtmodulemoduledeployerdeployandstore(moduledeployerjava:239) orgspringframeworkxddirtmodulemoduledeployerhandledeploy(moduledeployerjava:179) orgspringframeworkxddirtmodulemoduledeployerhandlemessageinternal(moduledeployerjava:150) orgspringframeworkintegrationhandlerabstractmessagehandlerhandlemessage(abstractmessagehandlerjava:78)  80 more caused by: javalangoutofmemoryerror: unable to create new native thread javalangthread$$yjp$$start0(native method) javalangthreadstart0(threadjava) javalangthreadstart(threadjava:693) javautilconcurrentthreadpoolexecutoraddworker(threadpoolexecutorjava:949) javautilconcurrentthreadpoolexecutorexecute(threadpoolexecutorjava:1371) orgjbossnettyutilinternaldeadlockproofworkerstart(deadlockproofworkerjava:38) orgjbossnettychannelsocketnioabstractnioselectoropenselector(abstractnioselectorjava:343) orgjbossnettychannelsocketnioabstractnioselector<init>(abstractnioselectorjava:95) orgjbossnettychannelsocketnioabstractnioworker<init>(abstractnioworkerjava:53) orgjbossnettychannelsocketnionioworker<init>(nioworkerjava:45) orgjbossnettychannelsocketnionioworkerpoolcreateworker(nioworkerpooljava:45) orgjbossnettychannelsocketnionioworkerpoolcreateworker(nioworkerpooljava:28) orgjbossnettychannelsocketnioabstractnioworkerpoolnewworker(abstractnioworkerpooljava:99) orgjbossnettychannelsocketnioabstractnioworkerpoolinit(abstractnioworkerpooljava:69) orgjbossnettychannelsocketnionioworkerpool<init>(nioworkerpooljava:39) orgjbossnettychannelsocketnionioworkerpool<init>(nioworkerpooljava:33) orgjbossnettychannelsocketnionioserversocketchannelfactory<init>(nioserversocketchannelfactoryjava:149) orgjbossnettychannelsocketnionioserversocketchannelfactory<init>(nioserversocketchannelfactoryjava:131) orgjbossnettychannelsocketnionioserversocketchannelfactory<init>(nioserversocketchannelfactoryjava:115) orgspringframeworkintegrationxhttpnettyhttpinboundchanneladapterdostart(nettyhttpinboundchanneladapterjava:114) orgspringframeworkintegrationendpointabstractendpointstart(abstractendpointjava:84) orgspringframeworkcontextsupportdefaultlifecycleprocessordostart(defaultlifecycleprocessorjava:173)  91 more {noformat} and the most similar text Containers stopped responding admin sha environment rabbit transport test 1 admin 2 containers initial event run containers quit responding admin server initial failure streams deployed secondary event shutting one container 1 following exception occurs admin server info - container departed groups error - attached container logs partial rolled attached admin log fairly complete does not exceed the minimum threshold of 75%.;0.02;7.13;1.0;8.24;1;1;0;0
266;http does not report failure to bind to port Stumbled upon this while having Hadoop daemons running but simple way to repoduce: {noformat} nc -lp 9000 stream create foo --definition http | log --deploy ==> all seems ok http post --data hello ==> Error 500 rightfully so {noformat};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Http does not report failure to bind to port stumbled upon this while having hadoop daemons running but simple way to repoduce: {noformat} nc -lp 9000 stream create foo --definition http | log --deploy ==> all seems ok http post --data hello ==> error 500 rightfully so {noformat} was most similar to the text Investigate intermittent failure test often fails running inside reproduce inside eclipse already tried fixing using different key space avail one explanation runs tests concurrently understanding does and similar to the text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available and similar to the text Hdfs sink support file naming strategy distinguish file currently written completed files file process written customized suffix added name eg temp once file closed suffix removed another value - default value dependent serialization format used customized (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
267;As a developer I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to identify the kafka configurations so that i could setup infrastructure to perform performance testing is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;5.64;1.0;8.33;1;1;1;1
268;As a developer I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family so I can continuously evaluate functionalities on every commit.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to resolve remaining gaps wrt ci pipelines for data flow and the family so i can continuously evaluate functionalities on every commit is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.04;2.0;1.0;1.67;0;1;1;1
269;As a developer I'd like to setup UI infrastructure so I can integrate admin_ui and Flo.;4;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to setup ui infrastructure so i can integrate admin_ui and flo is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like upgrade spring 13 release and similar to the text Developer id like review improve performance characteristics and similar to the text Spring user id like create streaming pipelines take advantage latest specs streaming (and these texts are all user stories with a worth of 3 story points).;0.02;5.83;1.0;8.33;1;1;1;1
270;REST API for Job Management Spring Batch Admin provides a complete but outdated implementation style which covers the full administrative lifecycle of batch jobs their creation stop/start and retrieving information about previous job executions and the status of currently executing job executions. SpringXD has a different way of deploying starting and stopping jobs - by sending messages to containers that run the batch job. However the reporting state of a job is still stored in a common job repository. The purpose of this story is to take the first step to merging in the existing code base that focuses only on the retrieval of information from Spring Batch Admin’s Job controller. The current ‘REST API’ style of these commands should stay as close to the original spring batch admin style as possible. There are several reasons for this 1. It works and time to springone is short and we mgmt has expectations around deliverables that we must strive to meet. 2. It gives Andrew a working contract to start developing a UI 3. We can take on this technical debt but refactor after RC1 and before GA while and deliver end-user functionality. Attached is the list of endpoints in spring batch admin;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Rest api for job management spring batch admin provides a complete but outdated implementation style which covers the full administrative lifecycle of batch jobs their creation stop/start and retrieving information about previous job executions and the status of currently executing job executions springxd has a different way of deploying starting and stopping jobs - by sending messages to containers that run the batch job however the reporting state of a job is still stored in a common job repository the purpose of this story is to take the first step to merging in the existing code base that focuses only on the retrieval of information from spring batch admin’s job controller the current ‘rest api’ style of these commands should stay as close to the original spring batch admin style as possible there are several reasons for this 1 it works and time to springone is short and we mgmt has expectations around deliverables that we must strive to meet 2 it gives andrew a working contract to start developing a ui 3 we can take on this technical debt but refactor after rc1 and before ga while and deliver end-user functionality attached is the list of endpoints in spring batch admin and the most similar text Developer like able configure exceptions thrown module within usual stream deployment property level also consider disabling retry problems running spring transport wed like way stop retries certain situations spring chapter transport note retry section written deliveries failing using custom never assumption message converted first attempt subsequent attempts also following unclear speaking based latter available custom module developers attempting throw results even spring configured use rabbit transport throwing custom processor module written spring integrations transformer stop retries does not exceed the minimum threshold of 75%.;0.04;2.0;1.0;1.67;0;0;0;0
271;Add a test suite to the admin-ui The admin-ui currently has no unit tests. Need to add a test suite and hook it up to the build so that tests are run on every build.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add a test suite to the admin-ui the admin-ui currently has no unit tests need to add a test suite and hook it up to the build so that tests are run on every build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like troubleshoot performance issues rabbit message implementation isolate bottleneck fix appropriate and similar to the text Continuation like investigate spark develop poc identify best appropriate design implementation and similar to the text Scd developer id like cc spi deployer cf improve overall design performance (and these texts are all user stories with a worth of 8 story points).;0.03;8.55;1.0;8.33;1;0;1;0
272;As a Spring XD on CF user I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics. *Possible APIs:* {code} ModuleStatus getStatus(ModuleDescriptor descriptor) Collection<ModuleDescriptor> listModules() Map<ModuleDescriptor.Key ModuleStatus> {code};4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a spring xd on cf user i'd like to use receptor implementation of admin spi every time i deploy spring xd modules so i can leverage the spi to query for module status and health metrics *possible apis:* {code} modulestatus getstatus(moduledescriptor descriptor) collection<moduledescriptor> listmodules() map<moduledescriptorkey modulestatus> {code} was most similar to the text Deploying source throws jackson exception upgrade jackson 22 included following change build script code description spring dirt configurations group code spring social twitter template depends classes and similar to the text Streamline arg management command line arguments especially default values currently scattered around different places aim regroup common place options classes make sense also happy system properties used vehicle and similar to the text Remove code extract target output channel proxy si proxies output channel module context unwrap proxy order add tap temporarily code elegant solution called involve si making interface method (and these texts are not user stories).;0.03;2.04;1.0;1.67;0;1;1;1
273;Migrate repositories to ZooKeeper all state about the running system (containers streams and jobs) should be available via ZK and ultimately the --store option should not be needed 1. Refactor ModuleDefinitionRepository to use ZooKeeper * remove RedisModuleDefinitionRepository * remove InMemoryModuleDefinitionRepository 2. Refactor ModuleDependencyRepository to use ZooKeeper * remove RedisModuleDependencyRepository * remove InMemoryModuleDependencyRepository 3. Refactor RuntimeModuleInfoRepository to use ZooKeeper (rename ModuleMetadata...) * remove RedisRuntimeModuleInfoRepository * remove AbstractRedisRuntimeModuleInfoRepository * remove InMemoryRuntimeModuleInfoRepository 4. Refactor RuntimeContainerModuleInfoRepository to use ZooKeeper (rename ContainerMetadata...) * remove RedisRuntimeContainerModuleInfoRepository * remove InMemoryRuntimeContainerModuleInfoRepository 5. Remove support for --store * remove the memory-store.xml and the redis-store.xml * instead include just one repositories.xml in shared server config * remove the associated property key and the *Options properties 6. Remove the events and listeners that were being used;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Migrate repositories to zookeeper all state about the running system (containers streams and jobs) should be available via zk and ultimately the --store option should not be needed 1 refactor moduledefinitionrepository to use zookeeper * remove redismoduledefinitionrepository * remove inmemorymoduledefinitionrepository 2 refactor moduledependencyrepository to use zookeeper * remove redismoduledependencyrepository * remove inmemorymoduledependencyrepository 3 refactor runtimemoduleinforepository to use zookeeper (rename modulemetadata) * remove redisruntimemoduleinforepository * remove abstractredisruntimemoduleinforepository * remove inmemoryruntimemoduleinforepository 4 refactor runtimecontainermoduleinforepository to use zookeeper (rename containermetadata) * remove redisruntimecontainermoduleinforepository * remove inmemoryruntimecontainermoduleinforepository 5 remove support for --store * remove the memory-storexml and the redis-storexml * instead include just one repositoriesxml in shared server config * remove the associated property key and the *options properties 6 remove the events and listeners that were being used was most similar to the text Upgrade latest release required latest sonar version may need wait fix groovy - please see following links details and similar to the text Needs write unique directory vs default occasionally 2 acceptance tests running simultaneously tests writes data hdfs directory cause test fail sporadically unique directory time share instance conflict and similar to the text Taps avoid transport hop taps currently source modules simply bridge tapped modules tap topic directly conversion first tap modules input channel note - ensure destroy works currently tap destroyed simple fact module longer module well need special handling tap adapter (and these texts are not user stories).;0.04;2.0;1.0;1.67;0;1;1;1
274;Allow direct binding even for module.count != 0;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Allow direct binding even for modulecount != 0 is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;0;1;0
275;Add filepollhdfs Acceptance Tests;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add filepollhdfs acceptance tests was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;4.94;1.0;8.33;1;1;1;1
276;HDFS Core writing helper classes Simple file writer that has existed in the spring hadoop samples.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Hdfs core writing helper classes simple file writer that has existed in the spring hadoop samples is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;4.48;1.0;7.9;1;0;1;0
277;Composite Multiple Sink Module This would allow multiple individual sink modules to be combined via the shell DSL so that each message sent to the composite sink module will be sent to each of the individual sink modules in turn. Internally this would probably use a recipient list router to send to each individual sink. Module options for each individual sink would be combined to create the overall options for the composite sink module in a similar way to existing composite modules. This would allow construction of streams with less communication with the message bus for example as an alternative to using a named topic in the message bus. Using this in conjunction with sinks built using existing composite module functionality (as a combination of processors and a sink) would allow more sophisticated combinations to be constructed and deployed as a single module (with no message bus communication). One particular application of this would be with tap and counter functionality. If multiple fields in a message need counted this currently needs to be done as separate streams tapping the original with the overhead of the tapped message being read from the message bus multiple times potentially on different nodes this enhancement would allow all the counters to be combined to make a more cohesive composite counter module so that the tapped message would only need to be read once.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Composite multiple sink module this would allow multiple individual sink modules to be combined via the shell dsl so that each message sent to the composite sink module will be sent to each of the individual sink modules in turn internally this would probably use a recipient list router to send to each individual sink module options for each individual sink would be combined to create the overall options for the composite sink module in a similar way to existing composite modules this would allow construction of streams with less communication with the message bus for example as an alternative to using a named topic in the message bus using this in conjunction with sinks built using existing composite module functionality (as a combination of processors and a sink) would allow more sophisticated combinations to be constructed and deployed as a single module (with no message bus communication) one particular application of this would be with tap and counter functionality if multiple fields in a message need counted this currently needs to be done as separate streams tapping the original with the overhead of the tapped message being read from the message bus multiple times potentially on different nodes this enhancement would allow all the counters to be combined to make a more cohesive composite counter module so that the tapped message would only need to be read once and the most similar text Assess sinks close client cache os - mac deployment type - sha - required software - sample server description destroying 3 streams sink 4th fail error connection number clients 4 exceeded limit 3 allowed default evaluation license steps reproduce shell execute following 4 times stream create name stocks definition http deploy stream destroy stocks does not exceed the minimum threshold of 75%.;0.11;2.0;1.0;1.67;0;1;0;0
278;List Streams/Jobs based with deployed modules Currently there is a stream list/job list which shows the status of a given stream/job along with the DSL. and there is runtime modules which shows all the deployed modules with their container info. We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text List streams/jobs based with deployed modules currently there is a stream list/job list which shows the status of a given stream/job along with the dsl and there is runtime modules which shows all the deployed modules with their container info we need a better rest endpoint that gives all the deployed modules for a given stream/job along with the status was most similar to the text Introduce admin ui consider moving encourage dependency injection ui javascript code see and similar to the text Automatically disable module components provide bpp possibly well remove existing module and similar to the text Provide options validation wherever come cmd line args options transport analytics etc validated issues reported users (and these texts are not user stories).;0.07;2.0;1.0;1.67;0;1;1;1
279;Support Groovy bean definitions as XD extensions Modify the PluginContextExtensionsInitializer to consume .groovy bean definitions as well as XML.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Support groovy bean definitions as xd extensions modify the plugincontextextensionsinitializer to consume groovy bean definitions as well as xml is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Scd developer id like create implementation use infrastructure lookup module coordinates name and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.03;8.16;1.0;8.33;1;0;1;0
280;As a developer I'd like to add an option to support Apache Ambari installed Spring XD on YARN so I can easily establish the cluster up and running.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to add an option to support apache ambari installed spring xd on yarn so i can easily establish the cluster up and running is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.12;2.0;1.0;1.67;0;1;1;1
281;SpringXD logs error and large stack trace when metric can't be found. Distracting. When a REST client of SpringXD (i.e. a dashboard) attempts to query (GET) a metric (e.g. counter gauge etc.) that does not exist the admin sever logs an ERROR and a large stack trace (attached). In usage of Spring XD we see this frequently because a dashboard is running but the streams and counters have not been created quite yet or initialized by messages flowing through the streams. With a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues. I would suggest logging a one line warning or info message instead of the error and stack trace.;0;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Springxd logs error and large stack trace when metric can't be found distracting when a rest client of springxd (ie a dashboard) attempts to query (get) a metric (eg counter gauge etc) that does not exist the admin sever logs an error and a large stack trace (attached) in usage of spring xd we see this frequently because a dashboard is running but the streams and counters have not been created quite yet or initialized by messages flowing through the streams with a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues i would suggest logging a one line warning or info message instead of the error and stack trace is a user story, and is worth 2 story points. This was predicted because it is most similar to the text User able shutdown container admin ui following stream definition deployed code stream create definition jdbc employer employee hdfs deploy code details and similar to the text User id like option configure permissions ill flexibility bind permissions rest endpoint specific role default roles admin crud viewer r and similar to the text User id like migrate 10 11 able port custom modules operationalize existing data pipelines also take advantage latest features (and these texts are all user stories with a worth of 2 story points).;0.02;5.64;1.0;8.33;1;0;1;0
282;Add Stream/Job destroy option at the UI Add an option to destroy the stream/job definitions. Also add confirm action that asks for user to confirm to proceed with destroy.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add stream/job destroy option at the ui add an option to destroy the stream/job definitions also add confirm action that asks for user to confirm to proceed with destroy is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like exception thrown module tap error channel receive failures and similar to the text User id like description modules use understand module purpose capabilities presumably module definition and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint (and these texts are all user stories with a worth of 8 story points).;0.02;5.83;1.0;8.33;1;0;1;0
283;Create XD source from POJO annotated @Source XD Module configured for component scanning classes (or methods?) annotated with @Source (consider @Processor and @Sink as well) and simply provide the POJOs and dependent jars in the module /lib directory. Custom processor is fairly straightforward currently but still requires an XML module definition to wire up the POJO as a service activator or transformer to the input and output channel. A service activator works for a POJO backed sink. Writing a source that is not backed by an existing inbound channel adapter is a bit more involved and requires more than basic familiarity with SI. It should be possible for XD to automatically create a polling source by wiring a Java method to an inbound adapter configured with a poller. Ideally we would require no XML even to enable component scanning- this will require some changes to the module registry/module initializer.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Create xd source from pojo annotated @source xd module configured for component scanning classes (or methods?) annotated with @source (consider @processor and @sink as well) and simply provide the pojos and dependent jars in the module /lib directory custom processor is fairly straightforward currently but still requires an xml module definition to wire up the pojo as a service activator or transformer to the input and output channel a service activator works for a pojo backed sink writing a source that is not backed by an existing inbound channel adapter is a bit more involved and requires more than basic familiarity with si it should be possible for xd to automatically create a polling source by wiring a java method to an inbound adapter configured with a poller ideally we would require no xml even to enable component scanning- this will require some changes to the module registry/module initializer and the most similar text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases does not exceed the minimum threshold of 75%.;0.04;2.0;1.0;1.67;0;1;0;0
284;Clean up MBean registration for failed module deployments When a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a JMX exception: {noformat} java.lang.RuntimeException: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:447) org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:346) org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:92) org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:655) org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494) org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488) org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293) org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485) org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) java.util.concurrent.FutureTask.run(FutureTask.java:266) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) java.util.concurrent.FutureTask.run(FutureTask.java:266) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176) org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51) org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346) org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149) org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112) org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773) org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:485) org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648) org.springframework.boot.SpringApplication.run(SpringApplication.java:311) org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130) org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:240) org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:184) org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:174) org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:164) org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:227) org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:429) ... 18 more Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output sends=0]] with key 'org.springframework.integration:type=MessageChannelname=output' nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610) org.springframework.integration.monitor.IntegrationMBeanExporter.registerChannels(IntegrationMBeanExporter.java:837) org.springframework.integration.monitor.IntegrationMBeanExporter.doStart(IntegrationMBeanExporter.java:459) org.springframework.integration.monitor.IntegrationMBeanExporter.start(IntegrationMBeanExporter.java:410) org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173) ... 33 more Caused by: javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0component=MessageChannelname=output com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195) org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663) org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:606) ... 37 more {noformat};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Clean up mbean registration for failed module deployments when a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a jmx exception: {noformat} javalangruntimeexception: orgspringframeworkcontextapplicationcontextexception: failed to start bean 'orgspringframeworkintegrationmonitorintegrationmbeanexporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=output sends=0]] with key 'orgspringframeworkintegration:type=messagechannelname=output' nested exception is javaxmanagementinstancealreadyexistsexception: xdfoo:module=http0component=messagechannelname=output orgspringframeworkxddirtservercontainerregistrardeploystreammodule(containerregistrarjava:447) orgspringframeworkxddirtservercontainerregistraronchildadded(containerregistrarjava:346) orgspringframeworkxddirtservercontainerregistraraccess$700(containerregistrarjava:92) orgspringframeworkxddirtservercontainerregistrar$deploymentlistenerchildevent(containerregistrarjava:655) orgapachecuratorframeworkrecipescachepathchildrencache$5apply(pathchildrencachejava:494) orgapachecuratorframeworkrecipescachepathchildrencache$5apply(pathchildrencachejava:488) orgapachecuratorframeworklistenlistenercontainer$1run(listenercontainerjava:92) comgooglecommonutilconcurrentmoreexecutors$samethreadexecutorserviceexecute(moreexecutorsjava:293) orgapachecuratorframeworklistenlistenercontainerforeach(listenercontainerjava:83) orgapachecuratorframeworkrecipescachepathchildrencachecalllisteners(pathchildrencachejava:485) orgapachecuratorframeworkrecipescacheeventoperationinvoke(eventoperationjava:35) orgapachecuratorframeworkrecipescachepathchildrencache$11run(pathchildrencachejava:755) javautilconcurrentexecutors$runnableadaptercall(executorsjava:511) javautilconcurrentfuturetaskrun(futuretaskjava:266) javautilconcurrentexecutors$runnableadaptercall(executorsjava:511) javautilconcurrentfuturetaskrun(futuretaskjava:266) javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1142) javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:617) javalangthreadrun(threadjava:744) caused by: orgspringframeworkcontextapplicationcontextexception: failed to start bean 'orgspringframeworkintegrationmonitorintegrationmbeanexporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5' nested exception is orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=output sends=0]] with key 'orgspringframeworkintegration:type=messagechannelname=output' nested exception is javaxmanagementinstancealreadyexistsexception: xdfoo:module=http0component=messagechannelname=output orgspringframeworkcontextsupportdefaultlifecycleprocessordostart(defaultlifecycleprocessorjava:176) orgspringframeworkcontextsupportdefaultlifecycleprocessoraccess$200(defaultlifecycleprocessorjava:51) orgspringframeworkcontextsupportdefaultlifecycleprocessor$lifecyclegroupstart(defaultlifecycleprocessorjava:346) orgspringframeworkcontextsupportdefaultlifecycleprocessorstartbeans(defaultlifecycleprocessorjava:149) orgspringframeworkcontextsupportdefaultlifecycleprocessoronrefresh(defaultlifecycleprocessorjava:112) orgspringframeworkcontextsupportabstractapplicationcontextfinishrefresh(abstractapplicationcontextjava:773) orgspringframeworkcontextsupportabstractapplicationcontextrefresh(abstractapplicationcontextjava:485) orgspringframeworkbootspringapplicationrefresh(springapplicationjava:648) orgspringframeworkbootspringapplicationrun(springapplicationjava:311) orgspringframeworkbootbuilderspringapplicationbuilderrun(springapplicationbuilderjava:130) orgspringframeworkxdmodulecoresimplemoduleinitialize(simplemodulejava:240) orgspringframeworkxddirtmodulemoduledeployerdeploy(moduledeployerjava:184) orgspringframeworkxddirtmodulemoduledeployerdeployandstore(moduledeployerjava:174) orgspringframeworkxddirtmodulemoduledeployerdeployandstore(moduledeployerjava:164) orgspringframeworkxddirtservercontainerregistrardeploymodule(containerregistrarjava:227) orgspringframeworkxddirtservercontainerregistrardeploystreammodule(containerregistrarjava:429)  18 more caused by: orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [messagechannelmonitor: [name=output sends=0]] with key 'orgspringframeworkintegration:type=messagechannelname=output' nested exception is javaxmanagementinstancealreadyexistsexception: xdfoo:module=http0component=messagechannelname=output orgspringframeworkjmxexportmbeanexporterregisterbeannameorinstance(mbeanexporterjava:610) orgspringframeworkintegrationmonitorintegrationmbeanexporterregisterchannels(integrationmbeanexporterjava:837) orgspringframeworkintegrationmonitorintegrationmbeanexporterdostart(integrationmbeanexporterjava:459) orgspringframeworkintegrationmonitorintegrationmbeanexporterstart(integrationmbeanexporterjava:410) orgspringframeworkcontextsupportdefaultlifecycleprocessordostart(defaultlifecycleprocessorjava:173)  33 more caused by: javaxmanagementinstancealreadyexistsexception: xdfoo:module=http0component=messagechannelname=output comsunjmxmbeanserverrepositoryaddmbean(repositoryjava:437) comsunjmxinterceptordefaultmbeanserverinterceptorregisterwithrepository(defaultmbeanserverinterceptorjava:1898) comsunjmxinterceptordefaultmbeanserverinterceptorregisterdynamicmbean(defaultmbeanserverinterceptorjava:966) comsunjmxinterceptordefaultmbeanserverinterceptorregisterobject(defaultmbeanserverinterceptorjava:900) comsunjmxinterceptordefaultmbeanserverinterceptorregistermbean(defaultmbeanserverinterceptorjava:324) comsunjmxmbeanserverjmxmbeanserverregistermbean(jmxmbeanserverjava:522) orgspringframeworkjmxsupportmbeanregistrationsupportdoregister(mbeanregistrationsupportjava:195) orgspringframeworkjmxexportmbeanexporterregisterbeaninstance(mbeanexporterjava:663) orgspringframeworkjmxexportmbeanexporterregisterbeannameorinstance(mbeanexporterjava:606)  37 more {noformat} and the most similar text New job executes sql script using jdbc create batch job executes sql script using jdbc - used jobs jobs etc christian following baed attached simple job module run sql commands db jdbc unzip folder create like job create definition jdbc master password table select count group deploy does not exceed the minimum threshold of 75%.;0.06;2.03;1.0;1.67;0;1;0;0
285;As a user I'd like to refer to documentation in wiki so that I can setup and configure Spark as a Batch job as recommended.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to refer to documentation in wiki so that i can setup and configure spark as a batch job as recommended is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;1;1;1
286;As a developer I'd like to split up spring-xd dependencies to more fine-grained so I can get the ones below the line down to spring-bus-* instead of spring-xd-* bundle.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to split up spring-xd dependencies to more fine-grained so i can get the ones below the line down to spring-bus-* instead of spring-xd-* bundle is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like use server modules centrally manage external properties and similar to the text Developer id like acceptance test coverage yarn verify simple features running yarn every build cycle and similar to the text Scs user id like option direct bind modules use messaging middleware eliminate latency important high throughput low latency use cases (and these texts are all user stories with a worth of 8 story points).;0.01;2.41;1.0;1.67;0;1;1;1
287;Testers need ability to wait for a file to be created in XD directory User's need ability to wait for user specified time in millis for a file to be created in the XD directory. If file is not created in allotted time then return false else return true. Also check to see if a file exists in the XD directory.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Testers need ability to wait for a file to be created in xd directory user's need ability to wait for user specified time in millis for a file to be created in the xd directory if file is not created in allotted time then return false else return true also check to see if a file exists in the xd directory was most similar to the text Module context true current configuration prevents modules default values evaluate null workaround either - module ppc allows nulls - rid placeholders foo and similar to the text Add definition twitter classes add objects package absence creates warnings compile time and similar to the text Add required jars needed use scheme talk hdfs http (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
288;As a developer I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor so I can interact with Diego runtime via Receptor API calls from XD.;5;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to create a [java client|https://githubcom/markfisher/receptor-client] for receptor so i can interact with diego runtime via receptor api calls from xd is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like isolate tests different project dirt project depend incorrect cp file generation eclipse and similar to the text User id like enable ha enable custom configuration details and similar to the text Developer want able override kafka defaults module consumers producers finely tune performance behaviour properties include - consumers - producers (and these texts are all user stories with a worth of 3 story points).;0.08;8.62;1.0;8.33;1;1;1;1
289;As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629] we would want to fix this experience for Kafka message bus.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a follow-up from [xd-3613|https://jiraspringio/browse/xd-3629] we would want to fix this experience for kafka message bus was most similar to the text Parameterize source add support tcp source currently hard-coded use udp port need parameterize port provide option use tcp and similar to the text User able specify deploy properties jobs clicking deploy job definitions page user able specify deployment manifest module count module etc and similar to the text Change metrics assertions integration tests use smart similar has done eg metrics related sinks use smart timings (and these texts are not user stories).;0.01;2.07;1.0;1.67;0;1;1;1
290;Container fails to start if JMX is enabled and manage_port is set The container will not start with JMX enabled and the management_port set. The stacktrace is attached and the settings for the container are enumerated below: export endpoints_jmx_enabled=true export endpoints_jmx_uniqueNames=true export endpoints_jolokia_enabled=true export XD_JMX_ENABLED=true export management_port=15005;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Container fails to start if jmx is enabled and manage_port is set the container will not start with jmx enabled and the management_port set the stacktrace is attached and the settings for the container are enumerated below: export endpoints_jmx_enabled=true export endpoints_jmx_uniquenames=true export endpoints_jolokia_enabled=true export xd_jmx_enabled=true export management_port=15005 is a user story, and is worth 5 story points. This was predicted because it is most similar to the text User id like googles protocol codec option objects based native specifications and similar to the text Scs user id like modules eureka installed also discover modules using spring admin spi reuse create data pipelines and similar to the text User id like either use sql options build job clause strict combo respectively (and these texts are all user stories with a worth of 5 story points).;0.08;8.16;1.0;8.33;1;0;1;0
291;Create REST API for getting information on a job execution for a given execution id Adopted functionality from Spring Batch admin Should include springmvc test framework style tests GET /batch/jobs/executions/{executionId} - Get information on all executions of a given job name.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create rest api for getting information on a job execution for a given execution id adopted functionality from spring batch admin should include springmvc test framework style tests get /batch/jobs/executions/{executionid} - get information on all executions of a given job name is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text User id like python processor efficiently perform data computations statistical investigate right approach native fits spring model integrate java and similar to the text User id like r processor efficiently perform data computations statistical context streaming pipeline investigate right approach fits spring model r java libraries (and these texts are all user stories with a worth of 8 story points).;0.03;2.2;1.0;1.67;0;0;1;0
292;As a Spring XD developer I'd like to move {{twittersearch}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to move {{twittersearch}} module from xd to s-c-s repo so i can use it as source modules to build streaming pipeline is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Spring developer id like move module scs use sink build streaming pipeline and similar to the text Spring developer id like port sftp module scs use source modules build streaming pipeline and similar to the text Spring developer id like port module scs use processor module build streaming pipeline (and these texts are all user stories with a worth of 5 story points).;0.06;2.0;1.0;1.67;0;1;1;1
293;Update payload-conversion demo to latest module spec Upload payload conversion demo such that a user can use the module upload feature against the sample.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update payload-conversion demo to latest module spec upload payload conversion demo such that a user can use the module upload feature against the sample is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text User need document covering recommendations deploying cluster using marathon framework (and these texts are all user stories with a worth of 8 story points).;0.02;3.87;1.0;1.67;0;0;1;0
294;HDFS sink should provide rolloverTime option not only idleTiemout When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file. Proposed option: rolloverTimeout timeout after file will be automatically closed Link: #XD-2413;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Hdfs sink should provide rollovertime option not only idletiemout when using hdfs sink with ildetimeout and rollover options in stream definition we have noticed that idletimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file proposed option: rollovertimeout timeout after file will be automatically closed link: #xd-2413 was most similar to the text Provide ability disable tab completion specific module options module options born equal expert ones show eg tab completion noisy esp given currently presents whole stream definition typed far completion opposed last bit and similar to the text Add support start apps yarn automatically type scd developer id like add support negotiate deploy modules groups build instrumentation start app instances automatically also take account app specifics and similar to the text Logging listener container narrow error see however was set error last year reduce log noise prefer elevate least warn address noise issue spring (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
295;As a performance tester I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. *Scope:* * Identify the bottlenecks * Document reasons * List pros/cons;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a performance tester i'd like to investigate why there's high cpu startup time for both admin and container servers perhaps profiling would assist isolating the bottlenecks *scope:* * identify the bottlenecks * document reasons * list pros/cons was most similar to the text Enabling support broken however triggered depending merged yet seems broken duplicate beans names and similar to the text Optimize queries batch domain object usages based discussion need better strategy handle queries updates batch domain objects and similar to the text Create dedicated similar setting property currently etc moreover strong string constant reference create dedicated matters namely making bits available module environment (and these texts are not user stories).;0.04;8.06;1.0;8.33;1;1;1;1
296;Upgrade asciidoctor toolchain This will in turn allow us to get rid of the custom logic for handling crossref links between documents;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Upgrade asciidoctor toolchain this will in turn allow us to get rid of the custom logic for handling crossref links between documents is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.02;5.64;1.0;8.33;1;0;1;0
297;As a user I'd like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have the option to stop an existing spark job so that i can clean-up resources at the time of completion is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;1;1;1
298;Add log-full-message Property to the Log Sink Allows looking at message headers without turning on debugging.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add log-full-message property to the log sink allows looking at message headers without turning on debugging was most similar to the text Jobs list rest endpoint include currently jobs definition list rest endpoint include given job and similar to the text Ability tap spark streaming processor output need support adding tap stream connects spark streaming processor modules output channel and similar to the text Add unit tests cc spi infrastructure test converter configuration definition objects (and these texts are not user stories).;0.07;8.55;1.0;8.33;1;1;1;1
299;Decouple messagebus dependencies *Refactoring scope:* (_spring-xd-dirt_) * Message bus dependencies The goal is to decouple them from startup phase to further enhance initialization time.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Decouple messagebus dependencies *refactoring scope:* (_spring-xd-dirt_) * message bus dependencies the goal is to decouple them from startup phase to further enhance initialization time is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Data scientist id like option process data using processor take advantage streaming machine learning abstractions implemented top and similar to the text Qa id like include acceptance test coverage batch job validate functionality part every ci build and similar to the text Developer id like add support explicit partition count configuration use option cleverly route payload intended consumer module (and these texts are all user stories with a worth of 5 story points).;0.06;8.62;1.0;8.33;1;0;1;0
300;As a user I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have the option of editing the deployed/undeployed stream so that i don't have to destroy to just change any deployment property is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;5.83;1.0;8.33;1;1;1;1
301;Investigate Redis connection timeout issues when running performance test With the performance test run the numbers (messages sent/received per second) keep varying as there are redis client connection timeout exceptions (Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out) at both redis inbound/outbound channel adapters as I increase the total number of messages being processed (max. 10K/second). Some of the exception messages for the review: 1) With connection pool (at Redis outbound): Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool nested exception is com.lambdaworks.redis.RedisException: Unable to connect at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:95) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:36) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:318) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:109) at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:157) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:137) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84) at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:71) at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:67) at org.springframework.xd.perftest.redis.outbound.RedisQOutboundChannelAdapter.handleMessageInternal(RedisQOutboundChannelAdapter.java:71) at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73) ... 17 more Caused by: com.lambdaworks.redis.RedisException: Unable to connect at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176) at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool$LettuceFactory.makeObject(DefaultLettucePool.java:252) at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1181) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:93) ... 29 more Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379 at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) 2) Without connection pool (at Redis inbound): Caused by: com.lambdaworks.redis.RedisException: Unable to connect at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176) at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:321) ... 12 more Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379 at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) ... 3 more;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Investigate redis connection timeout issues when running performance test with the performance test run the numbers (messages sent/received per second) keep varying as there are redis client connection timeout exceptions (caused by: orgjbossnettychannelconnecttimeoutexception: connection timed out) at both redis inbound/outbound channel adapters as i increase the total number of messages being processed (max 10k/second) some of the exception messages for the review: 1) with connection pool (at redis outbound): caused by: orgspringframeworkdataredisconnectionpoolexception: could not get a resource from the pool nested exception is comlambdaworksredisredisexception: unable to connect at orgspringframeworkdataredisconnectionlettucedefaultlettucepoolgetresource(defaultlettucepooljava:95) at orgspringframeworkdataredisconnectionlettucedefaultlettucepoolgetresource(defaultlettucepooljava:36) at orgspringframeworkdataredisconnectionlettucelettuceconnectionfactorycreatelettuceconnector(lettuceconnectionfactoryjava:318) at orgspringframeworkdataredisconnectionlettucelettuceconnectionfactorygetconnection(lettuceconnectionfactoryjava:109) at orgspringframeworkdatarediscoreredisconnectionutilsdogetconnection(redisconnectionutilsjava:81) at orgspringframeworkdatarediscoreredisconnectionutilsgetconnection(redisconnectionutilsjava:53) at orgspringframeworkdatarediscoreredistemplateexecute(redistemplatejava:157) at orgspringframeworkdatarediscoreredistemplateexecute(redistemplatejava:137) at orgspringframeworkdatarediscoreabstractoperationsexecute(abstractoperationsjava:84) at orgspringframeworkdatarediscoredefaultlistoperationsleftpush(defaultlistoperationsjava:71) at orgspringframeworkdatarediscoredefaultboundlistoperationsleftpush(defaultboundlistoperationsjava:67) at orgspringframeworkxdperftestredisoutboundredisqoutboundchanneladapterhandlemessageinternal(redisqoutboundchanneladapterjava:71) at orgspringframeworkintegrationhandlerabstractmessagehandlerhandlemessage(abstractmessagehandlerjava:73)  17 more caused by: comlambdaworksredisredisexception: unable to connect at comlambdaworksredisredisclientconnect(redisclientjava:176) at comlambdaworksredisredisclientconnectasync(redisclientjava:139) at orgspringframeworkdataredisconnectionlettucedefaultlettucepool$lettucefactorymakeobject(defaultlettucepooljava:252) at orgapachecommonspoolimplgenericobjectpoolborrowobject(genericobjectpooljava:1181) at orgspringframeworkdataredisconnectionlettucedefaultlettucepoolgetresource(defaultlettucepooljava:93)  29 more caused by: orgjbossnettychannelconnecttimeoutexception: connection timed out: localhost/127001:6379 at orgjbossnettychannelsocketnionioclientbossprocessconnecttimeout(nioclientbossjava:137) at orgjbossnettychannelsocketnionioclientbossprocess(nioclientbossjava:83) at orgjbossnettychannelsocketnioabstractnioselectorrun(abstractnioselectorjava:312) at orgjbossnettychannelsocketnionioclientbossrun(nioclientbossjava:42) 2) without connection pool (at redis inbound): caused by: comlambdaworksredisredisexception: unable to connect at comlambdaworksredisredisclientconnect(redisclientjava:176) at comlambdaworksredisredisclientconnectasync(redisclientjava:139) at orgspringframeworkdataredisconnectionlettucelettuceconnectionfactorycreatelettuceconnector(lettuceconnectionfactoryjava:321)  12 more caused by: orgjbossnettychannelconnecttimeoutexception: connection timed out: localhost/127001:6379 at orgjbossnettychannelsocketnionioclientbossprocessconnecttimeout(nioclientbossjava:137) at orgjbossnettychannelsocketnionioclientbossprocess(nioclientbossjava:83) at orgjbossnettychannelsocketnioabstractnioselectorrun(abstractnioselectorjava:312) at orgjbossnettychannelsocketnionioclientbossrun(nioclientbossjava:42)  3 more and the most similar text Reorganize manual strawman getting started rather meaty top level sections maybe section - running running distributed mode running yarn application configuration message configuration monitoring management technical documentation architecture distributed remove prefix interactive shell batch jobs streams modules tuples sources processors analytics sinks taps type conversion deployment better name best practices new section admin ui dsl reference rest api samples does not exceed the minimum threshold of 75%.;0.09;2.05;1.0;1.67;0;1;0;0
302;Create Sample Module projects Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to https://github.com/dturanski/siDslModule these should include unit and single node integration tests and demonstrate the use of Spring XD build and packaging tools and other module development support. This may be split out into separate tasks but should include a sample for source processor sink and job using @Configuration or XML configuration (either as separate samples or using build profiles).;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create sample module projects create one or more sample module projects in the spring xd examples repo to serve as templates for spring xd module projects similar to https://githubcom/dturanski/sidslmodule these should include unit and single node integration tests and demonstrate the use of spring xd build and packaging tools and other module development support this may be split out into separate tasks but should include a sample for source processor sink and job using @configuration or xml configuration (either as separate samples or using build profiles) was most similar to the text Add support data platform 20 apologies ticket already exists see one data platform 20 sandbox see supported spring yet hard add matter dropping lib folder allowing options passed option currently trying work following tutorial using 20 sandbox instead 13 sandbox thanks and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Fix servlet container issues several issues staged version - use tomcat instead jetty prevent starting yarn - guava 180 instead - push work client needs servlet api - updating instead -- causes curator also update throws exception startup (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
303;Add HdfsMongoDb Acceptance Test. Create Acceptance Test Add Mongo to Ec2 Acceptance Test Environment.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add hdfsmongodb acceptance test create acceptance test add mongo to ec2 acceptance test environment was most similar to the text Remove transport headers tapped stream transport headers removed taps and similar to the text Build breaks 18 build breaks 18 due changes dependency resolution and similar to the text Add back classifier build target add back classifier build target - was was accidentally removed (and these texts are not user stories).;0.16;8.16;1.0;8.33;1;1;1;1
304;REST endpoint/command interface for runtime module deployment properties We need a way to access the deployment properties for the deployed modules. For example: 'runtime module foo.sink.bar-2';0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Rest endpoint/command interface for runtime module deployment properties we need a way to access the deployment properties for the deployed modules for example: 'runtime module foosinkbar-2' is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text Developer id like migrate module deployment repository abstraction used definitions create spi (and these texts are all user stories with a worth of 8 story points).;0.02;5.83;1.0;8.33;1;0;1;0
305;As a developer I'd like to complete the remaining Kryo optimization changes so I can polish and get the guidelines documented appropriately.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to complete the remaining kryo optimization changes so i can polish and get the guidelines documented appropriately is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;4.48;1.0;7.9;1;1;1;1
306;As a user I'd like to have an option to specify _timeout_ so I can expect the job to not run forever if it is in hung state.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have an option to specify _timeout_ so i can expect the job to not run forever if it is in hung state is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;5.39;1.0;1.67;0;1;1;1
307;Remove unavailable jobs If a job is deployed an the singlenode job is canceled the job name cannot neither be reused nor destroyed. See screenshots.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Remove unavailable jobs if a job is deployed an the singlenode job is canceled the job name cannot neither be reused nor destroyed see screenshots was most similar to the text Ensure job definitions escaped ui using definition aaa definition starts ends definition composed job does appear definition page and similar to the text Ui implement job job definitions page job available repository job correctly implement job given job page indicate job definition and similar to the text Add caching likely involve module identity part key (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
308;Add code coverage to gradle build Build should be able to generate code coverage reports. After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle. http://www.gradle.org/docs/current/userguide/jacoco_plugin.html;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add code coverage to gradle build build should be able to generate code coverage reports after a quick tour of the intertubes it seems that jacoco is a well maintained project and has first class support inside gradle http://wwwgradleorg/docs/current/userguide/jacoco_pluginhtml was most similar to the text Resolve issues custom based batch jobs several issues making hard impossible create batch jobs use pig hive technologies supported spring apache project need make corresponding dependencies available and similar to the text Tap throws exception tap throws exception local mode resolve reference bean setting constructor argument nested exception bean named defined also fails using and similar to the text Hdfs sink support file naming strategy distinguish file currently written completed files file process written customized suffix added name eg temp once file closed suffix removed another value - default value dependent serialization format used customized (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
309;Set fetch size when reading from database in pre-packaged jobs When running a query against a large dataset JDBC will attempt to load the entire result set into memory by default. If this isn't desired (which would be the case in the prepackaged jobs) you can set the fetchSize on the JdbcCursorItemReader to set the number of rows to return with each fetch. It is good practice to make this match the commit interval. If the fetch size is not set with large datasets the stack blows with an OutOfMemoryException.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Set fetch size when reading from database in pre-packaged jobs when running a query against a large dataset jdbc will attempt to load the entire result set into memory by default if this isn't desired (which would be the case in the prepackaged jobs) you can set the fetchsize on the jdbccursoritemreader to set the number of rows to return with each fetch it is good practice to make this match the commit interval if the fetch size is not set with large datasets the stack blows with an outofmemoryexception was most similar to the text Spring - handling sink failures sink fails whatever reason possible handle say sending payload error queue later processing jdbc mongo sink fails due database connectivity loss modules designed certain principles contracts handle failures and similar to the text Error message memory leak eg error - web application appears started thread named abandoned connection cleanup thread has failed stop likely create memory leak thread name may different and similar to the text Disable collection object conversion provides collection object conversion produce first item target type matches results unfortunate side effect list return tuple misleading case preferable treat error argument tuple (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
310;As a user I want to have a documentation that shows how to configure multiple topics with Kafka source module.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i want to have a documentation that shows how to configure multiple topics with kafka source module is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.04;2.2;1.0;1.67;0;1;1;1
311;As a user I'd like to have the option to extend compression support so that I can override the defaults and customize as needed. Follow-up from this PR: https://github.com/spring-projects/spring-xd/pull/1346;3;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have the option to extend compression support so that i can override the defaults and customize as needed follow-up from this pr: https://githubcom/spring-projects/spring-xd/pull/1346 was most similar to the text Update processors transform section use shell commands instead curl see and similar to the text Need set small commit level acceptance tests default commit level jobs 1000 vs original 100 tests sporadically fail need set tests small value and similar to the text Add docs job item processor brief introduction topic linking relevant spring batch documentation (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
312;Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options. Redis can run on the same node as the benchmark.;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create microbenchmark for performace of redis and jdbc based aggregators would be good to have a general feel for the general performance of these two options redis can run on the same node as the benchmark is a user story, and is worth 3 story points. This was predicted because it is most similar to the text User id like enable ha enable custom configuration details and similar to the text Scd developer id like add support deploy yarn app hdfs automatically orchestrate overall deployment leveraging manifest deploy assets and similar to the text Developer id like isolate tests different project dirt project depend incorrect cp file generation eclipse (and these texts are all user stories with a worth of 3 story points).;0.02;4.38;1.0;6.41;1;0;1;0
313;Remove org. in hsqldb dependency;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Remove org in hsqldb dependency was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;2.51;1.0;1.67;0;1;1;1
314;Spring XD processor module classloader issue: ClassNotFoundException See http://stackoverflow.com/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Spring xd processor module classloader issue: classnotfoundexception see http://stackoverflowcom/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like troubleshoot performance issues rabbit message implementation isolate bottleneck fix appropriate and similar to the text Continuation like investigate spark develop poc identify best appropriate design implementation and similar to the text User id like separate file list deployment manifest properties include part stream definition (and these texts are all user stories with a worth of 8 story points).;0.02;7.7;0.0;1.67;0;0;1;0
315;Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase such as: * RESTModuleType and ModuleType enums * ModuleOption and DetailedModuleDefinitionResource.Option;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create project for model that is common between client and server this would elminate dependencies that are currently in the codebase such as: * restmoduletype and moduletype enums * moduleoption and detailedmoduledefinitionresourceoption is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Developer id like simplified ux around parameters escape parameter scope also test job identify ux differences and similar to the text Developer id like continue poc focused design spi generally applicable lattice receptor api one implementation option (and these texts are all user stories with a worth of 8 story points).;0.1;8.62;1.0;8.33;1;0;1;0
316;As a QA I'd like to include acceptance test coverage for _throughput-sampler_ sink module so that I can validate the functionality as part of every CI build.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a qa i'd like to include acceptance test coverage for _throughput-sampler_ sink module so that i can validate the functionality as part of every ci build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.01;8.62;1.0;8.33;1;1;1;1
317;Kafka Sink: Support async Producer The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss). Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element {{async=$\{async\}}};0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Kafka sink: support async producer the kafka sink supports properties for an async producer (eg {{queuebufferingmaxms}} ) but you cannot enable such a producer (only {{sync}} ) async producers batch messages (at the risk of message loss) add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element {{async=$\{async\}}} and the most similar text Scd developer id like implement operation single jvm use target running stream details note prerequisite determine consistent strategy jobs streams does not exceed the minimum threshold of 75%.;0.05;8.62;1.0;8.33;1;0;0;0
318;Assess XD Fails to connect to remote Redis Instance Deployment: Admin/Container Redis as data transport SHA: 45e1beb [Description] In the case that the Redis is not running locally XD cannot connect to the Redis instance even though the environment variable spring_redis_host has been set. [Steps to reproduce] * Shutdown local instance of Redis. * For both the admin and container execute the command prior to running the instances: ** export spring_redis_host=YourRedisHost * Start admin and container instances * deploy a simple stream ** You will see the following error: 13:56:59647 ERROR task-scheduler-9 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter@6a1f1d12] org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84) org.springframework.xd.dirt.integration.redis.RedisMessageBus$SendingHandler.handleMessageInternal(RedisMessageBus.java:235) org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255) org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317) org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113) org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97) org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) com.sun.proxy.$Proxy57.send(Unknown Source) org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114) org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44) org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93) org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:110) org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205) org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55) org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149) org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146) org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284) org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52) org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49) org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278) org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) java.util.concurrent.FutureTask.run(FutureTask.java:262) java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:97) org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:143) org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:41) org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:85) org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:55) org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169) org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149) org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84) org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:68) org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:60) org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter.handleMessageInternal(RedisQueueOutboundChannelAdapter.java:109) org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) ... 43 more Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool redis.clients.util.Pool.getResource(Pool.java:42) org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:90) ... 54 more Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused redis.clients.jedis.Connection.connect(Connection.java:142) redis.clients.jedis.BinaryClient.connect(BinaryClient.java:75) redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1724) redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65) org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:819) org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:429) org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:360) redis.clients.util.Pool.getResource(Pool.java:40) ... 55 more Caused by: java.net.ConnectException: Connection refused java.net.PlainSocketImpl.socketConnect(Native Method) java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339) java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200) java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182) java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) java.net.Socket.connect(Socket.java:579) redis.clients.jedis.Connection.connect(Connection.java:137) ... 62 more;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Assess xd fails to connect to remote redis instance deployment: admin/container redis as data transport sha: 45e1beb [description] in the case that the redis is not running locally xd cannot connect to the redis instance even though the environment variable spring_redis_host has been set [steps to reproduce] * shutdown local instance of redis * for both the admin and container execute the command prior to running the instances: ** export spring_redis_host=yourredishost * start admin and container instances * deploy a simple stream ** you will see the following error: 13:56:59647 error task-scheduler-9 handlerlogginghandler:145 - orgspringframeworkmessagingmessagehandlingexception: error occurred in message handler [orgspringframeworkintegrationredisoutboundredisqueueoutboundchanneladapter@6a1f1d12] orgspringframeworkintegrationhandlerabstractmessagehandlerhandlemessage(abstractmessagehandlerjava:84) orgspringframeworkxddirtintegrationredisredismessagebus$sendinghandlerhandlemessageinternal(redismessagebusjava:235) orgspringframeworkintegrationhandlerabstractmessagehandlerhandlemessage(abstractmessagehandlerjava:78) orgspringframeworkintegrationdispatcherabstractdispatchertryoptimizeddispatch(abstractdispatcherjava:116) orgspringframeworkintegrationdispatcherunicastingdispatcherdodispatch(unicastingdispatcherjava:101) orgspringframeworkintegrationdispatcherunicastingdispatcherdispatch(unicastingdispatcherjava:97) orgspringframeworkintegrationchannelabstractsubscribablechanneldosend(abstractsubscribablechanneljava:77) orgspringframeworkintegrationchannelabstractmessagechannelsend(abstractmessagechanneljava:255) orgspringframeworkintegrationchannelabstractmessagechannelsend(abstractmessagechanneljava:223) sunreflectnativemethodaccessorimplinvoke0(native method) sunreflectnativemethodaccessorimplinvoke(nativemethodaccessorimpljava:57) sunreflectdelegatingmethodaccessorimplinvoke(delegatingmethodaccessorimpljava:43) javalangreflectmethodinvoke(methodjava:606) orgspringframeworkaopsupportaoputilsinvokejoinpointusingreflection(aoputilsjava:317) orgspringframeworkaopframeworkreflectivemethodinvocationinvokejoinpoint(reflectivemethodinvocationjava:190) orgspringframeworkaopframeworkreflectivemethodinvocationproceed(reflectivemethodinvocationjava:157) orgspringframeworkintegrationmonitordirectchannelmetricsmonitorsend(directchannelmetricsjava:113) orgspringframeworkintegrationmonitordirectchannelmetricsdoinvoke(directchannelmetricsjava:97) orgspringframeworkintegrationmonitordirectchannelmetricsinvoke(directchannelmetricsjava:91) orgspringframeworkaopframeworkreflectivemethodinvocationproceed(reflectivemethodinvocationjava:179) orgspringframeworkaopframeworkjdkdynamicaopproxyinvoke(jdkdynamicaopproxyjava:207) comsunproxy$proxy57send(unknown source) orgspringframeworkmessagingcoregenericmessagingtemplatedosend(genericmessagingtemplatejava:114) orgspringframeworkmessagingcoregenericmessagingtemplatedosend(genericmessagingtemplatejava:44) orgspringframeworkmessagingcoreabstractmessagesendingtemplatesend(abstractmessagesendingtemplatejava:93) orgspringframeworkintegrationendpointsourcepollingchanneladapterhandlemessage(sourcepollingchanneladapterjava:110) orgspringframeworkintegrationendpointabstractpollingendpointdopoll(abstractpollingendpointjava:205) orgspringframeworkintegrationendpointabstractpollingendpointaccess$000(abstractpollingendpointjava:55) orgspringframeworkintegrationendpointabstractpollingendpoint$1call(abstractpollingendpointjava:149) orgspringframeworkintegrationendpointabstractpollingendpoint$1call(abstractpollingendpointjava:146) orgspringframeworkintegrationendpointabstractpollingendpoint$poller$1run(abstractpollingendpointjava:284) orgspringframeworkintegrationutilerrorhandlingtaskexecutor$1run(errorhandlingtaskexecutorjava:52) orgspringframeworkcoretasksynctaskexecutorexecute(synctaskexecutorjava:50) orgspringframeworkintegrationutilerrorhandlingtaskexecutorexecute(errorhandlingtaskexecutorjava:49) orgspringframeworkintegrationendpointabstractpollingendpoint$pollerrun(abstractpollingendpointjava:278) orgspringframeworkschedulingsupportdelegatingerrorhandlingrunnablerun(delegatingerrorhandlingrunnablejava:54) orgspringframeworkschedulingconcurrentreschedulingrunnablerun(reschedulingrunnablejava:81) javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) javautilconcurrentfuturetaskrun(futuretaskjava:262) javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskaccess$201(scheduledthreadpoolexecutorjava:178) javautilconcurrentscheduledthreadpoolexecutor$scheduledfuturetaskrun(scheduledthreadpoolexecutorjava:292) javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) javalangthreadrun(threadjava:745) caused by: orgspringframeworkdataredisredisconnectionfailureexception: cannot get jedis connection nested exception is redisclientsjedisexceptionsjedisconnectionexception: could not get a resource from the pool orgspringframeworkdataredisconnectionjedisjedisconnectionfactoryfetchjedisconnector(jedisconnectionfactoryjava:97) orgspringframeworkdataredisconnectionjedisjedisconnectionfactorygetconnection(jedisconnectionfactoryjava:143) orgspringframeworkdataredisconnectionjedisjedisconnectionfactorygetconnection(jedisconnectionfactoryjava:41) orgspringframeworkdatarediscoreredisconnectionutilsdogetconnection(redisconnectionutilsjava:85) orgspringframeworkdatarediscoreredisconnectionutilsgetconnection(redisconnectionutilsjava:55) orgspringframeworkdatarediscoreredistemplateexecute(redistemplatejava:169) orgspringframeworkdatarediscoreredistemplateexecute(redistemplatejava:149) orgspringframeworkdatarediscoreabstractoperationsexecute(abstractoperationsjava:84) orgspringframeworkdatarediscoredefaultlistoperationsleftpush(defaultlistoperationsjava:68) orgspringframeworkdatarediscoredefaultboundlistoperationsleftpush(defaultboundlistoperationsjava:60) orgspringframeworkintegrationredisoutboundredisqueueoutboundchanneladapterhandlemessageinternal(redisqueueoutboundchanneladapterjava:109) orgspringframeworkintegrationhandlerabstractmessagehandlerhandlemessage(abstractmessagehandlerjava:78)  43 more caused by: redisclientsjedisexceptionsjedisconnectionexception: could not get a resource from the pool redisclientsutilpoolgetresource(pooljava:42) orgspringframeworkdataredisconnectionjedisjedisconnectionfactoryfetchjedisconnector(jedisconnectionfactoryjava:90)  54 more caused by: redisclientsjedisexceptionsjedisconnectionexception: javanetconnectexception: connection refused redisclientsjedisconnectionconnect(connectionjava:142) redisclientsjedisbinaryclientconnect(binaryclientjava:75) redisclientsjedisbinaryjedisconnect(binaryjedisjava:1724) redisclientsjedisjedisfactorymakeobject(jedisfactoryjava:65) orgapachecommonspool2implgenericobjectpoolcreate(genericobjectpooljava:819) orgapachecommonspool2implgenericobjectpoolborrowobject(genericobjectpooljava:429) orgapachecommonspool2implgenericobjectpoolborrowobject(genericobjectpooljava:360) redisclientsutilpoolgetresource(pooljava:40)  55 more caused by: javanetconnectexception: connection refused javanetplainsocketimplsocketconnect(native method) javanetabstractplainsocketimpldoconnect(abstractplainsocketimpljava:339) javanetabstractplainsocketimplconnecttoaddress(abstractplainsocketimpljava:200) javanetabstractplainsocketimplconnect(abstractplainsocketimpljava:182) javanetsockssocketimplconnect(sockssocketimpljava:392) javanetsocketconnect(socketjava:579) redisclientsjedisconnectionconnect(connectionjava:137)  62 more and the most similar text Sources fail deploying yarn getting info - path cache event info - deploying module file stream info - deploying module file file group null null index 1 type sink parameters true mode replace children info - path cache event info - deploying module stream info - deploying module group null null index 0 type source parameters children warn - exception context initialization - cancelling refresh attempt error bean name defined class path resource resolve reference bean setting constructor argument nested exception error bean name defined class path resource bean instantiation constructor failed nested exception failed instantiate constructor exception nested exception error bean name defined class path resource bean instantiation constructor failed nested exception failed instantiate constructor exception nested exception 39 failed instantiate constructor exception nested exception 48 method 50 method 63 error - application startup failed error bean name defined class path resource resolve reference bean setting constructor argument nested exception error bean name defined class path resource bean instantiation constructor failed nested exception failed instantiate constructor exception nested exception error bean name defined class path resource bean instantiation constructor failed nested exception failed instantiate constructor exception nested exception 39 failed instantiate constructor exception nested exception 48 method does not exceed the minimum threshold of 75%.;0.02;2.05;1.0;1.67;0;1;0;0
319;Document direct binding As an s-c-d user I'd like to refer to documentation on direct binding so I can use it as a reference to deploy a stream that includes directly bound modules. Example: {code} java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-1.0.0.BUILD-SNAPSHOT.jar --modules=org.springframework.cloud.stream.module:time-source:1.0.0.BUILD-SNAPSHOTorg.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOTorg.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT --args.0.fixedDelay=7 --args.1.expression='payload.contains(6)' --aggregate=true --spring.cloud.stream.bindings.output=filtered {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Document direct binding as an s-c-d user i'd like to refer to documentation on direct binding so i can use it as a reference to deploy a stream that includes directly bound modules example: {code} java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-100build-snapshotjar --modules=orgspringframeworkcloudstreammodule:time-source:100build-snapshotorgspringframeworkcloudstreammodule:filter-processor:100build-snapshotorgspringframeworkcloudstreammodule:filter-processor:100build-snapshot --args0fixeddelay=7 --args1expression='payloadcontains(6)' --aggregate=true --springcloudstreambindingsoutput=filtered {code} and the most similar text Create benchmarking application demonstrate high performance message processing application live repository stream documented run benchmark made easy execute use generate traffic order saturate stream does not exceed the minimum threshold of 75%.;0.07;8.62;1.0;8.33;1;1;0;0
320;As a developer I'd like to port {{rich-gauge}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i'd like to port {{rich-gauge}} module from xd to s-c-s repo so i can use it as {{sink}} module to build streaming pipeline was most similar to the text Upgrade provides flavors commonly used make use and similar to the text Colors job definition tab different tabs table background color job definition tab green tabs white background consistent and similar to the text Tuple support storing nested tuples nested tuple structures supported index name (and these texts are not user stories).;0.02;8.01;1.0;8.33;1;1;1;1
321;Log Hadoop Distro and ZK client connect info on Container startup It would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Log hadoop distro and zk client connect info on container startup it would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up was most similar to the text Fix rest endpoint security security container admin server wont able fetch message rates deployed modules container rest endpoint needs fixed and similar to the text Scs - replace binder xml configuration create configuration must support replacing default codec implementation and similar to the text Create rest api stopping job executions adopted functionality spring batch admin include test framework style tests delete - stop job executions (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
322;As a developer I would like to connect to the broker that hosts the Rabbit queue so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i would like to connect to the broker that hosts the rabbit queue so i can connect to a rabbit cluster that's setup for ha/ft perhaps consider having this feature natively supported in spring amqp itself is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively (and these texts are all user stories with a worth of 8 story points).;0.02;5.83;1.0;8.33;1;1;1;1
323;As a user I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically. *Spike scope*: - Study simple consumer API functionality - Document findings approach and next steps;5;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to use kafka source through simple consumer api (as opposed to high-level) so that i can gain full control to offsets and partition assignment deterministically *spike scope*: - study simple consumer api functionality - document findings approach and next steps is a user story, and is worth 1 story points. This was predicted because it is most similar to the text Build manager id like schedule ci builds windows verify scope isolate remaining test failures experiment new ami images solid infrastructure fix failing tests and similar to the text User id like see date logs troubleshoot issues occurred specific day time property needs adjusted and similar to the text User id like refer wiki create job partitions turn expects columns explicitly included job definition also beneficial call-out sql metadata options mutually exclusive following logic needs documented use columns using partition column boolean return return true code (and these texts are all user stories with a worth of 1 story points).;0.03;2.0;1.0;1.67;0;1;1;1
324;Create an easier short-cut for launching adhoc Batch Jobs Currently for adhoc launching of Batch jobs you have to use: {code} stream create --name myTriggerStream --definition trigger > job:helloSpringXD {code} For renewed triggering of the job you have to undeploy and then redeploy the job. It would be nice if there was possibly a slightly simpler way of doing this. Just FYI - As a different approach you can also use the HTTP source: {source} job create --name myjob --definition myjob stream create --name myjobhttp --definition http > job:http http post --data {} {source};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create an easier short-cut for launching adhoc batch jobs currently for adhoc launching of batch jobs you have to use: {code} stream create --name mytriggerstream --definition trigger > job:hellospringxd {code} for renewed triggering of the job you have to undeploy and then redeploy the job it would be nice if there was possibly a slightly simpler way of doing this just fyi - as a different approach you can also use the http source: {source} job create --name myjob --definition myjob stream create --name myjobhttp --definition http > job:http http post --data {} {source} was most similar to the text Needs bounded task 11 channels run high volume environments might occur topic thread overwhelm system threads add local configuration limit thread pool used queue tasks threads available setting and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks and similar to the text Admin servers write streams delete also enable removal any code state written data node stream level eg state least need support boolean flag true leader admin deploy modules stream across available containers (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
325;As a Spring XD developer I'd like to port {{splitter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to port {{splitter}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Spring developer id like port tcp module scs use source module build streaming pipeline and similar to the text Spring developer id like port script module scs use processor module build streaming pipeline and similar to the text Spring developer id like port router module scs use sink module build streaming pipeline (and these texts are all user stories with a worth of 2 story points).;0.14;2.0;1.0;1.67;0;1;1;1
326;Update support for Hortonworks to HDP 2.3.2 We currently support HDP 2.3.0. The most recent HDP version is 2.3.2. This latest HDP release also changes Spark version to 1.4.1.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update support for hortonworks to hdp 232 we currently support hdp 230 the most recent hdp version is 232 this latest hdp release also changes spark version to 141 was most similar to the text Ui user view job properties specified job definition was well job parameters was and similar to the text Provide module build upload module provide maven execute module upload rest upload install module spring eg and similar to the text Document ability use flows streams test document eg http file (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
327;Test sink module in isolation Register the module under test Send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Test sink module in isolation register the module under test send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink was most similar to the text Use instance pooling reduce instantiation overhead and similar to the text Vary producer threads send messages 1000 bytes generator vary number producer threads measure rate calculate data transfer rate number threads 2 4 8 and similar to the text Parser able handle parameter name hyphen embedded right treats new parameter start fails (and these texts are not user stories).;0.01;2.04;1.0;1.67;0;1;1;1
328;As a user I should not be allowed to create a custom module with a _reserved_ keywords so that I it will avoid confusions from seeing duplicate strings in deployment manifest. *Example:* We would like to avoid a _custom_ module name of *producer* to eliminate the confusion below: {code} xd:>stream deploy --name test1 --properties module.producer.producer.deliveryMode= PERSISTENTmodule.log.criteria=groups.contains('group1') {code} [List of available reserved keywords|https://github.com/spring-projects/spring-xd/wiki/Deployment#deployment-properties];4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i should not be allowed to create a custom module with a _reserved_ keywords so that i it will avoid confusions from seeing duplicate strings in deployment manifest *example:* we would like to avoid a _custom_ module name of *producer* to eliminate the confusion below: {code} xd:>stream deploy --name test1 --properties moduleproducerproducerdeliverymode= persistentmodulelogcriteria=groupscontains('group1') {code} [list of available reserved keywords|https://githubcom/spring-projects/spring-xd/wiki/deployment#deployment-properties] was most similar to the text Update use test dependent external system success times service running slower test expects test fails unnecessarily once merged utilize feature wait result file stream written wait time twitter extended 1 min make search string tests fail consistently present and similar to the text Using transform shell displays error trying create stream example stream create definition transform deploy shell displays command failed error options module transform type processor valid script expression options mutually exclusive get following error and similar to the text Add named channel api need abstraction place retrieve messages named channel right implementation agnostic way quite useful integration tests streams eg focussed tests resorting nonessential sinks sources etc - eg code router code (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
329;As a developer I'd like to create a example to demonstrate JDBC to HDFS data movement.;5;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to create a example to demonstrate jdbc to hdfs data movement is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.08;2.2;1.0;1.67;0;1;1;1
330;As a s-c-d developer I'd like to collaborate with Boot engineering team and derive a strategy for module metadata via {{@ConfigurationProperties}} so I can implement the functionality to support {{shell}} {{autocompletion}} {{flo}} and {{ascii}} documentation in _spring-cloud-data_. Eric's [gap analysis|https://docs.google.com/document/d/1A-9RpgSNL6SXD61q9eW2YRkrkn3tXk09rdkx7eCKlxY/edit#] document captures all the specifics in detail.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a s-c-d developer i'd like to collaborate with boot engineering team and derive a strategy for module metadata via {{@configurationproperties}} so i can implement the functionality to support {{shell}} {{autocompletion}} {{flo}} and {{ascii}} documentation in _spring-cloud-data_ eric's [gap analysis|https://docsgooglecom/document/d/1a-9rpgsnl6sxd61q9ew2yrkrkn3txk09rdkx7ecklxy/edit#] document captures all the specifics in detail was most similar to the text Documentation source has conflicting information according documentation one options available source transport listed default sample definition provide yet appears default tcp two match might also useful possible values transport listed assume tcp udp and similar to the text Create benchmarking application demonstrate high performance message processing application live repository stream documented run benchmark made easy execute use generate traffic order saturate stream and similar to the text Needs bounded task 11 channels run high volume environments might occur topic thread overwhelm system threads add local configuration limit thread pool used queue tasks threads available setting (and these texts are not user stories).;0.05;2.41;1.0;1.67;0;1;1;1
331;Investigate setting up performance test environment on cloud providers Use a baseline DIRT infrastructure to measure throughput HA and scalability for various payload sizes. Depends on testing infrastructure setup configuration and availability.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Investigate setting up performance test environment on cloud providers use a baseline dirt infrastructure to measure throughput ha and scalability for various payload sizes depends on testing infrastructure setup configuration and availability was most similar to the text Ui shell remove any usage rest endpoints using json notation accessing rest endpoint using json file extension causes maintenance issues authorization rules necessary remove any usage admin ui shell time json endpoint deprecated removed ultimately and similar to the text Module info jdbc sink jobs unreadable module info command renders text pretty much unreadable reasonably sized screen see attached screen shot also jdbc pool settings mixed module settings making confusing list options does jobs and similar to the text Create batch job uses shell copy multiple files hdfs local directory inverse require custom inputoutput (and these texts are not user stories).;0.02;2.0;1.0;1.67;0;1;1;1
332;Remove container entry in Redis when the application context event to shutdown the container is fired;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Remove container entry in redis when the application context event to shutdown the container is fired was most similar to the text Initialize spring batch schema test run spring batch database has already test run and similar to the text Add integration tests job need add integration tests job and similar to the text Generate doc module options generate fragments modules options way date (and these texts are not user stories).;0.02;3.24;1.0;1.67;0;1;1;1
333;Update Creating a Source Module section to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update creating a source module section to use shell commands instead of curl see http://staticspringsourceorg/spring-xd/docs/10x-snapshot/reference/html/#_test_the_deployed_module was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Integrate code coverage reports ci process sure best done sonar sonar build plan nightly one frequent one master open question want fail build code coverage levels and similar to the text Remove main dirt driver present dirts present modules though blocked shortcoming described (and these texts are not user stories).;0.02;4.48;1.0;7.9;1;1;1;1
334;Create JSON to tab-delimited text transformer script We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Create json to tab-delimited text transformer script we need a generic script that can do json to tab-delimited text transformation for data written to hdfs/hawq external tables users should be able to specify columns/fields to be included was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Build script creates executable server artifact application good starting point main server host si based modules ingestion example and similar to the text Update sinks tcp section use shell commands instead curl see (and these texts are not user stories).;0.02;6.15;1.0;8.33;1;1;1;1
335;Fix JobCommandTests' verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this: String id = jobExecutions.getRows().get(0).getValue(1) displayJobExecution(id) It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Fix jobcommandtests' verification of shell result table rows using specific index some of the tests in jobcommandtests use the verification of shell command results table row on a specific row (mostly first row) like this: string id = jobexecutionsgetrows()get(0)getvalue(1) displayjobexecution(id) it is possible that the list of table rows may have the intended row in different order this poses inconsistent test failures was most similar to the text Sample app process analyze network packets create example application demonstrates processing stream network packets potential scenario detection ongoing cyber attacks scanning tls packets abuse ssl vulnerability heart bleed library help and similar to the text Investigate module leakage see report happen module holds classes hold knows integration test verifies nice tricky and similar to the text Ui unresponsive time chrome ui interface stream creation stops responding time starts working once browser history cookies etc cleaned drop stops working unable look edit module properties connecting different modules work either drag drop operations still work command line stream creation still works facing issues thanks (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
336;Update Spring Integration Splunk Extension to 1.1 GA;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Update spring integration splunk extension to 11 ga is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
337;Update Creating a Sink Module section to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.x-SNAPSHOT/reference/html/#_test_the_deployed_module_3;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update creating a sink module section to use shell commands instead of curl see http://staticspringsourceorg/spring-xd/docs/10x-snapshot/reference/html/#_test_the_deployed_module_3 was most similar to the text Additional rest endpoint working security see following error admin ui get forbidden and similar to the text Integrate code coverage reports ci process sure best done sonar sonar build plan nightly one frequent one master open question want fail build code coverage levels and similar to the text Remove main dirt driver present dirts present modules though blocked shortcoming described (and these texts are not user stories).;0.02;4.94;1.0;8.33;1;1;1;1
338;As a s-c-d developer I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader so I have an approach to handle external libraries required by OOTB modules.;4;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to experiment how do we resolve and then add module dependent jar's to boot loader so i have an approach to handle external libraries required by ootb modules is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Developer id like simplified ux around parameters escape parameter scope also test job identify ux differences and similar to the text Developer id like continue poc focused design spi generally applicable lattice receptor api one implementation option (and these texts are all user stories with a worth of 8 story points).;0.1;8.55;1.0;8.33;1;1;1;1
339;As a developer I'd like to move 'input/output type conversion' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to move 'input/output type conversion' from spring xd repo into spring-bus so i can update spring xd to inherit the features/functionalities via maven dependency is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like ability configure acls restrict access resources accessed admin ui examples create streams destroy streams view streams defaults and similar to the text User id like use use environments run scope complete remaining deployment properties work and similar to the text Developer someone easily deploy spark streaming module developed using (and these texts are all user stories with a worth of 8 story points).;0.05;8.62;1.0;8.33;1;1;1;1
340;Add deploy/undeploy/destroy 'all' commands for all applicable resources (streams tap job & trigger);0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add deploy/undeploy/destroy 'all' commands for all applicable resources (streams tap job & trigger) is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like upgrade kafka leverage latest features order test performance characteristics and similar to the text Developer id like benchmark rabbit performance use results reference setup cluster and similar to the text User id like option setup batching ingest data batches opposed (and these texts are all user stories with a worth of 8 story points).;0.02;2.51;1.0;1.67;0;0;1;0
341;Update build to use SHDP 2.2.0.RC1;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update build to use shdp 220rc1 was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;8.48;1.0;8.33;1;1;1;1
342;As a s-c-d user I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time.;1;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d user i should be prevented from creating streams with duplicate name i'd expect streams to have unique names all the time is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Users able execute sql processor job statement and similar to the text Developer id like add load sink module measure received throughput and similar to the text User id like option ack messages guarantee sent successful (and these texts are all user stories with a worth of 3 story points).;0.03;5.39;1.0;1.67;0;1;1;1
343;Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server was most similar to the text Add back classifier build target add back classifier build target - was was accidentally removed and similar to the text Initialize spring batch schema test run spring batch database has already test run and similar to the text Update analytics gauge section use shell commands instead curl (and these texts are not user stories).;0.02;8.62;1.0;8.33;1;1;1;1
344;As a s-c-d developer I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data] so I can build the project continuously on every commits.;4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a s-c-d developer i'd like to setup ci infrastructure for [s-c-d repo|https://githubcom/spring-cloud/spring-cloud-data] so i can build the project continuously on every commits was most similar to the text Add server info banner admin currently has shiny banner container has importantly does say port listening transport used etc and similar to the text Disable setting set false contexts getting destroyed properly cases prevents running successfully and similar to the text Eliminate package tangle see (and these texts are not user stories).;0.04;8.55;1.0;8.33;1;1;1;1
345;As a developer I'd like to host/read Python script (file) from HDFS so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.;5;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a developer i'd like to host/read python script (file) from hdfs so i can use the shell processor in xd (on cf) to delegate data science functionality to py runtime and receive the feedback back in xd was most similar to the text Add job integration tests using implementations uses problem was discovered manual integration test was executed minimum run implementations and similar to the text Exclude final includes need additional jars modules extensions and similar to the text Verify platform compatibility versions dependencies need make sure dependency using spring io platform dependencies one scenario dependency missing (and these texts are not user stories).;0.05;4.38;1.0;1.74;0;1;1;1
346;Ambari plugin doesn't work with security_enabled It seems like springxd_shell will pull jhs principal and keytab from mapred-site.xml. When springxd_shell is installed in edge node Amabri returns can't find jhs keytab and failed. Details [here|https://github.com/spring-projects/spring-xd-ambari/issues/8].;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Ambari plugin doesn't work with security_enabled it seems like springxd_shell will pull jhs principal and keytab from mapred-sitexml when springxd_shell is installed in edge node amabri returns can't find jhs keytab and failed details [here|https://githubcom/spring-projects/spring-xd-ambari/issues/8] was most similar to the text Retrieve information rich gauge part see get rid so-called service layer analytics project much right logic better live handler imo rest controllers depend cases and similar to the text Update documentation related transport eg need update section maybe remove mentions control replace any mentions transport cmd line arg property and similar to the text Incorrect message used reason message bound incorrect transport different set container log info main - transport rabbit info - test (and these texts are not user stories).;0.02;2.03;1.0;1.67;0;1;1;1
347;As a developer I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}} so I can refactor in order to improve performance throughput.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like revisit the design to determine the necessity for _id_ and _timestamp_ attributes in {{tuple}} so i can refactor in order to improve performance throughput is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.1;8.15;1.0;8.33;1;1;1;1
348;Create shell integration tests for job lifeycle creating job defs deploying jobs undeploying jobs deleting job defs;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create shell integration tests for job lifeycle creating job defs deploying jobs undeploying jobs deleting job defs is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option disable db requirement setup use dirt stream processing requirement and similar to the text Developer id like partitions scale containers bring running reestablish dynamic partitions and similar to the text User id like push custom module built rest api install custom module cluster (and these texts are all user stories with a worth of 8 story points).;0.02;8.16;1.0;8.33;1;0;1;0
349;Create Acceptance tests for Container Groups * Create infrastructure to retrieve container data. * Create infrastructure to retrieve Stream data and the associated container * Create tests that verify default behavior without group * Create tests that verify behavior with sink belonging to specific group * Create tests that verify behavior with processor belonging to specific group * Also generate tests for the scenarios above where the count >1;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Create acceptance tests for container groups * create infrastructure to retrieve container data * create infrastructure to retrieve stream data and the associated container * create tests that verify default behavior without group * create tests that verify behavior with sink belonging to specific group * create tests that verify behavior with processor belonging to specific group * also generate tests for the scenarios above where the count >1 is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like integrate spring data repository backed kafka leverage benefits local data affinity order run stateful stream processing logic and similar to the text User id like module consume database changes event streams incrementally synchronize real-time db updates destinations brokers db etc and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics (and these texts are all user stories with a worth of 8 story points).;0.02;2.0;1.0;1.67;0;0;1;0
350;As a Spring XD developer I'd like to move {{mongo}} module from XD to s-c-s repo so I can use it as sink to build streaming pipeline.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to move {{mongo}} module from xd to s-c-s repo so i can use it as sink to build streaming pipeline is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Spring developer id like move cassandra module scs use sink build streaming pipeline and similar to the text Lead id like review current architecture design specs address any foundation level gaps and similar to the text User id like option sink perform indexing search server (and these texts are all user stories with a worth of 5 story points).;0.08;8.55;1.0;8.33;1;1;1;1
351;Launching XD admin fails with ZK holding existing stream data Following exception is thrown when starting XD admin withe ZK holding the stream data: 2015-03-23 17:21:13831 1.2.0.SNAP ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception java.lang.NullPointerException at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:822) at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:896) at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:157) at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:56) at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:654) at org.springframework.xd.dirt.stream.dsl.ChannelNode.resolve(ChannelNode.java:144) at org.springframework.xd.dirt.stream.dsl.SourceChannelNode.resolve(SourceChannelNode.java:54) at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:125) at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:110) at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:121) at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84) at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101) at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.recalculateStreamStates(DefaultDeploymentStateRecalculator.java:96) at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.onSupervisorElected(DefaultDeploymentStateRecalculator.java:182) at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:468) at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443) at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745);0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Launching xd admin fails with zk holding existing stream data following exception is thrown when starting xd admin withe zk holding the stream data: 2015-03-23 17:21:13831 120snap error leaderselector-0 leaderleaderselector - the leader threw an exception javalangnullpointerexception at comfasterxmljacksoncorejsonfactorycreateparser(jsonfactoryjava:822) at comfasterxmljacksondatabindobjectreaderreadvalue(objectreaderjava:896) at orgspringframeworkxddirtstreamzookeeperzookeeperstreamdefinitionrepositoryfindone(zookeeperstreamdefinitionrepositoryjava:157) at orgspringframeworkxddirtstreamzookeeperzookeeperstreamdefinitionrepositoryfindone(zookeeperstreamdefinitionrepositoryjava:56) at orgspringframeworkxddirtstreamdslstreamconfigparserlookupstream(streamconfigparserjava:654) at orgspringframeworkxddirtstreamdslchannelnoderesolve(channelnodejava:144) at orgspringframeworkxddirtstreamdslsourcechannelnoderesolve(sourcechannelnodejava:54) at orgspringframeworkxddirtstreamdslstreamnoderesolve(streamnodejava:125) at orgspringframeworkxddirtstreamdslstreamconfigparserparse(streamconfigparserjava:110) at orgspringframeworkxddirtstreamxdstreamparserparse(xdstreamparserjava:121) at orgspringframeworkxddirtstreamstreamfactorycreatestream(streamfactoryjava:84) at orgspringframeworkxddirtserveradmindeploymentzkdeploymentloaderloadstream(deploymentloaderjava:101) at orgspringframeworkxddirtserveradmindeploymentzkdefaultdeploymentstaterecalculatorrecalculatestreamstates(defaultdeploymentstaterecalculatorjava:96) at orgspringframeworkxddirtserveradmindeploymentzkdefaultdeploymentstaterecalculatoronsupervisorelected(defaultdeploymentstaterecalculatorjava:182) at orgspringframeworkxddirtserveradmindeploymentzkdeploymentsupervisor$leaderlistenertakeleadership(deploymentsupervisorjava:468) at orgapachecuratorframeworkrecipesleaderleaderselector$wrappedlistenertakeleadership(leaderselectorjava:536) at orgapachecuratorframeworkrecipesleaderleaderselectordowork(leaderselectorjava:398) at orgapachecuratorframeworkrecipesleaderleaderselectordoworkloop(leaderselectorjava:443) at orgapachecuratorframeworkrecipesleaderleaderselectoraccess$100(leaderselectorjava:63) at orgapachecuratorframeworkrecipesleaderleaderselector$2call(leaderselectorjava:244) at orgapachecuratorframeworkrecipesleaderleaderselector$2call(leaderselectorjava:238) at javautilconcurrentfuturetaskrun(futuretaskjava:262) at javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) at javautilconcurrentfuturetaskrun(futuretaskjava:262) at javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) at javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) at javalangthreadrun(threadjava:745) and the most similar text Fix doc formatting issues noticed issues reviewing documentation sidebar longer was really nice somehow section giving error quote warning line invalid style paragraph appendix warning line include file found quote notice different appendix does not exceed the minimum threshold of 75%.;0.02;2.0;1.0;1.67;0;1;0;0
352;As a developer I'd like to develop a “singlenode�? (in a single JVM) implementation of XD Admin SPI (based on Module Launcher) so I can run data pipeline use-cases locally.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to develop a “singlenode�? (in a single jvm) implementation of xd admin spi (based on module launcher) so i can run data pipeline use-cases locally is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like document performance benchmark results along infrastructure specifics publish blog use reference setting spring cluster and similar to the text Developer id like build isolated use environments run hard requirement running and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.02;8.55;1.0;8.33;1;1;1;1
353;First deploy/launch of Pig job that includes yarn-site.xml file fails Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently. The error is: Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster which indicates that the yarn-site.xml file never made it to the classpath. Un-deploying and re-deploying the job seems to fix the problem.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text First deploy/launch of pig job that includes yarn-sitexml file fails deploying and launching a pig job that contains a yarn-sitexml config file fails on the first deploy after xd starts up this happens consistently the error is: error: could not find or load main class orgapachehadoopmapreducev2appmrappmaster which indicates that the yarn-sitexml file never made it to the classpath un-deploying and re-deploying the job seems to fix the problem is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like rest api point push archive includes custom module definitions configurations manually move set scope spike assess customer requirement brainstorm document options socialize team collect feedback identify phases create new stories and similar to the text Developer id like build data pipeline using kafka message demonstrate capabilities use case consider log aggregation lambda architecture avoid code duplication eliminate tight coupling logic kafka used reliable reprocessing and similar to the text Developer id like study taxi trips based stream trip reports new york city evaluate systems context real-time analytics using spring challenge (and these texts are all user stories with a worth of 8 story points).;0.01;2.0;1.0;1.67;0;0;1;0
354;As a user I'd like to have the option to _compress_ messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip zip compression and decompression.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have the option to _compress_ messages so that i can influence the performance throughput it'd be beneficial to have support for gzip zip compression and decompression is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like define security definitions configure entity rest api specific access policies and similar to the text Developer id like migrate current master branch ci builds instances manage reliably and similar to the text Developer id like fix offset management kafka source module efficiently perform fetch operation given offsets (and these texts are all user stories with a worth of 8 story points).;0.06;8.62;1.0;8.33;1;1;1;1
355;Facing issue while running Spring XD batch job on HDP version 2.3.2.0-2950 ***Version Spring XD Version : spring-xd-1.3.0.RELEASE spring-xd-1.3.0.RELEASE-yarn OS & Version: Linux 2.6.32-431.29.2.el6.x86_64 Java Version: java version 1.7.0_65 ***Description The simple word count map reduce job using spring xd is failing with inline error message. ***Steps to recreate the problem 1. Created a jar for simple word count map reduce job. 2. Created jar using information given in ( http://docs.spring.io/spring-hadoop/docs/2.0.2.RELEASE/reference/html/hadoop.html#hadoop:tasklet ) 3. Once the final jar was ready uploaded using module upload --name test_mr_module --type job --file /home/user/jar/samplemrjob.jar 4. After that created and deployed job using job create --name test_mr_job --definition test_mr_module --deploy 5. Finally launched using job launch test_mr_job which failed with inline error. ***Describe XD Deployment : Distributed Deployment Type : Distributed - YARN ( on AWS EC2 cloud ) Number of xd-admin’s and xd-container’s : 1 Admin and 3 Containers ***Describe Other Components Transport: Redis 3.0.1 ZooKeeper: Version 3.4.6.2.3.2.0-2950 Hadoop deployment Data Platform : Hortonworks HDP 2.3.2.0-2950 RDBMS: MySQL ***Error Message: ***************************************************** 05:29:52673 INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'test_mr_job' 05:29:53655 INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@6e5af900 moduleName = 'test_mr_module' moduleLabel = 'test_mr_module' group = 'test_mr_job' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]] 05:30:24351 ERROR inbound.job:test_mr_job-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step teststep in job test_mr_job java.lang.IllegalArgumentException: Unable to parse '/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework' as a URI check the setting for mapreduce.application.framework.path at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:443) . . . at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:54) at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:323) at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55) at java.lang.Thread.run(Thread.java:745) Caused by: java.net.URISyntaxException: Illegal character in path at index 11: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework at java.net.URI$Parser.fail(URI.java:2848) at java.net.URI$Parser.checkChars(URI.java:3021) at java.net.URI$Parser.parseHierarchical(URI.java:3105) at java.net.URI$Parser.parse(URI.java:3063) at java.net.URI.<init>(URI.java:588) at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:441) *****************************************************;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Facing issue while running spring xd batch job on hdp version 2320-2950 ***version spring xd version : spring-xd-130release spring-xd-130release-yarn os & version: linux 2632-431292el6x86_64 java version: java version 170_65 ***description the simple word count map reduce job using spring xd is failing with inline error message ***steps to recreate the problem 1 created a jar for simple word count map reduce job 2 created jar using information given in ( http://docsspringio/spring-hadoop/docs/202release/reference/html/hadoophtml#hadoop:tasklet ) 3 once the final jar was ready uploaded using module upload --name test_mr_module --type job --file /home/user/jar/samplemrjobjar 4 after that created and deployed job using job create --name test_mr_job --definition test_mr_module --deploy 5 finally launched using job launch test_mr_job which failed with inline error ***describe xd deployment : distributed deployment type : distributed - yarn ( on aws ec2 cloud ) number of xd-admin’s and xd-container’s : 1 admin and 3 containers ***describe other components transport: redis 301 zookeeper: version 3462320-2950 hadoop deployment data platform : hortonworks hdp 2320-2950 rdbms: mysql ***error message: ***************************************************** 05:29:52673 info deploymentspathchildrencache-0 containerdeploymentlistener - deploying job 'test_mr_job' 05:29:53655 info deploymentspathchildrencache-0 containerdeploymentlistener - deploying module [moduledescriptor@6e5af900 modulename = 'test_mr_module' modulelabel = 'test_mr_module' group = 'test_mr_job' sourcechannelname = [null] sinkchannelname = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]] 05:30:24351 error inboundjob:test_mr_job-redis:queue-inbound-channel-adapter1 stepabstractstep - encountered an error executing step teststep in job test_mr_job javalangillegalargumentexception: unable to parse '/hdp/apps/${hdpversion}/mapreduce/mapreducetargz#mr-framework' as a uri check the setting for mapreduceapplicationframeworkpath at orgapachehadoopmapreducejobsubmitteraddmrframeworktodistributedcache(jobsubmitterjava:443)    at orgspringframeworkintegrationredisinboundredisqueuemessagedrivenendpointaccess$300(redisqueuemessagedrivenendpointjava:54) at orgspringframeworkintegrationredisinboundredisqueuemessagedrivenendpoint$listenertaskrun(redisqueuemessagedrivenendpointjava:323) at orgspringframeworkintegrationutilerrorhandlingtaskexecutor$1run(errorhandlingtaskexecutorjava:55) at javalangthreadrun(threadjava:745) caused by: javaneturisyntaxexception: illegal character in path at index 11: /hdp/apps/${hdpversion}/mapreduce/mapreducetargz#mr-framework at javaneturi$parserfail(urijava:2848) at javaneturi$parsercheckchars(urijava:3021) at javaneturi$parserparsehierarchical(urijava:3105) at javaneturi$parserparse(urijava:3063) at javaneturi<init>(urijava:588) at orgapachehadoopmapreducejobsubmitteraddmrframeworktodistributedcache(jobsubmitterjava:441) ***************************************************** and the most similar text Multiple module instances consuming taps topics get duplicate messages message deploy one instance module eg using 1 0 consumes tap topic get duplicate messages using message looks like issue fix fixed rabbit message easy reproduce 2 container cluster using message create deploy streams follows code stream create definition http log name stream deploy name properties stream create definition transform tapped log name stream deploy name properties code container 1 send message code curl data test message code container 1 logs code info test message info test message tapped code container 2 code info test message tapped code ie tapped message picked tap module instances similarly topics create deploy streams code stream create definition http name stream deploy name properties stream create definition transform topic consumer 1 log name stream deploy name properties stream create definition transform topic consumer 2 log name stream deploy name properties code container 1 send message code curl data test message code container 1 logs code info test message topic consumer 2 info test message topic consumer 1 code container 2 code info test message topic consumer 2 info test message topic consumer 1 code ie topic message picked instance module stream case expect stream pick message once ie get single output stream test message topic consumer 2 once either container test message topic consumer 1 once either container does not exceed the minimum threshold of 75%.;0.03;2.0;1.0;1.67;0;1;0;0
356;As a user I'd like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository (metadata persistence). The scope of this task is to have the configuration specifics documented in the wiki.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have the flexibility to configure db creds so that i can use a db of choice for batch job repository (metadata persistence) the scope of this task is to have the configuration specifics documented in the wiki was most similar to the text List modules wrong throw exception listing modules nonexistent display empty table instead throw exception saying container exist and similar to the text Update docs new tap syntax taps channels need update docs preceding colon longer needed removed altogether examples like code bar code and similar to the text Create rest api stopping job executions adopted functionality spring batch admin include test framework style tests delete - stop job executions (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
357;Add support to load a twitter.properties file in the source;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add support to load a twitterproperties file in the source was most similar to the text Ui - container list - module properties - escape passwords and similar to the text User wants able know triggers job and similar to the text Failing intermittent reported (and these texts are not user stories).;0.02;5.83;1.0;8.33;1;1;1;1
358;As a s-c-d user I'd like to have the option of {{Gemfire}} as module registry so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d user i'd like to have the option of {{gemfire}} as module registry so i can build data pipelines that are entirely orchestrated within {{gemfire}} is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd user id like option stream repository build data pipelines entirely orchestrated within and similar to the text User need document covering recommendations deploying cluster using marathon framework and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint (and these texts are all user stories with a worth of 8 story points).;0.02;6.15;1.0;8.33;1;1;1;1
359;File sink should support rollover I wanted to have a rollover feature when I was streaming tweets to a file overnight just to avoid dealing with a single enormous file (in case I collected more data than my demo could handle and needed to split it up).;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text File sink should support rollover i wanted to have a rollover feature when i was streaming tweets to a file overnight just to avoid dealing with a single enormous file (in case i collected more data than my demo could handle and needed to split it up) was most similar to the text Module context true current configuration prevents modules default values evaluate null workaround either - module ppc allows nulls - rid placeholders foo and similar to the text Create reusable responsive ui layout render tabular view create reusable responsive ui layout render returned rest endpoint part try bootstrap 300 use responsive styles offered and similar to the text Remove currently gets added dependency need remove 10 fir pig jobs version remain though (and these texts are not user stories).;0.04;8.62;1.0;8.33;1;1;1;1
360;As a s-c-d developer I'd like to move {{kafka}} module from XD to s-c-s repo so I can use it as {{source}} to build streaming pipeline.;2;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a s-c-d developer i'd like to move {{kafka}} module from xd to s-c-s repo so i can use it as {{source}} to build streaming pipeline is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.02;8.62;1.0;8.33;1;1;1;1
361;Encapsulate retrieval of module deployment metadata See comment here: https://github.com/spring-projects/spring-xd/pull/912/files#r13331190;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Encapsulate retrieval of module deployment metadata see comment here: https://githubcom/spring-projects/spring-xd/pull/912/files#r13331190 was most similar to the text Add stage acceptance test build plan runs basic acceptance test application deployment run test application developed and similar to the text Update documentation module launcher document requires update running docker lattice also requires fix modules bound together and similar to the text Fix rest endpoint security security container admin server wont able fetch message rates deployed modules container rest endpoint needs fixed (and these texts are not user stories).;0.03;2.0;1.0;1.67;0;1;1;1
362;Batch jobs send job and step events on channels This is the other side of launching a job by sending a message. The Job plugin should add listeners at the job/step level so that the job/step context information can be sent out on a channel. :myjob.notifications is a suggested channel name that would be created automatically.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Batch jobs send job and step events on channels this is the other side of launching a job by sending a message the job plugin should add listeners at the job/step level so that the job/step context information can be sent out on a channel :myjobnotifications is a suggested channel name that would be created automatically was most similar to the text Ui user able view job detail specific job execution job executions page clicking details link job execution row user see job details job detail page show information job table listing jobs execution tab may omitted columns aggregated values convey information easily and similar to the text Need support ability test locators need able setup server has locators enable modules locator features run tests default tests locator activating profile containers example running profile export and similar to the text Ability override default module path individual flow currently modules assumed reuse modules defined dirt may require flexibility eg (and these texts are not user stories).;0.04;8.55;1.0;8.33;1;1;1;1
363;Set 'auto-startup' to false in Kafka source We have to explicitly set it to false in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Set 'auto-startup' to false in kafka source we have to explicitly set it to false in order to avoid an early start of the poller and the associated distpatcherhasnosubscribersexception was most similar to the text Add binary option source see and similar to the text Controllers return objects raw domain objects resource objects returned controller methods mvc tests added check returned values and similar to the text Parameterize source add support tcp source currently hard-coded use udp port need parameterize port provide option use tcp (and these texts are not user stories).;0.08;2.0;1.0;1.67;0;1;1;1
364;Module options are not trimmed Spring XD 1.1 container will throw following exception: {code} java.lang.IllegalStateException: Can't find class used for type of option 'myField': String org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147) org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202) org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164) org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44) org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127) org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174) org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96) ... {code} when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value): {code} options.myField.description = this is my field options.myField.type = String {code} Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map to avoid this problem?;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Module options are not trimmed spring xd 11 container will throw following exception: {code} javalangillegalstateexception: can't find class used for type of option 'myfield': string orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolvermakesimplemoduleoptions(defaultmoduleoptionsmetadataresolverjava:147) orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolverresolvenormalmetadata(defaultmoduleoptionsmetadataresolverjava:202) orgspringframeworkxdmoduleoptionsdefaultmoduleoptionsmetadataresolverresolve(defaultmoduleoptionsmetadataresolverjava:164) orgspringframeworkxdmoduleoptionsdelegatingmoduleoptionsmetadataresolverresolve(delegatingmoduleoptionsmetadataresolverjava:44) orgspringframeworkxdmoduleoptionsenvironmentawaremoduleoptionsmetadataresolverresolve(environmentawaremoduleoptionsmetadataresolverjava:127) orgspringframeworkxddirtstreamxdstreamparserparse(xdstreamparserjava:174) orgspringframeworkxddirtstreamabstractdeployersave(abstractdeployerjava:96)  {code} when module properties have a trailing whitespace character in type property (in example below there is a trailing space in optionsmyfieldtype value): {code} optionsmyfielddescription = this is my field optionsmyfieldtype = string {code} can the property values be trimmed before comparing to defaultmoduleoptionsmetadataresolver#short_classnames map to avoid this problem? and the most similar text Provide clean way get reference running currently message obtained stream testing scenarios depend sending payloads named channels require deployed module instance per se any stream flow control uses directly getting deployed module instance general expensive eg wait module deploy implementation known application starts improvement ask container does not exceed the minimum threshold of 75%.;0.02;8.55;1.0;8.33;1;1;0;0
365;partition jobs (jdbchdfs) are running in sequence The jdbchdfs jobs that are partitioned are running in sequence rather than in parallel. Our expectation with partition jobs is that they run in parallel. Job configuration is: jdbchdfs --driverClassName='oracle.jdbc.OracleDriver' --url='jdbc:oracle:thin:@=**********' --username='=**********' --password=********** --validationQuery='SELECT CURRENT_TIMESTAMP FROM DUAL' --tableName='HZ_ORGANIZATION_PROFILES' --columns='ORGANIZATION_PROFILE_ID ... VERSION_NUMBER' --partitions=10 --partitionColumn='ORGANIZATION_PROFILE_ID' --directory='/ingest/source/oracle11i/ar/hz_organization_profiles' --fileName=hz_organization_profiles --fileExtension=csv --delimiter=| --commitInterval=10000 --rollover=262144000 --dateFormat=yyyy-mmm-dd --partitionResultsTimeout=1800000 --testOnBorrow=false;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Partition jobs (jdbchdfs) are running in sequence the jdbchdfs jobs that are partitioned are running in sequence rather than in parallel our expectation with partition jobs is that they run in parallel job configuration is: jdbchdfs --driverclassname='oraclejdbcoracledriver' --url='jdbc:oracle:thin:@=**********' --username='=**********' --password=********** --validationquery='select current_timestamp from dual' --tablename='hz_organization_profiles' --columns='organization_profile_id  version_number' --partitions=10 --partitioncolumn='organization_profile_id' --directory='/ingest/source/oracle11i/ar/hz_organization_profiles' --filename=hz_organization_profiles --fileextension=csv --delimiter=| --commitinterval=10000 --rollover=262144000 --dateformat=yyyy-mmm-dd --partitionresultstimeout=1800000 --testonborrow=false was most similar to the text Give proper results back lukes original code uses code snippet seem behave strangely stored values seem fine method seems phony test 1 stream create foo definition 2 tap create bar definition 3 curl h gives default bucketing hourly chances empty and similar to the text Add acceptance test job stage uses distributed mode see stages one jobs run parallel like tests across rabbit transport occur parallel and similar to the text Reorganize manual strawman getting started rather meaty top level sections maybe section - running running distributed mode running yarn application configuration message configuration monitoring management technical documentation architecture distributed remove prefix interactive shell batch jobs streams modules tuples sources processors analytics sinks taps type conversion deployment better name best practices new section admin ui dsl reference rest api samples (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
366;As a QA I'd like to include acceptance test coverage for _field-value-counter_ sink module so that I can validate the functionality as part of every CI build.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a qa i'd like to include acceptance test coverage for _field-value-counter_ sink module so that i can validate the functionality as part of every ci build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Developer id like simplified ux around parameters escape parameter scope also test job identify ux differences and similar to the text Developer id like continue poc focused design spi generally applicable lattice receptor api one implementation option (and these texts are all user stories with a worth of 8 story points).;0.09;8.62;1.0;8.33;1;1;1;1
367;Add support for creating a spring batch job that references a named trigger;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add support for creating a spring batch job that references a named trigger is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.02;8.55;1.0;8.33;1;0;1;0
368;Add status column for 'stream list' shell command result {{stream list}} shell command should display status of the stream (deployed undeployed);0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add status column for 'stream list' shell command result {{stream list}} shell command should display status of the stream (deployed undeployed) is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like create tuple use measure tuple based payload performance and similar to the text Scd developer id like move external library project clear separation functionalities scd and similar to the text Developer id like add load sink module measure received throughput (and these texts are all user stories with a worth of 3 story points).;0.02;5.83;1.0;8.33;1;0;1;0
369;Stream should not be in deployed state following module failure. Run singlenode. Ensure twitterstream credentials are not valid. e.g. no consumerKey property. This is the default state. >stream create tweets --definition twitterstream | log --deploy Created and deployed stream 'tweets' Meanwhile Singlenode throws an exception the stacktrace below xd:>stream list Stream Name Stream Definition Status ----------- ------------------- -------- tweets twitterstream | log deployed {code} 15:54:07298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ${consumerKey} nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ${consumerKey} org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448) org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347) org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93) org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678) org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494) org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488) org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293) org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485) org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) java.util.concurrent.FutureTask.run(FutureTask.java:262) java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) java.util.concurrent.FutureTask.run(FutureTask.java:262) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ${consumerKey} nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ${consumerKey} {/code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Stream should not be in deployed state following module failure run singlenode ensure twitterstream credentials are not valid eg no consumerkey property this is the default state >stream create tweets --definition twitterstream | log --deploy created and deployed stream 'tweets' meanwhile singlenode throws an exception the stacktrace below xd:>stream list stream name stream definition status ----------- ------------------- -------- tweets twitterstream | log deployed {code} 15:54:07298 error deploymentspathchildrencache-0 cachepathchildrencache:550 - javalangruntimeexception: orgspringframeworkbeansfactorybeandefinitionstoreexception: invalid bean definition with name 'twittertemplate' defined in url [file:/users/dturanski/spring-xd/spring-xd-100m6/xd/modules/source/twitterstream/config/twitterstreamxml]: could not resolve placeholder 'consumerkey' in string value ${consumerkey} nested exception is javalangillegalargumentexception: could not resolve placeholder 'consumerkey' in string value ${consumerkey} orgspringframeworkxddirtservercontainerregistrardeploystreammodule(containerregistrarjava:448) orgspringframeworkxddirtservercontainerregistraronchildadded(containerregistrarjava:347) orgspringframeworkxddirtservercontainerregistraraccess$700(containerregistrarjava:93) orgspringframeworkxddirtservercontainerregistrar$deploymentlistenerchildevent(containerregistrarjava:678) orgapachecuratorframeworkrecipescachepathchildrencache$5apply(pathchildrencachejava:494) orgapachecuratorframeworkrecipescachepathchildrencache$5apply(pathchildrencachejava:488) orgapachecuratorframeworklistenlistenercontainer$1run(listenercontainerjava:92) comgooglecommonutilconcurrentmoreexecutors$samethreadexecutorserviceexecute(moreexecutorsjava:293) orgapachecuratorframeworklistenlistenercontainerforeach(listenercontainerjava:83) orgapachecuratorframeworkrecipescachepathchildrencachecalllisteners(pathchildrencachejava:485) orgapachecuratorframeworkrecipescacheeventoperationinvoke(eventoperationjava:35) orgapachecuratorframeworkrecipescachepathchildrencache$11run(pathchildrencachejava:755) javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) javautilconcurrentfuturetaskrun(futuretaskjava:262) javautilconcurrentexecutors$runnableadaptercall(executorsjava:471) javautilconcurrentfuturetaskrun(futuretaskjava:262) javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) javalangthreadrun(threadjava:744) caused by: orgspringframeworkbeansfactorybeandefinitionstoreexception: invalid bean definition with name 'twittertemplate' defined in url [file:/users/dturanski/spring-xd/spring-xd-100m6/xd/modules/source/twitterstream/config/twitterstreamxml]: could not resolve placeholder 'consumerkey' in string value ${consumerkey} nested exception is javalangillegalargumentexception: could not resolve placeholder 'consumerkey' in string value ${consumerkey} {/code} and the most similar text Composed options does trigger profile activation was process rewriting transform using profiles see broke eg basically composed module options activate profile problem real way know activate currently deploying part composed module metadata actually link whole metadata does really know part long story short may able activate union profiles breaks easily module compose foo definition transform transform try activate script expression profiles modules does not exceed the minimum threshold of 75%.;0.01;2.0;1.0;1.67;0;1;0;0
370;Add command for stream creation;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add command for stream creation was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;5.83;1.0;8.33;1;1;1;1
371;Document admin-ui improvements;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Document admin-ui improvements was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;2.37;1.0;1.67;0;1;1;1
372;Modularize XD UI From https://jira.springsource.org/browse/XD-1231 we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Modularize xd ui from https://jiraspringsourceorg/browse/xd-1231 we understand the importance of modularizing client side javascript code this story tracks modularization of xd ui was most similar to the text Cluster view create container details page please see discussion and similar to the text Cluster view improve hover capabilities please see discussion and similar to the text Backed aggregate counters return results inclusive time interval aggregate counter query return results inclusive start end time time resolutions minute hour day month (and these texts are not user stories).;0.03;8.62;1.0;8.33;1;1;1;1
373;Rename packages that is applicable for both stream/job Determine a better package name for the following packages once we have a common model that applies to both stream/job: `org.springframework.xd.dirt.stream` `org.springframework.xd.dirt.stream.zookeeper`;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Rename packages that is applicable for both stream/job determine a better package name for the following packages once we have a common model that applies to both stream/job: `orgspringframeworkxddirtstream` `orgspringframeworkxddirtstreamzookeeper` was most similar to the text Add tap support rabbit binder scd user id like tap primary pipeline fork data impacting original stream and similar to the text Add paging sorting field value counter api see discussion and similar to the text Remove footer admin ui please see discussion (and these texts are not user stories).;0.03;8.62;1.0;8.33;1;1;1;1
374;Add ability to inject delimiter on pre-packaged jobs that deal with files.;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add ability to inject delimiter on pre-packaged jobs that deal with files is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.02;8.62;1.0;8.33;1;0;1;0
375;As a s-c-d user I'd like to create a new banner so I can embed and display the banner when the shell server boots-up. Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?;1;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a s-c-d user i'd like to create a new banner so i can embed and display the banner when the shell server boots-up perhaps use this [banner generator|http://patorjkcom/software/taag/#p=display&f=standard&t=spring%20cloud%0adata%20flow%20%20%3e%3e%3e%3e%3e%20]? was most similar to the text Create document existing project template custom module creation wiki docs custom modules entire files good explore existing sts templates maven archetypes etc create new ones authoring custom modules and similar to the text Rpm upgrades wipeout installation operator id like upgrade latest releases spring yet lose older installation copy reuse previously used configurations and similar to the text Fix servlet container issues several issues staged version - use tomcat instead jetty prevent starting yarn - guava 180 instead - push work client needs servlet api - updating instead -- causes curator also update throws exception startup (and these texts are not user stories).;0.01;8.4;1.0;8.33;1;1;1;1
376;As a developer I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience.;3;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to run kafka tests with kafka server as a separate running process so that i can improve build experience is a user story, and is worth 5 story points. This was predicted because it is most similar to the text User id like refer pig sample use reference integrate pig jobs and similar to the text Scd user id like add rest support stream commands maneuver streaming pipeline backed and similar to the text Scd developer id like explore options bootstrap setup lattice based infrastructure scds bare metal deployment (and these texts are all user stories with a worth of 5 story points).;0.03;4.48;1.0;7.9;1;1;1;1
377;Vary message size (DB-2) Use a single producer single consumer prefetch size = 50. Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes. Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec. *Message Sizes:* 100 bytes 1000 10000 100000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Vary message size (db-2) use a single producer single consumer prefetch size = 50 send 1m messages and increase or decrease so that a given test iteration takes about 2 minutes vary the message size and measure the msg/sec rate and calculate data transfer rate in mb/sec *message sizes:* 100 bytes 1000 10000 100000 during the measurements look at the rabbitmq admin ui and see if the queue is backing up was most similar to the text Documentation source has conflicting information according documentation one options available source transport listed default sample definition provide yet appears default tcp two match might also useful possible values transport listed assume tcp udp and similar to the text Jdbc sink broken - looks like options booted jdbc sink broken simple time jdbc results bad sql grammar insert test payload values nested exception user lacks privilege object found test looks like options clobbered and similar to the text Error messages thrown sink starting server stream create name definition http new stream stream create name definition http new stream even server started streams successfully behavior inconsistent hdfs hdfs connection available stream using http hdfs fail (and these texts are not user stories).;0.01;8.15;1.0;8.33;1;1;1;1
378;Backport metadata retrieval stability improvements Backport stability improvements added as part of XD-2958 to the 1.1.x branch.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Backport metadata retrieval stability improvements backport stability improvements added as part of xd-2958 to the 11x branch is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like invoke rest apis shell validate operations and similar to the text Developer id like measure performance numbers simple stream characterize overall throughput and similar to the text Scd developer id like produce ref documentation scd architecture define deployment differences (and these texts are all user stories with a worth of 8 story points).;0.02;6.52;1.0;8.33;1;0;1;0
379;xd-admin silently fails if servers.yml is invalid for example: {code} xd: transport: rabbit messagebus: # local: # queueSize: 2147483647 # polling: 1000 # executor: # corePoolSize: 0 # maxPoolSize: 200 # queueSize: 2147483647 # keepAliveSeconds: 60 rabbit: # compressionLevel: 1 # bus-level property applies only when 'compress=true' for a stream module # See java.util.zip.Deflater 1=BEST_SPEED 9=BEST_COMPRESSION ... default: # ackMode: AUTO # Valid: AUTO (container acks) NONE (broker acks) MANUAL (consumer acks). # Upper case only. # Note: MANUAL requires specialized code in the consuming module and is unlikely to be # used in an XD application. For more information see # http://docs.spring.io/spring-integration/reference/html/amqp.html#amqp-inbound-ack # autoBindDLQ: false # backOffInitialInterval: 1000 # backOffMaxInterval: 10000 # backOffMultiplier: 2.0 # batchBufferLimit: 10000 batchingEnabled: true # batchSize: 100 # batchTimeout: 5000 # compress: false # concurrency: 1 # deliveryMode: PERSISTENT # maxAttempts: 3 # maxConcurrency: 1 # prefix: xdbus. # prefix for queue/exchange names so policies (ha dle etc.) can be applied # prefetch: 1 # replyHeaderPatterns: STANDARD_REPLY_HEADERS* # requestHeaderPatterns: STANDARD_REQUEST_HEADERS* # requeue: true # transacted: false # txSize: 1 # redis: # headers: # comman-delimited list of additional (string-valued) header names to transport # default: # default bus properties if not specified at the module level # backOffInitialInterval: 1000 # backOffMaxInterval: 10000 # backOffMultiplier: 2.0 # concurrency: 1 # maxAttempts: 3 # kafka: # brokers: localhost:9092 # zkAddress: localhost:2181 # numOfKafkaPartitionsForCountEqualsZero: 10 # socketBufferSize: 2097152 # offsetStoreTopic: SpringXdOffsets # offsetStoreSegmentSize: 25000000 # offsetStoreRetentionTime: 60000 # offsetStoreRequiredAcks: 1 # offsetStoreMaxFetchSize: 1048576 # offsetStoreBatchSize: 200 # offsetStoreBatchEnabled: false # offsetStoreBatchTime: 1000 # offsetUpdateTimeWindow: 10000 # offsetUpdateCount: 0 # offsetUpdateShutdownTimeout: 2000 default: batchingEnabled: true {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Xd-admin silently fails if serversyml is invalid for example: {code} xd: transport: rabbit messagebus: # local: # queuesize: 2147483647 # polling: 1000 # executor: # corepoolsize: 0 # maxpoolsize: 200 # queuesize: 2147483647 # keepaliveseconds: 60 rabbit: # compressionlevel: 1 # bus-level property applies only when 'compress=true' for a stream module # see javautilzipdeflater 1=best_speed 9=best_compression  default: # ackmode: auto # valid: auto (container acks) none (broker acks) manual (consumer acks) # upper case only # note: manual requires specialized code in the consuming module and is unlikely to be # used in an xd application for more information see # http://docsspringio/spring-integration/reference/html/amqphtml#amqp-inbound-ack # autobinddlq: false # backoffinitialinterval: 1000 # backoffmaxinterval: 10000 # backoffmultiplier: 20 # batchbufferlimit: 10000 batchingenabled: true # batchsize: 100 # batchtimeout: 5000 # compress: false # concurrency: 1 # deliverymode: persistent # maxattempts: 3 # maxconcurrency: 1 # prefix: xdbus # prefix for queue/exchange names so policies (ha dle etc) can be applied # prefetch: 1 # replyheaderpatterns: standard_reply_headers* # requestheaderpatterns: standard_request_headers* # requeue: true # transacted: false # txsize: 1 # redis: # headers: # comman-delimited list of additional (string-valued) header names to transport # default: # default bus properties if not specified at the module level # backoffinitialinterval: 1000 # backoffmaxinterval: 10000 # backoffmultiplier: 20 # concurrency: 1 # maxattempts: 3 # kafka: # brokers: localhost:9092 # zkaddress: localhost:2181 # numofkafkapartitionsforcountequalszero: 10 # socketbuffersize: 2097152 # offsetstoretopic: springxdoffsets # offsetstoresegmentsize: 25000000 # offsetstoreretentiontime: 60000 # offsetstorerequiredacks: 1 # offsetstoremaxfetchsize: 1048576 # offsetstorebatchsize: 200 # offsetstorebatchenabled: false # offsetstorebatchtime: 1000 # offsetupdatetimewindow: 10000 # offsetupdatecount: 0 # offsetupdateshutdowntimeout: 2000 default: batchingenabled: true {code} and the most similar text Job throws exception acceptance tests currently fails line stating data different table expected currently failing single deployment using transport also seeing following exception attached log error - error executing step job failed initialize reader input resource must exist reader strict mode url file present data present test least according checker local deployments does not exceed the minimum threshold of 75%.;0.04;6.15;1.0;8.33;1;1;0;0
380;Fix support for @CliAvailabilityIndicator See PR https://github.com/spring-projects/spring-xd/pull/1043/;0;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Fix support for @cliavailabilityindicator see pr https://githubcom/spring-projects/spring-xd/pull/1043/ is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer id like design document approach deploying stream single container modules within stream and similar to the text User id like option sink perform indexing search server and similar to the text Developer id like create separate yarn spi bundle spi variants one admin project (and these texts are all user stories with a worth of 5 story points).;0.02;6.58;1.0;8.33;1;0;1;0
381;Improve Module Options support note from PR #365 - which has been merged - providing the initial level of support... Pending issues (to be addressed in another PR?): - [x] complex case - [x] default values for complex case when option is not surfaced back to the module (eg suffix in our canonical example) - [ ] plugin provided options and values - [ ] descriptive defaults instead of actual defaults (e.g. \<use stream name\>) - [ ] JSR303 Validation;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Improve module options support note from pr #365 - which has been merged - providing the initial level of support pending issues (to be addressed in another pr?): - [x] complex case - [x] default values for complex case when option is not surfaced back to the module (eg suffix in our canonical example) - [ ] plugin provided options and values - [ ] descriptive defaults instead of actual defaults (eg \<use stream name\>) - [ ] jsr303 validation is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like rest api point push archive includes custom module definitions configurations manually move set scope spike assess customer requirement brainstorm document options socialize team collect feedback identify phases create new stories and similar to the text Developer id like build data pipeline using kafka message demonstrate capabilities use case consider log aggregation lambda architecture avoid code duplication eliminate tight coupling logic kafka used reliable reprocessing and similar to the text Developer id like study taxi trips based stream trip reports new york city evaluate systems context real-time analytics using spring challenge (and these texts are all user stories with a worth of 8 story points).;0.01;2.01;1.0;1.67;0;0;1;0
382;Need TCP-Client Source Acceptance test;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Need tcp-client source acceptance test is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like flexible module processor and similar to the text Developer id like option extending trigger abstraction implement trigger and similar to the text Developer id like build batch sample using demonstrate capabilities use cases consider jdbc hdfs hdfs jdbc (and these texts are all user stories with a worth of 8 story points).;0.02;6.15;1.0;8.33;1;0;1;0
383;As a Spring XD developer I'd like to move {{trigger}} module from XD to s-c-s repo so I can use it as source to build streaming pipeline.;2;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to move {{trigger}} module from xd to s-c-s repo so i can use it as source to build streaming pipeline is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Spring developer id like move cassandra module scs use sink build streaming pipeline and similar to the text Lead id like review current architecture design specs address any foundation level gaps and similar to the text User id like option sink perform indexing search server (and these texts are all user stories with a worth of 5 story points).;0.13;3.01;1.0;1.67;0;1;1;1
384;XD UI not usable with IE 11 Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Xd ui not usable with ie 11 trying to use the xd ui with internet explorer (version 110960017031) is difficult the screen doesn't refresh when streams/jobs are created or deployed had to erase the browsing history continuously to get state updates to show in the ui was most similar to the text Move ftp support x package batch package commit support ftp added bunch x classes belong dirt proper though added extension style project jobs module depend and similar to the text Use correct constant based version used keep getting following warning warn spring shell - deprecated instead use switch use value constant based version used and similar to the text Split 3 5 project split least 3 parts - classes resources pertaining - container server - shared classes additionally may consider splitting first two half well separate project cli handling hence introduce 2 projects yarn etc (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
385;The type StubDatasetOperations must implement the inherited abstract method DatasetOperations.getDatasetDescriptor(Class<T>) StubDatasetOperations class needs to be either declared asbtract or implemente inherited methods from DatasetOperations;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text The type stubdatasetoperations must implement the inherited abstract method datasetoperationsgetdatasetdescriptor(class<t>) stubdatasetoperations class needs to be either declared asbtract or implemente inherited methods from datasetoperations is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text Developer id like migrate module deployment repository abstraction used definitions create spi and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue (and these texts are all user stories with a worth of 8 story points).;0.04;6.58;1.0;8.33;1;0;1;0
386;Make module files classpath aware Currently living at the root of the project those files don't benefit from IDE SI awareness. Make it so that they belong to a java project which sees the correct version of the SI jars used. Has impact on the build.gradle file;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Make module files classpath aware currently living at the root of the project those files don't benefit from ide si awareness make it so that they belong to a java project which sees the correct version of the si jars used has impact on the buildgradle file is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User need ability configure docker containers link external services rabbit mongo etc includes pointers attributes environment variables and similar to the text User id like create stream generator ingest messages 1000 bytes one thread using container measure performance characteristics and similar to the text Scs developer id like investigate right approach include external library dependency ex mysql decide better handling libraries needs loaded available root cp (and these texts are all user stories with a worth of 8 story points).;0.03;2.07;1.0;1.67;0;0;1;0
387;Test Spark Module with maven spring-xd-module-parent java.lang.NoClassDefFoundError A test for a java spark module managed by maven with parent *spring-xd-module-parent* launch a _*java.lang.NoClassDefFoundError*_. I've forked the example repo [https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor|https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor] the samples project and created the *pom* file for the *spark-streaming-wordcount-java-processor* project and the corresponding test. Partial stack trace: {code:title=StackTrace} 2015-08-04 09:30:07211 ERROR [DeploymentsPathChildrenCache-0] listen.ListenerContainer (ListenerContainer.java:run(96)) - Listener (org.springframework.xd.dirt.server.container.DeploymentListener@729c251b) threw an exception java.lang.NoClassDefFoundError: org/eclipse/jetty/util/component/AggregateLifeCycle java.lang.ClassLoader.defineClass1(Native Method) java.lang.ClassLoader.defineClass(ClassLoader.java:760) java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) java.net.URLClassLoader.defineClass(URLClassLoader.java:467) java.net.URLClassLoader.access$100(URLClassLoader.java:73) java.net.URLClassLoader$1.run(URLClassLoader.java:368) java.net.URLClassLoader$1.run(URLClassLoader.java:362) java.security.AccessController.doPrivileged(Native Method) java.net.URLClassLoader.findClass(URLClassLoader.java:361) java.lang.ClassLoader.loadClass(ClassLoader.java:424) sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) java.lang.ClassLoader.loadClass(ClassLoader.java:357) java.lang.ClassLoader.defineClass1(Native Method) java.lang.ClassLoader.defineClass(ClassLoader.java:760) java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) java.net.URLClassLoader.defineClass(URLClassLoader.java:467) java.net.URLClassLoader.access$100(URLClassLoader.java:73) java.net.URLClassLoader$1.run(URLClassLoader.java:368) java.net.URLClassLoader$1.run(URLClassLoader.java:362) java.security.AccessController.doPrivileged(Native Method) java.net.URLClassLoader.findClass(URLClassLoader.java:361) java.lang.ClassLoader.loadClass(ClassLoader.java:424) sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) java.lang.ClassLoader.loadClass(ClassLoader.java:357) java.lang.ClassLoader.defineClass1(Native Method) java.lang.ClassLoader.defineClass(ClassLoader.java:760) java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) java.net.URLClassLoader.defineClass(URLClassLoader.java:467) java.net.URLClassLoader.access$100(URLClassLoader.java:73) java.net.URLClassLoader$1.run(URLClassLoader.java:368) java.net.URLClassLoader$1.run(URLClassLoader.java:362) java.security.AccessController.doPrivileged(Native Method) java.net.URLClassLoader.findClass(URLClassLoader.java:361) java.lang.ClassLoader.loadClass(ClassLoader.java:424) sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) java.lang.ClassLoader.loadClass(ClassLoader.java:357) java.lang.ClassLoader.defineClass1(Native Method) java.lang.ClassLoader.defineClass(ClassLoader.java:760) java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) java.net.URLClassLoader.defineClass(URLClassLoader.java:467) java.net.URLClassLoader.access$100(URLClassLoader.java:73) java.net.URLClassLoader$1.run(URLClassLoader.java:368) java.net.URLClassLoader$1.run(URLClassLoader.java:362) java.security.AccessController.doPrivileged(Native Method) java.net.URLClassLoader.findClass(URLClassLoader.java:361) java.lang.ClassLoader.loadClass(ClassLoader.java:424) sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) java.lang.ClassLoader.loadClass(ClassLoader.java:357) org.apache.spark.HttpServer.org$apache$spark$HttpServer$$doStart(HttpServer.scala:74) {code} When the *WordCountTest* test is launched the exception is launched. Is there a problem with the *spring-xd-module-parent* module ? Are some dependencies left?;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Test spark module with maven spring-xd-module-parent javalangnoclassdeffounderror a test for a java spark module managed by maven with parent *spring-xd-module-parent* launch a _*javalangnoclassdeffounderror*_ i've forked the example repo [https://githubcom/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor|https://githubcom/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor] the samples project and created the *pom* file for the *spark-streaming-wordcount-java-processor* project and the corresponding test partial stack trace: {code:title=stacktrace} 2015-08-04 09:30:07211 error [deploymentspathchildrencache-0] listenlistenercontainer (listenercontainerjava:run(96)) - listener (orgspringframeworkxddirtservercontainerdeploymentlistener@729c251b) threw an exception javalangnoclassdeffounderror: org/eclipse/jetty/util/component/aggregatelifecycle javalangclassloaderdefineclass1(native method) javalangclassloaderdefineclass(classloaderjava:760) javasecuritysecureclassloaderdefineclass(secureclassloaderjava:142) javaneturlclassloaderdefineclass(urlclassloaderjava:467) javaneturlclassloaderaccess$100(urlclassloaderjava:73) javaneturlclassloader$1run(urlclassloaderjava:368) javaneturlclassloader$1run(urlclassloaderjava:362) javasecurityaccesscontrollerdoprivileged(native method) javaneturlclassloaderfindclass(urlclassloaderjava:361) javalangclassloaderloadclass(classloaderjava:424) sunmisclauncher$appclassloaderloadclass(launcherjava:331) javalangclassloaderloadclass(classloaderjava:357) javalangclassloaderdefineclass1(native method) javalangclassloaderdefineclass(classloaderjava:760) javasecuritysecureclassloaderdefineclass(secureclassloaderjava:142) javaneturlclassloaderdefineclass(urlclassloaderjava:467) javaneturlclassloaderaccess$100(urlclassloaderjava:73) javaneturlclassloader$1run(urlclassloaderjava:368) javaneturlclassloader$1run(urlclassloaderjava:362) javasecurityaccesscontrollerdoprivileged(native method) javaneturlclassloaderfindclass(urlclassloaderjava:361) javalangclassloaderloadclass(classloaderjava:424) sunmisclauncher$appclassloaderloadclass(launcherjava:331) javalangclassloaderloadclass(classloaderjava:357) javalangclassloaderdefineclass1(native method) javalangclassloaderdefineclass(classloaderjava:760) javasecuritysecureclassloaderdefineclass(secureclassloaderjava:142) javaneturlclassloaderdefineclass(urlclassloaderjava:467) javaneturlclassloaderaccess$100(urlclassloaderjava:73) javaneturlclassloader$1run(urlclassloaderjava:368) javaneturlclassloader$1run(urlclassloaderjava:362) javasecurityaccesscontrollerdoprivileged(native method) javaneturlclassloaderfindclass(urlclassloaderjava:361) javalangclassloaderloadclass(classloaderjava:424) sunmisclauncher$appclassloaderloadclass(launcherjava:331) javalangclassloaderloadclass(classloaderjava:357) javalangclassloaderdefineclass1(native method) javalangclassloaderdefineclass(classloaderjava:760) javasecuritysecureclassloaderdefineclass(secureclassloaderjava:142) javaneturlclassloaderdefineclass(urlclassloaderjava:467) javaneturlclassloaderaccess$100(urlclassloaderjava:73) javaneturlclassloader$1run(urlclassloaderjava:368) javaneturlclassloader$1run(urlclassloaderjava:362) javasecurityaccesscontrollerdoprivileged(native method) javaneturlclassloaderfindclass(urlclassloaderjava:361) javalangclassloaderloadclass(classloaderjava:424) sunmisclauncher$appclassloaderloadclass(launcherjava:331) javalangclassloaderloadclass(classloaderjava:357) orgapachesparkhttpserverorg$apache$spark$httpserver$$dostart(httpserverscala:74) {code} when the *wordcounttest* test is launched the exception is launched is there a problem with the *spring-xd-module-parent* module ? are some dependencies left? and the most similar text Able bypass authorization checks appending json xml reproduce 1 enable security 2 use user has following role 3 make normal rest call code code yields desired response code error forbidden message access path code try code code produces code links self href content groups 0 null attributes ip host groups pid id links self href page size 20 1 1 number 0 code does not exceed the minimum threshold of 75%.;0.1;2.02;1.0;1.67;0;1;0;0
388;Parsing issues with kafka-bus.xml Using Kafka as a transport option yields: [2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml] Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml] nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute {1} associated with an element type value. org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70) org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85) org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303) org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180) org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216) org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187) org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313) org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138) org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116) org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330) org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243) org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254) org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94) org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609) org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464) org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691) org.springframework.boot.SpringApplication.run(SpringApplication.java:320) org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142) org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63) org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:606) com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid nested exception is org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute {1} associated with an element type value. org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303) org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180) org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216) org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242) ... 31 more Caused by: org.xml.sax.SAXParseException lineNumber: 9 columnNumber: 26 Open quote is expected for attribute {1} associated with an element type value. com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198) com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177) com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441) com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368) com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436) com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829) com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439) com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255) com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786) com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606) com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117) com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510) com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848) com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777) com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141) com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243) com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347) org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428) org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390) ... 36 more;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Parsing issues with kafka-busxml using kafka as a transport option yields: [2014-11-04 12:18:30528] boot - 24061 error [main] --- springapplication: application startup failed orgspringframeworkbeansfactoryparsingbeandefinitionparsingexception: configuration problem: failed to import bean definitions from url location [classpath*:/meta-inf/spring-xd/transports/kafka-busxml] offending resource: class path resource [meta-inf/spring-xd/bus/message-busxml] nested exception is orgspringframeworkbeansfactoryxmlxmlbeandefinitionstoreexception: line 9 in xml document from url [jar:file:/users/mbogoevici/gradle/caches/modules-2/files-21/orgspringframeworkxd/spring-xd-dirt/110build-snapshot/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-110build-snapshotjar!/meta-inf/spring-xd/transports/kafka-busxml] is invalid nested exception is orgxmlsaxsaxparseexception linenumber: 9 columnnumber: 26 open quote is expected for attribute {1} associated with an element type value orgspringframeworkbeansfactoryparsingfailfastproblemreportererror(failfastproblemreporterjava:70) orgspringframeworkbeansfactoryparsingreadercontexterror(readercontextjava:85) orgspringframeworkbeansfactoryparsingreadercontexterror(readercontextjava:76) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderimportbeandefinitionresource(defaultbeandefinitiondocumentreaderjava:248) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderparsedefaultelement(defaultbeandefinitiondocumentreaderjava:199) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderparsebeandefinitions(defaultbeandefinitiondocumentreaderjava:184) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderdoregisterbeandefinitions(defaultbeandefinitiondocumentreaderjava:141) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderregisterbeandefinitions(defaultbeandefinitiondocumentreaderjava:110) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderregisterbeandefinitions(xmlbeandefinitionreaderjava:508) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderdoloadbeandefinitions(xmlbeandefinitionreaderjava:391) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderloadbeandefinitions(xmlbeandefinitionreaderjava:335) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderloadbeandefinitions(xmlbeandefinitionreaderjava:303) orgspringframeworkbeansfactorysupportabstractbeandefinitionreaderloadbeandefinitions(abstractbeandefinitionreaderjava:180) orgspringframeworkbeansfactorysupportabstractbeandefinitionreaderloadbeandefinitions(abstractbeandefinitionreaderjava:216) orgspringframeworkbeansfactorysupportabstractbeandefinitionreaderloadbeandefinitions(abstractbeandefinitionreaderjava:187) orgspringframeworkcontextannotationconfigurationclassbeandefinitionreaderloadbeandefinitionsfromimportedresources(configurationclassbeandefinitionreaderjava:313) orgspringframeworkcontextannotationconfigurationclassbeandefinitionreaderloadbeandefinitionsforconfigurationclass(configurationclassbeandefinitionreaderjava:138) orgspringframeworkcontextannotationconfigurationclassbeandefinitionreaderloadbeandefinitions(configurationclassbeandefinitionreaderjava:116) orgspringframeworkcontextannotationconfigurationclasspostprocessorprocessconfigbeandefinitions(configurationclasspostprocessorjava:330) orgspringframeworkcontextannotationconfigurationclasspostprocessorpostprocessbeandefinitionregistry(configurationclasspostprocessorjava:243) orgspringframeworkcontextsupportpostprocessorregistrationdelegateinvokebeandefinitionregistrypostprocessors(postprocessorregistrationdelegatejava:254) orgspringframeworkcontextsupportpostprocessorregistrationdelegateinvokebeanfactorypostprocessors(postprocessorregistrationdelegatejava:94) orgspringframeworkcontextsupportabstractapplicationcontextinvokebeanfactorypostprocessors(abstractapplicationcontextjava:609) orgspringframeworkcontextsupportabstractapplicationcontextrefresh(abstractapplicationcontextjava:464) orgspringframeworkbootspringapplicationrefresh(springapplicationjava:691) orgspringframeworkbootspringapplicationrun(springapplicationjava:320) orgspringframeworkbootbuilderspringapplicationbuilderrun(springapplicationbuilderjava:142) orgspringframeworkbootbuilderspringapplicationbuilderrun(springapplicationbuilderjava:129) orgspringframeworkxddirtserversinglenodeapplicationrun(singlenodeapplicationjava:63) orgspringframeworkxddemokafkakafkademomain(kafkademojava:28) sunreflectnativemethodaccessorimplinvoke0(native method) sunreflectnativemethodaccessorimplinvoke(nativemethodaccessorimpljava:57) sunreflectdelegatingmethodaccessorimplinvoke(delegatingmethodaccessorimpljava:43) javalangreflectmethodinvoke(methodjava:606) comintellijrtexecutionapplicationappmainmain(appmainjava:134) caused by: orgspringframeworkbeansfactoryxmlxmlbeandefinitionstoreexception: line 9 in xml document from url [jar:file:/users/mbogoevici/gradle/caches/modules-2/files-21/orgspringframeworkxd/spring-xd-dirt/110build-snapshot/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-110build-snapshotjar!/meta-inf/spring-xd/transports/kafka-busxml] is invalid nested exception is orgxmlsaxsaxparseexception linenumber: 9 columnnumber: 26 open quote is expected for attribute {1} associated with an element type value orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderdoloadbeandefinitions(xmlbeandefinitionreaderjava:398) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderloadbeandefinitions(xmlbeandefinitionreaderjava:335) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderloadbeandefinitions(xmlbeandefinitionreaderjava:303) orgspringframeworkbeansfactorysupportabstractbeandefinitionreaderloadbeandefinitions(abstractbeandefinitionreaderjava:180) orgspringframeworkbeansfactorysupportabstractbeandefinitionreaderloadbeandefinitions(abstractbeandefinitionreaderjava:216) orgspringframeworkbeansfactoryxmldefaultbeandefinitiondocumentreaderimportbeandefinitionresource(defaultbeandefinitiondocumentreaderjava:242)  31 more caused by: orgxmlsaxsaxparseexception linenumber: 9 columnnumber: 26 open quote is expected for attribute {1} associated with an element type value comsunorgapachexercesinternalutilerrorhandlerwrappercreatesaxparseexception(errorhandlerwrapperjava:198) comsunorgapachexercesinternalutilerrorhandlerwrapperfatalerror(errorhandlerwrapperjava:177) comsunorgapachexercesinternalimplxmlerrorreporterreporterror(xmlerrorreporterjava:441) comsunorgapachexercesinternalimplxmlerrorreporterreporterror(xmlerrorreporterjava:368) comsunorgapachexercesinternalimplxmlscannerreportfatalerror(xmlscannerjava:1436) comsunorgapachexercesinternalimplxmlscannerscanattributevalue(xmlscannerjava:829) comsunorgapachexercesinternalimplxmlnsdocumentscannerimplscanattribute(xmlnsdocumentscannerimpljava:439) comsunorgapachexercesinternalimplxmlnsdocumentscannerimplscanstartelement(xmlnsdocumentscannerimpljava:255) comsunorgapachexercesinternalimplxmldocumentfragmentscannerimpl$fragmentcontentdrivernext(xmldocumentfragmentscannerimpljava:2786) comsunorgapachexercesinternalimplxmldocumentscannerimplnext(xmldocumentscannerimpljava:606) comsunorgapachexercesinternalimplxmlnsdocumentscannerimplnext(xmlnsdocumentscannerimpljava:117) comsunorgapachexercesinternalimplxmldocumentfragmentscannerimplscandocument(xmldocumentfragmentscannerimpljava:510) comsunorgapachexercesinternalparsersxml11configurationparse(xml11configurationjava:848) comsunorgapachexercesinternalparsersxml11configurationparse(xml11configurationjava:777) comsunorgapachexercesinternalparsersxmlparserparse(xmlparserjava:141) comsunorgapachexercesinternalparsersdomparserparse(domparserjava:243) comsunorgapachexercesinternaljaxpdocumentbuilderimplparse(documentbuilderimpljava:347) orgspringframeworkbeansfactoryxmldefaultdocumentloaderloaddocument(defaultdocumentloaderjava:76) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderdoloaddocument(xmlbeandefinitionreaderjava:428) orgspringframeworkbeansfactoryxmlxmlbeandefinitionreaderdoloadbeandefinitions(xmlbeandefinitionreaderjava:390)  36 more and the most similar text Modules redeploy properly node lost sha environment look deployment test view topology test scenario bring 5 container 2 admin cluster using 3 server ensemble create ticktock stream deploy properties kill one servers ensemble observed behavior particular scenario 3 containers affected killing kill pid 2 2 containers come back online even though show containers timeline deployed stream kill server ensemble waiting seconds modules note deployed modules module container id options deployment properties modules module container id options deployment properties modules module container id options deployment properties containers container id host ip address pid groups custom attributes redeploy stream modules module container id options deployment properties containers container id host ip address pid groups custom attributes foo does not exceed the minimum threshold of 75%.;0.02;8.62;1.0;8.33;1;1;0;0
389;As a QA I'd like to include acceptance test coverage for _http-client_ processor module so that I can validate the functionality as part of every CI build.;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a qa i'd like to include acceptance test coverage for _http-client_ processor module so that i can validate the functionality as part of every ci build is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.01;8.62;1.0;8.33;1;1;1;1
390;Upgrade to Spring Batch 3.0.0 M3;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Upgrade to spring batch 300 m3 was most similar to the text Support service pcf and similar to the text Update spring boot 10 ga and similar to the text Create documentation composed modules (and these texts are not user stories).;0.03;4.48;1.0;7.9;1;1;1;1
391;Acceptance test must be able to handle log names with PID suffix Introduced by XD-2006 admin and container logs will have a pid suffix appended to their filename. The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the xd_container_log_dir.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Acceptance test must be able to handle log names with pid suffix introduced by xd-2006 admin and container logs will have a pid suffix appended to their filename the acceptance tests will have to identify the pid for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the xd_container_log_dir was most similar to the text Build scripts refer sub projects unique place based change build scripts refer two different places check list sub projects simplify make available one place maintenance and similar to the text Add property polled sources polled message sources return one message per poll default polling say file directory many files files emitted once per user need configure limit number messages emitted per poll and similar to the text Harmonize common deployer properties applied modules deployers concept customization deployed modules memory cpu disk etc ticket handling properties assumption want set defaults deployment time (and these texts are not user stories).;0.13;2.0;1.0;1.67;0;1;1;1
392;The stream definition is not deleted in redis container when the stream is destroyed This only happened with distributed mode that uses redis as store. The single mode which uses in memory store works fine. Step to reproduce: Create stream: curl -X POST -d name=httptest -d definition=http|log http://localhost:8080/streams redis 127.0.0.1:6379> keys *httptest* 1) modules:httptest 2) streams.httptest 3) stream.definitions.httptest Delete Stream: curl -X DELETE http://localhost:8080/streams/httptest redis 127.0.0.1:6379> keys *httptest* 1) streams.httptest 2) stream.definitions.httptest stream still there not deleted Recreate the stream curl -X POST -d name=httptest -d definition=http|log http://localhost:8080/streams Got: <?xml version=1.0 encoding=UTF-8 standalone=yes?><errors xmlns:ns2=http://www.w3.org/2005/Atom><error logref=StreamAlreadyExistsException><message>There is already a stream with name 'httptest'</message></error>;0;1;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text The stream definition is not deleted in redis container when the stream is destroyed this only happened with distributed mode that uses redis as store the single mode which uses in memory store works fine step to reproduce: create stream: curl -x post -d name=httptest -d definition=http|log http://localhost:8080/streams redis 127001:6379> keys *httptest* 1) modules:httptest 2) streamshttptest 3) streamdefinitionshttptest delete stream: curl -x delete http://localhost:8080/streams/httptest redis 127001:6379> keys *httptest* 1) streamshttptest 2) streamdefinitionshttptest stream still there not deleted recreate the stream curl -x post -d name=httptest -d definition=http|log http://localhost:8080/streams got: <?xml version=10 encoding=utf-8 standalone=yes?><errors xmlns:ns2=http://wwww3org/2005/atom><error logref=streamalreadyexistsexception><message>there is already a stream with name 'httptest'</message></error> and the most similar text User trying access uri get fails forbidden error role view access details another url error does not exceed the minimum threshold of 75%.;0.03;2.0;1.0;1.67;0;0;0;0
393;Research Spark integration options *Spike scope:* * Brainstorm * Identify options * Document;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Research spark integration options *spike scope:* * brainstorm * identify options * document was most similar to the text Hdfs base integration core hdfs writer functionality spring batch and similar to the text Add integration tests job need add integration tests job and similar to the text Ignored consumer ignored consumer downstream modules end listening fewer partitions (and these texts are not user stories).;0.03;4.94;1.0;8.33;1;1;1;1
394;Custom location for modules.yml not working tried local xd-admin/xd-container after setting {code} export XD_MODULE_CONFIG_LOCATION=file:./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/config/ {code} have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module Also not working for me deploying on YARN this used to work at some point not sure how long ago I actually tested this part - M6/M7? The setting used for YARN deployment: {code} -Dxd.module.config.location: file:./ {code};0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Custom location for modulesyml not working tried local xd-admin/xd-container after setting {code} export xd_module_config_location=file:/spring-xd-100build-snapshot-yarn/config/ {code} have my twitter stuff in modulesyml in that directory but not picked up by the twitterstream module also not working for me deploying on yarn this used to work at some point not sure how long ago i actually tested this part - m6/m7? the setting used for yarn deployment: {code} -dxdmoduleconfiglocation: file:/ {code} was most similar to the text Create benchmarking application demonstrate high performance message processing application live repository stream documented run benchmark made easy execute use generate traffic order saturate stream and similar to the text Assess sinks close client cache os - mac deployment type - sha - required software - sample server description destroying 3 streams sink 4th fail error connection number clients 4 exceeded limit 3 allowed default evaluation license steps reproduce shell execute following 4 times stream create name stocks definition http deploy stream destroy stocks and similar to the text Give proper results back lukes original code uses code snippet seem behave strangely stored values seem fine method seems phony test 1 stream create foo definition 2 tap create bar definition 3 curl h gives default bucketing hourly chances empty (and these texts are not user stories).;0.01;2.0;1.0;1.67;0;1;1;1
395;Add more hands on example to MQTT doco Not everyone may be familiar with MQTT or esp. with MQTT inside Rabbit;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add more hands on example to mqtt doco not everyone may be familiar with mqtt or esp with mqtt inside rabbit is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like create tuple use measure tuple based payload performance and similar to the text Developer id like create separate lattice spi bundle spi variants one admin project and similar to the text Developer id like create separate spi bundle spi variants one admin project (and these texts are all user stories with a worth of 3 story points).;0.08;5.39;1.0;8.33;1;0;1;0
396;Update build to use SHDP 2.3.0.RC1;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Update build to use shdp 230rc1 was most similar to the text Ssl connections ignored and similar to the text Features bug fixes named channels and similar to the text Ssl support modules (and these texts are not user stories).;0.03;8.48;1.0;8.33;1;1;1;1
397;As a user I'd like to have the option to use the _SFTP_ source module so that I can access transfer and mange files over any reliable data streams. *Reference:* [Spring Integration SFTP Adapter|http://docs.spring.io/spring-integration/reference/html/sftp.html] Need to consider the infrastructure for testing.;2;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have the option to use the _sftp_ source module so that i can access transfer and mange files over any reliable data streams *reference:* [spring integration sftp adapter|http://docsspringio/spring-integration/reference/html/sftphtml] need to consider the infrastructure for testing was most similar to the text Add additional options file source seems like current file source results initial poc things parameterized polled directory needs useful production might want revisit and similar to the text Move ftp support x package batch package commit support ftp added bunch x classes belong dirt proper though added extension style project jobs module depend and similar to the text Use correct constant based version used keep getting following warning warn spring shell - deprecated instead use switch use value constant based version used (and these texts are not user stories).;0.06;2.0;1.0;1.67;0;1;1;1
398;As a user I'd like to have the configuration option to use an alternative DLQ so I can publish the message this time with additional headers including one that contains the exception (and stack trace).;3;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i'd like to have the configuration option to use an alternative dlq so i can publish the message this time with additional headers including one that contains the exception (and stack trace) is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.07;8.55;1.0;8.33;1;1;1;1
399;Have counters use Double arithmetic instead of Long Now that we have --incrementExpression we often want to increment by some domain specific value that may not be integral (e.g. Watts in smartgrid demo);0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Have counters use double arithmetic instead of long now that we have --incrementexpression we often want to increment by some domain specific value that may not be integral (eg watts in smartgrid demo) is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another and similar to the text Spring user id like use based receptor implementation admin spi based run data pipeline running cf (and these texts are all user stories with a worth of 8 story points).;0.07;7.13;1.0;8.24;1;0;1;0
400;Add ftp sink to default sink modules It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Add ftp sink to default sink modules it would be nice to have a simple ftp sink i had to do it for one of my projects therefore the sink already exists i would like to contribute but i don't know how you do the 'testing' part for that kind of module was most similar to the text Fix sonar build weird annotation dependency problem worked around compile sonar complains one solution add jackson 2 sonar manage and similar to the text Response code http source use case need http source module return instead 200 currently returned may codes useful able return simple additional option module allow configured and similar to the text Shell - handle pagination may broken 2 issues first need define proper ui interaction cli deal pagination course actual implementation (and these texts are not user stories).;0.02;2.09;1.0;1.67;0;1;1;1
401;As a user I want to be able to provide the partitioning logic for a named destination so that I can control the ordering of outbound messages.;1;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a user i want to be able to provide the partitioning logic for a named destination so that i can control the ordering of outbound messages is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like option write file roll sink store events local file system and similar to the text Field engineer id like comparison storm examples spring easy relate implementation standpoint and similar to the text Pm id like smart grid demo ported spring samples (and these texts are all user stories with a worth of 8 story points).;0.04;7.13;1.0;8.24;1;1;1;1
402;UI: The user should provide username/password to gain access to the UI Secure Admin UI to challenge users to enter username and password to gain access.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Ui: the user should provide username/password to gain access to the ui secure admin ui to challenge users to enter username and password to gain access was most similar to the text Create documentation general dsl syntax wiki section included well describes general usage dsl syntax and similar to the text Rename module also supports udp transport option allows udp well tcp and similar to the text Create streams test method execution keep track named streams create use destroy (and these texts are not user stories).;0.09;2.0;1.0;1.67;0;1;1;1
403;Upgrade sink and processor modules to use new conversion service;0;3;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Upgrade sink and processor modules to use new conversion service is a user story, and is worth 3 story points. This was predicted because it is most similar to the text Developer id like upgrade spring 13 release and similar to the text Developer id like review improve performance characteristics and similar to the text Spring user id like create streaming pipelines take advantage latest specs streaming (and these texts are all user stories with a worth of 3 story points).;0.02;6.15;1.0;8.33;1;0;1;0
404;Admin & Launcher startup fails when XD_JMX_ENABLED is set to true When exporting of MBeans are enabled via XD_JMX_ENABLED (also jmxEnabled as in application.yml) the Admin and Lancher server application fail to start. Since the admin applications has the same 'integrationMbeanExporter' bean name for IntegrationMBeanExporter as that its ParentConfiguration there is a naming conflicts and the exception thrown as: (Same is the case for launcher and its parent configuration) Exception in thread main org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mbeanExporter' defined in class org.springframework.context.annotation.MBeanExportConfiguration: Invocation of init method failed nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter' nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553) org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304) org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300) org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195) org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700) org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760) org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482) org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:124) org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609) org.springframework.boot.SpringApplication.run(SpringApplication.java:321) org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130) org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:60) org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:42) Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter' nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610) org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:535) org.springframework.jmx.export.MBeanExporter.afterPropertiesSet(MBeanExporter.java:417) org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612) org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549) ... 15 more Caused by: javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporter com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:513) org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195) org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663) org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:600) ... 19 more;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts.  XUSP could not provide an answer as the amount of similarity between the given text Admin & launcher startup fails when xd_jmx_enabled is set to true when exporting of mbeans are enabled via xd_jmx_enabled (also jmxenabled as in applicationyml) the admin and lancher server application fail to start since the admin applications has the same 'integrationmbeanexporter' bean name for integrationmbeanexporter as that its parentconfiguration there is a naming conflicts and the exception thrown as: (same is the case for launcher and its parent configuration) exception in thread main orgspringframeworkbeansfactorybeancreationexception: error creating bean with name 'mbeanexporter' defined in class orgspringframeworkcontextannotationmbeanexportconfiguration: invocation of init method failed nested exception is orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [orgspringframeworkintegrationmonitorintegrationmbeanexporter@1de40d3e] with key 'integrationmbeanexporter' nested exception is javaxmanagementinstancealreadyexistsexception: orgspringframeworkintegrationmonitor:name=integrationmbeanexportertype=integrationmbeanexporter orgspringframeworkbeansfactorysupportabstractautowirecapablebeanfactoryinitializebean(abstractautowirecapablebeanfactoryjava:1553) orgspringframeworkbeansfactorysupportabstractautowirecapablebeanfactorydocreatebean(abstractautowirecapablebeanfactoryjava:539) orgspringframeworkbeansfactorysupportabstractautowirecapablebeanfactorycreatebean(abstractautowirecapablebeanfactoryjava:475) orgspringframeworkbeansfactorysupportabstractbeanfactory$1getobject(abstractbeanfactoryjava:304) orgspringframeworkbeansfactorysupportdefaultsingletonbeanregistrygetsingleton(defaultsingletonbeanregistryjava:228) orgspringframeworkbeansfactorysupportabstractbeanfactorydogetbean(abstractbeanfactoryjava:300) orgspringframeworkbeansfactorysupportabstractbeanfactorygetbean(abstractbeanfactoryjava:195) orgspringframeworkbeansfactorysupportdefaultlistablebeanfactorypreinstantiatesingletons(defaultlistablebeanfactoryjava:700) orgspringframeworkcontextsupportabstractapplicationcontextfinishbeanfactoryinitialization(abstractapplicationcontextjava:760) orgspringframeworkcontextsupportabstractapplicationcontextrefresh(abstractapplicationcontextjava:482) orgspringframeworkbootcontextembeddedembeddedwebapplicationcontextrefresh(embeddedwebapplicationcontextjava:124) orgspringframeworkbootspringapplicationrefresh(springapplicationjava:609) orgspringframeworkbootspringapplicationrun(springapplicationjava:321) orgspringframeworkbootbuilderspringapplicationbuilderrun(springapplicationbuilderjava:130) orgspringframeworkxddirtserveradminserverapplicationrun(adminserverapplicationjava:60) orgspringframeworkxddirtserveradminserverapplicationmain(adminserverapplicationjava:42) caused by: orgspringframeworkjmxexportunabletoregistermbeanexception: unable to register mbean [orgspringframeworkintegrationmonitorintegrationmbeanexporter@1de40d3e] with key 'integrationmbeanexporter' nested exception is javaxmanagementinstancealreadyexistsexception: orgspringframeworkintegrationmonitor:name=integrationmbeanexportertype=integrationmbeanexporter orgspringframeworkjmxexportmbeanexporterregisterbeannameorinstance(mbeanexporterjava:610) orgspringframeworkjmxexportmbeanexporterregisterbeans(mbeanexporterjava:535) orgspringframeworkjmxexportmbeanexporterafterpropertiesset(mbeanexporterjava:417) orgspringframeworkbeansfactorysupportabstractautowirecapablebeanfactoryinvokeinitmethods(abstractautowirecapablebeanfactoryjava:1612) orgspringframeworkbeansfactorysupportabstractautowirecapablebeanfactoryinitializebean(abstractautowirecapablebeanfactoryjava:1549)  15 more caused by: javaxmanagementinstancealreadyexistsexception: orgspringframeworkintegrationmonitor:name=integrationmbeanexportertype=integrationmbeanexporter comsunjmxmbeanserverrepositoryaddmbean(repositoryjava:437) comsunjmxinterceptordefaultmbeanserverinterceptorregisterwithrepository(defaultmbeanserverinterceptorjava:1898) comsunjmxinterceptordefaultmbeanserverinterceptorregisterdynamicmbean(defaultmbeanserverinterceptorjava:966) comsunjmxinterceptordefaultmbeanserverinterceptorregisterobject(defaultmbeanserverinterceptorjava:900) comsunjmxinterceptordefaultmbeanserverinterceptorregistermbean(defaultmbeanserverinterceptorjava:324) comsunjmxmbeanserverjmxmbeanserverregistermbean(jmxmbeanserverjava:513) orgspringframeworkjmxsupportmbeanregistrationsupportdoregister(mbeanregistrationsupportjava:195) orgspringframeworkjmxexportmbeanexporterregisterbeaninstance(mbeanexporterjava:663) orgspringframeworkjmxexportmbeanexporterregisterbeannameorinstance(mbeanexporterjava:600)  19 more and the most similar text Source displays incorrect information using hdfs sink deploying stream hdfs sink jdbc source displays incorrect information jdbc source issue occurs 1 containers deployed source deployed one container sink deployed another container checked rest endpoints seem show correct information test case say 2 containers source sink deployed container show correct information stream used testing purposes follows - stream create definition jdbc employer employee hdfs deploy attach issue has also reported using source hdfs sink thanks does not exceed the minimum threshold of 75%.;0.03;2.03;1.0;1.67;0;1;0;0
405;As a Spring XD developer I'd like to port {{shell}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.;2;2;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a spring xd developer i'd like to port {{shell}} module from xd to s-c-s repo so i can use it as {{processor}} module to build streaming pipeline is a user story, and is worth 2 story points. This was predicted because it is most similar to the text Spring developer id like port tcp module scs use source module build streaming pipeline and similar to the text Spring developer id like port script module scs use processor module build streaming pipeline and similar to the text Spring developer id like port router module scs use sink module build streaming pipeline (and these texts are all user stories with a worth of 2 story points).;0.13;2.0;1.0;1.67;0;1;1;1
406;StreamDeployer.deleteAll() does not handle dependency tracking create a composed module use it in a stream delete ALL streams. Try to delete the composed module => fails thinking that it's still used by the stream;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Streamdeployerdeleteall() does not handle dependency tracking create a composed module use it in a stream delete all streams try to delete the composed module => fails thinking that it's still used by the stream is a user story, and is worth 8 story points. This was predicted because it is most similar to the text User id like use expressions inline stream definition level operate payload consistently using any custom modules and similar to the text Scd developer id like add support different binder types modules channels plug rabbit kafka source sink read write respectively and similar to the text User want configure docker containers using service discovery tools manage processes services cluster find talk one another (and these texts are all user stories with a worth of 8 story points).;0.03;2.0;1.0;1.67;0;0;1;0
407;Remove support for the leading : on items that have a declared namespace When using jobs taps we no longer need to have the leading :. i.e. :tap:foo. We should only support tap:foo.;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Remove support for the leading : on items that have a declared namespace when using jobs taps we no longer need to have the leading : ie :tap:foo we should only support tap:foo is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Scd developer id like cc spi deployer cf improve overall design performance and similar to the text Field engineer id like comparison spark streaming examples spring easy relate implementation standpoint and similar to the text User id like separate file list deployment manifest properties include part stream definition (and these texts are all user stories with a worth of 8 story points).;0.06;6.15;1.0;8.33;1;0;1;0
408;Issue with pagination in web UI In JOBS tab Quick-filter search box paging functionality is not working as expected. Items stay in the page they were first loaded after filtering. ex. If there were 500 pages of jobs and you are filtering for a job which was in 345. page after the filtering you have to navigate to that page in order to see the job. It needs to be rendered on the first page.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Issue with pagination in web ui in jobs tab quick-filter search box paging functionality is not working as expected items stay in the page they were first loaded after filtering ex if there were 500 pages of jobs and you are filtering for a job which was in 345 page after the filtering you have to navigate to that page in order to see the job it needs to be rendered on the first page was most similar to the text Streamline arg management command line arguments especially default values currently scattered around different places aim regroup common place options classes make sense also happy system properties used vehicle and similar to the text Kafka tests assume offset 0 testing queue partitions content read assumed start offset 0 incorrect topics may exist already especially ci environment and similar to the text Library support changes shell level following merge following changes need happen level module list show libraries library list added show libs module register accept library register added module info accept libs library info added (and these texts are not user stories).;0.04;2.0;1.0;1.67;0;1;1;1
409;As a developer I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits.;1;4;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to upgrade to shdp ga release so that i can sync -up with the latest bits is a user story, and is worth 5 story points. This was predicted because it is most similar to the text Developer want abstraction support multiple binder types future and similar to the text Developer id like revisit existing design identify known limitations gaps and similar to the text Developer id like upgrade reactor 20 release synchronize stable dependencies (and these texts are all user stories with a worth of 5 story points).;0.02;8.62;1.0;8.33;1;1;1;1
410;As a user I'd like to have an option of _AWS_ source module so that I can ingest data from Amazon S3 or use the Simple Email Service (SES). *Reference:* [Spring Integration AWS Extension|https://github.com/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws];4;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text As a user i'd like to have an option of _aws_ source module so that i can ingest data from amazon s3 or use the simple email service (ses) *reference:* [spring integration aws extension|https://githubcom/spring-projects/spring-integration-extensions/tree/master/spring-integration-aws] was most similar to the text Disable collection object conversion provides collection object conversion produce first item target type matches results unfortunate side effect list return tuple misleading case preferable treat error argument tuple and similar to the text Error message memory leak eg error - web application appears started thread named abandoned connection cleanup thread has failed stop likely create memory leak thread name may different and similar to the text Create documentation section best practices include guidance setting rabbit message prefetch concurrency also discuss bypass functionality - reference another section covers probably include scale http sources eg need use load balancer (and these texts are not user stories).;0.05;2.0;1.0;1.67;0;1;1;1
411;Add twitter oauth properties file to config dir Those property keys should then be provided as defaults for the placeholders in source/twittersearch.xml;0;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text Add twitter oauth properties file to config dir those property keys should then be provided as defaults for the placeholders in source/twittersearchxml is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like publish performance benchmarks along infrastructure specifics users use reference setting spring cluster and similar to the text Developer id like setup performance testing infrastructure start benching kafka baselines continue and similar to the text Spring user id like use cluster message create streams batch pipelines (and these texts are all user stories with a worth of 8 story points).;0.11;2.0;1.0;1.67;0;0;1;0
412;As a developer I'd like to add support to _flush_ offsets intelligently so I can reliably process streams based on successful message acknowledgements from the module-producer.;5;5;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The prediction is that the text As a developer i'd like to add support to _flush_ offsets intelligently so i can reliably process streams based on successful message acknowledgements from the module-producer is a user story, and is worth 8 story points. This was predicted because it is most similar to the text Developer id like study state management requirements brainstorm identify design add stateful stream processing support and similar to the text User need ability create docker images ci build build need docker image test deploy image environments and similar to the text Azure user id like data azure event hubs leverage service process analyze large volumes data (and these texts are all user stories with a worth of 8 story points).;0.01;2.0;1.0;1.67;0;1;1;1
413;Display a Rich Gauge;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Display a rich gauge was most similar to the text Update spring platform 101 and similar to the text Test and similar to the text Retrieve information counter (and these texts are not user stories).;0.03;2.24;0.0;1.67;0;1;1;1
414;XD scripts lib path needs to be dynamic We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc. are dynamically updated.;0;0;XUSP is an algorithm that is designed to automatically determine the amount of story points for a given user story. The prediction of the story point value is made using a specific process called xDNN. xDNN classifies texts based on the similarity between it and already learned texts. The text was refused as it is not a user story. This was determined because the text Xd scripts lib path needs to be dynamic we currently have the manually created xd scripts this makes it difficult to maintain as the lib path is error prone with the changes we need to make sure that the properties such as lib path etc are dynamically updated was most similar to the text Use descriptive texts module options defaults need way tell user option determined bindings module info command references read use stream name example and similar to the text Fix crosstalk shell integration tests looks like application used shell integration test class shared test classes well causes issues common tests need avoid scenarios and similar to the text Better printing array default documentation default value array current behavior using produces useless results like also constantly changing results (and these texts are not user stories).;0.08;2.0;1.0;1.67;0;1;1;1
